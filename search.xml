<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker 镜像都失效之后的处理</title>
    <url>/linux/docker-proxy/</url>
    <content><![CDATA[<h1 id="Docker-镜像都失效之后的处理"><a href="#Docker-镜像都失效之后的处理" class="headerlink" title="Docker 镜像都失效之后的处理"></a>Docker 镜像都失效之后的处理</h1><p>在 2024 年，所有的 docker 镜像已经失效了，想要继续进行 <code>docker pull</code> 就需要自建镜像，或者使用代理进行 pull，这里记录一下具体的处理方式。</p>
<h2 id="Docker-system-代理"><a href="#Docker-system-代理" class="headerlink" title="Docker system 代理"></a>Docker system 代理</h2><p><strong>在执行docker pull时，是由守护进程dockerd来执行。因此，代理需要配在dockerd的环境中。而这个环境，则是受systemd所管控，因此实际是systemd的配置。</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> -p /etc/systemd/system/docker.service.d<br>sudo <span class="hljs-built_in">touch</span> /etc/systemd/system/docker.service.d/proxy.conf<br></code></pre></td></tr></table></figure>
<p>在这个proxy.conf文件（可以是任意*.conf的形式）中，添加以下内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[Service]<br>Environment=<span class="hljs-string">&quot;HTTP_PROXY=http://127.0.0.1:10800&quot;</span><br>Environment=<span class="hljs-string">&quot;HTTPS_PROXY=http://127.0.0.1:10800&quot;</span><br>Environment=<span class="hljs-string">&quot;NO_PROXY=localhost,127.0.0.1,.example.com&quot;</span><br></code></pre></td></tr></table></figure>
<p>注意，当使用 k8s 的时候，容器的 <code>http://127.0.0.1:10800</code> 是不可访问的，需要设置为 <code>docker0</code> 的 ip 地址。</p>
<h2 id="Docker-容器内部代理"><a href="#Docker-容器内部代理" class="headerlink" title="Docker 容器内部代理"></a>Docker 容器内部代理</h2><p><strong>在容器运行阶段，如果需要代理上网，则需要配置 ~/.docker/config.json。以下配置，只在Docker 17.07及以上版本生效。</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">&#123;<br> <span class="hljs-string">&quot;proxies&quot;</span>:<br> &#123;<br>   <span class="hljs-string">&quot;default&quot;</span>:<br>   &#123;<br>     <span class="hljs-string">&quot;httpProxy&quot;</span>: <span class="hljs-string">&quot;http://127.0.0.1:10800&quot;</span>,<br>     <span class="hljs-string">&quot;httpsProxy&quot;</span>: <span class="hljs-string">&quot;http://127.0.0.1:10800&quot;</span>,<br>     <span class="hljs-string">&quot;noProxy&quot;</span>: <span class="hljs-string">&quot;localhost,127.0.0.1,.example.com&quot;</span><br>   &#125;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="SSH-端口转发"><a href="#SSH-端口转发" class="headerlink" title="SSH 端口转发"></a>SSH 端口转发</h1><h2 id="本地访问远程端口"><a href="#本地访问远程端口" class="headerlink" title="本地访问远程端口"></a>本地访问远程端口</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -L [LOCAL_IP:]LOCAL_PORT:DESTINATION:DESTINATION_PORT [USER@]SSH_SERVER<br></code></pre></td></tr></table></figure>
<h2 id="远程访问本地的端口"><a href="#远程访问本地的端口" class="headerlink" title="远程访问本地的端口"></a>远程访问本地的端口</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -R [REMOTE:]REMOTE_PORT:DESTINATION:DESTINATION_PORT [USER@]SSH_SERVER<br></code></pre></td></tr></table></figure>
<p>比如要把本机的代理 <code>http://127.0.0.1:10800</code> 端口共享到远程的所有 IP 上的 10801 端口，则是</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -R 0.0.0.0:10801:127.0.0.1:10800 username@ip -p port<br></code></pre></td></tr></table></figure>
<p>注意，默认是无法在远程服务器上监听 <code>0.0.0.0</code> 的，如果想要监听，需要修改 <code>/etc/ssh/sshd_config</code> 中的 <code>GatewayPorts yes</code> 才行。</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>幸福论</title>
    <url>/uncategorized/happiness/</url>
    <content><![CDATA[<h1 id="Async-的一些想法"><a href="#Async-的一些想法" class="headerlink" title="Async 的一些想法"></a>Async 的一些想法</h1><p>文明其精神，野蛮其体魄。</p>
<p>在这篇文章里记录关于幸福的观点和思考。</p>
<p>幸福不是一件容易的事：她很难求之于自身，但要想在别处得到则不可能。——尚福尔</p>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>在这里介绍的内容主要从平常、实用的角度出发，所以保留了与此角度相关的谬误。</p>
<p>一些补充书籍：卡丹奴斯本的《论逆境》。</p>
<p>一般来说，各个时代的智者们，都说过同样的话语，而愚人们——也就是各个时代数不胜数的大多数人——也做着恰恰相反的同一样事情。</p>
<h1 id="一些基本的划分"><a href="#一些基本的划分" class="headerlink" title="一些基本的划分"></a>一些基本的划分</h1><p>亚里士多德把人生能够得到的好处分为三类——外在之物、人的灵魂和人的身体。</p>
<p>在这里，叔本华认为决定凡人命运的根本差别在于三项内容：</p>
<ul>
<li>人的<strong>自身</strong>，最广泛意义上属于人的个性的东西。健康、力量、外貌、气质、道德品格、精神智力、潜在发展。</li>
<li>人所拥有的<strong>身外之物</strong>，财产和其他占有物。</li>
<li>人向其他人所<strong>显示的样子</strong>，人在其他人眼中的样子，亦即人们对他的看法。他人的看法包括：<ul>
<li>名誉</li>
<li>地位</li>
<li>名声</li>
</ul>
</li>
</ul>
<p>其中，最重要的是第一项，也就是<strong>人的自身</strong>，是因为第一项的差别是由大自然决定的，而后两项只是出自人为的划分。</p>
<p>对于一个人的幸福，甚至对于他的整个存在方式，最重要的就是他自身的内在素质，内在素质直接决定了这个人能否得到内心的幸福，因为内心的快乐和痛苦首先是人的感情、意欲和思想的产物。</p>
<p>第二项和第三项属于自身以外的所有事物，他们想要起作用的方式是间接的，通过影响我们的自身感情来实现的。因此，同一样外在的事物和同一样的境遇，对于我们每个人的影响都不尽相同；即使是生活在同一个环境中的每一个人，都生活在不同的世界中。因为与一个人直接相关的是一个人对事物的看法、他的情感和意欲活动。</p>
]]></content>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>Internlm-01-书生·浦语大模型全链路开源体系</title>
    <url>/internlm/internlm-01/</url>
    <content><![CDATA[<h1 id="书生·浦语大模型全链路开源体系"><a href="#书生·浦语大模型全链路开源体系" class="headerlink" title="书生·浦语大模型全链路开源体系"></a>书生·浦语大模型全链路开源体系</h1><h2 id="大模型概述"><a href="#大模型概述" class="headerlink" title="大模型概述"></a>大模型概述</h2><h3 id="大模型成为了热门关键词"><a href="#大模型成为了热门关键词" class="headerlink" title="大模型成为了热门关键词"></a>大模型成为了热门关键词</h3><p>大模型成为发展通用人工智能的重要途经，图中展示了大模型的热度增长和 OpenAI GPT 系列的迭代过程。</p>
<p><img  src="image.png"  ><span class="image-caption">大模型成为热门关键词</span></p>
<h3 id="大模型成为了发展通用人工智能的重要途径"><a href="#大模型成为了发展通用人工智能的重要途径" class="headerlink" title="大模型成为了发展通用人工智能的重要途径"></a>大模型成为了发展通用人工智能的重要途径</h3><p><img  src="image-20240104194412083.png"  ><span class="image-caption">大模型成为了发展通用人工智能的重要途径</span></p>
<h2 id="书生·浦语大模型"><a href="#书生·浦语大模型" class="headerlink" title="书生·浦语大模型"></a>书生·浦语大模型</h2><h3 id="开源历程"><a href="#开源历程" class="headerlink" title="开源历程"></a>开源历程</h3><p><img  src="image-20240104194442165.png"  ><span class="image-caption">书生·浦语的开源历程</span></p>
<p>书生·浦语大模型从 6.7 开始，开源了 InternLM-7B、InternLM-Chat-7B、Lagent、InternLM-20B 等项目。</p>
<h3 id="系列模型"><a href="#系列模型" class="headerlink" title="系列模型"></a>系列模型</h3><p><img  src="image-20240104194623711.png"  ><span class="image-caption">书生·浦语系列模型</span></p>
<h3 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h3><p><img  src="image-20240104194715248.png"  ><span class="image-caption">性能比较</span></p>
<p>可以看出，书生·浦语 20B 模型全面领先相近量级的开源模型，并且达到了和 Llama2-70B 相近的水平。</p>
<h2 id="书生·浦语全链条开源体系"><a href="#书生·浦语全链条开源体系" class="headerlink" title="书生·浦语全链条开源体系"></a>书生·浦语全链条开源体系</h2><h3 id="体系概述"><a href="#体系概述" class="headerlink" title="体系概述"></a>体系概述</h3><p><strong><a href="https://github.com/orgs/InternLM/repositories?type=all">InternLM (github.com)</a></strong></p>
<p><img  src="image-20240104194911061.png"  ><span class="image-caption">体系概述</span></p>
<h3 id="数据开源"><a href="#数据开源" class="headerlink" title="数据开源"></a>数据开源</h3><p><img  src="image-20240104194948553.png"  ><span class="image-caption">数据开源</span></p>
<h3 id="预训练开源"><a href="#预训练开源" class="headerlink" title="预训练开源"></a>预训练开源</h3><p><img  src="image-20240104195041865.png"  ><span class="image-caption">预训练开源</span></p>
<h3 id="微调开源"><a href="#微调开源" class="headerlink" title="微调开源"></a>微调开源</h3><p><strong><a href="https://github.com/InternLM/xtuner">InternLM/xtuner: A toolkit for efficiently fine-tuning LLM (InternLM, Llama, Baichuan, Qwen, ChatGLM) (github.com)</a></strong></p>
<p><img  src="image-20240104195250624.png"  ><span class="image-caption">微调开源</span></p>
<h3 id="评测开源"><a href="#评测开源" class="headerlink" title="评测开源"></a>评测开源</h3><p><strong><a href="https://github.com/open-compass/OpenCompass/">open-compass/opencompass: OpenCompass is an LLM evaluation platform, supporting a wide range of models (LLaMA, LLaMa2, ChatGLM2, ChatGPT, Claude, etc) over 50+ datasets. (github.com)</a></strong></p>
<p><img  src="image-20240104195322676.png"  ><span class="image-caption">评测开源-题目类型</span></p>
<p><img  src="image-20240104195342281.png"  ><span class="image-caption">评测开源-OpenCompass</span></p>
<p><img  src="image-20240104195354357.png"  ><span class="image-caption">OpenCompass 架构</span></p>
<h3 id="部署开源"><a href="#部署开源" class="headerlink" title="部署开源"></a>部署开源</h3><p><strong><a href="https://github.com/InternLM/lmdeploy">InternLM/lmdeploy: LMDeploy is a toolkit for compressing, deploying, and serving LLMs. (github.com)</a></strong></p>
<p><img  src="image-20240104195614821.png"  ><span class="image-caption">部署开源</span></p>
<h3 id="智能体开源"><a href="#智能体开源" class="headerlink" title="智能体开源"></a>智能体开源</h3><p><strong><a href="https://github.com/InternLM/lagent">InternLM/lagent: A lightweight framework for building LLM-based agents (github.com)</a></strong></p>
<p><img  src="image-20240104195658280.png"  ><span class="image-caption">智能体开源</span></p>
<h3 id="智能体工具箱"><a href="#智能体工具箱" class="headerlink" title="智能体工具箱"></a>智能体工具箱</h3><p><strong><a href="https://github.com/InternLM/agentlego">InternLM/agentlego: Enhance LLM agents with versatile tool APIs (github.com)</a></strong></p>
<p><img  src="image-20240104195750076.png"  ><span class="image-caption">智能体工具箱</span></p>
<h2 id="从模型到应用"><a href="#从模型到应用" class="headerlink" title="从模型到应用"></a>从模型到应用</h2><p><img  src="image-20240104194844022.png"  ><span class="image-caption">如何从模型到应用</span></p>
]]></content>
      <categories>
        <category>internlm</category>
      </categories>
  </entry>
  <entry>
    <title>Internlm-02-浦语大模型趣味 Demo</title>
    <url>/internlm/internlm-02/</url>
    <content><![CDATA[<h1 id="浦语大模型趣味-Demo"><a href="#浦语大模型趣味-Demo" class="headerlink" title="浦语大模型趣味 Demo"></a>浦语大模型趣味 Demo</h1><h2 id="大模型及-InternLM-模型简介"><a href="#大模型及-InternLM-模型简介" class="headerlink" title="大模型及 InternLM 模型简介"></a>大模型及 InternLM 模型简介</h2><h3 id="什么是大模型"><a href="#什么是大模型" class="headerlink" title="什么是大模型"></a>什么是大模型</h3><p>大模型是指在机器学习或人工智能领域中具有巨大参数数量和强大计算能力的模型。它们利用海量数据进行训练，拥有数十亿甚至数千亿个参数。大模型的崛起归因于数据量增长、计算能力提升和算法优化等因素。它们在自然语言处理、计算机视觉、语音识别等任务中展现出惊人性能，常采用深度神经网络结构，如Transformer、BERT、GPT等。</p>
<p>这些模型的优势在于能够捕捉和理解数据中更复杂、抽象的特征和关系。通过大规模参数的学习，它们可以提高泛化能力，在未经大量特定领域数据训练的情况下表现优异。然而，它们也面临着挑战，如巨大计算资源需求、高昂训练成本、对大规模数据的依赖和可解释性等问题。因此，在性能、成本和道德等方面需要权衡考量其应用和发展。</p>
<h2 id="InternLM-模型全链条开源"><a href="#InternLM-模型全链条开源" class="headerlink" title="InternLM 模型全链条开源"></a>InternLM 模型全链条开源</h2><p>包括了 InternLM、Lagent、浦语·灵笔等项目，详情可见：<br><a href="https://github.com/InternLM/InternLM">InternLM</a><br><a href="https://enableasync.github.io/internlm/internlm-01/">EnableAsync 的博客</a></p>
<h2 id="InternLM-Chat-7B-智能对话-Demo"><a href="#InternLM-Chat-7B-智能对话-Demo" class="headerlink" title="InternLM-Chat-7B 智能对话 Demo"></a>InternLM-Chat-7B 智能对话 Demo</h2><p>InternLM已经开源了一个70亿参数的基础模型和一个专为实际场景量身定制的聊天模型。该模型具有以下特点：</p>
<ul>
<li>它利用数万亿高质量标记进行训练，建立了强大的知识库。</li>
<li>支持8,000的上下文窗口长度，能够处理更长的输入序列并具备更强的推理能力。</li>
<li>为用户提供了多功能工具集，灵活构建自己的工作流程。</li>
</ul>
<h3 id="demo-代码"><a href="#demo-代码" class="headerlink" title="demo 代码"></a>demo 代码</h3><p>最简单的 <code>cli_demo</code> 代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br><br><br>model_name_or_path = <span class="hljs-string">&quot;/root/model/Shanghai_AI_Laboratory/internlm-chat-7b&quot;</span><br><br>tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=<span class="hljs-literal">True</span>)<br>model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=<span class="hljs-literal">True</span>, torch_dtype=torch.bfloat16, device_map=<span class="hljs-string">&#x27;auto&#x27;</span>)<br>model = model.<span class="hljs-built_in">eval</span>()<br><br>system_prompt = <span class="hljs-string">&quot;&quot;&quot;You are an AI assistant whose name is InternLM (书生·浦语).</span><br><span class="hljs-string">- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span><br><span class="hljs-string">- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>messages = [(system_prompt, <span class="hljs-string">&#x27;&#x27;</span>)]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;=============Welcome to InternLM chatbot, type &#x27;exit&#x27; to exit.=============&quot;</span>)<br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    input_text = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;User  &gt;&gt;&gt; &quot;</span>)<br>    input_text.replace(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-keyword">if</span> input_text == <span class="hljs-string">&quot;exit&quot;</span>:<br>        <span class="hljs-keyword">break</span><br>    response, history = model.chat(tokenizer, input_text, history=messages)<br>    messages.append((input_text, response))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;robot &gt;&gt;&gt; <span class="hljs-subst">&#123;response&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure></p>
<h3 id="运行效果"><a href="#运行效果" class="headerlink" title="运行效果"></a>运行效果</h3><p>运行效果如下图所示：</p>
<p><img  src="story.png"  ><span class="image-caption">InternLM生成小故事</span></p>
<h2 id="Lagent-智能体工具调用-Demo"><a href="#Lagent-智能体工具调用-Demo" class="headerlink" title="Lagent 智能体工具调用 Demo"></a>Lagent 智能体工具调用 Demo</h2><p>Lagent 是一个轻量级、开源的基于大语言模型的智能体（agent）框架，支持用户快速地将一个大语言模型转变为多种类型的智能体，并提供了一些典型工具为大语言模型赋能。通过 Lagent 框架可以更好的发挥 InternLM 的全部性能。</p>
<h3 id="demo-代码-1"><a href="#demo-代码-1" class="headerlink" title="demo 代码"></a>demo 代码</h3><p>教程中提供了一个 web demo 如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> copy<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> streamlit <span class="hljs-keyword">as</span> st<br><span class="hljs-keyword">from</span> streamlit.logger <span class="hljs-keyword">import</span> get_logger<br><br><span class="hljs-keyword">from</span> lagent.actions <span class="hljs-keyword">import</span> ActionExecutor, GoogleSearch, PythonInterpreter<br><span class="hljs-keyword">from</span> lagent.agents.react <span class="hljs-keyword">import</span> ReAct<br><span class="hljs-keyword">from</span> lagent.llms <span class="hljs-keyword">import</span> GPTAPI<br><span class="hljs-keyword">from</span> lagent.llms.huggingface <span class="hljs-keyword">import</span> HFTransformerCasualLM<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SessionState</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Initialize session state variables.&quot;&quot;&quot;</span><br>        st.session_state[<span class="hljs-string">&#x27;assistant&#x27;</span>] = []<br>        st.session_state[<span class="hljs-string">&#x27;user&#x27;</span>] = []<br><br>        <span class="hljs-comment">#action_list = [PythonInterpreter(), GoogleSearch()]</span><br>        action_list = [PythonInterpreter()]<br>        st.session_state[<span class="hljs-string">&#x27;plugin_map&#x27;</span>] = &#123;<br>            action.name: action<br>            <span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> action_list<br>        &#125;<br>        st.session_state[<span class="hljs-string">&#x27;model_map&#x27;</span>] = &#123;&#125;<br>        st.session_state[<span class="hljs-string">&#x27;model_selected&#x27;</span>] = <span class="hljs-literal">None</span><br>        st.session_state[<span class="hljs-string">&#x27;plugin_actions&#x27;</span>] = <span class="hljs-built_in">set</span>()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">clear_state</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Clear the existing session state.&quot;&quot;&quot;</span><br>        st.session_state[<span class="hljs-string">&#x27;assistant&#x27;</span>] = []<br>        st.session_state[<span class="hljs-string">&#x27;user&#x27;</span>] = []<br>        st.session_state[<span class="hljs-string">&#x27;model_selected&#x27;</span>] = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;chatbot&#x27;</span> <span class="hljs-keyword">in</span> st.session_state:<br>            st.session_state[<span class="hljs-string">&#x27;chatbot&#x27;</span>]._session_history = []<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">StreamlitUI</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, session_state: SessionState</span>):<br>        self.init_streamlit()<br>        self.session_state = session_state<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_streamlit</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Initialize Streamlit&#x27;s UI settings.&quot;&quot;&quot;</span><br>        st.set_page_config(<br>            layout=<span class="hljs-string">&#x27;wide&#x27;</span>,<br>            page_title=<span class="hljs-string">&#x27;lagent-web&#x27;</span>,<br>            page_icon=<span class="hljs-string">&#x27;./docs/imgs/lagent_icon.png&#x27;</span>)<br>        <span class="hljs-comment"># st.header(&#x27;:robot_face: :blue[Lagent] Web Demo &#x27;, divider=&#x27;rainbow&#x27;)</span><br>        st.sidebar.title(<span class="hljs-string">&#x27;模型控制&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setup_sidebar</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Setup the sidebar for model and plugin selection.&quot;&quot;&quot;</span><br>        model_name = st.sidebar.selectbox(<br>            <span class="hljs-string">&#x27;模型选择：&#x27;</span>, options=[<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>,<span class="hljs-string">&#x27;internlm&#x27;</span>])<br>        <span class="hljs-keyword">if</span> model_name != st.session_state[<span class="hljs-string">&#x27;model_selected&#x27;</span>]:<br>            model = self.init_model(model_name)<br>            self.session_state.clear_state()<br>            st.session_state[<span class="hljs-string">&#x27;model_selected&#x27;</span>] = model_name<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;chatbot&#x27;</span> <span class="hljs-keyword">in</span> st.session_state:<br>                <span class="hljs-keyword">del</span> st.session_state[<span class="hljs-string">&#x27;chatbot&#x27;</span>]<br>        <span class="hljs-keyword">else</span>:<br>            model = st.session_state[<span class="hljs-string">&#x27;model_map&#x27;</span>][model_name]<br><br>        plugin_name = st.sidebar.multiselect(<br>            <span class="hljs-string">&#x27;插件选择&#x27;</span>,<br>            options=<span class="hljs-built_in">list</span>(st.session_state[<span class="hljs-string">&#x27;plugin_map&#x27;</span>].keys()),<br>            default=[<span class="hljs-built_in">list</span>(st.session_state[<span class="hljs-string">&#x27;plugin_map&#x27;</span>].keys())[<span class="hljs-number">0</span>]],<br>        )<br><br>        plugin_action = [<br>            st.session_state[<span class="hljs-string">&#x27;plugin_map&#x27;</span>][name] <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> plugin_name<br>        ]<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;chatbot&#x27;</span> <span class="hljs-keyword">in</span> st.session_state:<br>            st.session_state[<span class="hljs-string">&#x27;chatbot&#x27;</span>]._action_executor = ActionExecutor(<br>                actions=plugin_action)<br>        <span class="hljs-keyword">if</span> st.sidebar.button(<span class="hljs-string">&#x27;清空对话&#x27;</span>, key=<span class="hljs-string">&#x27;clear&#x27;</span>):<br>            self.session_state.clear_state()<br>        uploaded_file = st.sidebar.file_uploader(<br>            <span class="hljs-string">&#x27;上传文件&#x27;</span>, <span class="hljs-built_in">type</span>=[<span class="hljs-string">&#x27;png&#x27;</span>, <span class="hljs-string">&#x27;jpg&#x27;</span>, <span class="hljs-string">&#x27;jpeg&#x27;</span>, <span class="hljs-string">&#x27;mp4&#x27;</span>, <span class="hljs-string">&#x27;mp3&#x27;</span>, <span class="hljs-string">&#x27;wav&#x27;</span>])<br>        <span class="hljs-keyword">return</span> model_name, model, plugin_action, uploaded_file<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_model</span>(<span class="hljs-params">self, option</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Initialize the model based on the selected option.&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> option <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> st.session_state[<span class="hljs-string">&#x27;model_map&#x27;</span>]:<br>            <span class="hljs-keyword">if</span> option.startswith(<span class="hljs-string">&#x27;gpt&#x27;</span>):<br>                st.session_state[<span class="hljs-string">&#x27;model_map&#x27;</span>][option] = GPTAPI(<br>                    model_type=option)<br>            <span class="hljs-keyword">else</span>:<br>                st.session_state[<span class="hljs-string">&#x27;model_map&#x27;</span>][option] = HFTransformerCasualLM(<br>                    <span class="hljs-string">&#x27;/root/model/Shanghai_AI_Laboratory/internlm-chat-7b&#x27;</span>)<br>        <span class="hljs-keyword">return</span> st.session_state[<span class="hljs-string">&#x27;model_map&#x27;</span>][option]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">initialize_chatbot</span>(<span class="hljs-params">self, model, plugin_action</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Initialize the chatbot with the given model and plugin actions.&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> ReAct(<br>            llm=model, action_executor=ActionExecutor(actions=plugin_action))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">render_user</span>(<span class="hljs-params">self, prompt: <span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-keyword">with</span> st.chat_message(<span class="hljs-string">&#x27;user&#x27;</span>):<br>            st.markdown(prompt)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">render_assistant</span>(<span class="hljs-params">self, agent_return</span>):<br>        <span class="hljs-keyword">with</span> st.chat_message(<span class="hljs-string">&#x27;assistant&#x27;</span>):<br>            <span class="hljs-keyword">for</span> action <span class="hljs-keyword">in</span> agent_return.actions:<br>                <span class="hljs-keyword">if</span> (action):<br>                    self.render_action(action)<br>            st.markdown(agent_return.response)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">render_action</span>(<span class="hljs-params">self, action</span>):<br>        <span class="hljs-keyword">with</span> st.expander(action.<span class="hljs-built_in">type</span>, expanded=<span class="hljs-literal">True</span>):<br>            st.markdown(<br>                <span class="hljs-string">&quot;&lt;p style=&#x27;text-align: left;display:flex;&#x27;&gt; &lt;span style=&#x27;font-size:14px;font-weight:600;width:70px;text-align-last: justify;&#x27;&gt;插    件&lt;/span&gt;&lt;span style=&#x27;width:14px;text-align:left;display:block;&#x27;&gt;:&lt;/span&gt;&lt;span style=&#x27;flex:1;&#x27;&gt;&quot;</span>  <span class="hljs-comment"># noqa E501</span><br>                + action.<span class="hljs-built_in">type</span> + <span class="hljs-string">&#x27;&lt;/span&gt;&lt;/p&gt;&#x27;</span>,<br>                unsafe_allow_html=<span class="hljs-literal">True</span>)<br>            st.markdown(<br>                <span class="hljs-string">&quot;&lt;p style=&#x27;text-align: left;display:flex;&#x27;&gt; &lt;span style=&#x27;font-size:14px;font-weight:600;width:70px;text-align-last: justify;&#x27;&gt;思考步骤&lt;/span&gt;&lt;span style=&#x27;width:14px;text-align:left;display:block;&#x27;&gt;:&lt;/span&gt;&lt;span style=&#x27;flex:1;&#x27;&gt;&quot;</span>  <span class="hljs-comment"># noqa E501</span><br>                + action.thought + <span class="hljs-string">&#x27;&lt;/span&gt;&lt;/p&gt;&#x27;</span>,<br>                unsafe_allow_html=<span class="hljs-literal">True</span>)<br>            <span class="hljs-keyword">if</span> (<span class="hljs-built_in">isinstance</span>(action.args, <span class="hljs-built_in">dict</span>) <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;text&#x27;</span> <span class="hljs-keyword">in</span> action.args):<br>                st.markdown(<br>                    <span class="hljs-string">&quot;&lt;p style=&#x27;text-align: left;display:flex;&#x27;&gt;&lt;span style=&#x27;font-size:14px;font-weight:600;width:70px;text-align-last: justify;&#x27;&gt; 执行内容&lt;/span&gt;&lt;span style=&#x27;width:14px;text-align:left;display:block;&#x27;&gt;:&lt;/span&gt;&lt;/p&gt;&quot;</span>,  <span class="hljs-comment"># noqa E501</span><br>                    unsafe_allow_html=<span class="hljs-literal">True</span>)<br>                st.markdown(action.args[<span class="hljs-string">&#x27;text&#x27;</span>])<br>            self.render_action_results(action)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">render_action_results</span>(<span class="hljs-params">self, action</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Render the results of action, including text, images, videos, and</span><br><span class="hljs-string">        audios.&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">isinstance</span>(action.result, <span class="hljs-built_in">dict</span>)):<br>            st.markdown(<br>                <span class="hljs-string">&quot;&lt;p style=&#x27;text-align: left;display:flex;&#x27;&gt;&lt;span style=&#x27;font-size:14px;font-weight:600;width:70px;text-align-last: justify;&#x27;&gt; 执行结果&lt;/span&gt;&lt;span style=&#x27;width:14px;text-align:left;display:block;&#x27;&gt;:&lt;/span&gt;&lt;/p&gt;&quot;</span>,  <span class="hljs-comment"># noqa E501</span><br>                unsafe_allow_html=<span class="hljs-literal">True</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;text&#x27;</span> <span class="hljs-keyword">in</span> action.result:<br>                st.markdown(<br>                    <span class="hljs-string">&quot;&lt;p style=&#x27;text-align: left;&#x27;&gt;&quot;</span> + action.result[<span class="hljs-string">&#x27;text&#x27;</span>] +<br>                    <span class="hljs-string">&#x27;&lt;/p&gt;&#x27;</span>,<br>                    unsafe_allow_html=<span class="hljs-literal">True</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;image&#x27;</span> <span class="hljs-keyword">in</span> action.result:<br>                image_path = action.result[<span class="hljs-string">&#x27;image&#x27;</span>]<br>                image_data = <span class="hljs-built_in">open</span>(image_path, <span class="hljs-string">&#x27;rb&#x27;</span>).read()<br>                st.image(image_data, caption=<span class="hljs-string">&#x27;Generated Image&#x27;</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;video&#x27;</span> <span class="hljs-keyword">in</span> action.result:<br>                video_data = action.result[<span class="hljs-string">&#x27;video&#x27;</span>]<br>                video_data = <span class="hljs-built_in">open</span>(video_data, <span class="hljs-string">&#x27;rb&#x27;</span>).read()<br>                st.video(video_data)<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;audio&#x27;</span> <span class="hljs-keyword">in</span> action.result:<br>                audio_data = action.result[<span class="hljs-string">&#x27;audio&#x27;</span>]<br>                audio_data = <span class="hljs-built_in">open</span>(audio_data, <span class="hljs-string">&#x27;rb&#x27;</span>).read()<br>                st.audio(audio_data)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    logger = get_logger(__name__)<br>    <span class="hljs-comment"># Initialize Streamlit UI and setup sidebar</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;ui&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> st.session_state:<br>        session_state = SessionState()<br>        session_state.init_state()<br>        st.session_state[<span class="hljs-string">&#x27;ui&#x27;</span>] = StreamlitUI(session_state)<br><br>    <span class="hljs-keyword">else</span>:<br>        st.set_page_config(<br>            layout=<span class="hljs-string">&#x27;wide&#x27;</span>,<br>            page_title=<span class="hljs-string">&#x27;lagent-web&#x27;</span>,<br>            page_icon=<span class="hljs-string">&#x27;./docs/imgs/lagent_icon.png&#x27;</span>)<br>        <span class="hljs-comment"># st.header(&#x27;:robot_face: :blue[Lagent] Web Demo &#x27;, divider=&#x27;rainbow&#x27;)</span><br>    model_name, model, plugin_action, uploaded_file = st.session_state[<br>        <span class="hljs-string">&#x27;ui&#x27;</span>].setup_sidebar()<br><br>    <span class="hljs-comment"># Initialize chatbot if it is not already initialized</span><br>    <span class="hljs-comment"># or if the model has changed</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;chatbot&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> st.session_state <span class="hljs-keyword">or</span> model != st.session_state[<br>            <span class="hljs-string">&#x27;chatbot&#x27;</span>]._llm:<br>        st.session_state[<span class="hljs-string">&#x27;chatbot&#x27;</span>] = st.session_state[<br>            <span class="hljs-string">&#x27;ui&#x27;</span>].initialize_chatbot(model, plugin_action)<br><br>    <span class="hljs-keyword">for</span> prompt, agent_return <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(st.session_state[<span class="hljs-string">&#x27;user&#x27;</span>],<br>                                    st.session_state[<span class="hljs-string">&#x27;assistant&#x27;</span>]):<br>        st.session_state[<span class="hljs-string">&#x27;ui&#x27;</span>].render_user(prompt)<br>        st.session_state[<span class="hljs-string">&#x27;ui&#x27;</span>].render_assistant(agent_return)<br>    <span class="hljs-comment"># User input form at the bottom (this part will be at the bottom)</span><br>    <span class="hljs-comment"># with st.form(key=&#x27;my_form&#x27;, clear_on_submit=True):</span><br><br>    <span class="hljs-keyword">if</span> user_input := st.chat_input(<span class="hljs-string">&#x27;&#x27;</span>):<br>        st.session_state[<span class="hljs-string">&#x27;ui&#x27;</span>].render_user(user_input)<br>        st.session_state[<span class="hljs-string">&#x27;user&#x27;</span>].append(user_input)<br>        <span class="hljs-comment"># Add file uploader to sidebar</span><br>        <span class="hljs-keyword">if</span> uploaded_file:<br>            file_bytes = uploaded_file.read()<br>            file_type = uploaded_file.<span class="hljs-built_in">type</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;image&#x27;</span> <span class="hljs-keyword">in</span> file_type:<br>                st.image(file_bytes, caption=<span class="hljs-string">&#x27;Uploaded Image&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;video&#x27;</span> <span class="hljs-keyword">in</span> file_type:<br>                st.video(file_bytes, caption=<span class="hljs-string">&#x27;Uploaded Video&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;audio&#x27;</span> <span class="hljs-keyword">in</span> file_type:<br>                st.audio(file_bytes, caption=<span class="hljs-string">&#x27;Uploaded Audio&#x27;</span>)<br>            <span class="hljs-comment"># Save the file to a temporary location and get the path</span><br>            file_path = os.path.join(root_dir, uploaded_file.name)<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> tmpfile:<br>                tmpfile.write(file_bytes)<br>            st.write(<span class="hljs-string">f&#x27;File saved at: <span class="hljs-subst">&#123;file_path&#125;</span>&#x27;</span>)<br>            user_input = <span class="hljs-string">&#x27;我上传了一个图像，路径为: &#123;file_path&#125;. &#123;user_input&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                file_path=file_path, user_input=user_input)<br>        agent_return = st.session_state[<span class="hljs-string">&#x27;chatbot&#x27;</span>].chat(user_input)<br>        st.session_state[<span class="hljs-string">&#x27;assistant&#x27;</span>].append(copy.deepcopy(agent_return))<br>        logger.info(agent_return.inner_steps)<br>        st.session_state[<span class="hljs-string">&#x27;ui&#x27;</span>].render_assistant(agent_return)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))<br>    root_dir = os.path.join(root_dir, <span class="hljs-string">&#x27;tmp_dir&#x27;</span>)<br>    os.makedirs(root_dir, exist_ok=<span class="hljs-literal">True</span>)<br>    main()<br><br></code></pre></td></tr></table></figure></p>
<h3 id="demo-运行方式"><a href="#demo-运行方式" class="headerlink" title="demo 运行方式"></a>demo 运行方式</h3><p>demo 运行方式如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">streamlit run /root/code/lagent/examples/react_web_demo.py --server.address 127.0.0.1 --server.port 6006<br></code></pre></td></tr></table></figure>
<h3 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h3><p><img  src="lagent-1.png"  ><span class="image-caption">Lagent效果展示1</span></p>
<p><img  src="lagent-2.png"  ><span class="image-caption">Lagent效果展示2</span></p>
<p><img  src="lagent-3.png"  ><span class="image-caption">Lagent效果展示3</span></p>
<p><img  src="lagent-4.png"  ><span class="image-caption">Lagent效果展示4</span></p>
<p>可以看到，lagent能够通过 python 代码解决一些数学问题，而对于很困难的数学问题，解决起来会出现一些问题。</p>
<h2 id="浦语·灵笔图文理解创作-Demo"><a href="#浦语·灵笔图文理解创作-Demo" class="headerlink" title="浦语·灵笔图文理解创作 Demo"></a>浦语·灵笔图文理解创作 Demo</h2><p><strong>浦语·灵笔</strong>是基于<a href="https://github.com/InternLM/InternLM/tree/main">书生·浦语</a>大语言模型研发的视觉-语言大模型，提供出色的图文理解和创作能力，具有多项优势：</p>
<ul>
<li><p><strong>图文交错创作</strong>: 浦语·灵笔可以为用户打造图文并貌的专属文章。生成的文章文采斐然，图文相得益彰，提供沉浸式的阅读体验。这一能力由以下步骤实现：</p>
<ol>
<li><strong>理解用户指令，创作符合要求的长文章</strong>。</li>
<li><strong>智能分析文章，自动规划插图的理想位置，确定图像内容需求。</strong></li>
<li><strong>多层次智能筛选，从图库中锁定最完美的图片。</strong></li>
</ol>
</li>
<li><p><strong>基于丰富多模态知识的图文理解</strong>: 浦语·灵笔设计了高效的训练策略，为模型注入海量的多模态概念和知识数据，赋予其强大的图文理解和对话能力。</p>
</li>
<li><strong>杰出性能</strong>: 浦语·灵笔在多项视觉语言大模型的主流评测上均取得了最佳性能，包括<a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation">MME Benchmark</a> (英文评测), <a href="https://opencompass.org.cn/leaderboard-multimodal">MMBench</a> (英文评测), <a href="https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard">Seed-Bench</a> (英文评测), <a href="https://opencompass.org.cn/leaderboard-multimodal">CCBench</a>(中文评测), <a href="https://opencompass.org.cn/leaderboard-multimodal">MMBench-CN</a> (中文评测)。<h3 id="demo-代码-2"><a href="#demo-代码-2" class="headerlink" title="demo 代码"></a>demo 代码</h3></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root/code<br>git <span class="hljs-built_in">clone</span> https://gitee.com/internlm/InternLM-XComposer.git<br><span class="hljs-built_in">cd</span> /root/code/InternLM-XComposer<br>git checkout 3e8c79051a1356b9c388a6447867355c0634932d  <span class="hljs-comment"># 最好保证和教程的 commit 版本一致</span><br></code></pre></td></tr></table></figure>
<h3 id="demo-运行方式-1"><a href="#demo-运行方式-1" class="headerlink" title="demo 运行方式"></a>demo 运行方式</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root/code/InternLM-XComposer<br>python examples/web_demo.py  \<br>    --folder /root/model/Shanghai_AI_Laboratory/internlm-xcomposer-7b \<br>    --num_gpus 1 \<br>    --port 6006<br></code></pre></td></tr></table></figure>
<h3 id="效果展示-1"><a href="#效果展示-1" class="headerlink" title="效果展示"></a>效果展示</h3><p><img  src="灵笔-1.png"  ><span class="image-caption">浦语·灵笔效果展示1</span></p>
<p><img  src="灵笔-2.png"  ><span class="image-caption">浦语·灵笔效果展示2</span></p>
<p><img  src="灵笔-3.png"  ><span class="image-caption">浦语·灵笔效果展示3</span></p>
<h2 id="huggingface-hub-下载文件"><a href="#huggingface-hub-下载文件" class="headerlink" title="huggingface_hub 下载文件"></a>huggingface_hub 下载文件</h2><p><img  src="huggingface_hub_download.png"  ><span class="image-caption">使用 huggingface_hub 库下载文件</span></p>
]]></content>
      <categories>
        <category>internlm</category>
      </categories>
  </entry>
  <entry>
    <title>Kind 的一些使用心得</title>
    <url>/uncategorized/kind/</url>
    <content><![CDATA[<h1 id="Kind-的一些使用心得"><a href="#Kind-的一些使用心得" class="headerlink" title="Kind 的一些使用心得"></a>Kind 的一些使用心得</h1><p>因为 Kind 启动相比于 Minikube 更快，而且支持多 Node，所以现在换成了 Kind，这里记录一些 Kind 的使用心得。</p>
<h2 id="1-Kind-安装"><a href="#1-Kind-安装" class="headerlink" title="1. Kind 安装"></a>1. Kind 安装</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64<br><span class="hljs-built_in">chmod</span> +x ./kind<br><span class="hljs-built_in">mv</span> ./kind /usr/bin/kind<br></code></pre></td></tr></table></figure>
<h2 id="2-使用-Kind-创建含有两个-Node-的-kubernetes-集群"><a href="#2-使用-Kind-创建含有两个-Node-的-kubernetes-集群" class="headerlink" title="2. 使用 Kind 创建含有两个 Node 的 kubernetes 集群"></a>2. 使用 Kind 创建含有两个 Node 的 kubernetes 集群</h2><h3 id="1-创建配置文件"><a href="#1-创建配置文件" class="headerlink" title="1. 创建配置文件"></a>1. 创建配置文件</h3><p>这里我创建了两个 Node，使用以下配置文件，并将其命名为 <code>kind.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># a cluster with 1 control-plane nodes and 2 workers</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Cluster</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kind.x-k8s.io/v1alpha4</span><br><span class="hljs-attr">nodes:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">control-plane</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br></code></pre></td></tr></table></figure>
<h3 id="2-创建集群"><a href="#2-创建集群" class="headerlink" title="2. 创建集群"></a>2. 创建集群</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 旧版</span><br>sudo kind create cluster --config kind.yaml<br><span class="hljs-comment"># 新版</span><br>kind create cluster --name higress --config=cluster.conf<br></code></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># cluster.conf</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Cluster</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kind.x-k8s.io/v1alpha4</span><br><span class="hljs-comment"># networking:</span><br>  <span class="hljs-comment"># WARNING: It is _strongly_ recommended that you keep this the default</span><br>  <span class="hljs-comment"># (127.0.0.1) for security reasons. However it is possible to change this.</span><br>  <span class="hljs-comment"># apiServerAddress: &quot;0.0.0.0&quot;</span><br>  <span class="hljs-comment"># By default the API server listens on a random open port.</span><br>  <span class="hljs-comment"># You may choose a specific port but probably don&#x27;t need to in most cases.</span><br>  <span class="hljs-comment"># Using a random port makes it easier to spin up multiple clusters.</span><br>  <span class="hljs-comment"># apiServerPort: 6443</span><br><span class="hljs-attr">networking:</span><br>  <span class="hljs-attr">serviceSubnet:</span> <span class="hljs-string">&quot;10.96.0.0/12&quot;</span><br><span class="hljs-attr">nodes:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">control-plane</span><br>  <span class="hljs-attr">kubeadmConfigPatches:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">|</span><br><span class="hljs-string">    kind: InitConfiguration</span><br><span class="hljs-string">    nodeRegistration:</span><br><span class="hljs-string">      kubeletExtraArgs:</span><br><span class="hljs-string">        node-labels: &quot;ingress-ready=true&quot;</span><br><span class="hljs-string"></span>  <span class="hljs-attr">extraPortMappings:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>    <span class="hljs-attr">hostPort:</span> <span class="hljs-number">80</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">443</span><br>    <span class="hljs-attr">hostPort:</span> <span class="hljs-number">443</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">role:</span> <span class="hljs-string">worker</span><br></code></pre></td></tr></table></figure>
<p>这里需要注意的点有：</p>
<ol>
<li>不要设置集群 name，在我本地，如果设置了 name 会导致 kubeconfig 无法导出。（现在已修复，可以设置）</li>
<li>要使用 sudo，在我本地，如果不使用 sudo 会导致无法创建集群，原因未知。（因为 docker 需要 sudo，配置 docker 不用 sudo 之后就可以了）</li>
<li>这里 build image 的时候，会把当前的 proxy 配置也记住，所以如果要修改 proxy 配置，要重新 build image。</li>
<li>在 create 的时候可能会因为代理导致 create 失败，需要在 <code>~/.docker/config.json</code> 设置 no_proxy，如下所示：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">&#123;<br> <span class="hljs-string">&quot;proxies&quot;</span>:<br> &#123;<br>   <span class="hljs-string">&quot;default&quot;</span>:<br>   &#123;<br>     <span class="hljs-string">&quot;httpProxy&quot;</span>: <span class="hljs-string">&quot;http://172.17.0.1:10800&quot;</span>,<br>     <span class="hljs-string">&quot;httpsProxy&quot;</span>: <span class="hljs-string">&quot;http://172.17.0.1:10800&quot;</span>,<br>     <span class="hljs-string">&quot;noProxy&quot;</span>: <span class="hljs-string">&quot;localhost,127.0.0.1,10.96.0.0/12,172.18.0.0/28,172.18.0.3,::1,higress-control-plane&quot;</span><br>   &#125;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>其中最重要的是 <code>higress-control-plan</code>，不过为了防止无法访问 ClusterIP，我也配置了 <code>10.96.0.0/12</code> 和 Docker 网段 <code>172.18.0.0/28</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Creating cluster <span class="hljs-string">&quot;kind&quot;</span> ...<br> ✓ Ensuring node image (kindest/node:v1.21.1) 🖼<br> ✓ Preparing nodes 📦 📦 📦  <br> ✓ Writing configuration 📜 <br> ✓ Starting control-plane 🕹️ <br> ✓ Installing CNI 🔌 <br> ✓ Installing StorageClass 💾 <br> ✓ Joining worker nodes 🚜 <br>Set kubectl context to <span class="hljs-string">&quot;kind-kind&quot;</span><br>You can now use your cluster with:<br><br>kubectl cluster-info --context kind-kind<br></code></pre></td></tr></table></figure>
<p>如果出现以上信息表示创建成功，可以进行下一步。</p>
<h3 id="3-导出-kubeconfig"><a href="#3-导出-kubeconfig" class="headerlink" title="3. 导出 kubeconfig"></a>3. 导出 kubeconfig</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">kind export kubeconfig<br></code></pre></td></tr></table></figure>
<p>如果不使用这一步，会导致使用 <code>kubectl</code> 的时候必须加上 <code>sudo</code>，否则无法连接到 kubernetes。</p>
<h2 id="3-安装-kubernetes-dashboard"><a href="#3-安装-kubernetes-dashboard" class="headerlink" title="3. 安装 kubernetes-dashboard"></a>3. 安装 kubernetes-dashboard</h2><h3 id="1-使用-helm-安装-dashboard"><a href="#1-使用-helm-安装-dashboard" class="headerlink" title="1. 使用 helm 安装 dashboard"></a>1. 使用 helm 安装 dashboard</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Add kubernetes-dashboard repository</span><br>helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/<br>helm repo update<br><span class="hljs-comment"># Deploy a Helm Release named &quot;dashboard&quot; using the kubernetes-dashboard chart</span><br>helm install dashboard kubernetes-dashboard/kubernetes-dashboard<br></code></pre></td></tr></table></figure>
<h3 id="2-转发-dashboard-pod"><a href="#2-转发-dashboard-pod" class="headerlink" title="2. 转发 dashboard pod"></a>2. 转发 dashboard pod</h3><p>这一步的目的是在本地访问部署了 dashboard 的 pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> POD_NAME=$(kubectl get pods -n default -l <span class="hljs-string">&quot;app.kubernetes.io/name=kubernetes-dashboard,app.kubernetes.io/instance=dashboard&quot;</span> -o jsonpath=<span class="hljs-string">&quot;&#123;.items[0].metadata.name&#125;&quot;</span>)<br>  <span class="hljs-built_in">echo</span> https://127.0.0.1:8443/<br>  kubectl -n default port-forward <span class="hljs-variable">$POD_NAME</span> 8443:8443<br></code></pre></td></tr></table></figure>
<p>之后会提示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Forwarding from 127.0.0.1:8443 -&gt; 8443<br>Forwarding from [::1]:8443 -&gt; 8443<br></code></pre></td></tr></table></figure>
<p>说明转发成功，此时访问 <a href="https://127.0.0.1:8443/">https://127.0.0.1:8443/</a> ，注意是 https</p>
<h3 id="2-1-或者可以不转发使用-service-暴露服务"><a href="#2-1-或者可以不转发使用-service-暴露服务" class="headerlink" title="2.1 或者可以不转发使用 service 暴露服务"></a>2.1 或者可以不转发使用 service 暴露服务</h3><p>这里为了测试使用了 NodePort 方式暴露</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">kubectl expose deploy dashboard-kubernetes-dashboard --name dashboard-nodeport --port 8443 --target-port=8443 --<span class="hljs-built_in">type</span>=NodePort<br></code></pre></td></tr></table></figure>
<h3 id="2-2-新版的-dashboard-的转发"><a href="#2-2-新版的-dashboard-的转发" class="headerlink" title="2.2 新版的 dashboard 的转发"></a>2.2 新版的 dashboard 的转发</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443<br></code></pre></td></tr></table></figure>
<p>当用户在安装了 kind 的电脑上访问 pods 中的服务时，是这样的</p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><code class="hljs livescript">user -&gt; docker proxy<span class="hljs-function"><span class="hljs-params">(docker 监听的端口)</span> -&gt;</span> services<span class="hljs-function"><span class="hljs-params">(nodeport 等)</span> -&gt;</span> pod<br></code></pre></td></tr></table></figure>
<p>当用 kubectl 开启了转发时，访问的网络是</p>
<figure class="highlight xl"><table><tr><td class="code"><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">user</span> -&gt;</span> <span class="hljs-function"><span class="hljs-title">kubectl</span> port-forward -&gt;</span> pod<br></code></pre></td></tr></table></figure>
<p>在 kind 中，worker 的 ClusterIP 可以用 <code>docker inspect</code> 查看。</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><code class="hljs pgsql">➜  git:(master) ✗ k -n kubesphere-<span class="hljs-keyword">system</span> <span class="hljs-keyword">get</span> svc ks-console<br><span class="hljs-type">NAME</span>         <span class="hljs-keyword">TYPE</span>       <span class="hljs-keyword">CLUSTER</span>-IP      <span class="hljs-keyword">EXTERNAL</span>-IP   PORT(S)        AGE<br>ks-console   NodePort   <span class="hljs-number">10.99</span><span class="hljs-number">.226</span><span class="hljs-number">.191</span>   &lt;<span class="hljs-keyword">none</span>&gt;        <span class="hljs-number">80</span>:<span class="hljs-number">30880</span>/TCP   <span class="hljs-number">21</span>h<br><br>➜  git:(master) ✗ docker ps | grep kind<br>c46d6ca06e9f        kindest/node:v1<span class="hljs-number">.19</span><span class="hljs-number">.1</span>              &quot;/usr/local/bin/entr…&quot;   <span class="hljs-number">28</span> hours ago        Up <span class="hljs-number">28</span> hours         <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">53079</span>-&gt;<span class="hljs-number">6443</span>/tcp   kind-control-plane<br><br>➜  git:(master) ✗ docker inspect c46d6ca06e9f | grep -i ipadd<br>            &quot;SecondaryIPAddresses&quot;: <span class="hljs-keyword">null</span>,<br>            &quot;IPAddress&quot;: &quot;&quot;,<br>                    &quot;IPAddress&quot;: &quot;172.20.0.2&quot;,<br><br>➜  git:(master) ✗ curl -I <span class="hljs-number">172.20</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>:<span class="hljs-number">30880</span><br>HTTP/<span class="hljs-number">1.1</span> <span class="hljs-number">302</span> <span class="hljs-built_in">Found</span><br>Vary: Accept-<span class="hljs-keyword">Encoding</span><br><span class="hljs-keyword">Location</span>: /<span class="hljs-keyword">login</span><br>Content-<span class="hljs-keyword">Type</span>: <span class="hljs-type">text</span>/html; charset=utf<span class="hljs-number">-8</span><br>Content-Length: <span class="hljs-number">43</span><br><span class="hljs-type">Date</span>: Fri, <span class="hljs-number">19</span> Mar <span class="hljs-number">2021</span> <span class="hljs-number">07</span>:<span class="hljs-number">56</span>:<span class="hljs-number">34</span> GMT<br><span class="hljs-keyword">Connection</span>: keep-alive<br>Keep-Alive: timeout=<span class="hljs-number">5</span><br></code></pre></td></tr></table></figure>
<h3 id="3-生成-token"><a href="#3-生成-token" class="headerlink" title="3. 生成 token"></a>3. 生成 token</h3><p>不出意外 dashboard 需要 token 来登录，使用以下步骤来生成 token：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">kubectl create serviceaccount dashboard -n default<br>kubectl create rolebinding def-ns-admin --clusterrole=admin --serviceaccount=default:def-ns-admin<br>kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=default:dashboard<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">kubectl describe sa dashboard<br>Name:                dashboard<br>Namespace:           default<br>Labels:              &lt;none&gt;<br>Annotations:         &lt;none&gt;<br>Image pull secrets:  &lt;none&gt;<br>Mountable secrets:   dashboard-token-vzzjn<br>Tokens:              dashboard-token-vzzjn<br>Events:              &lt;none&gt;<br></code></pre></td></tr></table></figure>
<p>这里可以看到 <code>dashboard-token-vzzjn</code> 就是我们需要的 token，使用以下命令显示具体内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">kubectl describe secret dashboard-token-vzzjn<br></code></pre></td></tr></table></figure>
<p>之后就可以将具体的 token 粘贴在 dashboard 中登录。</p>
<h3 id="3-1-新版的生成"><a href="#3-1-新版的生成" class="headerlink" title="3.1 新版的生成"></a>3.1 新版的生成</h3><p><a href="https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md">https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md</a></p>
<h2 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h2><h3 id="配置-docker-不用-sudo"><a href="#配置-docker-不用-sudo" class="headerlink" title="配置 docker 不用 sudo"></a>配置 docker 不用 sudo</h3><p>创建名为docker的组，如果之前已经有该组就会报错，可以忽略这个错误。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo groupadd docker<br></code></pre></td></tr></table></figure>
<p>将当前用户加入组docker</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo gpasswd -a <span class="hljs-variable">$&#123;USER&#125;</span> docker<br></code></pre></td></tr></table></figure>
<p>重启docker服务（生产环境请慎用）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo systemctl restart docker<br></code></pre></td></tr></table></figure>
<p>添加访问和执行权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">chmod</span> a+rw /var/run/docker.sock<br></code></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>k8s, kind</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 多用户管理</title>
    <url>/uncategorized/linux-user/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><h4 id="1-1-什么是Linux用户管理？"><a href="#1-1-什么是Linux用户管理？" class="headerlink" title="1.1 什么是Linux用户管理？"></a>1.1 什么是Linux用户管理？</h4><p>Linux用户管理是指在Linux系统中管理用户账户的过程，包括创建、删除和设置用户属性等操作。</p>
<h4 id="1-2-为什么Linux用户管理重要？"><a href="#1-2-为什么Linux用户管理重要？" class="headerlink" title="1.2 为什么Linux用户管理重要？"></a>1.2 为什么Linux用户管理重要？</h4><p>Linux用户管理对于系统安全和资源管理非常重要。良好的用户管理可以确保只有授权的用户能够访问系统，并且可以限制其权限，减少潜在的风险和安全漏洞。</p>
<h3 id="2-用户账户创建和删除"><a href="#2-用户账户创建和删除" class="headerlink" title="2. 用户账户创建和删除"></a>2. 用户账户创建和删除</h3><h4 id="2-0-创建用户文件夹"><a href="#2-0-创建用户文件夹" class="headerlink" title="2.0 创建用户文件夹"></a>2.0 创建用户文件夹</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> john<br></code></pre></td></tr></table></figure>
<h4 id="2-1-创建用户账户"><a href="#2-1-创建用户账户" class="headerlink" title="2.1 创建用户账户"></a>2.1 创建用户账户</h4><p>在Linux中，可以使用<code>useradd</code>命令创建用户账户。例如，要创建名为”john”的用户账户，可以运行以下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">useradd john</span><br></code></pre></td></tr></table></figure>
<h4 id="2-2-删除用户账户"><a href="#2-2-删除用户账户" class="headerlink" title="2.2 删除用户账户"></a>2.2 删除用户账户</h4><p>要删除用户账户，可以使用<code>userdel</code>命令。例如，要删除名为”john”的用户账户，可以运行以下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">userdel john</span><br></code></pre></td></tr></table></figure>
<h4 id="2-3-设置用户账户的属性"><a href="#2-3-设置用户账户的属性" class="headerlink" title="2.3 设置用户账户的属性"></a>2.3 设置用户账户的属性</h4><p>可以使用<code>usermod</code>命令来设置用户账户的属性，如用户主目录、登录Shell等。例如，要将用户”john”的主目录设置为”/home/john”，可以运行以下命令：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">usermod -d <span class="hljs-regexp">/home/</span>john john<br></code></pre></td></tr></table></figure>
<h3 id="3-用户登录和注销"><a href="#3-用户登录和注销" class="headerlink" title="3. 用户登录和注销"></a>3. 用户登录和注销</h3><h4 id="3-1-远程登录"><a href="#3-1-远程登录" class="headerlink" title="3.1 远程登录"></a>3.1 远程登录</h4><p>要通过SSH进行远程登录，可以使用<code>ssh</code>命令。例如，要从本地计算机登录到远程主机”example.com”，可以运行以下命令：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">ssh</span> username<span class="hljs-variable">@example</span>.com<br></code></pre></td></tr></table></figure>
<h4 id="3-2-本地登录"><a href="#3-2-本地登录" class="headerlink" title="3.2 本地登录"></a>3.2 本地登录</h4><p>要在本地登录Linux系统，可以使用登录管理器（如GDM或LightDM）或文本模式登录。在登录界面上输入用户名和密码即可登录。</p>
<h4 id="3-3-强制用户注销"><a href="#3-3-强制用户注销" class="headerlink" title="3.3 强制用户注销"></a>3.3 强制用户注销</h4><p>如果需要强制注销用户，可以使用<code>pkill</code>命令。例如，要强制注销用户”john”，可以运行以下命令：</p>
<figure class="highlight cos"><table><tr><td class="code"><pre><code class="hljs cos">pkill -<span class="hljs-keyword">KILL</span> -u john<br></code></pre></td></tr></table></figure>
<h3 id="4-用户密码管理"><a href="#4-用户密码管理" class="headerlink" title="4. 用户密码管理"></a>4. 用户密码管理</h3><h4 id="4-1-密码策略"><a href="#4-1-密码策略" class="headerlink" title="4.1 密码策略"></a>4.1 密码策略</h4><p>为了保护用户账户安全，应采用合理的密码策略。可以通过修改<code>/etc/login.defs</code>文件来设置密码策略，如最小密码长度、密码过期时间等。</p>
<h4 id="4-2-修改用户密码"><a href="#4-2-修改用户密码" class="headerlink" title="4.2 修改用户密码"></a>4.2 修改用户密码</h4><p>要修改用户密码，可以使用<code>passwd</code>命令。例如，要修改用户”john”的密码，可以运行以下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">passwd john</span><br></code></pre></td></tr></table></figure>
<h4 id="4-3-重置用户密码"><a href="#4-3-重置用户密码" class="headerlink" title="4.3 重置用户密码"></a>4.3 重置用户密码</h4><p>如果用户忘记密码或需要管理员重置密码，可以使用<code>passwd</code>命令。管理员可以用以下命令重置用户”john”的密码：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">sudo passwd john</span><br></code></pre></td></tr></table></figure>
<h3 id="5-用户组管理"><a href="#5-用户组管理" class="headerlink" title="5. 用户组管理"></a>5. 用户组管理</h3><h4 id="5-1-什么是用户组？"><a href="#5-1-什么是用户组？" class="headerlink" title="5.1 什么是用户组？"></a>5.1 什么是用户组？</h4><p>用户组是将多个用户集合在一起管理的机制。用户组可以简化权限管理，并允许共享文件和目录访问权限。</p>
<h4 id="5-2-创建用户组"><a href="#5-2-创建用户组" class="headerlink" title="5.2 创建用户组"></a>5.2 创建用户组</h4><p>要创建用户组，可以使用<code>groupadd</code>命令。例如，要创建名为”developers”的用户组，可以运行以下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">groupadd developers</span><br></code></pre></td></tr></table></figure>
<h4 id="5-3-将用户添加到用户组"><a href="#5-3-将用户添加到用户组" class="headerlink" title="5.3 将用户添加到用户组"></a>5.3 将用户添加到用户组</h4><p>要将用户添加到用户组，可以使用<code>usermod</code>命令。例如，要将用户”john”添加到用户组”developers”，可以运行以下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">usermod -aG developers john</span><br></code></pre></td></tr></table></figure>
<h4 id="5-4-从用户组中移除用户"><a href="#5-4-从用户组中移除用户" class="headerlink" title="5.4 从用户组中移除用户"></a>5.4 从用户组中移除用户</h4><p>要从用户组中移除用户，可以使用<code>gpasswd</code>命令。例如，要将用户”john”从用户组”developers”中移除，可以运行以下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">gpasswd -d john developers</span><br></code></pre></td></tr></table></figure>
<h3 id="6-权限和访问控制"><a href="#6-权限和访问控制" class="headerlink" title="6. 权限和访问控制"></a>6. 权限和访问控制</h3><h4 id="6-1-文件权限概述"><a href="#6-1-文件权限概述" class="headerlink" title="6.1 文件权限概述"></a>6.1 文件权限概述</h4><p>在Linux系统中，每个文件和目录都有一组权限，用于控制对其的访问。权限分为三个类别：所有者（文件的拥有者）、群组（文件所属的组）和其他人（除了所有者和群组之外的其他用户）。</p>
<h4 id="6-2-修改文件权限"><a href="#6-2-修改文件权限" class="headerlink" title="6.2 修改文件权限"></a>6.2 修改文件权限</h4><p>要修改文件的权限，可以使用<code>chmod</code>命令。权限可以用数字表示法（如<code>chmod 644 file.txt</code>）或符号表示法（如<code>chmod u+r file.txt</code>）来设置。</p>
<p>示例：</p>
<figure class="highlight gams"><table><tr><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> chmod <span class="hljs-number">644</span> <span class="hljs-keyword">file</span>.txt<br></code></pre></td></tr></table></figure>
<p>该命令将文件<code>file.txt</code>的权限设置为 <code>-rw-r--r--</code>，即文件所有者可读写，群组和其他人只可读取。</p>
<h4 id="6-3-设置特殊权限"><a href="#6-3-设置特殊权限" class="headerlink" title="6.3 设置特殊权限"></a>6.3 设置特殊权限</h4><p>除了基本的读取、写入和执行权限外，还有一些特殊权限：</p>
<ul>
<li>Setuid（SUID）：允许以文件所有者的权限运行可执行文件。</li>
<li>Setgid（SGID）：允许以文件所属组的权限运行可执行文件。</li>
<li>Sticky位：只有文件所有者才能删除或重命名该文件。</li>
</ul>
<p>可以使用<code>chmod</code>命令的符号表示法来设置特殊权限。</p>
<p>示例：</p>
<figure class="highlight gams"><table><tr><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> chmod +s <span class="hljs-keyword">file</span>.txt<br></code></pre></td></tr></table></figure>
<p>该命令将文件<code>file.txt</code>的Setuid权限位设置为开启。</p>
<h4 id="6-4-使用访问控制列表（ACL）"><a href="#6-4-使用访问控制列表（ACL）" class="headerlink" title="6.4 使用访问控制列表（ACL）"></a>6.4 使用访问控制列表（ACL）</h4><p>访问控制列表（Access Control Lists，ACL）是一种更灵活的权限控制机制。ACL允许向每个文件或目录添加多个用户或组，并为它们提供不同的权限。可以使用<code>setfacl</code>命令来设置和修改ACL。</p>
<p>示例：</p>
<figure class="highlight gams"><table><tr><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> setfacl -m u:user:rwx <span class="hljs-keyword">file</span>.txt<br></code></pre></td></tr></table></figure>
<p>该命令将文件<code>file.txt</code>的ACL添加了一个新的用户<code>user</code>，并赋予该用户读、写和执行的权限。</p>
<h4 id="6-5-修改文件所有者"><a href="#6-5-修改文件所有者" class="headerlink" title="6.5 修改文件所有者"></a>6.5 修改文件所有者</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 遇到权限不足的情况自行添加sudo，没sudo权限就联系管理员吧</span><br><span class="hljs-built_in">chown</span> user1 aFile <span class="hljs-comment"># 修改aFile的所属用户为user1；</span><br><span class="hljs-built_in">chown</span> user1: aFile <span class="hljs-comment"># 修改aFile的所属用户为user1，所属用户组为user1所在的主组；</span><br><span class="hljs-built_in">chown</span> :Group1 aFile <span class="hljs-comment"># 修改aFile的所属用户组为Group1，所属用户不变；</span><br><span class="hljs-built_in">chown</span> user1:Group2 aFile <span class="hljs-comment"># 修改aFile的所属用户为user1，所属用户组为Group2；</span><br></code></pre></td></tr></table></figure>
<h3 id="7-用户切换和身份验证"><a href="#7-用户切换和身份验证" class="headerlink" title="7. 用户切换和身份验证"></a>7. 用户切换和身份验证</h3><h4 id="7-1-su命令"><a href="#7-1-su命令" class="headerlink" title="7.1 su命令"></a>7.1 su命令</h4><p><code>su</code>命令（切换用户）允许当前用户切换到其他用户账户。通过<code>su</code>命令，可以以其他用户的身份执行命令，需要输入目标用户的密码。</p>
<p>示例：</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><code class="hljs crmsh">$ su <span class="hljs-keyword">user</span><br><span class="hljs-title">Password</span>: <br>$ whoami<br>user<br></code></pre></td></tr></table></figure>
<h4 id="7-2-sudo命令"><a href="#7-2-sudo命令" class="headerlink" title="7.2 sudo命令"></a>7.2 sudo命令</h4><p><code>sudo</code>命令（以超级用户权限执行命令）允许授权的用户以超级用户或其他用户的身份执行命令。使用<code>sudo</code>命令可以在不直接使用超级用户账户的情况下执行特权操作。</p>
<p>示例：</p>
<figure class="highlight n1ql"><table><tr><td class="code"><pre><code class="hljs n1ql">$ sudo apt-get <span class="hljs-keyword">update</span><br>[sudo] <span class="hljs-keyword">password</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">user</span>: <br></code></pre></td></tr></table></figure>
<h4 id="7-3-SSH密钥身份验证"><a href="#7-3-SSH密钥身份验证" class="headerlink" title="7.3 SSH密钥身份验证"></a>7.3 SSH密钥身份验证</h4><p>SSH密钥身份验证使用公钥和私钥来进行身份验证，比传统的基于密码的身份验证更安全。它允许用户通过生成密钥对，并将公钥复制到目标服务器上的授权文件中，从而无需输入密码即可登录。</p>
<p>示例：</p>
<ol>
<li>生成SSH密钥对：</li>
</ol>
<figure class="highlight armasm"><table><tr><td class="code"><pre><code class="hljs armasm">$ ssh-keygen -t rsa -<span class="hljs-keyword">b</span> <span class="hljs-number">4096</span><br></code></pre></td></tr></table></figure>
<ol>
<li>将公钥复制到目标服务器：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql">$ ssh<span class="hljs-operator">-</span><span class="hljs-keyword">copy</span><span class="hljs-operator">-</span>id <span class="hljs-keyword">user</span><span class="hljs-variable">@server</span><br></code></pre></td></tr></table></figure>
<ol>
<li>使用私钥登录：</li>
</ol>
<figure class="highlight typescript"><table><tr><td class="code"><pre><code class="hljs typescript">$ ssh -i ~<span class="hljs-regexp">/.ssh/i</span>d_rsa user<span class="hljs-meta">@server</span><br></code></pre></td></tr></table></figure>
<h3 id="8-用户管理工具"><a href="#8-用户管理工具" class="headerlink" title="8. 用户管理工具"></a>8. 用户管理工具</h3><h4 id="8-1-useradd命令"><a href="#8-1-useradd命令" class="headerlink" title="8.1 useradd命令"></a>8.1 useradd命令</h4><p><code>useradd</code>命令用于创建新用户账户。可以指定用户名、用户ID、主组ID和其他选项来创建用户。</p>
<p>示例：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">$ sudo useradd -m -s <span class="hljs-regexp">/bin/</span>bash username<br></code></pre></td></tr></table></figure>
<p>该命令以默认配置创建一个名为<code>username</code>的新用户。</p>
<h4 id="8-2-userdel命令"><a href="#8-2-userdel命令" class="headerlink" title="8.2 userdel命令"></a>8.2 userdel命令</h4><p><code>userdel</code>命令用于删除用户账户。可以指定要删除的用户以及其他选项来删除用户。</p>
<p>示例：</p>
<figure class="highlight crystal"><table><tr><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>sudo userdel -r username<br></code></pre></td></tr></table></figure>
<p>该命令将删除名为<code>username</code>的用户账户及其相关文件和目录。</p>
<h4 id="8-3-passwd命令"><a href="#8-3-passwd命令" class="headerlink" title="8.3 passwd命令"></a>8.3 passwd命令</h4><p><code>passwd</code>命令用于更改用户的密码。用户可以使用<code>passwd</code>命令自行更改密码，或者管理员可以使用<code>passwd</code>命令为其他用户重置密码。</p>
<p>示例：</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><code class="hljs ada">$ passwd<br>Changing password <span class="hljs-keyword">for</span> user.<br><span class="hljs-keyword">New</span> password: <br>Retype <span class="hljs-keyword">new</span> password: <br></code></pre></td></tr></table></figure>
<h4 id="8-4-groupadd命令"><a href="#8-4-groupadd命令" class="headerlink" title="8.4 groupadd命令"></a>8.4 groupadd命令</h4><p><code>groupadd</code>命令用于创建新的用户组。可以指定组名、组ID和其他选项来创建用户组。</p>
<p>示例：</p>
<figure class="highlight crystal"><table><tr><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>sudo groupadd groupname<br></code></pre></td></tr></table></figure>
<p>该命令创建一个名为<code>groupname</code>的新用户组。</p>
<h4 id="8-5-groupdel命令"><a href="#8-5-groupdel命令" class="headerlink" title="8.5 groupdel命令"></a>8.5 groupdel命令</h4><p><code>groupdel</code>命令用于删除用户组。可以指定要删除的用户组以及其他选项来删除用户组。</p>
<p>示例：</p>
<figure class="highlight crystal"><table><tr><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>sudo groupdel groupname<br></code></pre></td></tr></table></figure>
<p>该命令将删除名为<code>groupname</code>的用户组。</p>
<h4 id="8-6-id命令"><a href="#8-6-id命令" class="headerlink" title="8.6 id命令"></a>8.6 id命令</h4><p><code>id</code>命令用于显示用户和组的信息。可以使用该命令查看用户和组的ID、名称和所属组等信息。</p>
<p>示例：</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><code class="hljs routeros">$ id username<br><span class="hljs-attribute">uid</span>=1000(username) <span class="hljs-attribute">gid</span>=1000(username) <span class="hljs-attribute">groups</span>=1000(username)<br></code></pre></td></tr></table></figure>
<h3 id="9-用户管理的最佳实践"><a href="#9-用户管理的最佳实践" class="headerlink" title="9. 用户管理的最佳实践"></a>9. 用户管理的最佳实践</h3><h4 id="9-1-最小化权限原则"><a href="#9-1-最小化权限原则" class="headerlink" title="9.1 最小化权限原则"></a>9.1 最小化权限原则</h4><p>根据最小化权限原则，用户仅应被授予完成其工作所需的最低权限级别。这有助于减少潜在的滥用风险和错误操作。</p>
<p>示例：</p>
<ul>
<li>给予普通用户只读权限，而不是完全的读写权限。</li>
</ul>
<h4 id="9-2-定期审查用户账户"><a href="#9-2-定期审查用户账户" class="headerlink" title="9.2 定期审查用户账户"></a>9.2 定期审查用户账户</h4><p>定期审查用户账户可以识别和禁用不再需要的或已过期的账户，确保账户列表的精简和安全。</p>
<p>示例：</p>
<ul>
<li>每个季度对系统中的用户账户进行审查，禁用已经离职或不再需要的账户。</li>
</ul>
<h4 id="9-3-使用复杂密码"><a href="#9-3-使用复杂密码" class="headerlink" title="9.3 使用复杂密码"></a>9.3 使用复杂密码</h4><p>应鼓励或要求用户使用复杂的密码，包括字母、数字和特殊字符的组合，并限制密码长度。</p>
<p>示例：</p>
<ul>
<li>强制要求用户设置至少8位字符的密码，包含大写字母、小写字母、数字和特殊字符。</li>
</ul>
<h4 id="9-4-启用登录审计"><a href="#9-4-启用登录审计" class="headerlink" title="9.4 启用登录审计"></a>9.4 启用登录审计</h4><p>登录审计记录用户的登录行为和活动，有助于检测和调查安全事件。可以通过配置登录审计日志来启用该功能。</p>
<p>示例：</p>
<ul>
<li>配置系统以记录用户登录信息，包括登录时间、IP地址和源地址等。</li>
</ul>
<h3 id="10-总结"><a href="#10-总结" class="headerlink" title="10. 总结"></a>10. 总结</h3><p>Linux用户管理是在Linux操作系统中创建、删除、配置和管理用户账户的过程。本指南旨在提供对Linux用户管理的全面概述，并解释其重要性以及如何有效地管理用户。</p>
<p>在第一部分，我们介绍了Linux用户管理的基础知识，包括什么是Linux用户管理以及为什么它很重要。了解这些基本概念可以帮助我们更好地理解后续章节内容。</p>
<p>接下来，我们详细介绍了用户账户的创建和删除。我们学习了如何创建新的用户账户，设置其属性，并且在需要时如何安全地删除用户账户。这些操作对于管理用户的访问权限非常重要。</p>
<p>第三部分涵盖了用户登录和注销的不同方法。我们介绍了远程登录和本地登录的区别，并了解了如何强制用户注销，从而增强系统的安全性。</p>
<p>密码管理是用户管理的一个重要方面，因此我们专门介绍了密码策略的实施以及如何修改和重置用户密码。这有助于确保用户账户的安全性。</p>
<p>用户组管理是另一个重要主题，我们解释了什么是用户组，如何创建用户组以及如何将用户添加到用户组或从用户组中移除用户。通过使用用户组，我们可以更好地组织和管理用户。</p>
<p>在权限和访问控制部分，我们介绍了文件权限的概念，并讨论了如何修改文件权限以及如何使用访问控制列表（ACL）来更细粒度地控制文件访问。</p>
<p>另外，我们还详细介绍了用户切换和身份验证的不同方法，包括su命令、sudo命令和SSH密钥身份验证。这些方法使得用户能够在系统上执行特定任务或以其他用户身份登录。</p>
<p>最后，在用户管理工具部分，我们列举了一些常用的命令，例如useradd、userdel、passwd、groupadd、groupdel和id，用于在命令行界面中管理用户和用户组。</p>
<p>我们还提供了一些用户管理的最佳实践，如最小化权限原则、定期审查用户账户、使用复杂密码和启用登录审计。这些实践有助于提高系统的安全性和管理效率。</p>
<p>通过本指南，读者可以获得关于Linux用户管理的全面了解，并学习如何在Linux操作系统中高效管理用户账户和权限。</p>
]]></content>
  </entry>
  <entry>
    <title>Linux 的一些使用心得</title>
    <url>/linux/linux/</url>
    <content><![CDATA[<h1 id="SSH-端口转发"><a href="#SSH-端口转发" class="headerlink" title="SSH 端口转发"></a>SSH 端口转发</h1><h2 id="本地访问远程端口"><a href="#本地访问远程端口" class="headerlink" title="本地访问远程端口"></a>本地访问远程端口</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -L [LOCAL_IP:]LOCAL_PORT:DESTINATION:DESTINATION_PORT [USER@]SSH_SERVER<br></code></pre></td></tr></table></figure>
<h2 id="远程访问本地的端口"><a href="#远程访问本地的端口" class="headerlink" title="远程访问本地的端口"></a>远程访问本地的端口</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -R [REMOTE:]REMOTE_PORT:DESTINATION:DESTINATION_PORT [USER@]SSH_SERVER<br></code></pre></td></tr></table></figure>
<p>比如要把本机的代理 <code>http://127.0.0.1:10800</code> 端口共享到远程的所有 IP 上的 10801 端口，则是</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -R 0.0.0.0:10801:127.0.0.1:10800 username@ip -p port<br></code></pre></td></tr></table></figure>
<p>注意，默认是无法在远程服务器上监听 <code>0.0.0.0</code> 的，如果想要监听，需要修改 <code>/etc/ssh/sshd_config</code> 中的 <code>GatewayPorts yes</code> 才行。</p>
<p>如果网络不稳定，容易断开连接，用以下命令将该连接只用作隧道（-N），同时增加心跳<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=3 -N -R 0.0.0.0:10800:127.0.0.1:10800 kdzlys@117.139.126.36 -p 2224<br></code></pre></td></tr></table></figure></p>
<h1 id="conda-init-fish-之后-fish-崩溃"><a href="#conda-init-fish-之后-fish-崩溃" class="headerlink" title="conda init fish 之后 fish 崩溃"></a>conda init fish 之后 fish 崩溃</h1><p>原因是 ubuntu 默认的 fish 是 2.x 版本，而 conda init fish 对应的脚本对应 fish 3.x 版本，所以在安装 fish 的时候需要安装 fish 3 版本。<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo apt-add-repository ppa:fish-shell/release-3<br>sudo apt update<br>sudo apt install fish<br></code></pre></td></tr></table></figure></p>
<h1 id="关闭-kde-文件索引程序"><a href="#关闭-kde-文件索引程序" class="headerlink" title="关闭 kde 文件索引程序"></a>关闭 kde 文件索引程序</h1><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">balooctl <span class="hljs-built_in">suspend</span><br>balooctl <span class="hljs-built_in">disable</span><br></code></pre></td></tr></table></figure>
<h1 id="Linux-下抓-HTTPS-包"><a href="#Linux-下抓-HTTPS-包" class="headerlink" title="Linux 下抓 HTTPS 包"></a>Linux 下抓 HTTPS 包</h1><h2 id="使用-MITMProxy"><a href="#使用-MITMProxy" class="headerlink" title="使用 MITMProxy"></a>使用 MITMProxy</h2><ol>
<li>运行 MITMProxy</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker run --<span class="hljs-built_in">rm</span> -it -p 18080:8080 -p 127.0.0.1:8081:8081 -v ~/.mitmproxy:/home/mitmproxy/.mitmproxy  mitmproxy/mitmproxy mitmweb --web-host 0.0.0.0 --<span class="hljs-built_in">set</span> block_global=<span class="hljs-literal">false</span> --<span class="hljs-built_in">set</span> ssl_insecure=<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure>
<ol>
<li>导入证书至浏览器或其他工具</li>
<li>使用代理访问 HTTPS 页面</li>
</ol>
<h1 id="更新-ubuntu-22-04-之后网易云音乐无法使用"><a href="#更新-ubuntu-22-04-之后网易云音乐无法使用" class="headerlink" title="更新 ubuntu 22.04 之后网易云音乐无法使用"></a>更新 ubuntu 22.04 之后网易云音乐无法使用</h1><p>修改 <code>/opt/netease/netease-cloud-music/netease-cloud-music.bash</code> 为以下内容<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span><br>HERE=<span class="hljs-string">&quot;<span class="hljs-subst">$(dirname <span class="hljs-string">&quot;<span class="hljs-subst">$(readlink -f <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;0&#125;</span>&quot;</span>)</span>&quot;</span>)</span>&quot;</span><br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;HERE&#125;</span>&quot;</span>/libs<br><span class="hljs-built_in">export</span> QT_PLUGIN_PATH=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;HERE&#125;</span>&quot;</span>/plugins <br><span class="hljs-built_in">export</span> QT_QPA_PLATFORM_PLUGIN_PATH=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;HERE&#125;</span>&quot;</span>/plugins/platforms<br><span class="hljs-built_in">cd</span> /lib/x86_64-linux-gnu/<br><span class="hljs-built_in">exec</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;HERE&#125;</span>&quot;</span>/netease-cloud-music <span class="hljs-variable">$@</span><br><br></code></pre></td></tr></table></figure></p>
<h1 id="关闭无用启动项"><a href="#关闭无用启动项" class="headerlink" title="关闭无用启动项"></a>关闭无用启动项</h1><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看启动项</span><br><span class="hljs-built_in">ls</span> -l /etc/xdg/autostart<br><br><span class="hljs-comment"># 重命名</span><br>sudo <span class="hljs-built_in">mv</span> something something.bak<br></code></pre></td></tr></table></figure>
<h1 id="Vmware-更新内核失败"><a href="#Vmware-更新内核失败" class="headerlink" title="Vmware 更新内核失败"></a>Vmware 更新内核失败</h1><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/mkubecek/vmware-host-modules.git<br>git checkout &lt;your_version&gt;<br>sudo make<br>sudo make install<br></code></pre></td></tr></table></figure>
<h1 id="双系统-Windows-更新失败"><a href="#双系统-Windows-更新失败" class="headerlink" title="双系统 Windows 更新失败"></a>双系统 Windows 更新失败</h1><p>我这里双系统 Windows 更新失败的原因是 Windows 引导出现了问题，可以进入 Windows 输入 <code>msconfig</code> 查看引导选项卡下是否有内容，我是用过 systemd boot 来引导的 Windows，所以没有出现内容。</p>
<p>在 BIOS 中更改成直接引导 Windows 之后便可以正常更新了。</p>
<h1 id="按时间降序最近安装的程序"><a href="#按时间降序最近安装的程序" class="headerlink" title="按时间降序最近安装的程序"></a>按时间降序最近安装的程序</h1><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> $(<span class="hljs-built_in">ls</span> -1t /var/log/dpkg.log*); <span class="hljs-keyword">do</span> <br>      zcat -f <span class="hljs-variable">$x</span> |<span class="hljs-built_in">tac</span> |grep -e <span class="hljs-string">&quot; install &quot;</span> -e <span class="hljs-string">&quot; upgrade &quot;</span>; <br><span class="hljs-keyword">done</span> | awk -F <span class="hljs-string">&quot;:a&quot;</span> <span class="hljs-string">&#x27;&#123;print $1 &quot; :a&quot; $2&#125;&#x27;</span> |column -t<br></code></pre></td></tr></table></figure>
<h1 id="常用的一些-gnome-extensions"><a href="#常用的一些-gnome-extensions" class="headerlink" title="常用的一些 gnome extensions"></a>常用的一些 gnome extensions</h1><h2 id="Unite"><a href="#Unite" class="headerlink" title="Unite"></a>Unite</h2><p>最大化时隐藏标题栏</p>
<h2 id="Clear-Top-Bar"><a href="#Clear-Top-Bar" class="headerlink" title="Clear Top Bar"></a>Clear Top Bar</h2><p>状态栏变成透明的</p>
<h2 id="ddterm"><a href="#ddterm" class="headerlink" title="ddterm"></a>ddterm</h2><p>按 <code>F10</code> 快速启动命令行，再按 <code>F10</code> 隐藏，十分方便</p>
<h2 id="Desktop-Icons-NG-DING"><a href="#Desktop-Icons-NG-DING" class="headerlink" title="Desktop Icons NG(DING)"></a>Desktop Icons NG(DING)</h2><p>在桌面上显示图标</p>
<h2 id="Lock-Keys"><a href="#Lock-Keys" class="headerlink" title="Lock Keys"></a>Lock Keys</h2><p>可以显示当前大小写状况</p>
<h2 id="NetSpeed"><a href="#NetSpeed" class="headerlink" title="NetSpeed"></a>NetSpeed</h2><p>显示当前网速</p>
<h2 id="TopIcons-Plus（在-gnome-40-之后使用-Ubuntu-Appindicators-替代）"><a href="#TopIcons-Plus（在-gnome-40-之后使用-Ubuntu-Appindicators-替代）" class="headerlink" title="TopIcons Plus（在 gnome 40 之后使用 Ubuntu Appindicators 替代）"></a>TopIcons Plus（在 gnome 40 之后使用 Ubuntu Appindicators 替代）</h2><p>在顶部显示图标</p>
<h2 id="Dash-to-Dock"><a href="#Dash-to-Dock" class="headerlink" title="Dash to Dock"></a>Dash to Dock</h2><p>在底部智能显示一个 Dock</p>
<h1 id="换-MAC-地址"><a href="#换-MAC-地址" class="headerlink" title="换 MAC 地址"></a>换 MAC 地址</h1><p>有的时候需要更换 linux 的 ip 地址：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo ifconfig eth0 down<br>sudo ifconfig wlo1 hw ether 02:42:41:7d:b7:6e<br>sudo ifconfig wlo1 up<br></code></pre></td></tr></table></figure>
<p>这里 <code>eth0</code> 是网络 interface，ether 之后的参数就是 MAC 地址</p>
<h1 id="输入法"><a href="#输入法" class="headerlink" title="输入法"></a>输入法</h1><h2 id="Fcitx-失效"><a href="#Fcitx-失效" class="headerlink" title="Fcitx 失效"></a>Fcitx 失效</h2><ul>
<li><p>使用 im-config 修复</p>
</li>
<li><p>可能是 fcitx 没有正常启动，即还是 ibus，可以修改 ~/.pam_environment</p>
</li>
<li><p>使用 <code>fcitx5-diagnose</code> 命令根据提示设置环境变量</p>
</li>
<li><p>删除 <code>/etc/profile.d/pop-im-ibus.sh</code> （pop os）</p>
<p> <code>/etc/profile.d/pop-im-ibus.sh</code> （源文件： /etc/gdm3/Xsession ）设置了环境变量 <code>XMODIFIERS</code> ，在 <code>/etc/X11/Xsession.d/70im-config_launch</code> 中有如下代码：</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-keyword">if</span> [ -z <span class="hljs-string">&quot;<span class="hljs-variable">$XMODIFIERS</span>&quot;</span> ] &amp;&amp; \  <span class="hljs-comment"># 如果环境变量 XMODIFIERS 没有被设置</span><br>   ...<br>   <span class="hljs-comment"># 设置环境变量以启动用户指定的输入法</span><br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure>
<p> 因为 <code>XMODIFIERS</code> 被设置了，所以 <code>设置环境变量以启动用户指定的输入法</code> 没有执行，所以 fcitx 没有被启动。</p>
<p> <code>/etc/profile.d/pop-im-ibus.sh</code> 第一次出现于 <code>pop-os_20.10_amd64_intel_4.iso</code> （发布于 2020 年 12 月中旬）</p>
<p> 相关 issue，<a href="https://github.com/pop-os/pop/issues/1445">https://github.com/pop-os/pop/issues/1445</a></p>
</li>
</ul>
<h1 id="Dash-to-dock"><a href="#Dash-to-dock" class="headerlink" title="Dash to dock"></a>Dash to dock</h1><h2 id="Dash-to-dock-重叠问题"><a href="#Dash-to-dock-重叠问题" class="headerlink" title="Dash to dock 重叠问题"></a>Dash to dock 重叠问题</h2><p>   Pop os 自带的 Dock 与 Dash to dock 发生了重叠</p>
   <figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">cd /usr/share/gnome-shell/extensions<br>sudo mv cosmic-dock@system76.com cosmic-dock@system76.com.bak # 关闭自带的 dock<br></code></pre></td></tr></table></figure>
<p>   之后重启 gnome 即可解决</p>
<h1 id="Alt-Tab-时阻止相同应用叠加"><a href="#Alt-Tab-时阻止相同应用叠加" class="headerlink" title="Alt + Tab 时阻止相同应用叠加"></a>Alt + Tab 时阻止相同应用叠加</h1><p>在 gnome 设置中，打开 keyboard shortcut，将 <code>Switch windows</code> 设置为 <code>Alt + Tab</code> ，而不是默认的 <code>Switch applications</code>。</p>
<p>参考：<a href="https://superuser.com/questions/394376/how-to-prevent-gnome-shells-alttab-from-grouping-windows-from-similar-apps">https://superuser.com/questions/394376/how-to-prevent-gnome-shells-alttab-from-grouping-windows-from-similar-apps</a></p>
<h1 id="fluxion"><a href="#fluxion" class="headerlink" title="fluxion"></a>fluxion</h1><h2 id="扫描不到热点"><a href="#扫描不到热点" class="headerlink" title="扫描不到热点"></a>扫描不到热点</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo airmon-ng<br>sudo airmon-ng start fluxwl0<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> FLUXIONAirmonNG=1<br></code></pre></td></tr></table></figure>
<p>执行上述命令后再运行 fluxion 即可。</p>
<h2 id="解除-53-端口被-systemd-resolved-占用"><a href="#解除-53-端口被-systemd-resolved-占用" class="headerlink" title="解除 53 端口被 systemd-resolved 占用"></a>解除 53 端口被 systemd-resolved 占用</h2><ol>
<li>先停用 systemd-resolved 服务</li>
</ol>
<figure class="highlight nsis"><table><tr><td class="code"><pre><code class="hljs nsis"><span class="hljs-params">system</span>ctl stop <span class="hljs-params">system</span>d-resolved<br></code></pre></td></tr></table></figure>
<ol>
<li>编辑 /etc/systemd/resolved.conf 文件</li>
</ol>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">vi <span class="hljs-regexp">/etc/</span>systemd/resolved.conf<br></code></pre></td></tr></table></figure>
<ol>
<li>换下面说明更改，然后按一下“esc”键，再输入“:wq”（不要输入引号），回车保存即可。</li>
</ol>
<figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Resolve]</span><br><span class="hljs-attr">DNS</span>=<span class="hljs-number">8.8</span>.<span class="hljs-number">8.8</span>  <span class="hljs-comment">#取消注释，增加dns</span><br><span class="hljs-comment">#FallbackDNS=</span><br><span class="hljs-comment">#Domains=</span><br><span class="hljs-comment">#LLMNR=no</span><br><span class="hljs-comment">#MulticastDNS=no</span><br><span class="hljs-comment">#DNSSEC=no</span><br><span class="hljs-comment">#Cache=yes</span><br><span class="hljs-attr">DNSStubListener</span>=<span class="hljs-literal">no</span>  <span class="hljs-comment">#取消注释，把yes改为no</span><br></code></pre></td></tr></table></figure>
<ol>
<li>最后运行下面命令即可。</li>
</ol>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk">ln -sf <span class="hljs-regexp">/run/</span>systemd<span class="hljs-regexp">/resolve/</span>resolv.conf <span class="hljs-regexp">/etc/</span>resolv.conf<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>一些有意思的图</title>
    <url>/uncategorized/meme/</url>
    <content><![CDATA[<h1 id="关于是否写脚本自动化"><a href="#关于是否写脚本自动化" class="headerlink" title="关于是否写脚本自动化"></a>关于是否写脚本自动化</h1><p><img  src="v2-7012fc4ee97f0b520094f731152eaac5_b.jpg"  ><span class="image-caption">img</span></p>
]]></content>
  </entry>
  <entry>
    <title>人性的弱点笔记</title>
    <url>/uncategorized/people/</url>
    <content><![CDATA[<h1 id="来自-Async-的-Tips"><a href="#来自-Async-的-Tips" class="headerlink" title="来自 Async 的 Tips"></a>来自 Async 的 Tips</h1><p>注意，在使用这些技巧的时候，不要过度，我们不必要太过迁就和顺从任何人。</p>
<p>人们不会珍惜轻易得到的东西。</p>
<h1 id="一、基本技巧"><a href="#一、基本技巧" class="headerlink" title="一、基本技巧"></a>一、基本技巧</h1><p>1、不要批评（待人接物的第一大忌）</p>
<p>2、自我价值感、对尊重和真诚欣赏的渴望（这种说话方式非常值钱）</p>
<p>3、站在对方的角度思考问题。诉诸对方的内在需要。（让整个世界前来为你助力）</p>
<h1 id="二、如何让大家都喜欢你"><a href="#二、如何让大家都喜欢你" class="headerlink" title="二、如何让大家都喜欢你"></a>二、如何让大家都喜欢你</h1><p>4、真的喜欢别人、注意小节。我们都喜欢那些喜欢我们的人。（这样做，谁会不喜欢你？）</p>
<p>5、一笑值千金。（这能留下美好的第一印象）</p>
<p>6、记住名字。（这会让人一下子喜欢上你）</p>
<p>7、全心关注，是一种微妙的恭维，很少有人，很少有人抵抗得住。倾听，鼓励对方多聊自己。（怎样才叫“会聊天”）</p>
<p>8、聊对方感兴趣的话题。（提高你的影响力）</p>
<p>9、和人们聊他们自己，他们会听几个小时都不烦。使对方感到自己是重要的，要真心实意。（一句话焐热人心）</p>
<h1 id="三、如何有逻辑地说服他人"><a href="#三、如何有逻辑地说服他人" class="headerlink" title="三、如何有逻辑地说服他人"></a>三、如何有逻辑地说服他人</h1><p>10、不要信任自己的第一直觉冲动。在意见不合时，我们的第一自然反应是抗辩。小心！保持冷静，小心你的第一反应。那是你最糟糕的瞬间，而不是最好的时候。试着建立理解的桥梁，不要构建误解的深渊。<br>赢得争论的唯一方法是避免争论。（第一大忌：伤敌一万，自损八千）</p>
<p>11、我们偶尔知道自己会毫无阻力地改变主意，没有什么沉重心情，但如果有人说我们错了，我们就会因为对指责的憎恨而铁下心来。我们在形成信念时很随意，随意得叫人吃惊，但当任何人提出要剥离这些信念时，我们就会充满保卫它们的可怕激情。显然，并非那些想法很重要，而是我们的自尊受到了威胁……<br>尊重对方的观点，永远别说“你不对”。（第二大忌：一句惹怒全世界的话）</p>
<p>12、有勇气承认自己的错误，会产生某种满足感。它不仅能让内疚感和自卫感一扫而光，还常能解决错误所带来的问题。<br>假如你错了，立刻真心诚意地承认。（拆招卸力）</p>
<p>13、先说友善的话，气氛对了之后再说别的。（开口前结局已定）</p>
<p>14、先让对方回答“对”“是的”。（如何引导对方的思路）</p>
<p>15、尽量让对方多说。（贵人语迟）</p>
<p>16、我们喜欢别人问我们希望什么，我们需要什么，我们有什么观点。<br>让对方感觉，那是他自己的主意。（洗脑术：如何让人深信不疑）</p>
<p>17、努力从对方的视角看问题，要诚实。（如何让别人关注你）</p>
<p>18、你现在这样感觉，我没有任何理由怪你，如果我是你，我一定也会是那个感觉。<br>真正体会和感受对方的观点和渴望。（提高你的人格魅力）</p>
<p>19、我们所有人在心底都是理想家，喜欢认为自己拥有高尚的情操。<br>诉诸高尚的情操。（如何让人乐意服你）</p>
<p>20、把你的观点，演成故事。（说不透时，卖个故事）</p>
<p>21、抛出挑战。（最后一招，下封战书）</p>
<h1 id="四、成为一个领袖：如何改变他人而不冒犯人或引起反感、愤怒或怨恨"><a href="#四、成为一个领袖：如何改变他人而不冒犯人或引起反感、愤怒或怨恨" class="headerlink" title="四、成为一个领袖：如何改变他人而不冒犯人或引起反感、愤怒或怨恨"></a>四、成为一个领袖：如何改变他人而不冒犯人或引起反感、愤怒或怨恨</h1><p>22、先要懂得欣赏，不做作地称赞。（如何让大家都尊重你）</p>
<p>23、让人们注意自己的错误时，间接一点儿。（批评但不招人恨）</p>
<p>24、批评对方之前，不妨先说说自己犯过的错。（服人而不得罪人）</p>
<p>25、不要直接下命令，而要利用问句。（世界上没有任何人能指使我）</p>
<p>26、让对方保全颜面。（第一大忌：犯众怒）</p>
<p>27、每个人都喜欢称赞，但表扬必须具体，否则就特别假，成了说好话哄骗人。记住，我们都渴望赞美和认可，会不惜一切去争取。但没有人喜欢虚假，所有人都讨厌奉承。<br>称赞最细小的进步，称赞每一个进步。不要吝啬你的嘉许和赞扬，要真诚。（水涨船高：激励下属成事儿）</p>
<p>28、给人一个无法抗拒、无法辜负的好评。（你的期望永远不会落空）</p>
<p>29、学会鼓励人，鼓励会使改变看起来很容易。（让人乐意照你说的去改）</p>
<p>30、一个高产能的领袖，在改变别人的态度和行为时，应该牢记以下原则：</p>
<ul>
<li>要真诚。做不到的承诺，不要承诺。忘记对自己的好处，关注对方的利益。</li>
<li>精确地知道你想让对方做什么。</li>
<li>要共情。问自己：对方想要的到底是什么？</li>
<li>想想如果按照你说的做，对方会得到什么。</li>
<li>把这么做所能带来的好处，和对方的需要进行匹配。</li>
<li>发出要求时，要更改方式，要传达给对方一个观念：对方本人将是受益者。我们不能这么粗鲁地下令：“约翰，明天有客户来，我需要一个整洁的仓库。所以，去打扫干净，把货架上的货物摆放整齐，把货柜擦亮。”我们可以换一个方式来说同一件事，告诉约翰完成这个任务对他会有什么好处：“约翰，我们有件事得马上做好。现在就做，回头就不用手忙脚乱了。我明天会带几个客户来看我们的设施。我想带他们去看看仓库，但现在乱糟糟的。如果你愿意清理一下，把货架上的货物摆放整齐，把货柜擦一擦，我们就会显得更干练，你就给公司形象贡献了自己的那份力量。”</li>
<li>使人们乐意去做你要他们做的事。（让人乐意照你说的去做）</li>
</ul>
]]></content>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust的一些学习心得</title>
    <url>/rust/rust/</url>
    <content><![CDATA[<h1 id="Rust-标准库-trait"><a href="#Rust-标准库-trait" class="headerlink" title="Rust 标准库 trait"></a>Rust 标准库 trait</h1><p>假设有以下变量：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">t</span> = T::<span class="hljs-title function_ invoke__">new</span>()<br></code></pre></td></tr></table></figure>
<h2 id="impl-From-lt-U-gt-for-T"><a href="#impl-From-lt-U-gt-for-T" class="headerlink" title="impl From&lt;U&gt; for T"></a><code>impl From&lt;U&gt; for T</code></h2><p>如果为 <code>T</code> 实现了 <code>From&lt;U&gt;</code> 则可以通过 <code>T::from(U)</code> 得到 <code>T</code>。</p>
<p>例如 <code>String</code> 实现了 <code>From&lt;&amp;str&gt;</code>，所以 <code>String</code> 可以从 <code>&amp;str</code> 生成。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">string</span> = <span class="hljs-string">&quot;hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>();<br><span class="hljs-keyword">let</span> <span class="hljs-variable">other_string</span> = <span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;hello&quot;</span>);<br><br><span class="hljs-built_in">assert_eq!</span>(string, other_string);<br></code></pre></td></tr></table></figure>
<p><code>impl Into&lt;U&gt; for T</code></p>
<p>如果为 <code>T</code> 实现了 <code>Into&lt;U&gt;</code> 则可以通过 <code>t.into()</code> 消耗自己得到 <code>U</code>。</p>
<p>例如 <code>String</code> 类型实现了 <code>Into&lt;Vec&lt;u8&gt;&gt;</code>。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">is_hello</span>&lt;T: <span class="hljs-built_in">Into</span>&lt;<span class="hljs-type">Vec</span>&lt;<span class="hljs-type">u8</span>&gt;&gt;&gt;(s: T) &#123;<br>   <span class="hljs-keyword">let</span> <span class="hljs-variable">bytes</span> = <span class="hljs-string">b&quot;hello&quot;</span>.<span class="hljs-title function_ invoke__">to_vec</span>();<br>   <span class="hljs-built_in">assert_eq!</span>(bytes, s.<span class="hljs-title function_ invoke__">into</span>());<br>&#125;<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = <span class="hljs-string">&quot;hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>();<br><span class="hljs-title function_ invoke__">is_hello</span>(s);<br></code></pre></td></tr></table></figure>
<p>在实际编程中，用来接收多种类型的参数，如 <code>Into&lt;String&gt;</code> 可以同时接收 <code>String</code> 和 <code>&amp;str</code>。</p>
<h2 id="impl-AsRef-lt-U-gt-for-T"><a href="#impl-AsRef-lt-U-gt-for-T" class="headerlink" title="impl AsRef&lt;U&gt; for T"></a><code>impl AsRef&lt;U&gt; for T</code></h2><p>如果为 <code>T</code> 实现了 <code>AsRef&lt;U&gt;</code> 则可以通过 <code>t.as_ref()</code> 得到 <code>&amp;U</code>。</p>
<p>注：</p>
<ol>
<li>与 <code>Into&lt;U&gt;</code> 不同的是，<code>AsRef&lt;U&gt;</code> 只是类型转换，<code>t</code> 对象本身没有被消耗；</li>
<li><code>T: AsRef&lt;U&gt;</code> 中的 <code>T</code>，可以接受 资源拥有者（owned）类型，共享引用（shared referrence）类型 ，可变引用（mutable referrence）类型。</li>
</ol>
<p>例如 <code>String</code> 和 <code>&amp;str</code> 都实现了 <code>AsRef&lt;str&gt;</code>：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">is_hello</span>&lt;T: <span class="hljs-built_in">AsRef</span>&lt;<span class="hljs-type">str</span>&gt;&gt;(s: T) &#123;<br>   <span class="hljs-built_in">assert_eq!</span>(<span class="hljs-string">&quot;hello&quot;</span>, s.<span class="hljs-title function_ invoke__">as_ref</span>());<br>&#125;<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = <span class="hljs-string">&quot;hello&quot;</span>;<br><span class="hljs-title function_ invoke__">is_hello</span>(s);<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = <span class="hljs-string">&quot;hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>();<br><span class="hljs-title function_ invoke__">is_hello</span>(s);<br></code></pre></td></tr></table></figure>
<h2 id="impl-AsMut-lt-U-gt-for-T"><a href="#impl-AsMut-lt-U-gt-for-T" class="headerlink" title="impl AsMut&lt;U&gt; for T"></a><code>impl AsMut&lt;U&gt; for T</code></h2><p>如果为 <code>T</code> 实现了 <code>AsRef&lt;U&gt;</code> 则可以通过 <code>t.as_mut()</code> 得到 <code>&amp;mut U</code>。</p>
<h2 id="impl-Borror-lt-U-gt-for-T"><a href="#impl-Borror-lt-U-gt-for-T" class="headerlink" title="impl Borror&lt;U&gt; for T"></a><code>impl Borror&lt;U&gt; for T</code></h2><p>如果 <code>T</code> 实现了 <code>Borrow&lt;U&gt;</code>，那么，<code>t</code> 可执行 <code>.borrow()</code> 操作，即 <code>t.borrow()</code>。操作的结果，我们得到了一个类型为 <code>&amp;U</code> 的新引用。</p>
<p><code>Borrow</code> 可以认为是 <code>AsRef</code> 的严格版本，它对普适引用操作的前后类型之间附加了一些其它限制。</p>
<p><code>Borrow</code> 的前后类型之间要求必须有内部等价性。不具有这个等价性的两个类型之间，不能实现 <code>Borrow</code>。</p>
<p><code>AsRef</code> 更通用，更普遍，覆盖类型更多，是 <code>Borrow</code> 的超集。</p>
<p>举例：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::borrow::Borrow;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">check</span>&lt;T: Borrow&lt;<span class="hljs-type">str</span>&gt;&gt;(s: T) &#123;<br>    <span class="hljs-built_in">assert_eq!</span>(<span class="hljs-string">&quot;Hello&quot;</span>, s.<span class="hljs-title function_ invoke__">borrow</span>());<br>&#125;<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = <span class="hljs-string">&quot;Hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>();<br><br><span class="hljs-title function_ invoke__">check</span>(s);<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = <span class="hljs-string">&quot;Hello&quot;</span>;<br><br><span class="hljs-title function_ invoke__">check</span>(s);<br></code></pre></td></tr></table></figure>
<h2 id="impl-BorrowMut-lt-U-gt-for-T"><a href="#impl-BorrowMut-lt-U-gt-for-T" class="headerlink" title="impl BorrowMut&lt;U&gt; for T"></a><code>impl BorrowMut&lt;U&gt; for T</code></h2><p>如果 <code>T</code> 实现了 <code>BorrowMut&lt;U&gt;</code>，那么，<code>t</code> 可执行 <code>.borrow_mut()</code> 操作，即 <code>t.borrow_mut()</code>。操作的结果我们得到类型为 <code>&amp;mut U</code> 的一个可变（mutable）引用。</p>
<h2 id="impl-ToOwned-for-T"><a href="#impl-ToOwned-for-T" class="headerlink" title="impl ToOwned for T"></a><code>impl ToOwned for T</code></h2><p><code>ToOwned</code> 为 <code>Clone</code> 的普适版本。它提供了 <code>.to_owned()</code> 方法，用于类型转换。</p>
<p>有些实现了 <code>Clone</code> 的类型 <code>T</code> 可以从引用状态实例 <code>&amp;T</code> 通过 <code>.clone()</code> 方法，生成具有所有权的 <code>T</code> 的实例。但是它只能由 <code>&amp;T</code> 生成 <code>T</code>。而对于其它形式的引用，<code>Clone</code> 就无能为力了。</p>
<p>而 <code>ToOwned</code> trait 能够从任意引用类型实例，生成具有所有权的类型实例。</p>
<h2 id="impl-Deref-for-T"><a href="#impl-Deref-for-T" class="headerlink" title="impl Deref for T"></a><code>impl Deref for T</code></h2><p><code>Deref</code> 是 <code>deref</code> 操作符 <code>*</code> 的 trait，比如 <code>*v</code>。</p>
<p>一般理解，<code>*t</code> 操作，是 <code>&amp;t</code> 的反向操作，即试图由资源的引用获取到资源的拷贝（如果资源类型实现了 <code>Copy</code>），或所有权（资源类型没有实现 <code>Copy</code>）。</p>
<p>Rust 中，本操作符行为可以重载。这也是 Rust 操作符的基本特点。本身没有什么特别的。</p>
<h3 id="强制隐式转换（coercion）"><a href="#强制隐式转换（coercion）" class="headerlink" title="强制隐式转换（coercion）"></a>强制隐式转换（coercion）</h3><p><code>Deref</code> 神奇的地方并不在本身 <code>解引</code> 这个意义上，Rust 的设计者在它之上附加了一个特性：<code>强制隐式转换</code>，这才是它神奇之处。</p>
<p>这种隐式转换的规则为：</p>
<p>一个类型为 <code>T</code> 的对象 <code>t</code>，如果 <code>T: Deref&lt;Target=U&gt;</code>，那么，相关 <code>t</code> 的某个智能指针或引用（比如 <code>&amp;foo</code>）在应用的时候会自动转换成 <code>&amp;U</code>。</p>
<p>粗看这条规则，貌似有点类似于 <code>AsRef</code>，而跟 <code>解引</code> 似乎风马牛不相及。实际里面有些玄妙之处。</p>
<p>Rust 编译器会在做 <code>*v</code> 操作的时候，自动先把 <code>v</code> 做引用归一化操作，即转换成内部通用引用的形式 <code>&amp;v</code>，整个表达式就变成 <code>*&amp;v</code>。这里面有两种情况：</p>
<ol>
<li>把其它类型的指针（比如在库中定义的，<code>Box</code>, <code>Rc</code>, <code>Arc</code>, <code>Cow</code> 等），转成内部标准形式 <code>&amp;v</code>；</li>
<li>把多重 <code>&amp;</code> （比如：<code>&amp;&amp;&amp;&amp;&amp;&amp;&amp;v</code>），简化成 <code>&amp;v</code>（通过插入足够数量的 <code>*</code> 进行解引）。</li>
</ol>
<p>所以，它实际上在解引用之前做了一个引用的归一化操作。</p>
<p>为什么要转呢？ 因为编译器设计的能力是，只能够对 <code>&amp;v</code> 这种引用进行解引用。其它形式的它不认识，所以要做引用归一化操作。</p>
<p>使用引用进行过渡也是为了能够防止不必要的拷贝。</p>
<p>下面举一些例子：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">foo</span>(s: &amp;<span class="hljs-type">str</span>) &#123;<br>    <span class="hljs-comment">// borrow a string for a second</span><br>&#125;<br><br><span class="hljs-comment">// String implements Deref&lt;Target=str&gt;</span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">owned</span> = <span class="hljs-string">&quot;Hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>();<br><br><span class="hljs-comment">// therefore, this works:</span><br><span class="hljs-title function_ invoke__">foo</span>(&amp;owned);<br></code></pre></td></tr></table></figure>
<p>因为 <code>String</code> 实现了 <code>Deref&lt;Target=str&gt;</code>。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::rc::Rc;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">foo</span>(s: &amp;<span class="hljs-type">str</span>) &#123;<br>    <span class="hljs-comment">// borrow a string for a second</span><br>&#125;<br><br><span class="hljs-comment">// String implements Deref&lt;Target=str&gt;</span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">owned</span> = <span class="hljs-string">&quot;Hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>();<br><span class="hljs-keyword">let</span> <span class="hljs-variable">counted</span> = Rc::<span class="hljs-title function_ invoke__">new</span>(owned);<br><br><span class="hljs-comment">// therefore, this works:</span><br><span class="hljs-title function_ invoke__">foo</span>(&amp;counted);<br></code></pre></td></tr></table></figure>
<p>因为 <code>Rc&lt;T&gt;</code> 实现了 <code>Deref&lt;Target=T&gt;</code>。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">foo</span>(s: &amp;[<span class="hljs-type">i32</span>]) &#123;<br>    <span class="hljs-comment">// borrow a slice for a second</span><br>&#125;<br><br><span class="hljs-comment">// Vec&lt;T&gt; implements Deref&lt;Target=[T]&gt;</span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">owned</span> = <span class="hljs-built_in">vec!</span>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>];<br><br><span class="hljs-title function_ invoke__">foo</span>(&amp;owned);<br></code></pre></td></tr></table></figure>
<p>因为 <code>Vec&lt;T&gt;</code> 实现了 <code>Deref&lt;Target=[T]&gt;</code>。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Foo</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Foo</span> &#123;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">foo</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Foo&quot;</span>); &#125;<br>&#125;<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">f</span> = &amp;&amp;Foo;<br><br>f.<span class="hljs-title function_ invoke__">foo</span>();<br>(&amp;f).<span class="hljs-title function_ invoke__">foo</span>();<br>(&amp;&amp;f).<span class="hljs-title function_ invoke__">foo</span>();<br>(&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;f).<span class="hljs-title function_ invoke__">foo</span>();<br></code></pre></td></tr></table></figure>
<p>上面那几种函数的调用，效果是一样的。</p>
<p><code>coercion</code> 的设计，是 Rust 中仅有的类型隐式转换，设计它的目的，是为了简化程序的书写，让代码不至于过于繁琐。把人从无尽的类型细节中解脱出来，让书写 Rust 代码变成一件快乐的事情。</p>
<h2 id="Cow"><a href="#Cow" class="headerlink" title="Cow"></a><code>Cow</code></h2><p><code>Clone-on-write</code>，即写时克隆。本质上是一个智能指针。</p>
<p>它有两个可选值：</p>
<ul>
<li><code>Borrowed</code>，用于包裹对象的引用（通用引用）；</li>
<li><code>Owned</code>，用于包裹对象的所有者；</li>
</ul>
<p><code>Cow</code> 提供</p>
<ol>
<li>对此对象的不可变访问（比如可直接调用此对象原有的不可变方法）；</li>
<li>如果遇到需要修改此对象，或者需要获得此对象的所有权的情况，<code>Cow</code> 提供方法做克隆处理，并避免多次重复克隆。</li>
</ol>
<p><code>Cow</code> 的设计目的是提高性能（减少复制）同时增加灵活性，因为大部分情况下，业务场景都是读多写少。利用 <code>Cow</code>，可以用统一，规范的形式实现，需要写的时候才做一次对象复制。这样就可能会大大减少复制的次数。</p>
<p>它有以下几个要点需要掌握：</p>
<ol>
<li><code>Cow&lt;T&gt;</code> 能直接调用 <code>T</code> 的不可变方法，因为 <code>Cow</code> 这个枚举，实现了 <code>Deref</code>；</li>
<li>在需要写 <code>T</code>的时候，可以使用 <code>.to_mut()</code> 方法得到一个具有所有权的值的可变借用；<ol>
<li>注意，调用 <code>.to_mut()</code> 不一定会产生克隆；</li>
<li>在已经具有所有权的情况下，调用 <code>.to_mut()</code> 有效，但是不会产生新的克隆；</li>
<li>多次调用 <code>.to_mut()</code> 只会产生一次克隆。</li>
</ol>
</li>
<li>在需要写 <code>T</code> 的时候，可以使用 <code>.into_owned()</code> 创建新的拥有所有权的对象，这个过程往往意味着内存拷贝并创建新对象；<ol>
<li>如果之前 <code>Cow</code> 中的值是借用状态，调用此操作将执行克隆；</li>
<li>本方法，参数是<code>self</code>类型，它会“吃掉”原先的那个对象，调用之后原先的对象的生命周期就截止了，在 <code>Cow</code> 上不能调用多次；</li>
</ol>
</li>
</ol>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><code>.to_mut()</code> 举例</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::borrow::Cow;<br><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">cow</span>: Cow&lt;[_]&gt; = Cow::<span class="hljs-title function_ invoke__">Owned</span>(<span class="hljs-built_in">vec!</span>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">hello</span> = cow.<span class="hljs-title function_ invoke__">to_mut</span>();<br><br><span class="hljs-built_in">assert_eq!</span>(hello, &amp;[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);<br></code></pre></td></tr></table></figure>
<p><code>.into_owned()</code> 举例</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::borrow::Cow;<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">cow</span>: Cow&lt;[_]&gt; = Cow::<span class="hljs-title function_ invoke__">Owned</span>(<span class="hljs-built_in">vec!</span>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]);<br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">hello</span> = cow.<span class="hljs-title function_ invoke__">into_owned</span>();<br><br><span class="hljs-built_in">assert_eq!</span>(<span class="hljs-built_in">vec!</span>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], hello);<br></code></pre></td></tr></table></figure>
<p>综合举例</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::borrow::Cow;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">abs_all</span>(input: &amp;<span class="hljs-keyword">mut</span> Cow&lt;[<span class="hljs-type">i32</span>]&gt;) &#123;<br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..input.<span class="hljs-title function_ invoke__">len</span>() &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">v</span> = input[i];<br>        <span class="hljs-keyword">if</span> v &lt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-comment">// clones into a vector the first time (if not already owned)</span><br>            input.<span class="hljs-title function_ invoke__">to_mut</span>()[i] = -v;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="更多的例子"><a href="#更多的例子" class="headerlink" title="更多的例子"></a>更多的例子</h3><p>题目：写一个函数，过滤掉输入的字符串中的所有空格字符，并返回过滤后的字符串。</p>
<p>对这个简单的问题，不用思考，我们都可以很快写出代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">remove_spaces</span>(input: &amp;<span class="hljs-type">str</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">String</span> &#123;<br>   <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buf</span> = <span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">with_capacity</span>(input.<span class="hljs-title function_ invoke__">len</span>());<br><br>   <span class="hljs-keyword">for</span> <span class="hljs-variable">c</span> <span class="hljs-keyword">in</span> input.<span class="hljs-title function_ invoke__">chars</span>() &#123;<br>      <span class="hljs-keyword">if</span> c != <span class="hljs-string">&#x27; &#x27;</span> &#123;<br>         buf.<span class="hljs-title function_ invoke__">push</span>(c);<br>      &#125;<br>   &#125;<br><br>   buf<br>&#125;<br></code></pre></td></tr></table></figure>
<p>设计函数输入参数的时候，我们会停顿一下，这里，用 <code>&amp;str</code> 好呢，还是 <code>String</code> 好呢？思考一番，从性能上考虑，有如下结论：</p>
<ol>
<li>如果使用 <code>String</code> 则外部在调用此函数的时候，<ol>
<li>如果外部的字符串是 <code>&amp;str</code>，那么，它需要做一次克隆，才能调用此函数；</li>
<li>如果外部的字符串是 <code>String</code>，那么，它不需要做克隆，就可以调用此函数。但是，一旦调用后，外部那个字符串的所有权就被 <code>move</code> 到此函数中了，外部的后续代码将无法再使用原字符串。</li>
</ol>
</li>
<li>如果使用 <code>&amp;str</code>，则不存在上述两个问题。但可能会遇到生命周期的问题，需要注意。</li>
</ol>
<p>继续分析上面的例子，我们发现，在函数体内，做了一次新字符串对象的生成和拷贝。</p>
<p>让我们来仔细分析一下业务需求。最坏的情况下，如果字符串中没有空白字符，那最好是直接原样返回。这种情况做这样一次对象的拷贝，完全就是浪费了。</p>
<p>于是我们心想改进这个算法。很快，又遇到了另一个问题，返回值是 <code>String</code> 的嘛，我不论怎样，要把 <code>&amp;str</code> 转换成 <code>String</code> 返回，始终都要经历一次复制。于是我们快要放弃了。</p>
<p>好吧，<code>Cow</code> 君这时出马了。写出了如下代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::borrow::Cow;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">remove_spaces</span>&lt;<span class="hljs-symbol">&#x27;a</span>&gt;(input: &amp;<span class="hljs-symbol">&#x27;a</span> <span class="hljs-type">str</span>) <span class="hljs-punctuation">-&gt;</span> Cow&lt;<span class="hljs-symbol">&#x27;a</span>, <span class="hljs-type">str</span>&gt; &#123;<br>    <span class="hljs-keyword">if</span> input.<span class="hljs-title function_ invoke__">contains</span>(<span class="hljs-string">&#x27; &#x27;</span>) &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buf</span> = <span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">with_capacity</span>(input.<span class="hljs-title function_ invoke__">len</span>());<br><br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">c</span> <span class="hljs-keyword">in</span> input.<span class="hljs-title function_ invoke__">chars</span>() &#123;<br>            <span class="hljs-keyword">if</span> c != <span class="hljs-string">&#x27; &#x27;</span> &#123;<br>                buf.<span class="hljs-title function_ invoke__">push</span>(c);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> Cow::<span class="hljs-title function_ invoke__">Owned</span>(buf);<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> Cow::<span class="hljs-title function_ invoke__">Borrowed</span>(input);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>完美解决了业务逻辑与返回值类型冲突的问题。本例可细细品味。</p>
<p>外部程序，拿到这个 <code>Cow</code> 返回值后，按照我们上文描述的 <code>Cow</code> 的特性使用就好了。</p>
<h2 id="Send-和-Sync"><a href="#Send-和-Sync" class="headerlink" title="Send 和 Sync"></a><code>Send</code> 和 <code>Sync</code></h2><p><code>std::marker</code> 模块中，有两个 trait：<code>Send</code> 和 <code>Sync</code>，它们与多线程安全相关。</p>
<p>标记为 <code>marker trait</code> 的 trait，它实际就是一种约定，没有方法的定义，也没有关联元素（associated items）。仅仅是一种约定，实现了它的类型必须满足这种约定。一种类型是否加上这种约定，要么是编译器的行为，要么是人工手动的行为。</p>
<p><code>Send</code> 和 <code>Sync</code> 在大部分情况下（针对 Rust 的基础类型和 std 中的大部分类型），会由编译器自动推导出来。对于不能由编译器自动推导出来的类型，要使它们具有 <code>Send</code> 或 <code>Sync</code> 的约定，可以由人手动实现。实现的时候，必须使用 <code>unsafe</code> 前缀，因为 Rust 默认不信任程序员，由程序员自己控制的东西，统统标记为 <code>unsafe</code>，出了问题（比如，把不是线程安全的对象加上 <code>Sync</code> 约定）由程序员自行负责。</p>
<p>它们的定义如下：</p>
<p>如果 <code>T: Send</code>，那么将 <code>T</code> 传到另一个线程中时（按值传送），不会导致数据竞争或其它不安全情况。</p>
<ol>
<li><code>Send</code> 是对象可以安全发送到另一个执行体中；</li>
<li><code>Send</code> 使被发送对象可以和产生它的线程解耦，防止原线程将此资源释放后，在目标线程中使用出错（use after free）。</li>
</ol>
<p>如果 <code>T: Sync</code>，那么将 <code>&amp;T</code> 传到另一个线程中时，不会导致数据竞争或其它不安全情况。</p>
<ol>
<li><code>Sync</code> 是可以被同时多个执行体访问而不出错；</li>
<li><code>Sync</code> 防止的是竞争；</li>
</ol>
<p>推论：</p>
<ol>
<li><code>T: Sync</code> 意味着 <code>&amp;T: Send</code>；</li>
<li><code>Sync + Copy = Send</code>；</li>
<li>当 <code>T: Send</code> 时，可推导出 <code>&amp;mut T: Send</code>；</li>
<li>当 <code>T: Sync</code> 时，可推导出 <code>&amp;mut T: Sync</code>；</li>
<li>当 <code>&amp;mut T: Send</code> 时，不能推导出 <code>T: Send</code>；</li>
</ol>
<p>（注：<code>T</code>, <code>&amp;T</code>, <code>&amp;mut T</code>，<code>Box&lt;T&gt;</code> 等都是不同的类型）</p>
<p>具体的类型：</p>
<ol>
<li>原始类型（比如： u8, f64），都是 <code>Sync</code>，都是 <code>Copy</code>，因此都是 <code>Send</code>；</li>
<li>只包含原始类型的复合类型，都是 <code>Sync</code>，都是 <code>Copy</code>，因此都是 <code>Send</code>；</li>
<li>当 <code>T: Sync</code>，<code>Box&lt;T&gt;</code>, <code>Vec&lt;T&gt;</code> 等集合类型是 <code>Sync</code>；</li>
<li>具有内部可变性的的指针，不是 <code>Sync</code> 的，比如 <code>Cell</code>, <code>RefCell</code>, <code>UnsafeCell</code>；</li>
<li><code>Rc</code> 不是 <code>Sync</code>。因为只要一做 <code>&amp;Rc&lt;T&gt;</code> 操作，就会克隆一个新引用，它会以非原子性的方式修改引用计数，所以是不安全的；</li>
<li>被 <code>Mutex</code> 和 <code>RWLock</code> 锁住的类型 <code>T: Send</code>，是 <code>Sync</code> 的；</li>
<li>原始指针（<code>*mut</code>, <code>*const</code>）既不是 <code>Send</code> 也不是 <code>Sync</code>；</li>
</ol>
<p>Rust 正是通过这两大武器：<code>所有权和生命周期</code> + <code>Send 和 Sync</code>（本质上为类型系统）来为并发编程提供了安全可靠的基础设施。使得程序员可以放心在其上构建稳健的并发模型。这也正是 Rust 的核心设计观的体现：内核只提供最基础的原语，真正的实现能分离出去就分离出去。并发也是如此。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><a href="https://github.com/rustcc/RustPrimer">https://github.com/rustcc/RustPrimer</a></li>
</ol>
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>rust</tag>
      </tags>
  </entry>
  <entry>
    <title>远程服务器的 Git 使用本地的密钥——ssh-agent</title>
    <url>/linux/ssh-agent/</url>
    <content><![CDATA[<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>有的时候我们在远程服务器上开发，但是远程服务器有多个人使用，我们并不想把自己的私钥放到服务器上，但是又想通过私钥连接到 Github 等远程仓库，那么该怎么做呢？</p>
<h1 id="SSH-Agent"><a href="#SSH-Agent" class="headerlink" title="SSH Agent"></a>SSH Agent</h1><p>SSH Agent 是一个程序，用于管理多个 SSH 密钥并为 SSH 协议提供身份验证服务。它主要用于以下几点：</p>
<ul>
<li>密钥管理：SSH Agent 可以存储用户的私钥，并在需要时提供给 SSH 客户端，从而避免每次连接时都需要输入密码。</li>
<li>身份验证：当用户尝试连接到远程服务器时，SSH Agent 会自动处理身份验证过程，提高安全性。</li>
<li>多会话支持：用户可以在多个终端会话或应用程序中使用同一个 SSH Agent，而不需要重复加载密钥。</li>
<li>在使用 SSH 进行远程操作时，启动 SSH Agent 并将私钥添加到其中，可以简化连接过程并提高效率。</li>
</ul>
<p>例如，在 Linux 系统中，可以通过以下命令启动 SSH Agent 并添加私钥：<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">eval</span> `ssh-agent -s`<br>ssh-add ~/.ssh/id_rsa<br></code></pre></td></tr></table></figure><br>这样，后续的 SSH 连接将自动使用这些密钥进行身份验证。</p>
<h1 id="在-Windows-上开启-SSH-Agent"><a href="#在-Windows-上开启-SSH-Agent" class="headerlink" title="在 Windows 上开启 SSH Agent"></a>在 Windows 上开启 SSH Agent</h1><p>根据微软帮助，我们能够通过以下方式开启 ssh-agent 并加入我们的私钥：<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># By default the ssh-agent service is disabled. Configure it to start automatically.</span><br><span class="hljs-comment"># Make sure you&#x27;re running as an Administrator.</span><br>Get-Service ssh-agent | Set-Service -StartupType Automatic<br><br><span class="hljs-comment"># Start the service</span><br>Start-Service ssh-agent<br><br><span class="hljs-comment"># This should return a status of Running</span><br>Get-Service ssh-agent<br><br><span class="hljs-comment"># Now load your key files into ssh-agent</span><br>ssh-add <span class="hljs-variable">$env</span>:USERPROFILE\.ssh\id_ecdsa<br><br><span class="hljs-comment"># Check that it worked</span><br>ssh-add -l<br></code></pre></td></tr></table></figure></p>
<h1 id="vscode-中启用-SSH-Agent"><a href="#vscode-中启用-SSH-Agent" class="headerlink" title="vscode 中启用 SSH Agent"></a>vscode 中启用 SSH Agent</h1><p>首先要在 ssh 中开启 <code>ForwardAgent</code>，具体方法是编辑 ssh config：<br><figure class="highlight coffeescript"><table><tr><td class="code"><pre><code class="hljs coffeescript">Host <span class="hljs-keyword">async</span><span class="hljs-number">-004</span><br>    HostName IP<br>    ForwardAgent <span class="hljs-literal">yes</span><br></code></pre></td></tr></table></figure><br>之后在本地的 vsocde 设置中搜索 <code>Enable Agent Forwarding</code> 并开启。</p>
<p>之后 F1 搜索 Kill，关闭远程 vscode server，之后重新连接远程服务器，这个时候远程服务器上输入 <code>ssh-add -l</code> 应该能看到我们之前在 Windows 上添加的私钥，就实现了密钥的安全转发。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_keymanagement">https://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_keymanagement</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/394555196">https://zhuanlan.zhihu.com/p/394555196</a></li>
</ol>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>tensorflow 中的一些坑</title>
    <url>/uncategorized/tensorflow/</url>
    <content><![CDATA[<h1 id="Tensorflow-安装之后无法使用-GPU，但是-Pytorch-可以"><a href="#Tensorflow-安装之后无法使用-GPU，但是-Pytorch-可以" class="headerlink" title="Tensorflow 安装之后无法使用 GPU，但是 Pytorch 可以"></a>Tensorflow 安装之后无法使用 GPU，但是 Pytorch 可以</h1><p>有错误提示：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs pain">tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.<br></code></pre></td></tr></table></figure></p>
<p>原因是 Tensorflow 无法使用 cudnn 的库，找个安装了 Pytorch 的环境，导出其中的 cudnn 路径：<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> CUDNN_PATH=~/miniconda3/envs/sd/lib/python3.12/site-packages/nvidia/cudnn<br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=<span class="hljs-string">&quot;<span class="hljs-variable">$CUDNN_PATH</span>/lib&quot;</span>:<span class="hljs-variable">$LD_LIBRARY_PATH</span><br></code></pre></td></tr></table></figure></p>
<p>之后测试通过：<br><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-built_in">print</span>(tf.test.is_gpu_available())<br></code></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>ai</tag>
      </tags>
  </entry>
  <entry>
    <title>一些杂记</title>
    <url>/uncategorized/%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>本杂记包括了一些思考和记录，具体涉及到的内容包括：</p>
<ul>
<li><a href="https://space.bilibili.com/391930545/channel/collectiondetail?sid=598034">Maki的完美算术教室的个人空间-Maki的完美算术教室个人主页-哔哩哔哩视频 (bilibili.com)</a></li>
</ul>
<h1 id="如何高效地读数学书"><a href="#如何高效地读数学书" class="headerlink" title="如何高效地读数学书"></a>如何高效地读数学书</h1><p>“the best way to learn is to teach“. 学习的方法按效率从低到高可以排为</p>
<ul>
<li>传统的上课听讲模式, 完全被老师牵着鼻子走</li>
<li>自己啃书, 补全细节, 勤用互联网, 老师, 同学等资源</li>
<li>以教会别人为目的的学习</li>
</ul>
<p><strong>数学的核心</strong>（对于小学数学、中学数学、大学数学乃至数学家学习数学都是需要掌握这些，数学的核心对于不同人可以不一样）</p>
<ul>
<li><strong>概念</strong>（不是每一个概念都是重要的概念，但是作为老师教的每一个概念都是重要的）</li>
<li><strong>定理</strong>（连接不同的概念，有些是联系（贯穿）两个领域，用A领域的方法解决B领域的问题）</li>
<li><strong>方法</strong>（最难教的就是方法。概括，归纳，总结之后才会有方法。每一门数学（代数，分析，几何）都有对应的方法。方法和经验成正比。方法有基础和进阶的，学会性质和做练习掌握基本的方法，通过掌握引理和定理加做练习掌握高级的方法）</li>
</ul>
<p><strong>数学书的内容</strong></p>
<ul>
<li><strong>定义</strong>：花很多时间在问自己为什么这么定义（看数学书很多时候，搞明白了为什么这么定义才能读懂。定义是必须要记住的，定理性质引理都是围绕定义概念展开）</li>
<li>例子（证明）</li>
<li>性质（证明）（定义的简单性质）</li>
<li>引理（证明）</li>
<li>定理（（包含推论）（证明）（历史上很多时候是先有定理）怎么记住定理：问自己为什么会有这个定理）要能举出例子，不能停留在会证明。定理是非常重要的命题。群同构第一定理为什么重要，因为很多地方用到</li>
<li>练习（证明）</li>
</ul>
<h1 id="如何燃起自己的热情"><a href="#如何燃起自己的热情" class="headerlink" title="如何燃起自己的热情"></a>如何燃起自己的热情</h1><h2 id="有限VS无限"><a href="#有限VS无限" class="headerlink" title="有限VS无限"></a>有限VS无限</h2><p>当你的目标有限时，你就有了一个上确界，不会超过它。比如拿菲尔茨奖不是一个好目标，一是比较虚荣，二是拿到了之后论文数量少了25%，而且写出来论文引用频率下降了（菲尔茨奖的魔咒）。</p>
<p><strong>理想情况</strong>是目标趋于+∞，目标是变动的，趋于+∞越快越好。</p>
<h2 id="热情从何而来"><a href="#热情从何而来" class="headerlink" title="热情从何而来"></a>热情从何而来</h2><p>最小的想法是一个小火苗，可遇可不求。弱者思维会觉得很好笑，并评价自己肯定做不到，自我菲薄，强者思维也会笑，笑完之后觉得是可行的，并专注地执行下去，一直坚持。</p>
<p>坚持坚持再坚持，直到一个里程碑（反馈，新的热情）。</p>
<p>真正阻碍你的<strong>只有你自己</strong>。</p>
<p>没有借口、阻力、绝对要求，每天至少8小时。切勿三分钟热度， 每天都学，可以少量的微习惯。由积分中值定理可知，<strong>平均值</strong>很重要。</p>
<h2 id="纯粹"><a href="#纯粹" class="headerlink" title="纯粹"></a>纯粹</h2><p>不想太多，不去纠结，想想自己的目标，今天要写多少页讲义。</p>
<p>重在每天的努力，120分钟的电影，在人生中是努力119分钟，成功1分钟。</p>
<h2 id="一定完成的紧迫感"><a href="#一定完成的紧迫感" class="headerlink" title="一定完成的紧迫感"></a>一定完成的紧迫感</h2><p>每天早晨醒来，第一个想法是冥想。不必放假，每天时刻有一定要完成的紧迫感，一定要把“家里的漏水”处理好。重要的事，内因，非做不可，不做不行，日拱一卒。</p>
<h2 id="承诺"><a href="#承诺" class="headerlink" title="承诺"></a>承诺</h2><p>你敢不敢承诺？弱者思维不敢承诺，承诺了就一定要去做到，可以晚点。积分总值会是100，但是平均相对会动态变化。</p>
<p>先胜后战：先确定自己能大概率打赢，再去打，心里有数。不可以心里没数没有目标再去做事！</p>
<p>战什么？人性。不动脑子，是懒惰；想得太多。是贪婪。是在承诺的先决条件下，最好的状况是中庸和谐。</p>
<h2 id="不要让热情一次性烧完"><a href="#不要让热情一次性烧完" class="headerlink" title="不要让热情一次性烧完"></a>不要让热情一次性烧完</h2><p>手机到1%充电也可以，不要烧完。但是0%关机了再充电，就是要几分钟才能启动，内心要承受巨大的压力。</p>
<h1 id="克服自己的无知和无能"><a href="#克服自己的无知和无能" class="headerlink" title="克服自己的无知和无能"></a>克服自己的无知和无能</h1><p>无知不意味着自己的愚蠢、不思上进、头脑空空，而是意味着自己承认自己的认知（知识、思维等）存在盲区，需要提升。即承认无知不是否定自己，而是承认自己存在进步空间。</p>
<p>无能同理，是承认自己没有做到本可以做到的事情，而非自我贬低成废物。 如何克服？很难，要吃苦。</p>
<p>欲戴王冠，必承其重。 </p>
<p>我们很容易将平易的生活看做理所当然，将他人的成功看做天才的必然，殊不知生活中有许多等着我们处理的事，他人为了成功做出改变、克服困难、花费努力。 </p>
<p>这是一种认知上的“桎梏”，需要跳出过去的失败、现在的迷惘、“娱乐至死”的陷阱以及情绪化的泥淖。</p>
<h2 id="克服“情绪无能”"><a href="#克服“情绪无能”" class="headerlink" title="克服“情绪无能”"></a>克服“情绪无能”</h2><p>（即沉湎于无尽或突然的情绪之中并无法自拔，对学业、事业产生长期或短期的恶性影响）</p>
<p>下法“替代批判”，用（某种角度或层面的）事实来替代：如生气→他人的问题，自卑、沮丧→自己的问题。</p>
<p>在面对自己的问题时，不可一味否定自己，尊重事实，并且给予自己鼓励。</p>
<p>中法“不批判”，跳出情绪的坑，不过多浪费时间。 上法“化批判为动力”，不受影响，从批判中汲取动力向前。</p>
<p>我们可以将“评价”、“情绪”、“结果”进行一个剥离。通常的逻辑是不理想的结果→较低的自我评价→负面情绪→下次行动时逃避或“惯性失败”循环。</p>
<p>客观认识不理想的结果，分析出其中的主客观上的问题，提升自己的认知与能力；客观认识情绪，知道情绪是长期进化所形成的，接纳情绪而非为情绪所困；正视自己，不夸大自己的能力，也不轻易贬低自己。</p>
<h2 id="克服“事业无能"><a href="#克服“事业无能" class="headerlink" title="克服“事业无能"></a>克服“事业无能</h2><p>（即不能做/做好事情，指事项、事务、事业）</p>
<p>（1）依旧是克服情绪化，即情绪干扰做事；（2）投入与产出，即用相对客观的视角评价目前的方法、进度；（3）人与贡献，更加注意区分数量与质量。</p>
<p>做事不能只凭着一腔热血或者跟着感觉走，就好比走路，一个人不可能在不知道自己的方向、位置、速度、时间的情况下走到终点，因此做事时必然要不时进行评估。同时在许多情况下，数量堆叠不能换来质量飞升，但是许多人早已习惯把数量当质量，就如同盲目刷题那样，不知所以。</p>
<p>（4）把握关键目标（某种意义、价值），并且将其拆解成可执行、可评价的阶段目标。</p>
<p>（5）识别做事的关键方法，并且无局限地优化。 所做的事情拥有某种崇高价值时人才会有较强的动力，但虚无缥缈的目标不利于指导人的行为，因此要进行拆解。至于优化方法，则是一种不断优化、追求进步的突破，这种突破的追求往往因为得过且过的心理而不能发生，因此要保持这种追求。</p>
<p>（6）小本本记想法 看起来简单甚至有些笨的想法，但是功用巨大。记录想法、做法、结果，我想我可以尝试（总是苦恼某些碎片化的想法转瞬即逝）。 </p>
<p>（7）突破认知、超越前人。“圣人无常师”，学习是为了提升自己，而当有超越一位老师（亦或是友人、亲长、前辈等）的心思时，才有了站在ta的肩上拾级而上、继续发展的基础。 </p>
<p>（8）批判性视角。从局中抽离，准确认知人事物。</p>
<p>“无能之无能” 认识到能力问题，不回避能力问题，解决能力问题。 </p>
<p>问题是提升能力问题很痛苦。 解决自己的无能、解决情绪化、解决愚笨（慢反应）与小聪明（自以为是）。 </p>
<p>将自己与社会、世界联系起来，不能遗世而独立。 继承昨日的优秀，改善昨日的问题，让问题在今日消失，让渺远的未来不在迷惘。</p>
<h1 id="学习专注力"><a href="#学习专注力" class="headerlink" title="学习专注力"></a>学习专注力</h1><p>1、SMART Goal原理 围绕一个目标专注（目标感）</p>
<p>Specific 具体的<br>Measurable 可量化<br>Attainable 可实现<br>Reward 奖励，适当奖励<br>Time 时间投入</p>
<p>常见误区：高估一天能做到的事情，低估一年能做到的事情。急于求成，没有长期规划，没有持续投入。</p>
<p>2、在于质量，不在于数量，追求效果</p>
<p>3、环境很重要，避免干扰</p>
<p>4、专注力锻炼，干扰下强制专注</p>
<p> 5、避免社会诱惑的干扰</p>
<p>6、善于利用辅助工具，减少工作量，提升正向反馈出现的概率。</p>
<h1 id="预备队思想"><a href="#预备队思想" class="headerlink" title="预备队思想"></a>预备队思想</h1><p>以正合以奇胜。</p>
<p>奇兵：预备队</p>
<p>未雨绸缪</p>
<p>凡事预则立，不预则废</p>
<h1 id="关于嘲笑"><a href="#关于嘲笑" class="headerlink" title="关于嘲笑"></a>关于嘲笑</h1><p>本质：传递负面能量的方式，人性之恶。</p>
<p>一种刻意塑造的对立和优越感，是为浮躁。</p>
<p>「千万不要像……样子」、「你什么档次，跟我……」</p>
<p>刻意对立 <code>-&gt;</code> 抬高优越感 <code>-&gt;</code> 嘲笑不断 <code>-&gt;</code> 形成本能</p>
]]></content>
  </entry>
  <entry>
    <title>阿德勒心理学讲义</title>
    <url>/uncategorized/%E9%98%BF%E5%BE%B7%E5%8B%92%E5%BF%83%E7%90%86%E5%AD%A6%E8%AE%B2%E4%B9%89/</url>
    <content><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>本文是对《阿德勒心理学讲义》的总结和记录</p>
<p><strong>子曰：“仁远乎哉？我欲仁，斯仁至矣。”</strong></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>阿尔弗雷德·阿德勒（Adler Alfred,1870-1937），奥地利心理学家，个体心理学派创始人，人本主义心理学先驱，现代自我心理学之父。阿德勒认为人们为得到满足和实现自我而一生努力奋斗，以补偿产生自童年时期的强烈自卑感。大部分人可以满意地实现补偿，而那些没有成功实现补偿的则发展为神经症。他与弗洛伊德和荣格并称为20世纪精神分析学派三大巨擘。</p>
<p>阿德勒出生在奥地利维也纳郊区的一个犹太粮商家庭，家境富裕。他在家中六个孩子中排行老三。3岁时，睡在身旁的弟弟去世，他幼年又有两次被车撞的经历，使他十分畏惧死亡。5岁时得了肺炎，痊愈后他决定当医生。</p>
<p>1895年，阿德勒进入维也纳大学学习，取得医学博士学位，成为一名眼科医师，他特别注意身体器官的自卑，认为它是驱使个人采取行动的真正动力。后转向精神病学研究，曾追随弗洛伊德探讨神经症问题。</p>
<p>1896年4月到9月，他应征服役，在奥地利军队的一所医院工作。1897年到1898年，他又回到维也纳大学深造。期间，他和来自俄国的留学生罗莎（Raissa Timofeyewna Epstein）结婚。他们生育四个孩子，三女一男，其中亚历山德拉（Alexandra）和库尔特（Kurt）后来成为阿德勒学派的心理学家。</p>
<p>1899年至1900年，他与弗洛伊德在同一个城市行医，两人结识并成为好友。不久，他又和威廉·斯特克尔一起从事《心理分析汇编》的编辑工作。1902年，阿德勒与精神分析创始人弗洛伊德成为当时精神分析学派的核心成员。他是第一个虔诚地对弗洛伊德理论产生兴趣的人，认识到其理论打开了精神病学和心理学一个新发展阶段。</p>
<p>1908年在奥地利萨尔茨堡召开的第一次国际心理分析会议上，阿德勒发表了关于“好斗的冲动”的报告。1910年任维也纳精神分析学会主席。1911年因突出强调社会因素的作用，拒绝接受弗洛伊德将性作为人类行为的重要动机的观点，公开反对弗洛伊德的泛性论而两人关系破裂，阿德勒创立个体心理学（Individual Psychology），另建自由精神分析研究会。1912年改称个体心理学会，成为一个颇有影响的学派。1914年他创办《国际个体心理学杂志》。1920年后他任教于维也纳教育学院，并在学校系统中组织儿童指导临床活动，成立儿童指导中心。1922年至1930年期间，他主持召开了五次国际个体心理学会议。1926年任美国哥伦比亚大学客座教授。1932年他到长岛医学院主持美国医学心理学的第一个讲座。1934年定居纽约。1937年赴苏格兰亚伯丁做讲演旅行时病逝。</p>
<p>阿德勒的学说以“自卑感”与“创造性自我”为中心，并强调“社会意识”。主要概念是创造性自我、生活风格、假想的目的论、追求优越、自卑感、补偿和社会兴趣。他继承了弗洛伊德的精神分析理念，但其基本观点与之大相径庭。</p>
<p>个体心理学认为人的行为是由社会力量决定的。阿德勒认为人天生就是一种社会存在物，在社会生活中，人们进行交往，相互依赖，相互合作；而弗洛伊德则强调人的生物学本能，人的成长过程是本能的自然展开，其行为是先天决定的。</p>
<p>个体心理学视人格为统一的整体，强调其不可分割。阿德勒认为每个人的人格都是内在各种动机、特质、兴趣、价值所构成的统一整体；弗洛伊德把人格分为本我、自我、超我这些不同的部分，各部分各司其职。</p>
<p>阿德勒认为人是一个有意识的存在物。通常，人能意识到行为的动机，意识与无意识并非绝对对立。对某些事物，如果我们意会到了，那么就是意识的；如果失于意会，那么就是无意识的。意识的行为是人类主要的行为。</p>
<p>阿德勒强调未来对人的行为的影响。他认为，人既然是有意识的，就能意识到未来的种种条件，制定某种计划用以指导自己的行为。阿德勒也承认过去的经验（特别是原始的经验）对人的行为有影响，但他认为不是决定性的。</p>
<p>个体心理学认为性只是人类行为的动力因素之一。阿德勒并不完全否认性的作用，但他认为性的作用在决定人的行为方面只扮演一个极不重要的角色。他认为，真正对人的行为起作用的还是人的社会需要。</p>
<p>阿德勒个体心理学思想主要概念包括以下方面：</p>
<p>一是追求优越。阿德勒认为，追求优越是人们行为的根本动力，也是阿德勒个体心理学的核心。他认为人人都有一种向往权力意志这种天生的内驱力，力图做一个没有缺陷的、完善的人。因此羡慕别人、胜过别人、征服别人等都是这种追求优越的人格体现。阿德勒区分了追求优越的两种不同方法：一种是只追求个人优越，很少关心他人，其行为往往受过度夸张的自卑感驱使。另一种是追求一种优越、完善的社会，使每个人都获得益处。</p>
<p>二是自卑与补偿。阿德勒把自卑与补偿看作是追求优越的动力根源。他指出，自卑与补偿是与生俱来的。因为人在婴幼儿时期，在生理、心理和社会三方面都处于劣势，需要依赖成年人才能生存，他们由此必然产生自卑和补偿心理。当然，这种自卑与补偿心理在大多数情况下是正常的健康的反应，可以驱使人们实现自己的潜能。但是，如果不能成功地进行补偿，就会产生自卑情结，导致心理疾病的发生。</p>
<p>三是生活风格。阿德勒把个人追求优越的目标的生活方式称为生活风格。阿德勒认为儿童到5岁左右便形成了生活风格。其家庭关系、生活条件和经验决定了他今后一生的生活特点。他提出三种研究途径：出生顺序、早期记忆和梦的分析。</p>
<p>他指出，在家庭中，父母对子女教养的方式或给予的关注会根据子女的出生顺序而变化，同胞兄弟姐妹之间也常常因要争取父母的爱而相互竞争。因此，长子的性格特征是聪明、有成就需要但害怕竞争；次子喜欢竞争、有强烈的反抗性；最小的孩子有雄心但懒散、难以实现抱负。独生子女的性格类似于长子，因为其竞争对手往往来自学校的同学。</p>
<p>阿德勒根据人的记忆具有主观性、创造性和想象性的特点，认为个体对于自己早年生活的记忆往往为人们了解其独特的个性提供了线索。阿德勒认为意识和潜意识共同构成一个统一的整体，因此，梦能够显示一个人的生活风格。</p>
<p>四是创造性自我。阿德勒认为，每个人在形成自己的生活风格时并不是消极被动的，人是有意识的个体，可以选择自己的生活道路，参与决定自己的命运。创造性自我能够使我们成为自己生活的主人，决定了人的心理健康与否、社会兴趣正确与否。影响人的成长有三个要素，即遗传、环境和创造能力。其中创造能力起重要作用，它与其他两个要素结合起来，才能克服人生障碍。阿德勒反对弗洛伊德的宿命论观点，他认为人从遗传与早期经验中获得的只是一些“砖块”。它追求经验，甚至创造经验以帮助个人完成他独特的生活作风。</p>
<p>五是社会兴趣。社会兴趣是阿德勒个体心理学中的基本概念之一，是指对所有社会成员的一种情感，或指人具有一种为他人、为社会的先天思想准备和自然倾向。他认为人是社会性生物，人的本性具有社会兴趣的潜能。社会兴趣不仅是一种涉及与别人交往时的情感，它也是一种对生活的评价态度和认同能力。阿德勒还认为有无社会兴趣是衡量个体是否健康的主要标准，社会兴趣的水平决定一个人生活意义的大小和对社会贡献的程度。阿德勒认为社会兴趣是人类本性的一部分，植根于每个人的潜能之中，因此，必须先发展起社会兴趣，才能形成有用的生活风格。</p>
<p>阿德勒指出，可以通过人们的职业选择、参与社会活动和爱情婚姻这三大任务的解决情况来衡量其社会兴趣的发展状况。三大任务的顺利解决反映了个体具有丰富的社会兴趣，反之则是缺乏社会兴趣。缺乏社会兴趣的人会产生两种错误的生活风格：一种是优越情结；另一种是自卑情结。他还根据人们所具有的社会兴趣表现的特点，把人划分为四种类型：一是统治——支配型；二是索取——依赖型；三是回避型；四是社会利益型。他认为，前三种类型的人的社会兴趣和生活风格都是错误的，只有第四种类型的人具有正确的社会兴趣和健康的生活风格。</p>
<p>1927年，《阿德勒心理学讲义》（又译作《生活的科学》，The Science of Living）在英国首次出版，书中包括了个体心理学的主要原则。本书尤其有趣的是阿德勒的研究方法，他用大量的例子来说明他提出的理论观点。贯穿全书的主线是具有社会需要的理解和我们的意愿，有效地尽我们所能，为公共福利做出贡献的重要性。读者还会发现，常识在阿德勒的思维中起着重要作用。事实上，有一个故事，在一次心理学讲座上，有人评论他所说的一切都是些常识。“常识有什么不好？”他回答说。</p>
<p>阿德勒致力于倡导与人直接相关的心理学，即生活的心理学，他教给我们生活的“常识”，帮助我们了解自己的人生目标，从而活出生命的意义。人与生俱来就有追求成功和幸福的意愿，但并非总能如愿以偿。阿德勒认为，人如果丧失了具有社会价值的人生目标，就会产生自卑情结，从而陷入无益的生活面向。</p>
<p>阿德勒首创“自卑情结”一词，首度将“补偿作用”运用于心理学，开创了心理自助运动的先河——帮助人们与自卑感共存共荣，拥有有益的人生目标，进而活出生命的意义。</p>
<p>阿德勒指出：“每个人都有自卑感。”他所创立的个体心理学，紧扣“自卑感的问题与力量”发展，形成一套阿德勒的不完美生活哲学。自卑感是人类努力与成就的基础，却也是一切心理问题的根源。因此，阿德勒深入分析自卑感，揭开其副产品——“自卑情结”与“优越情结”对人们的戕害，并提出过好生活该有的“常识”“社会兴趣”与“社会适应能力”，期盼能帮助人们与自卑感共存共荣，消除情结的障碍，设定有用与健全的人生目标，进而活出生命的意义。</p>
<p>阿德勒主张，决定我们生活形态的“人生风格”（the style of life）在四五岁时就由“人生原型”决定。因此，对于孩童的教育要从小开始，而且方向必须正确。童年时期如果出了差错（如父母过于溺爱），未来就得付出很大的代价（如犯罪）。而对于行为出现偏差的人，最好的方法就是减低他们的自卑感（但无须完全根除，因为自卑感也是让人向上的力量），让他们发展出对人生有用的“社会兴趣”（social interest），进而导正他们的人生目标。</p>
<p>《阿德勒心理学讲义》以社会兴趣为核心，从原型、人格、童年、家庭、梦境、教育、人际关系、爱情与婚姻等人生百景出发，论道说理，揭示重点，并用形形色色的临床故事，来阐释、佐证，非常具有可读性和教育意义。</p>
<p>通过本书，你将能正确地认识自己，拥抱人人都有的自卑感，并将其化为养分，萌生勇气，面对一切挑战与逆境。</p>
<p>人，因不完美而奋发向上，而人生会因不完美而更趋完美。</p>
<p>阿德勒说：人，做得到任何事！他不在乎过去，不认同宿命论与天注定，主张事在人为，并如此相信：唯有你自己，能决定你人生的样貌；也唯有你自己，才能改写人生的剧本。阿德勒用一生观察并剖析“何而为人”，终得此结论。</p>
<h1 id="生活的科学-The-Science-of-Living"><a href="#生活的科学-The-Science-of-Living" class="headerlink" title="生活的科学-The Science of Living"></a>生活的科学-The Science of Living</h1><p>以阿德勒来说，他对心理学的兴趣源于行医。行医让我明了目的论（又称目标论）的观点。如果想了解心理事实，目的论是不可或缺的</p>
<p>在医学界，所有的器官都有明确的目标，并朝着该目标努力发展，等发展到一定的形态，就代表这些器官已发育成熟。此外，当器官出现缺陷时，自然会采取特别的方式来克服缺憾，或者改由其他器官承担缺损器官的功能。<strong>生命总会设法延续下去，而且在面对外来阻碍时，生命的力量绝不会还没挣扎就先高举白旗。</strong></p>
<p>人类心理层面的活动也和生命的功能面向类似。<strong>每一个人心里都有一个类似目标或理想的概念，一心想要超越现状，并通过制订出具体的未来方向，来克服目前的缺憾和困难。通过这个具体目标，人们得以想象未来成功的样貌，进而感受并认定自己必能超越当下的困境。要是感受不到目标，个人的所作所为只是行礼如仪，毫无意义可言。</strong></p>
]]></content>
  </entry>
  <entry>
    <title>非暴力沟通</title>
    <url>/uncategorized/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E6%B2%9F%E9%80%9A/</url>
    <content><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>本文是对《非暴力沟通-两性篇》的总结和记录</p>
<p><strong>子曰：“仁远乎哉？我欲仁，斯仁至矣。”</strong></p>
<p>作者的核心观点是：人的需要在得到满足的时候会产生一些感受，在没有得到满足时会产生另一些感受。我们需要听到感受和隐藏在感受之后的核心需要以及对方需要我们怎么做来满足他们的核心需要。</p>
<p>我没有把他写成正面感受或者负面感受，是因为作者认为负面情绪和正面情绪都是有价值的，因为它们都是对生命的诉说，即都表达了需求有没有得到满足。（如果你爱的人愿意将自己的痛苦表达出来，你是否会认为这是一种消极和不愉快的体验呢？）</p>
<p>当我们开始生气或即将发动攻势时，我们首先要做的就是意识到我们可能没有听清对方的话。</p>
<p>少评判，多想想对方到底想表达什么。</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h2 id="感受词汇卡"><a href="#感受词汇卡" class="headerlink" title="感受词汇卡"></a>感受词汇卡</h2><h3 id="需要得到满足时的感受"><a href="#需要得到满足时的感受" class="headerlink" title="需要得到满足时的感受"></a>需要得到满足时的感受</h3><p>兴奋、喜悦、欣喜、甜蜜、精力充沛、兴高采烈</p>
<p>感激、感动、乐观、自信、振作、振奋、开心、高兴</p>
<p>快乐、愉快、幸福、陶醉、满足、欣慰、心旷神怡</p>
<p>喜出望外、平静、自在、舒适、放松、踏实、安全</p>
<p>温暖、放心、无忧无虑</p>
<h3 id="需要没有得到满足时的感受"><a href="#需要没有得到满足时的感受" class="headerlink" title="需要没有得到满足时的感受"></a>需要没有得到满足时的感受</h3><p>害怕、担心、焦虑、忧虑、着急、紧张、心神不宁</p>
<p>心烦意乱、忧伤、沮丧、灰心、气馁、泄气、绝望</p>
<p>伤感、凄凉、悲伤、恼怒、愤怒、烦恼、苦恼、生气</p>
<p>厌烦、不满、不快、不耐烦、不高兴、震惊、失望</p>
<p>困惑、茫然、寂寞、孤独、郁闷、难过、悲观、沉重</p>
<p>麻木、精疲力尽、萎靡不振、疲惫不堪、昏昏欲睡</p>
<p>无精打采、尴尬、惭愧、内疚、妒忌、遗憾、不舒服</p>
<h2 id="两性相处时的典型冲突"><a href="#两性相处时的典型冲突" class="headerlink" title="两性相处时的典型冲突"></a>两性相处时的典型冲突</h2><p>女性认为男性并没有清楚地表达出自己内心的感受和想法，像约翰·韦恩这样的男人就是通过简单粗暴地给别人“贴标签”模式来交流的，即在他的眼里，要么是好人，要么是坏蛋，是好人就请他喝一杯，是坏人就直接干掉好了。</p>
<p>通过这样的沟通方式，很多男人根本不知道怎样和自己的情绪建立联系。事实上，作为一名男性，作者（马歇尔）之前接受的基本上也是这种沟通方式的训练。如果他被训练成了一名战斗英雄，那么他就不希望自己的意识受制于自己的感受。所以，对于一个可能一直在玩洋娃娃的女人来说，嫁给一个长年在枪林弹雨里摸爬滚打的战斗英雄并不见得是一种很美好的体验。因为女人希望他们之间保持亲密，而这位战斗英雄的词典中压根儿就没有“亲密”这个词。</p>
<p>另外，很多女人并没有学会怎样清楚地了解自己的需要。几个世纪以来，她们被灌输的思想都是如何忽略和克制自己内心的需要，以体谅和照顾男人的感受。因此，她们常常依赖于男人的引领，并在某种程度上期望男人能够猜出她们需要什么、想要什么，继而顾及并满足她们的需要。</p>
<h1 id="关于婚姻"><a href="#关于婚姻" class="headerlink" title="关于婚姻"></a>关于婚姻</h1><p>由于我们被灌输了太多关于“婚姻意味着什么”的疯狂观念，所以我们会发现，维系夫妻间的婚内关系要比处理情侣间的未婚关系复杂得多。但同时，我发现，当我不再把和我一起生活的那个人看作“我的妻子”的时候，我就能更好地享受婚姻，因为在我所处的文化环境中，当有人提到“我的妻子”时，他会不由自主地认为妻子是他的某种私人财产。</p>
<p>非暴力沟通能帮助我们建立起一种关系，在这种关系中，我们彼此能够发自内心地互相给予。这就意味着，当与伴侣相处时，我们不会再因为自己顶着“妻子”“丈夫”的名头而暗含着我们“有责任”、“有义务”、“理应”或“必须”为对方做些什么，也不必再因为内疚、羞愧、潜意识、恐惧、义务或责任而去给予。在我看来，如果我们为伴侣做任何事情都是在这类动因的驱使下才完成的，我们每个人也会因此而迷失自我。当我们接受源自这类动因而被给予的任何东西时，我们也知道自己必将为此付出代价，因为这种给予是以牺牲对方的利益为前提的。因此，非暴力沟通真正令我感兴趣的是，这是一种能够让我们为对方真诚付出的沟通方式。</p>
<p>如果我们学会了发自内心地给予，并在给予时感觉就像接受时一样快乐，结果会怎么样呢？当我们以一种极富人情味的方式去做一件事情时，我认为给予者与接受者并没有太大的区别。反之，当我们以一种我称之为评判的方式彼此互动时，给予才会显得不那么有趣。</p>
<h1 id="四个问题"><a href="#四个问题" class="headerlink" title="四个问题"></a>四个问题</h1><p>你能告诉我，作为你的伴侣或朋友，我曾经做过哪件事，让你感到你的生活不那么美好吗？（观察）</p>
<p>当我做这件令你感到不开心的事时，你的感受如何？（感受）</p>
<p>你的哪些需要没有得到满足呢？（需要）【“我有这样的感受是因为我原本喜欢<strong>_</strong>（或者因为我原本想<strong>_</strong>/原本希望<strong>_</strong>/原本渴望<strong>_</strong>）】</p>
<p>我们能够做些什么，让彼此的生活变得更加美好呢？（请求）</p>
<p>非暴力沟通的主旨就是，在任一特定情境下，将这四个方面的内容准确地传递给对方。当然，我们的需要并不是总能得到满足。在非暴力沟通中，我们也会说“谢谢”，并通过回答前三个问题来告诉对方，他们怎样真正地充实了我们的生活。我们会告诉他们：（1）他们所做的哪些事情充实了我们的人生；（2）我们有什么样的感受；（3）我们的哪些需要因他们的行为而得到了满足。</p>
<h2 id="评判"><a href="#评判" class="headerlink" title="评判"></a>评判</h2><p>阻碍人们坦诚交流的沟通方式主要有两种。第一种是任何听起来含有评判对方之意的讯息。</p>
<p>你只是在第一个问题描述他们的行为时涉及了他们，并没有评判他们的行为。第二个到第四个问题都是关于你自己的：你的感受、你未得到满足的需要和你的请求。如果你的问题中有什么字眼容易被对方听成是对他们的指责，我猜想你肯定是在这四部分内容中夹杂了自己的一些评判。</p>
<h2 id="强制"><a href="#强制" class="headerlink" title="强制"></a>强制</h2><p>第二种阻碍人们坦诚交流的沟通方式是任何带有强迫意味的暗示。作为一名想用非暴力沟通方式进行交流的人，你希望向对方传达你刚才所写下的这四个方面的内容，让他觉得这是一份礼物、一个交心的机会，而不是一种要求或者命令。</p>
<p>在非暴力沟通语言中，评判和命令是要杜绝的。当我们告诉他人自己的请求需要什么时，我们传达的信息是：“如果你愿意，请这样做，但不要以牺牲你自己的需要为代价为我做任何事情，也永远不要为我做任何可能会给你带来哪怕一丝恐惧、内疚、羞愧、怨恨或屈服感的事情，不然，我们都会感到痛苦。请遵从你的内心，如果你觉得，满足我的需要对你自己而言也是一份礼物，那么我希望你能尊重我的请求。”只有当彼此都不觉得自己是在损失、付出或屈服时，这一行为才是双赢的。</p>
<h2 id="同理倾听"><a href="#同理倾听" class="headerlink" title="同理倾听"></a>同理倾听</h2><p>非暴力沟通主要由两个关键部分组成：第一部分是要向对方清楚明白地传达有关这四个方面的信息，但不能让对方觉得你是在评判或者命令他。第二部分则是学会去倾听对方发出的有关这四个方面的信息，而<strong>不要去关注他们是在指责你还是在以非暴力沟通方式与你交流。</strong></p>
<p>例如，当对方说“你知道吗？你的问题就在于<strong><strong>”时，通过这对耳朵我听到的是“我希望你能</strong></strong>”。我并没有听到任何评判、指责或攻击。通过这样一对耳朵，我能够意识到，所有批评都是对方的需要没有得到满足时的一种值得同理的宣泄。</p>
<p>之所以说其值得同理，是因为这样的表达方式通常说明表达者的需要没有得到满足时，会导致各种紧张局面相继出现。凭借非暴力沟通语言的技巧，我们就能够越过这个坎。因为我们从来听不见指责，我们听到的永远只有对方那些<strong>未被满足的需要</strong>。</p>
<h2 id="安慰和同理心的区别"><a href="#安慰和同理心的区别" class="headerlink" title="安慰和同理心的区别"></a>安慰和同理心的区别</h2><p>马歇尔：如果对方说他们确实需要安慰，而与此同时，我们也心甘情愿地想去安慰他们，那就没有什么问题。但如果他们想要的是同理心，而我们给他们的却是安慰，这时，问题就来了。比如，有一次，我的大女儿一边照镜子，一边说：“我丑得像头猪。”“不，你是世界上最美丽的女孩！”我立马说道。她喊了声“爸呀”，然后就摔上门出去了。事实上，我当时就是在那里做着评判，而她其实是希望我留意她的感受，但是我却尝试着去安慰她，我这么做实则是为了满足我自己的需要。然后，你们猜猜我做了什么？我对自己做了一番检讨之后，走进了另外一个房间，边走边说：“你一年到头每一天都在宣扬这个，但当它发生在你自己身上时，你却忘记了。你忘了那句箴言：‘不要急着做什么，站在那里就好。’”之后，我走到她面前，对她说：</p>
<p>我猜你需要的是我能体会到你对自己形象的失望之情，而不是我的安慰。</p>
<p>女儿（参与者I扮演）：是的，你总想着和稀泥敷衍我。（观众发出笑声）</p>
<p>马歇尔：嗯，我认罪。</p>
<h1 id="如何表达感激"><a href="#如何表达感激" class="headerlink" title="如何表达感激"></a>如何表达感激</h1><p>马歇尔：在表达感激时，我们需要记住三个要素。不要试图通过语言去赞扬，因为在非暴力沟通中并没有赞扬之类的东西，赞扬实际上是一种典型的评判技巧。赞扬是为了操纵对方，让对方按照我们希望的方式去行事，而感激则只是表明对方的行为给我们带来了一种美好的感受。经理们会觉得赞扬很管用，他们说，有研究表明，如果他们每天至少赞扬员工一次，员工会更加努力地工作。虽然赞扬在短时间内可能有效，但一旦员工们发现经理们的赞扬是出于操纵他们的目的，赞扬就将失去作用。在非暴力沟通中，我从来不会为了尝试得到任何回报而去表达感激。我们表达感激只是为了去“祝贺”他人的行为，为了让对方知道他们所做的一些事情给我们带来了很棒的感受。表达发自内心的感激的三个要素是：</p>
<p>（1） 我们需要很明确地知道对方做了什么让我们想要感激；</p>
<p>（2） 我们的感受；</p>
<p>（3） 这让我们的什么需要得到了满足。</p>
<h1 id="非暴力沟通对“爱”是如何理解的"><a href="#非暴力沟通对“爱”是如何理解的" class="headerlink" title="非暴力沟通对“爱”是如何理解的"></a>非暴力沟通对“爱”是如何理解的</h1><p>马歇尔：以上阐述可能会让你明白，非暴力沟通实际上来源于我在理解爱、表达爱和践行爱方面所做的尝试。我所得出的结论是，爱不只是我们所感受到的，还是我们所表达的、所做的和所拥有的。同时，爱还是我们能够给予别人的：我们通过某种方式奉献自己的时间和精力。任何时候，当你真诚地展示自己，敞开心扉，别无所求时，这本身就是一种恩赐。不指责，不批评，也不惩罚，只是告诉你自己：“这就是我，这就是我想要的，这就是我脆弱的地方。”而在我看来，这种给予就是爱的表现。</p>
<p>我们对他人的倾听是我们奉献自己的另外一种方式。带着同理心去倾听他人，与他们的内心联系在一起，不做任何评判，这就是一份礼物。当我们尝试去倾听别人的心声和他们想要的东西时，这也是一种礼物。所以，非暴力沟通只是我所理解的爱的一种表现。这么看来，它就类似于“爱人如己”和“不论断人，就不受论断”的观念。</p>
<p>当我们以这种方式与人交流时，不可思议的事情就会发生。这种美、这种力量将我们与一种神奇的能量联系在了一起。所以，非暴力沟通能够帮助我将这种美丽而神圣的能量长留在心中，让我能够通过这种能量与他人建立联系，而这就是我所经历过的最接近于“爱”的东西。</p>
]]></content>
  </entry>
  <entry>
    <title>Higress AI Wasm 插件开发记录</title>
    <url>/higress/higress/</url>
    <content><![CDATA[<h1 id="Higress-背景"><a href="#Higress-背景" class="headerlink" title="Higress 背景"></a>Higress 背景</h1><p>Higress 是基于阿里内部两年多的 Envoy Gateway 实践沉淀，以开源 Istio 与 Envoy 为核心构建的云原生 API 网关。</p>
<p><img  src="overview.png"   style="zoom: 33%;" /><span class="image-caption">image</span></p>
<p>Higress 实现了安全防护网关、流量网关、微服务网关三层网关合一，可以显著降低网关的部署和运维成本。</p>
<p><img  src="云原生网关.png"   style="zoom:50%;" /><span class="image-caption">image</span></p>
<h1 id="Higress-与大模型"><a href="#Higress-与大模型" class="headerlink" title="Higress 与大模型"></a>Higress 与大模型</h1><p>以 ChatGPT 为代表的 AIGC（人工智能生成内容）技术正在引领企业生产的巨大变革，并在企业应用开发领域中占据了重要地位。AI 大模型凭借其卓越的学习和理解能力，可以辅助完成各种复杂的任务，极大地提升了工作效率和创新能力。</p>
<p>在软件开发领域，AI 大模型能够显著提高开发人员的工作效率。它们可以协助编写和调试代码，自动生成测试用例，并提供最佳实践建议，从而加速开发周期，降低错误率。科研领域的研究人员则利用这些模型快速获取和理解最新的科研进展，自动化文献综述和数据分析，节省大量时间和精力。</p>
<p>然而，随着 AI 大模型在企业中的应用不断深入，许多企业开始探索如何降低这些技术的使用成本。一个常见的解决方案是通过网关进行 AI 大模型的 API 管理。这样的管理方式不仅能够集中控制和优化模型的调用频率和资源使用，还可以保障数据安全和隐私合规。通过网关，企业能够灵活地调整使用策略，以更低的成本享受 AI 技术带来的高效益。</p>
<p>Higress 前瞻性地通过 Wasm 实现了LLM Proxy 插件和 AI Assistant 插件帮助开发者快速构建 RAG 应用。</p>
<h1 id="为-Higress-开发-ai-cache-插件的意义"><a href="#为-Higress-开发-ai-cache-插件的意义" class="headerlink" title="为 Higress 开发 ai-cache 插件的意义"></a>为 Higress 开发 ai-cache 插件的意义</h1><p><img  src="arch.png"   style="zoom: 33%;" /><span class="image-caption">image-20240826154248690</span></p>
<p>AI 缓存插件的目标是在构建 AI 应用时，通过智能缓存机制，<strong>减少对LLM提供商API的请求数量，从而降低使用成本，同时确保返回结果的质量</strong>。</p>
<p>在具体实现过程中，Higress AI-Cache 利用向量相似度技术，通过分析和比较用户查询的特征向量，与缓存中已有的查询结果进行匹配。当用户发起新的查询时，Higress 首先计算该查询的向量表示，并在缓存中寻找相似度较高的结果。如果找到足够相似的缓存结果，插件将直接返回该结果，而无需再向LLM提供商API发出新的请求。</p>
<p>该插件适用于多个LLM提供商API，例如通义千问、moonshot、OpenAI等。通过集成这些API，插件可以在不同的AI应用场景中灵活应用，包括但不限于智能客服、内容生成、代码编写和调试等领域。</p>
<p>Higress AI 缓存插件核心优势在于，通过减少不必要的API调用，显著降低了使用大型语言模型的成本。同时，向量相似度技术确保了缓存结果的准确性和相关性，使得用户体验不受影响。插件还具备动态更新和管理缓存的功能，能够根据查询频率和变化情况，自动调整缓存策略，以保持最佳性能。</p>
<h1 id="AI-Cache-插件运行流程"><a href="#AI-Cache-插件运行流程" class="headerlink" title="AI-Cache 插件运行流程"></a>AI-Cache 插件运行流程</h1><p><img  src="seq.png"   style="zoom:50%;" /><span class="image-caption">image-20240826155252868</span></p>
<ol>
<li>当用户请求 LLM API 时，首先在 AI-Cache 插件中对用户的请求内容进行 Embedding 操作，将用户的请求转换为向量数据。</li>
<li>之后在向量数据库中进行相似度搜索。当相似度高于预先设定的阈值时直接返回 Cache 中的内容，不请求 LLM API。否则执行下一个步骤。</li>
<li>当相似度低于预先设定的阈值时，使用 AI-Proxy 插件进行请求转发，向 LLM API 发送请求。并将请求结果缓存在本地的向量数据库中，并把结果返回给用户。</li>
</ol>
<h1 id="Docker-compose-部署-Higress-进行插件开发"><a href="#Docker-compose-部署-Higress-进行插件开发" class="headerlink" title="Docker compose 部署 Higress 进行插件开发"></a>Docker compose 部署 Higress 进行插件开发</h1><p>使用 K8s 进行 Higress 开发时复杂度较高，这里介绍使用 Docker compose 开发的方法。</p>
<h2 id="docker-compose-文件编写"><a href="#docker-compose-文件编写" class="headerlink" title="docker-compose 文件编写"></a>docker-compose 文件编写</h2><p>首先是 <code>docker-compose.yml</code> 文件的编写，这里给出我使用的文件内容，其中的要点主要有：</p>
<ol>
<li>对 higress 的环境变量设置：<code>--component-log-level wasm:debug</code> 和 <code>/etc/envoy/envoy.yaml</code> 分别指定日志级别和配置文件。</li>
<li>wasm 文件和 envoy.yaml 文件的映射。</li>
<li>higress 的上游服务需要和 higress 在同一个 network 中。</li>
<li>higress 的上游服务需要在 higress 之前启动完成。</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.7&#x27;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">envoy:</span><br>    <span class="hljs-comment"># image: higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/gateway:v1.4.0-rc.1</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/gateway:1.4.2</span><br>    <span class="hljs-attr">entrypoint:</span> <span class="hljs-string">/usr/local/bin/envoy</span><br>    <span class="hljs-comment"># 注意这里对wasm开启了debug级别日志，正式部署时则默认info级别</span><br>    <span class="hljs-attr">command:</span> <span class="hljs-string">-c</span> <span class="hljs-string">/etc/envoy/envoy.yaml</span> <span class="hljs-string">--component-log-level</span> <span class="hljs-string">wasm:debug</span><br>    <span class="hljs-attr">depends_on:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">httpbin</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">redis</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">chroma</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">es</span><br>    <span class="hljs-attr">networks:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">wasmtest</span><br>    <span class="hljs-attr">ports:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;10000:10000&quot;</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9901:9901&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">./envoy.yaml:/etc/envoy/envoy.yaml</span><br>    <span class="hljs-comment"># 注意默认没有这两个 wasm 的时候，docker 会创建文件夹，这样会出错，需要有 wasm 文件之后 down 然后重新 up</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">./ai-cache.wasm:/etc/envoy/ai-cache.wasm</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">./ai-proxy.wasm:/etc/envoy/ai-proxy.wasm</span><br><br>  <span class="hljs-attr">chroma:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">chromadb/chroma</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;8001:8000&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">chroma-data:/chroma/chroma</span><br><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis:latest</span><br>    <span class="hljs-attr">networks:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">wasmtest</span><br>    <span class="hljs-attr">ports:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;6379:6379&quot;</span><br><br>  <span class="hljs-attr">httpbin:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">kennethreitz/httpbin:latest</span><br>    <span class="hljs-attr">networks:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">wasmtest</span><br>    <span class="hljs-attr">ports:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;12345:80&quot;</span><br><br>  <span class="hljs-attr">es:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">elasticsearch:8.15.0</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;TZ=Asia/Shanghai&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;discovery.type=single-node&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;xpack.security.http.ssl.enabled=false&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;xpack.license.self_generated.type=trial&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;ELASTIC_PASSWORD=123456&quot;</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">wasmtest</span><br><br><span class="hljs-attr">volumes:</span><br>  <span class="hljs-attr">weaviate_data:</span> &#123;&#125;<br>  <span class="hljs-attr">chroma-data:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">local</span><br><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">wasmtest:</span> &#123;&#125;<br></code></pre></td></tr></table></figure>
<h2 id="envoy-yaml-文件编写"><a href="#envoy-yaml-文件编写" class="headerlink" title="envoy.yaml 文件编写"></a>envoy.yaml 文件编写</h2><p>在这里踩过许多坑，一一记录下来：</p>
<ol>
<li>在 wasm 插件中如果需要请求外部服务，需要在 <code>envoy.yaml</code> 中的 <code>clusters</code> 中一一指定并使用 <code>cluster_name</code> 访问，比如需要访问远程的 Dashscope Embedding 接口，则需要创建 <code>cluster_name</code> 名为 <code>outbound|443||dashvector.dns</code> 的 cluster，之后在代码中通过以下方式访问：</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">client := wrapper.NewClusterClient(wrapper.DnsCluster&#123;<br>			ServiceName: c.serviceName,<br>			Port:        c.servicePort,<br>			Domain:      c.serviceHost,<br>		&#125;)<br></code></pre></td></tr></table></figure>
<p>   这里的 client 支持以下方法：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> HttpClient <span class="hljs-keyword">interface</span> &#123;<br>	Get(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Head(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Options(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Post(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Put(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Patch(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Delete(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Connect(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Trace(path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>	Call(method, path <span class="hljs-type">string</span>, headers [][<span class="hljs-number">2</span>]<span class="hljs-type">string</span>, body []<span class="hljs-type">byte</span>, cb ResponseCallback, timeoutMillisecond ...<span class="hljs-type">uint32</span>) <span class="hljs-type">error</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>   <strong>注意，这里的 HttpClient 是异步的，所以如果需要对结果进行处理之后再继续进行，则需要把逻辑写在 <code>ResponseCallback</code> 中。</strong></p>
<ol>
<li>如果请求的服务是 HTTPS，则需要在 <code>cluster</code> 中指定是 <code>tls</code> 以及服务对应的 <code>sni</code>。</li>
<li>envoy.yaml 里配置 Redis cluster 时，socketAddr 要尽量用 IP，不要用主机名。详细原因在 Wasm 插件编写中解释。</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">admin:</span><br>  <span class="hljs-attr">address:</span><br>    <span class="hljs-attr">socket_address:</span><br>      <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>      <span class="hljs-attr">address:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>      <span class="hljs-attr">port_value:</span> <span class="hljs-number">9901</span><br><span class="hljs-attr">static_resources:</span><br>  <span class="hljs-attr">listeners:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">listener_0</span><br>    <span class="hljs-attr">address:</span><br>      <span class="hljs-attr">socket_address:</span><br>        <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>        <span class="hljs-attr">address:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br>        <span class="hljs-attr">port_value:</span> <span class="hljs-number">10000</span><br>    <span class="hljs-attr">filter_chains:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">filters:</span><br>      <span class="hljs-comment"># httpbin</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">envoy.filters.network.http_connection_manager</span><br>        <span class="hljs-attr">typed_config:</span><br>          <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager</span><br>          <span class="hljs-attr">scheme_header_transformation:</span><br>            <span class="hljs-attr">scheme_to_overwrite:</span> <span class="hljs-string">https</span><br>          <span class="hljs-attr">stat_prefix:</span> <span class="hljs-string">ingress_http</span><br>          <span class="hljs-attr">route_config:</span><br>            <span class="hljs-attr">name:</span> <span class="hljs-string">local_route</span><br>            <span class="hljs-attr">virtual_hosts:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">local_service</span><br>              <span class="hljs-attr">domains:</span> [<span class="hljs-string">&quot;*&quot;</span>]<br>              <span class="hljs-attr">routes:</span><br>              <span class="hljs-bullet">-</span> <span class="hljs-attr">match:</span><br>                  <span class="hljs-attr">prefix:</span> <span class="hljs-string">&quot;/&quot;</span><br>                <span class="hljs-attr">route:</span><br>                  <span class="hljs-attr">cluster:</span> <span class="hljs-string">llm</span><br>                  <span class="hljs-attr">timeout:</span> <span class="hljs-string">300s</span><br><br>          <span class="hljs-attr">http_filters:</span><br>          <span class="hljs-comment"># ai-cache</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">ai-cache</span><br>            <span class="hljs-attr">typed_config:</span><br>              <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">type.googleapis.com/udpa.type.v1.TypedStruct</span><br>              <span class="hljs-attr">type_url:</span> <span class="hljs-string">type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm</span><br>              <span class="hljs-attr">value:</span><br>                <span class="hljs-attr">config:</span><br>                  <span class="hljs-attr">name:</span> <span class="hljs-string">ai-cache</span><br>                  <span class="hljs-attr">vm_config:</span><br>                    <span class="hljs-attr">runtime:</span> <span class="hljs-string">envoy.wasm.runtime.v8</span><br>                    <span class="hljs-attr">code:</span><br>                      <span class="hljs-attr">local:</span><br>                        <span class="hljs-attr">filename:</span> <span class="hljs-string">/etc/envoy/ai-cache.wasm</span><br>                  <span class="hljs-attr">configuration:</span><br>                    <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">&quot;type.googleapis.com/google.protobuf.StringValue&quot;</span><br>                    <span class="hljs-attr">value:</span> <span class="hljs-string">|</span><br><span class="hljs-string">                      &#123;</span><br><span class="hljs-string">                        &quot;embeddingProvider&quot;: &#123;</span><br><span class="hljs-string">                          &quot;type&quot;: &quot;dashscope&quot;,</span><br><span class="hljs-string">                          &quot;serviceName&quot;: &quot;dashscope&quot;,</span><br><span class="hljs-string">                          &quot;apiKey&quot;: &quot;sk-key&quot;,</span><br><span class="hljs-string">                          &quot;DashScopeServiceName&quot;: &quot;dashscope&quot;</span><br><span class="hljs-string">                        &#125;,</span><br><span class="hljs-string">                        &quot;vectorProvider&quot;: &#123;</span><br><span class="hljs-string">                          &quot;VectorStoreProviderType&quot;: &quot;elasticsearch&quot;,</span><br><span class="hljs-string">                          &quot;ThresholdRelation&quot;: &quot;gte&quot;,</span><br><span class="hljs-string">                          &quot;ESThreshold&quot;: 0.7,</span><br><span class="hljs-string">                          &quot;ESServiceName&quot;: &quot;es&quot;,</span><br><span class="hljs-string">                          &quot;ESIndex&quot;: &quot;higress&quot;,</span><br><span class="hljs-string">                          &quot;ESUsername&quot;: &quot;elastic&quot;,</span><br><span class="hljs-string">                          &quot;ESPassword&quot;: &quot;123456&quot;</span><br><span class="hljs-string">                        &#125;,</span><br><span class="hljs-string">                        &quot;cacheKeyFrom&quot;: &#123;</span><br><span class="hljs-string">                          &quot;requestBody&quot;: &quot;&quot;</span><br><span class="hljs-string">                        &#125;,</span><br><span class="hljs-string">                        &quot;cacheValueFrom&quot;: &#123;</span><br><span class="hljs-string">                          &quot;responseBody&quot;: &quot;&quot;</span><br><span class="hljs-string">                        &#125;,</span><br><span class="hljs-string">                        &quot;cacheStreamValueFrom&quot;: &#123;</span><br><span class="hljs-string">                          &quot;responseBody&quot;: &quot;&quot;</span><br><span class="hljs-string">                        &#125;,</span><br><span class="hljs-string">                        &quot;returnResponseTemplate&quot;: &quot;&quot;,</span><br><span class="hljs-string">                        &quot;returnTestResponseTemplate&quot;: &quot;&quot;,</span><br><span class="hljs-string">                        &quot;ReturnStreamResponseTemplate&quot;: &quot;&quot;,</span><br><span class="hljs-string">                        &quot;redis&quot;: &#123;</span><br><span class="hljs-string">                          &quot;serviceName&quot;: &quot;redis_cluster&quot;,</span><br><span class="hljs-string">                          &quot;timeout&quot;: 2000</span><br><span class="hljs-string">                        &#125;</span><br><span class="hljs-string">                      &#125;</span><br><span class="hljs-string"></span><br>          <span class="hljs-comment"># 上面的配置中 redis 的配置名字是 redis，而不是 golang tag 中的 redisConfig</span><br>                        <span class="hljs-comment"># &quot;vectorProvider&quot;: &#123;</span><br>                        <span class="hljs-comment">#   &quot;VectorStoreProviderType&quot;: &quot;chroma&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ChromaServiceName&quot;: &quot;chroma&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ChromaCollectionID&quot;: &quot;0294deb1-8ef5-4582-b21c-75f23093db2c&quot;</span><br>                        <span class="hljs-comment"># &#125;,</span><br><br>                        <span class="hljs-comment"># &quot;vectorProvider&quot;: &#123;</span><br>                        <span class="hljs-comment">#   &quot;VectorStoreProviderType&quot;: &quot;elasticsearch&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ThresholdRelation&quot;: &quot;gte&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ESThreshold&quot;: 0.7,</span><br>                        <span class="hljs-comment">#   &quot;ESServiceName&quot;: &quot;es&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ESIndex&quot;: &quot;higress&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ESUsername&quot;: &quot;elastic&quot;,</span><br>                        <span class="hljs-comment">#   &quot;ESPassword&quot;: &quot;123456&quot;</span><br>                        <span class="hljs-comment"># &#125;,</span><br>          <span class="hljs-comment"># llm-proxy</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">llm-proxy</span><br>            <span class="hljs-attr">typed_config:</span><br>              <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">type.googleapis.com/udpa.type.v1.TypedStruct</span><br>              <span class="hljs-attr">type_url:</span> <span class="hljs-string">type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm</span><br>              <span class="hljs-attr">value:</span><br>                <span class="hljs-attr">config:</span><br>                  <span class="hljs-attr">name:</span> <span class="hljs-string">llm</span><br>                  <span class="hljs-attr">vm_config:</span><br>                    <span class="hljs-attr">runtime:</span> <span class="hljs-string">envoy.wasm.runtime.v8</span><br>                    <span class="hljs-attr">code:</span><br>                      <span class="hljs-attr">local:</span><br>                        <span class="hljs-attr">filename:</span> <span class="hljs-string">/etc/envoy/ai-proxy.wasm</span><br>                  <span class="hljs-attr">configuration:</span><br>                    <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">&quot;type.googleapis.com/google.protobuf.StringValue&quot;</span><br>                    <span class="hljs-attr">value:</span> <span class="hljs-string">|</span> <span class="hljs-comment"># 插件配置</span><br>                      &#123;<br>                        <span class="hljs-attr">&quot;provider&quot;:</span> &#123;<br>                          <span class="hljs-attr">&quot;type&quot;:</span> <span class="hljs-string">&quot;openai&quot;</span>,                                <br>                          <span class="hljs-attr">&quot;apiTokens&quot;:</span> [<br>                            <span class="hljs-string">&quot;YOUR_API_TOKEN&quot;</span><br>                          ],<br>                          <span class="hljs-attr">&quot;openaiCustomUrl&quot;:</span> <span class="hljs-string">&quot;172.17.0.1:8000/v1/chat/completions&quot;</span><br>                        &#125;<br>                      &#125;<br><br><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">envoy.filters.http.router</span><br>      <br>  <span class="hljs-attr">clusters:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">httpbin</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">30s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">LOGICAL_DNS</span><br>    <span class="hljs-comment"># Comment out the following line to test on v6 networks</span><br>    <span class="hljs-attr">dns_lookup_family:</span> <span class="hljs-string">V4_ONLY</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">httpbin</span><br>      <span class="hljs-attr">endpoints:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>            <span class="hljs-attr">address:</span><br>              <span class="hljs-attr">socket_address:</span><br>                <span class="hljs-attr">address:</span> <span class="hljs-string">httpbin</span><br>                <span class="hljs-attr">port_value:</span> <span class="hljs-number">80</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outbound|6379||redis_cluster</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">1s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">strict_dns</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">outbound|6379||redis_cluster</span><br>      <span class="hljs-attr">endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>                <span class="hljs-attr">address:</span><br>                  <span class="hljs-attr">socket_address:</span><br>                    <span class="hljs-attr">address:</span> <span class="hljs-number">172.17</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><br>                    <span class="hljs-attr">port_value:</span> <span class="hljs-number">6379</span><br>    <span class="hljs-attr">typed_extension_protocol_options:</span><br>      <span class="hljs-attr">envoy.filters.network.redis_proxy:</span><br>        <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">type.googleapis.com/envoy.extensions.filters.network.redis_proxy.v3.RedisProtocolOptions</span><br>  <span class="hljs-comment"># chroma</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outbound|8001||chroma.dns</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">30s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">LOGICAL_DNS</span><br>    <span class="hljs-attr">dns_lookup_family:</span> <span class="hljs-string">V4_ONLY</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">outbound|8001||chroma.dns</span><br>      <span class="hljs-attr">endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>                <span class="hljs-attr">address:</span><br>                  <span class="hljs-attr">socket_address:</span><br>                    <span class="hljs-attr">address:</span> <span class="hljs-number">172.17</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span> <span class="hljs-comment"># 本地 API 服务地址，这里是 docker0</span><br>                    <span class="hljs-attr">port_value:</span> <span class="hljs-number">8001</span><br><br>  <span class="hljs-comment"># es</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outbound|9200||es.dns</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">30s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">LOGICAL_DNS</span><br>    <span class="hljs-attr">dns_lookup_family:</span> <span class="hljs-string">V4_ONLY</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">outbound|9200||es.dns</span><br>      <span class="hljs-attr">endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>                <span class="hljs-attr">address:</span><br>                  <span class="hljs-attr">socket_address:</span><br>                    <span class="hljs-attr">address:</span> <span class="hljs-number">172.17</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span> <span class="hljs-comment"># 本地 API 服务地址，这里是 docker0</span><br>                    <span class="hljs-attr">port_value:</span> <span class="hljs-number">9200</span><br><br>  <span class="hljs-comment"># llm</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">llm</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">30s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">LOGICAL_DNS</span><br>    <span class="hljs-attr">dns_lookup_family:</span> <span class="hljs-string">V4_ONLY</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">llm</span><br>      <span class="hljs-attr">endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>                <span class="hljs-attr">address:</span><br>                  <span class="hljs-attr">socket_address:</span><br>                    <span class="hljs-attr">address:</span> <span class="hljs-number">172.17</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span> <span class="hljs-comment"># 本地 API 服务地址，这里是 docker0</span><br>                    <span class="hljs-attr">port_value:</span> <span class="hljs-number">8000</span><br>  <span class="hljs-comment"># dashvector</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outbound|443||dashvector.dns</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">30s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">LOGICAL_DNS</span><br>    <span class="hljs-attr">dns_lookup_family:</span> <span class="hljs-string">V4_ONLY</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">outbound|443||dashvector.dns</span><br>      <span class="hljs-attr">endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>                <span class="hljs-attr">address:</span><br>                  <span class="hljs-attr">socket_address:</span><br>                    <span class="hljs-attr">address:</span> <span class="hljs-string">vrs-cn-0dw3vnaqs0002z.dashvector.cn-hangzhou.aliyuncs.com</span><br>                    <span class="hljs-attr">port_value:</span> <span class="hljs-number">443</span><br>    <span class="hljs-attr">transport_socket:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">envoy.transport_sockets.tls</span><br>      <span class="hljs-attr">typed_config:</span><br>        <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext</span><br>        <span class="hljs-attr">&quot;sni&quot;:</span> <span class="hljs-string">&quot;vrs-cn-0dw3vnaqs0002z.dashvector.cn-hangzhou.aliyuncs.com&quot;</span><br>  <span class="hljs-comment"># dashscope</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">outbound|443||dashscope.dns</span><br>    <span class="hljs-attr">connect_timeout:</span> <span class="hljs-string">30s</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">LOGICAL_DNS</span><br>    <span class="hljs-attr">dns_lookup_family:</span> <span class="hljs-string">V4_ONLY</span><br>    <span class="hljs-attr">lb_policy:</span> <span class="hljs-string">ROUND_ROBIN</span><br>    <span class="hljs-attr">load_assignment:</span><br>      <span class="hljs-attr">cluster_name:</span> <span class="hljs-string">outbound|443||dashscope.dns</span><br>      <span class="hljs-attr">endpoints:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">lb_endpoints:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">endpoint:</span><br>                <span class="hljs-attr">address:</span><br>                  <span class="hljs-attr">socket_address:</span><br>                    <span class="hljs-attr">address:</span> <span class="hljs-string">dashscope.aliyuncs.com</span><br>                    <span class="hljs-attr">port_value:</span> <span class="hljs-number">443</span><br>    <span class="hljs-attr">transport_socket:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">envoy.transport_sockets.tls</span><br>      <span class="hljs-attr">typed_config:</span><br>        <span class="hljs-string">&quot;@type&quot;</span><span class="hljs-string">:</span> <span class="hljs-string">type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext</span><br>        <span class="hljs-attr">&quot;sni&quot;:</span> <span class="hljs-string">&quot;dashscope.aliyuncs.com&quot;</span><br></code></pre></td></tr></table></figure>
<h2 id="Wasm-插件编写"><a href="#Wasm-插件编写" class="headerlink" title="Wasm 插件编写"></a>Wasm 插件编写</h2><h3 id="Wasm-插件中无法使用-golang-的-net-http-库发送请求，必须使用-higress-封装的-HTTP-client"><a href="#Wasm-插件中无法使用-golang-的-net-http-库发送请求，必须使用-higress-封装的-HTTP-client" class="headerlink" title="Wasm 插件中无法使用 golang 的 net/http 库发送请求，必须使用 higress 封装的 HTTP client"></a>Wasm 插件中无法使用 golang 的 <code>net/http</code> 库发送请求，必须使用 higress 封装的 HTTP client</h3><h3 id="Wasm-插件请求-Redis-时，提示-“bad-argument”-错误"><a href="#Wasm-插件请求-Redis-时，提示-“bad-argument”-错误" class="headerlink" title="Wasm 插件请求 Redis 时，提示 “bad argument” 错误"></a>Wasm 插件请求 Redis 时，提示 “bad argument” 错误</h3><p>   解决办法：envoy.yaml 里配置 Redis cluster 时，socketAddr 要用 IP，不要用主机名。</p>
<p>   在开发 Wasm 插件过程中，我们镜像会使用 Docker Compose + Envoy + Volume Mount 的方式测试本地构建出来的插件。如果插件需要连接 Redis，那么我们就需要在 envoy.yaml 中配置一个 Redis 的 cluster。如果配置中的 Redis 节点地址使用机器名，那么在启动插件的时候可能会出现初始化 Redis 客户端报“bad argument”的错误。</p>
<p>   原因：这种错误一般只发生在插件在 <code>parseConfig</code> 阶段调用 <code>RedisClusterClient.Init()</code> 函数的时候。、</p>
<p>   在 Envoy 初始化的过程中，集群信息的初始化与 Wasm 插件的初始化可以认为是并行进行的。如果使用主机名进行配置，要获取实例的实际 IP 就需要经过 DNS 解析。而 DNS 解析一般是需要一些时间的，Redis 客户端的初始化又需要与 Redis 集群建立连接和通信。这一延迟就可能会导致 Wasm 插件进行初始化时 Redis 的集群信息还没有就绪，进而引发上述报错。</p>
<p>   而在 Higress 的实际运行过程中，集群信息是通过 xDS 进行下发的，这个延迟的问题不会非常显著。</p>
<h3 id="proxywasm-ResumeHttpRequest-的使用"><a href="#proxywasm-ResumeHttpRequest-的使用" class="headerlink" title="proxywasm.ResumeHttpRequest() 的使用"></a><code>proxywasm.ResumeHttpRequest()</code> 的使用</h3><p>下面是一个 wasm 插件访问外部请求并返回给下游的例子：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">onHttpRequestHeaders</span><span class="hljs-params">(ctx wrapper.HttpContext, config MyConfig, log wrapper.Log)</span></span> types.Action &#123;<br>  <span class="hljs-comment">// 使用client的Get方法发起HTTP Get调用，此处省略了timeout参数，默认超时时间500毫秒</span><br>  config.client.Get(config.requestPath, <span class="hljs-literal">nil</span>,<br>    <span class="hljs-comment">// 回调函数，将在响应异步返回时被执行</span><br>    <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(statusCode <span class="hljs-type">int</span>, responseHeaders http.Header, responseBody []<span class="hljs-type">byte</span>)</span></span> &#123;<br>      <span class="hljs-comment">// 请求没有返回200状态码，进行处理</span><br>      <span class="hljs-keyword">if</span> statusCode != http.StatusOK &#123;<br>        log.Errorf(<span class="hljs-string">&quot;http call failed, status: %d&quot;</span>, statusCode)<br>        proxywasm.SendHttpResponse(http.StatusInternalServerError, <span class="hljs-literal">nil</span>,<br>          []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;http call failed&quot;</span>), <span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">return</span><br>      &#125;<br>      <span class="hljs-comment">// 打印响应的HTTP状态码和应答body</span><br>      log.Infof(<span class="hljs-string">&quot;get status: %d, response body: %s&quot;</span>, statusCode, responseBody)<br>      <span class="hljs-comment">// 从应答头中解析token字段设置到原始请求头中</span><br>      token := responseHeaders.Get(config.tokenHeader)<br>      <span class="hljs-keyword">if</span> token != <span class="hljs-string">&quot;&quot;</span> &#123;<br>        proxywasm.AddHttpRequestHeader(config.tokenHeader, token)<br>      &#125;<br>      <span class="hljs-comment">// 恢复原始请求流程，继续往下处理，才能正常转发给后端服务</span><br>      proxywasm.ResumeHttpRequest()<br>    &#125;)<br>  <span class="hljs-comment">// 需要等待异步回调完成，返回Pause状态，可以被ResumeHttpRequest恢复</span><br>  <span class="hljs-keyword">return</span> types.ActionPause<br>&#125;<br></code></pre></td></tr></table></figure>
<p>在这里需要注意的是 <code>onHttpRequestHeaders</code> 方法返回了 <code>types.ActionPause</code> 等待了 <code>Get</code> 方法，我们前面说过 <code>client.Get</code> 是一个异步请求，如果不显式地进行等待，那么下游无法得到 higress 的请求结果。因此这里返回 <code>types.ActionPause</code> 等待请求完成之后，在 <code>client.Get</code> 的 response callback 函数中调用 <code>proxywasm.ResumeHttpRequest()</code> 恢复原始请求流程，继续往下处理，才能正常转发给后端服务。</p>
]]></content>
      <categories>
        <category>higress</category>
      </categories>
  </entry>
  <entry>
    <title>Internlm-03-基于 InternLM 和 LangChain 搭建你的知识库</title>
    <url>/internlm/internlm-03/</url>
    <content><![CDATA[<h1 id="基于-InternLM-和-LangChain-搭建你的知识库"><a href="#基于-InternLM-和-LangChain-搭建你的知识库" class="headerlink" title="基于 InternLM 和 LangChain 搭建你的知识库"></a>基于 InternLM 和 LangChain 搭建你的知识库</h1><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="InternLM-环境"><a href="#InternLM-环境" class="headerlink" title="InternLM 环境"></a>InternLM 环境</h3><p>开发环境除了 <code>pytorch</code> 等库以外，还需要安装以下库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 升级pip</span><br>python -m pip install --upgrade pip<br><br>pip install modelscope==1.9.5<br>pip install transformers==4.35.2<br>pip install streamlit==1.24.0<br>pip install sentencepiece==0.1.99<br>pip install accelerate==0.24.1<br></code></pre></td></tr></table></figure>
<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">import torch<br>from modelscope import snapshot_download, AutoModel, AutoTokenizer<br>import os<br>model_dir = snapshot_download(<span class="hljs-string">&#x27;Shanghai_AI_Laboratory/internlm-chat-7b&#x27;</span>, cache_dir=<span class="hljs-string">&#x27;/root/data/model&#x27;</span>, revision=<span class="hljs-string">&#x27;v1.0.3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h3 id="配置-Langchain"><a href="#配置-Langchain" class="headerlink" title="配置 Langchain"></a>配置 Langchain</h3><p>除了配置大模型的运行环境以外，还需要配置 Langchain 运行环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install langchain==0.0.292<br>pip install gradio==4.4.0<br>pip install chromadb==0.4.15<br>pip install sentence-transformers==2.2.2<br>pip install unstructured==0.10.30<br>pip install markdown==3.3.7<br></code></pre></td></tr></table></figure>
<p><img  src="安装依赖.png"  ><span class="image-caption">安装依赖</span></p>
<h3 id="下载-Embedding-模型"><a href="#下载-Embedding-模型" class="headerlink" title="下载 Embedding 模型"></a>下载 Embedding 模型</h3><p>同时，我们需要使用到开源词向量模型 <a href="https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2">Sentence Transformer - paraphrase-multilingual-MiniLM-L12-v2</a>:（我们也可以选用别的开源词向量模型来进行 Embedding，教程中选用这个模型是相对轻量、支持中文且效果较好的，我这里选择使用了更为好用的 bge 系列的 Embedding 模型 <a href="[BAAI/bge-large-zh-v1.5 · Hugging Face](https://huggingface.co/BAAI/bge-large-zh-v1.5">BAAI/bge-large-zh-v1.5</a>)）</p>
<p>首先需要使用 <code>huggingface</code> 官方提供的 <code>huggingface-cli</code> 命令行工具。安装依赖:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install -U huggingface_hub<br></code></pre></td></tr></table></figure>
<p>然后在和 <code>/root/data</code> 目录下新建python文件 <code>download_hf.py</code>，填入以下代码：</p>
<ul>
<li>resume-download：断点续下</li>
<li>local-dir：本地存储路径。（linux环境下需要填写绝对路径）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 下载模型</span><br>os.system(<span class="hljs-string">&#x27;huggingface-cli download --resume-download BAAI/bge-large-zh-v1.5 --local-dir /root/data/model/bge-large-zh-v1.5&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>但是，使用 huggingface 下载可能速度较慢，我们可以使用 huggingface 镜像下载。与使用hugginge face下载相同，只需要填入镜像地址即可。</p>
<p>将 <code>download_hf.py</code> 中的代码修改为以下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 设置环境变量</span><br>os.environ[<span class="hljs-string">&#x27;HF_ENDPOINT&#x27;</span>] = <span class="hljs-string">&#x27;https://hf-mirror.com&#x27;</span><br><br><span class="hljs-comment"># 下载模型</span><br>os.system(<span class="hljs-string">&#x27;huggingface-cli download --resume-download BAAI/bge-large-zh-v1.5 --local-dir /root/data/model/bge-large-zh-v1.5&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>然后，在 <code>/root/data</code> 目录下执行该脚本即可自动开始下载：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python download_hf.py<br></code></pre></td></tr></table></figure>
<p><img  src="下载bge.png"  ><span class="image-caption">下载bge模型</span></p>
<h3 id="下载-NLTK-相关资源"><a href="#下载-NLTK-相关资源" class="headerlink" title="下载 NLTK 相关资源"></a>下载 NLTK 相关资源</h3><p>我们在使用开源词向量模型构建开源词向量的时候，需要用到第三方库 <code>nltk</code> 的一些资源。正常情况下，其会自动从互联网上下载，但可能由于网络原因会导致下载中断，此处我们可以从国内仓库镜像地址下载相关资源，保存到服务器上。</p>
<p>我们用以下命令下载 nltk 资源并解压到服务器上：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root<br>git <span class="hljs-built_in">clone</span> https://gitee.com/yzy0612/nltk_data.git  --branch gh-pages<br><span class="hljs-built_in">cd</span> nltk_data<br><span class="hljs-built_in">mv</span> packages/*  ./<br><span class="hljs-built_in">cd</span> tokenizers<br>unzip punkt.zip<br><span class="hljs-built_in">cd</span> ../taggers<br>unzip averaged_perceptron_tagger.zip<br></code></pre></td></tr></table></figure>
<p>之后使用时服务器即会自动使用已有资源，无需再次下载。</p>
<h3 id="下载教程代码"><a href="#下载教程代码" class="headerlink" title="下载教程代码"></a>下载教程代码</h3><p>我们在仓库中同步提供了所有脚本，可以查看该教程文件的同级目录的 <code>demo</code> 文件夹。</p>
<p>建议通过以下目录将仓库 clone 到本地，可以直接在本地运行相关代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root/data<br>git <span class="hljs-built_in">clone</span> https://github.com/InternLM/tutorial<br></code></pre></td></tr></table></figure>
<p>通过上述命令，可以将本仓库 clone 到本地 <code>root/data/tutorial</code> 目录下，在之后的过程中可以对照仓库中的脚本来完成自己的代码，也可以直接使用仓库中的脚本。</p>
<h2 id="知识库搭建"><a href="#知识库搭建" class="headerlink" title="知识库搭建"></a>知识库搭建</h2><h3 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h3><p>教程选择了由上海人工智能实验室开源的一系列大模型工具开源仓库作为语料库来源，包括：</p>
<ul>
<li><a href="https://gitee.com/open-compass/opencompass">OpenCompass</a>：面向大模型评测的一站式平台</li>
<li><a href="https://gitee.com/InternLM/lmdeploy">IMDeploy</a>：涵盖了 LLM 任务的全套轻量化、部署和服务解决方案的高效推理工具箱</li>
<li><a href="https://gitee.com/InternLM/xtuner">XTuner</a>：轻量级微调大语言模型的工具库</li>
<li><a href="https://gitee.com/InternLM/InternLM-XComposer">InternLM-XComposer</a>：浦语·灵笔，基于书生·浦语大语言模型研发的视觉-语言大模型</li>
<li><a href="https://gitee.com/InternLM/lagent">Lagent</a>：一个轻量级、开源的基于大语言模型的智能体（agent）框架</li>
<li><a href="https://gitee.com/InternLM/InternLM">InternLM</a>：一个开源的轻量级训练框架，旨在支持大模型训练而无需大量的依赖</li>
</ul>
<p>首先我们需要将上述远程开源仓库 Clone 到本地，可以使用以下命令：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 进入到数据库盘</span><br>cd <span class="hljs-regexp">/root/</span>data<br><span class="hljs-comment"># clone 上述开源仓库</span><br>git clone https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/open-compass/</span>opencompass.git<br>git clone https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/InternLM/</span>lmdeploy.git<br>git clone https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/InternLM/</span>xtuner.git<br>git clone https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/InternLM/</span>InternLM-XComposer.git<br>git clone https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/InternLM/</span>lagent.git<br>git clone https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/InternLM/</span>InternLM.git<br></code></pre></td></tr></table></figure>
<p>接着，为语料处理方便，我们将选用上述仓库中所有的 markdown、txt 文件作为示例语料库。注意，也可以选用其中的代码文件加入到知识库中，但需要针对代码文件格式进行额外处理（因为代码文件对逻辑联系要求较高，且规范性较强，在分割时最好基于代码模块进行分割再加入向量数据库）。</p>
<p>我们首先将上述仓库中所有满足条件的文件路径找出来，我们定义一个函数，该函数将递归指定文件夹路径，返回其中所有满足条件（即后缀名为 .md 或者 .txt 的文件）的文件路径：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_files</span>(<span class="hljs-params">dir_path</span>):<br>    <span class="hljs-comment"># args：dir_path，目标文件夹路径</span><br>    file_list = []<br>    <span class="hljs-keyword">for</span> filepath, dirnames, filenames <span class="hljs-keyword">in</span> os.walk(dir_path):<br>        <span class="hljs-comment"># os.walk 函数将递归遍历指定文件夹</span><br>        <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames:<br>            <span class="hljs-comment"># 通过后缀名判断文件类型是否满足要求</span><br>            <span class="hljs-keyword">if</span> filename.endswith(<span class="hljs-string">&quot;.md&quot;</span>):<br>                <span class="hljs-comment"># 如果满足要求，将其绝对路径加入到结果列表</span><br>                file_list.append(os.path.join(filepath, filename))<br>            <span class="hljs-keyword">elif</span> filename.endswith(<span class="hljs-string">&quot;.txt&quot;</span>):<br>                file_list.append(os.path.join(filepath, filename))<br>    <span class="hljs-keyword">return</span> file_list<br></code></pre></td></tr></table></figure>
<h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><p>得到所有目标文件路径之后，我们可以使用 LangChain 提供的 FileLoader 对象来加载目标文件，得到由目标文件解析出的纯文本内容。由于不同类型的文件需要对应不同的 FileLoader，我们判断目标文件类型，并针对性调用对应类型的 FileLoader，同时，调用 FileLoader 对象的 load 方法来得到加载之后的纯文本对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> UnstructuredFileLoader<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> UnstructuredMarkdownLoader<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_text</span>(<span class="hljs-params">dir_path</span>):<br>    <span class="hljs-comment"># args：dir_path，目标文件夹路径</span><br>    <span class="hljs-comment"># 首先调用上文定义的函数得到目标文件路径列表</span><br>    file_lst = get_files(dir_path)<br>    <span class="hljs-comment"># docs 存放加载之后的纯文本对象</span><br>    docs = []<br>    <span class="hljs-comment"># 遍历所有目标文件</span><br>    <span class="hljs-keyword">for</span> one_file <span class="hljs-keyword">in</span> tqdm(file_lst):<br>        file_type = one_file.split(<span class="hljs-string">&#x27;.&#x27;</span>)[-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">if</span> file_type == <span class="hljs-string">&#x27;md&#x27;</span>:<br>            loader = UnstructuredMarkdownLoader(one_file)<br>        <span class="hljs-keyword">elif</span> file_type == <span class="hljs-string">&#x27;txt&#x27;</span>:<br>            loader = UnstructuredFileLoader(one_file)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 如果是不符合条件的文件，直接跳过</span><br>            <span class="hljs-keyword">continue</span><br>        docs.extend(loader.load())<br>    <span class="hljs-keyword">return</span> docs<br></code></pre></td></tr></table></figure>
<p>使用上文函数，我们得到的 <code>docs</code> 为一个纯文本对象对应的列表。</p>
<h3 id="构建向量数据库"><a href="#构建向量数据库" class="headerlink" title="构建向量数据库"></a>构建向量数据库</h3><p>得到该列表之后，我们就可以将它引入到 LangChain 框架中构建向量数据库。由纯文本对象构建向量数据库，我们需要先对文本进行分块，接着对文本块进行向量化。</p>
<p>LangChain 提供了多种文本分块工具，此处我们使用字符串递归分割器，并选择分块大小为 500，块重叠长度为 150（由于篇幅限制，此处没有展示切割效果，学习者可以自行尝试一下，想要深入学习 LangChain 文本分块可以参考教程 <a href="https://github.com/datawhalechina/prompt-engineering-for-developers/blob/9dbcb48416eb8af9ff9447388838521dc0f9acb0/content/LangChain Chat with Your Data/1.简介 Introduction.md">《LangChain - Chat With Your Data》</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><br>text_splitter = RecursiveCharacterTextSplitter(<br>    chunk_size=<span class="hljs-number">500</span>, chunk_overlap=<span class="hljs-number">150</span>)<br>split_docs = text_splitter.split_documents(docs)<br></code></pre></td></tr></table></figure>
<p>接着我们选用开源词向量模型 <a href="https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2">Sentence Transformer</a> 来进行文本向量化。LangChain 提供了直接引入 HuggingFace 开源社区中的模型进行向量化的接口：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.embeddings.huggingface <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><br>embeddings = HuggingFaceEmbeddings(model_name=<span class="hljs-string">&quot;/root/data/model/bge-large-zh-v1.5&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>同时，考虑到 Chroma 是目前最常用的入门数据库，我们选择 Chroma 作为向量数据库，基于上文分块后的文档以及加载的开源向量化模型，将语料加载到指定路径下的向量数据库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><br><span class="hljs-comment"># 定义持久化路径</span><br>persist_directory = <span class="hljs-string">&#x27;data_base/vector_db/chroma&#x27;</span><br><span class="hljs-comment"># 加载数据库</span><br>vectordb = Chroma.from_documents(<br>    documents=split_docs,<br>    embedding=embeddings,<br>    persist_directory=persist_directory  <span class="hljs-comment"># 允许我们将persist_directory目录保存到磁盘上</span><br>)<br><span class="hljs-comment"># 将加载的向量数据库持久化到磁盘上</span><br>vectordb.persist()<br></code></pre></td></tr></table></figure>
<h3 id="整体脚本"><a href="#整体脚本" class="headerlink" title="整体脚本"></a>整体脚本</h3><p>将上述代码整合在一起为知识库搭建的脚本：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先导入所需第三方库</span><br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> UnstructuredFileLoader<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> UnstructuredMarkdownLoader<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings.huggingface <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 获取文件路径函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_files</span>(<span class="hljs-params">dir_path</span>):<br>    <span class="hljs-comment"># args：dir_path，目标文件夹路径</span><br>    file_list = []<br>    <span class="hljs-keyword">for</span> filepath, dirnames, filenames <span class="hljs-keyword">in</span> os.walk(dir_path):<br>        <span class="hljs-comment"># os.walk 函数将递归遍历指定文件夹</span><br>        <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames:<br>            <span class="hljs-comment"># 通过后缀名判断文件类型是否满足要求</span><br>            <span class="hljs-keyword">if</span> filename.endswith(<span class="hljs-string">&quot;.md&quot;</span>):<br>                <span class="hljs-comment"># 如果满足要求，将其绝对路径加入到结果列表</span><br>                file_list.append(os.path.join(filepath, filename))<br>            <span class="hljs-keyword">elif</span> filename.endswith(<span class="hljs-string">&quot;.txt&quot;</span>):<br>                file_list.append(os.path.join(filepath, filename))<br>    <span class="hljs-keyword">return</span> file_list<br><br><span class="hljs-comment"># 加载文件函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_text</span>(<span class="hljs-params">dir_path</span>):<br>    <span class="hljs-comment"># args：dir_path，目标文件夹路径</span><br>    <span class="hljs-comment"># 首先调用上文定义的函数得到目标文件路径列表</span><br>    file_lst = get_files(dir_path)<br>    <span class="hljs-comment"># docs 存放加载之后的纯文本对象</span><br>    docs = []<br>    <span class="hljs-comment"># 遍历所有目标文件</span><br>    <span class="hljs-keyword">for</span> one_file <span class="hljs-keyword">in</span> tqdm(file_lst):<br>        file_type = one_file.split(<span class="hljs-string">&#x27;.&#x27;</span>)[-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">if</span> file_type == <span class="hljs-string">&#x27;md&#x27;</span>:<br>            loader = UnstructuredMarkdownLoader(one_file)<br>        <span class="hljs-keyword">elif</span> file_type == <span class="hljs-string">&#x27;txt&#x27;</span>:<br>            loader = UnstructuredFileLoader(one_file)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 如果是不符合条件的文件，直接跳过</span><br>            <span class="hljs-keyword">continue</span><br>        docs.extend(loader.load())<br>    <span class="hljs-keyword">return</span> docs<br><br><span class="hljs-comment"># 目标文件夹</span><br>tar_dir = [<br>    <span class="hljs-string">&quot;/root/data/InternLM&quot;</span>,<br>    <span class="hljs-string">&quot;/root/data/InternLM-XComposer&quot;</span>,<br>    <span class="hljs-string">&quot;/root/data/lagent&quot;</span>,<br>    <span class="hljs-string">&quot;/root/data/lmdeploy&quot;</span>,<br>    <span class="hljs-string">&quot;/root/data/opencompass&quot;</span>,<br>    <span class="hljs-string">&quot;/root/data/xtuner&quot;</span><br>]<br><br><span class="hljs-comment"># 加载目标文件</span><br>docs = []<br><span class="hljs-keyword">for</span> dir_path <span class="hljs-keyword">in</span> tar_dir:<br>    docs.extend(get_text(dir_path))<br><br><span class="hljs-comment"># 对文本进行分块</span><br>text_splitter = RecursiveCharacterTextSplitter(<br>    chunk_size=<span class="hljs-number">500</span>, chunk_overlap=<span class="hljs-number">150</span>)<br>split_docs = text_splitter.split_documents(docs)<br><br><span class="hljs-comment"># 加载开源词向量模型</span><br>embeddings = HuggingFaceEmbeddings(model_name=<span class="hljs-string">&quot;/root/data/model/bge-large-zh-v1.5&quot;</span>)<br><br><span class="hljs-comment"># 构建向量数据库</span><br><span class="hljs-comment"># 定义持久化路径</span><br>persist_directory = <span class="hljs-string">&#x27;data_base/vector_db/chroma&#x27;</span><br><span class="hljs-comment"># 加载数据库</span><br>vectordb = Chroma.from_documents(<br>    documents=split_docs,<br>    embedding=embeddings,<br>    persist_directory=persist_directory  <span class="hljs-comment"># 允许我们将persist_directory目录保存到磁盘上</span><br>)<br><span class="hljs-comment"># 将加载的向量数据库持久化到磁盘上</span><br>vectordb.persist()<br></code></pre></td></tr></table></figure>
<p>可以在 <code>/root/data</code> 下新建一个 <code>demo</code>目录，将该脚本和后续脚本均放在该目录下运行。运行上述脚本，即可在本地构建已持久化的向量数据库，后续直接导入该数据库即可，无需重复构建。</p>
<h2 id="InternLM-接入-LangChain"><a href="#InternLM-接入-LangChain" class="headerlink" title="InternLM 接入 LangChain"></a>InternLM 接入 LangChain</h2><p>为便捷构建 LLM 应用，我们需要基于本地部署的 InternLM，继承 LangChain 的 LLM 类自定义一个 InternLM LLM 子类，从而实现将 InternLM 接入到 LangChain 框架中。完成 LangChain 的自定义 LLM 子类之后，可以以完全一致的方式调用 LangChain 的接口，而无需考虑底层模型调用的不一致。</p>
<p>基于本地部署的 InternLM 自定义 LLM 类并不复杂，我们只需从 LangChain.llms.base.LLM 类继承一个子类，并重写构造函数与 <code>_call</code> 函数即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.llms.base <span class="hljs-keyword">import</span> LLM<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Any</span>, <span class="hljs-type">List</span>, <span class="hljs-type">Optional</span><br><span class="hljs-keyword">from</span> langchain.callbacks.manager <span class="hljs-keyword">import</span> CallbackManagerForLLMRun<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">InternLM_LLM</span>(<span class="hljs-title class_ inherited__">LLM</span>):<br>    <span class="hljs-comment"># 基于本地 InternLM 自定义 LLM 类</span><br>    tokenizer : AutoTokenizer = <span class="hljs-literal">None</span><br>    model: AutoModelForCausalLM = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_path :<span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-comment"># model_path: InternLM 模型路径</span><br>        <span class="hljs-comment"># 从本地初始化模型</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;正在从本地加载模型...&quot;</span>)<br>        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=<span class="hljs-literal">True</span>)<br>        self.model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=<span class="hljs-literal">True</span>).to(torch.bfloat16).cuda()<br>        self.model = self.model.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;完成本地模型的加载&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_call</span>(<span class="hljs-params">self, prompt : <span class="hljs-built_in">str</span>, stop: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                run_manager: <span class="hljs-type">Optional</span>[CallbackManagerForLLMRun] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                **kwargs: <span class="hljs-type">Any</span></span>):<br>        <span class="hljs-comment"># 重写调用函数</span><br>        system_prompt = <span class="hljs-string">&quot;&quot;&quot;You are an AI assistant whose name is InternLM (书生·浦语).</span><br><span class="hljs-string">        - InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span><br><span class="hljs-string">        - InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <br>        messages = [(system_prompt, <span class="hljs-string">&#x27;&#x27;</span>)]<br>        response, history = self.model.chat(self.tokenizer, prompt , history=messages)<br>        <span class="hljs-keyword">return</span> response<br>        <br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_llm_type</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;InternLM&quot;</span><br></code></pre></td></tr></table></figure>
<p>在上述类定义中，重写了构造函数和 <code>_call</code> 函数：对于构造函数，我们在对象实例化的一开始加载本地部署的 InternLM 模型，从而避免每一次调用都需要重新加载模型带来的时间过长；<code>_call</code> 函数是 LLM 类的核心函数，LangChain 会调用该函数来调用 LLM，在该函数中，我们调用已实例化模型的 chat 方法，从而实现对模型的调用并返回调用结果。</p>
<p>在整体项目中，我们将上述代码封装为 LLM.py，后续将直接从该文件中引入自定义的 LLM 类。</p>
<h2 id="构建检索问答链"><a href="#构建检索问答链" class="headerlink" title="构建检索问答链"></a>构建检索问答链</h2><p>LangChain 通过提供检索问答链对象来实现对于 RAG 全流程的封装。所谓检索问答链，即通过一个对象完成检索增强问答（即RAG）的全流程，针对 RAG 的更多概念，我们会在视频内容中讲解，也欢迎读者查阅该教程来进一步了解：<a href="https://github.com/datawhalechina/llm-universe/tree/main">《LLM Universe》</a>。我们可以调用一个 LangChain 提供的 <code>RetrievalQA</code> 对象，通过初始化时填入已构建的数据库和自定义 LLM 作为参数，来简便地完成检索增强问答的全流程，LangChain 会自动完成基于用户提问进行检索、获取相关文档、拼接为合适的 Prompt 并交给 LLM 问答的全部流程。</p>
<h3 id="加载向量数据库"><a href="#加载向量数据库" class="headerlink" title="加载向量数据库"></a>加载向量数据库</h3><p>首先我们需要将上文构建的向量数据库导入进来，我们可以直接通过 Chroma 以及上文定义的词向量模型来加载已构建的数据库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings.huggingface <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 定义 Embeddings</span><br>embeddings = HuggingFaceEmbeddings(model_name=<span class="hljs-string">&quot;/root/data/model/bge-large-zh-v1.5&quot;</span>)<br><br><span class="hljs-comment"># 向量数据库持久化路径</span><br>persist_directory = <span class="hljs-string">&#x27;data_base/vector_db/chroma&#x27;</span><br><br><span class="hljs-comment"># 加载数据库</span><br>vectordb = Chroma(<br>    persist_directory=persist_directory, <br>    embedding_function=embeddings<br>)<br></code></pre></td></tr></table></figure>
<p>上述代码得到的 <code>vectordb</code> 对象即为我们已构建的向量数据库对象，该对象可以针对用户的 <code>query</code> 进行语义向量检索，得到与用户提问相关的知识片段。</p>
<h3 id="实例化自定义-LLM-与-Prompt-Template"><a href="#实例化自定义-LLM-与-Prompt-Template" class="headerlink" title="实例化自定义 LLM 与 Prompt Template"></a>实例化自定义 LLM 与 Prompt Template</h3><p>接着，我们实例化一个基于 InternLM 自定义的 LLM 对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> LLM <span class="hljs-keyword">import</span> InternLM_LLM<br>llm = InternLM_LLM(model_path = <span class="hljs-string">&quot;/root/data/model/Shanghai_AI_Laboratory/internlm-chat-7b&quot;</span>)<br>llm.predict(<span class="hljs-string">&quot;你是谁&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>构建检索问答链，还需要构建一个 Prompt Template，该 Template 其实基于一个带变量的字符串，在检索之后，LangChain 会将检索到的相关文档片段填入到 Template 的变量中，从而实现带知识的 Prompt 构建。我们可以基于 LangChain 的 Template 基类来实例化这样一个 Template 对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br><span class="hljs-comment"># 我们所构造的 Prompt 模板</span><br>template = <span class="hljs-string">&quot;&quot;&quot;使用以下上下文来回答用户的问题。如果你不知道答案，就说你不知道。总是使用中文回答。</span><br><span class="hljs-string">问题: &#123;question&#125;</span><br><span class="hljs-string">可参考的上下文：</span><br><span class="hljs-string">···</span><br><span class="hljs-string">&#123;context&#125;</span><br><span class="hljs-string">···</span><br><span class="hljs-string">如果给定的上下文无法让你做出回答，请回答你不知道。</span><br><span class="hljs-string">有用的回答:&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># 调用 LangChain 的方法来实例化一个 Template 对象，该对象包含了 context 和 question 两个变量，在实际调用时，这两个变量会被检索到的文档片段和用户提问填充</span><br>QA_CHAIN_PROMPT = PromptTemplate(input_variables=[<span class="hljs-string">&quot;context&quot;</span>,<span class="hljs-string">&quot;question&quot;</span>],template=template)<br></code></pre></td></tr></table></figure>
<h3 id="构建检索问答链-1"><a href="#构建检索问答链-1" class="headerlink" title="构建检索问答链"></a>构建检索问答链</h3><p>最后，可以调用 LangChain 提供的检索问答链构造函数，基于我们的自定义 LLM、Prompt Template 和向量知识库来构建一个基于 InternLM 的检索问答链：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> RetrievalQA<br><br>qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectordb.as_retriever(),return_source_documents=<span class="hljs-literal">True</span>,chain_type_kwargs=&#123;<span class="hljs-string">&quot;prompt&quot;</span>:QA_CHAIN_PROMPT&#125;)<br></code></pre></td></tr></table></figure>
<p>得到的 <code>qa_chain</code> 对象即可以实现我们的核心功能，即基于 InternLM 模型的专业知识库助手。我们可以对比该检索问答链和纯 LLM 的问答效果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 检索问答链回答效果</span><br>question = <span class="hljs-string">&quot;什么是InternLM&quot;</span><br>result = qa_chain(&#123;<span class="hljs-string">&quot;query&quot;</span>: question&#125;)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;检索问答链回答 question 的结果：&quot;</span>)<br><span class="hljs-built_in">print</span>(result[<span class="hljs-string">&quot;result&quot;</span>])<br><br><span class="hljs-comment"># 仅 LLM 回答效果</span><br>result_2 = llm(question)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;大模型回答 question 的结果：&quot;</span>)<br><span class="hljs-built_in">print</span>(result_2)<br></code></pre></td></tr></table></figure>
<h2 id="部署一个-Web-Demo"><a href="#部署一个-Web-Demo" class="headerlink" title="部署一个 Web Demo"></a>部署一个 Web Demo</h2><p>之后我们可以基于 Gradio 框架将其部署到 Web 网页，从而搭建一个小型 Demo，便于测试与使用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入必要的库</span><br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings.huggingface <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> LLM <span class="hljs-keyword">import</span> InternLM_LLM<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_chain</span>():<br>    <span class="hljs-comment"># 加载问答链</span><br>    <span class="hljs-comment"># 定义 Embeddings</span><br>    embeddings = HuggingFaceEmbeddings(model_name=<span class="hljs-string">&quot;/root/data/model/bge-large-zh-v1.5&quot;</span>)<br><br>    <span class="hljs-comment"># 向量数据库持久化路径</span><br>    persist_directory = <span class="hljs-string">&#x27;data_base/vector_db/chroma&#x27;</span><br><br>    <span class="hljs-comment"># 加载数据库</span><br>    vectordb = Chroma(<br>        persist_directory=persist_directory,  <span class="hljs-comment"># 允许我们将persist_directory目录保存到磁盘上</span><br>        embedding_function=embeddings<br>    )<br><br>    llm = InternLM_LLM(model_path = <span class="hljs-string">&quot;/root/data/model/Shanghai_AI_Laboratory/internlm-chat-7b&quot;</span>)<br><br>    template = <span class="hljs-string">&quot;&quot;&quot;使用以下上下文来回答用户的问题。如果你不知道答案，就说你不知道。总是使用中文回答。</span><br><span class="hljs-string">    问题: &#123;question&#125;</span><br><span class="hljs-string">    可参考的上下文：</span><br><span class="hljs-string">    ···</span><br><span class="hljs-string">    &#123;context&#125;</span><br><span class="hljs-string">    ···</span><br><span class="hljs-string">    如果给定的上下文无法让你做出回答，请回答你不知道。</span><br><span class="hljs-string">    有用的回答:&quot;&quot;&quot;</span><br><br>    QA_CHAIN_PROMPT = PromptTemplate(input_variables=[<span class="hljs-string">&quot;context&quot;</span>,<span class="hljs-string">&quot;question&quot;</span>],<br>                                    template=template)<br><br>    <span class="hljs-comment"># 运行 chain</span><br>    <span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> RetrievalQA<br><br>    qa_chain = RetrievalQA.from_chain_type(llm,<br>                                        retriever=vectordb.as_retriever(),<br>                                        return_source_documents=<span class="hljs-literal">True</span>,<br>                                        chain_type_kwargs=&#123;<span class="hljs-string">&quot;prompt&quot;</span>:QA_CHAIN_PROMPT&#125;)<br>    <br>    <span class="hljs-keyword">return</span> qa_chain<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model_center</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    存储问答 Chain 的对象 </span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.chain = load_chain()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">qa_chain_self_answer</span>(<span class="hljs-params">self, question: <span class="hljs-built_in">str</span>, chat_history: <span class="hljs-built_in">list</span> = []</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        调用不带历史记录的问答链进行回答</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> question == <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(question) &lt; <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, chat_history<br>        <span class="hljs-keyword">try</span>:<br>            chat_history.append(<br>                (question, self.chain(&#123;<span class="hljs-string">&quot;query&quot;</span>: question&#125;)[<span class="hljs-string">&quot;result&quot;</span>]))<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, chat_history<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-keyword">return</span> e, chat_history<br><br><br>model_center = Model_center()<br><br>block = gr.Blocks()<br><span class="hljs-keyword">with</span> block <span class="hljs-keyword">as</span> demo:<br>    <span class="hljs-keyword">with</span> gr.Row(equal_height=<span class="hljs-literal">True</span>):   <br>        <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">15</span>):<br>            gr.Markdown(<span class="hljs-string">&quot;&quot;&quot;&lt;h1&gt;&lt;center&gt;InternLM&lt;/center&gt;&lt;/h1&gt;</span><br><span class="hljs-string">                &lt;center&gt;书生浦语&lt;/center&gt;</span><br><span class="hljs-string">                &quot;&quot;&quot;</span>)<br>        <span class="hljs-comment"># gr.Image(value=LOGO_PATH, scale=1, min_width=10,show_label=False, show_download_button=False)</span><br><br>    <span class="hljs-keyword">with</span> gr.Row():<br>        <span class="hljs-keyword">with</span> gr.Column(scale=<span class="hljs-number">4</span>):<br>            chatbot = gr.Chatbot(height=<span class="hljs-number">450</span>, show_copy_button=<span class="hljs-literal">True</span>)<br>            <span class="hljs-comment"># 创建一个文本框组件，用于输入 prompt。</span><br>            msg = gr.Textbox(label=<span class="hljs-string">&quot;Prompt/问题&quot;</span>)<br><br>            <span class="hljs-keyword">with</span> gr.Row():<br>                <span class="hljs-comment"># 创建提交按钮。</span><br>                db_wo_his_btn = gr.Button(<span class="hljs-string">&quot;Chat&quot;</span>)<br>            <span class="hljs-keyword">with</span> gr.Row():<br>                <span class="hljs-comment"># 创建一个清除按钮，用于清除聊天机器人组件的内容。</span><br>                clear = gr.ClearButton(<br>                    components=[chatbot], value=<span class="hljs-string">&quot;Clear console&quot;</span>)<br>                <br>        <span class="hljs-comment"># 设置按钮的点击事件。当点击时，调用上面定义的 qa_chain_self_answer 函数，并传入用户的消息和聊天历史记录，然后更新文本框和聊天机器人组件。</span><br>        db_wo_his_btn.click(model_center.qa_chain_self_answer, inputs=[<br>                            msg, chatbot], outputs=[msg, chatbot])<br>        <br>    gr.Markdown(<span class="hljs-string">&quot;&quot;&quot;提醒：&lt;br&gt;</span><br><span class="hljs-string">    1. 初始化数据库时间可能较长，请耐心等待。</span><br><span class="hljs-string">    2. 使用中如果出现异常，将会在文本输入框进行展示，请不要惊慌。 &lt;br&gt;</span><br><span class="hljs-string">    &quot;&quot;&quot;</span>)<br><span class="hljs-comment"># threads to consume the request</span><br>gr.close_all()<br><span class="hljs-comment"># 启动新的 Gradio 应用，设置分享功能为 True，并使用环境变量 PORT1 指定服务器端口。</span><br><span class="hljs-comment"># demo.launch(share=True, server_port=int(os.environ[&#x27;PORT1&#x27;]))</span><br><span class="hljs-comment"># 直接启动</span><br>demo.launch()<br></code></pre></td></tr></table></figure>
<p>运行截图如下：</p>
<p><img  src="gradio.png"  ><span class="image-caption">运行gradio</span></p>
<p><img  src="Langchain+InternLM问答.png"  ><span class="image-caption">Langchain+InternLM问答</span></p>
<p>如图，能够正确地回答知识库中的知识。</p>
<h2 id="问题解决以及-Langchain-调试"><a href="#问题解决以及-Langchain-调试" class="headerlink" title="问题解决以及 Langchain 调试"></a>问题解决以及 Langchain 调试</h2><p>我们在遇到奇怪问题的时候，想要调试 Langchain，这个时候可以借助 Langchain 的全局设置设置调试模式，设置方式如下所示：</p>
<p><a href="https://python.langchain.com/docs/guides/debugging">Debugging | 🦜️🔗 Langchain</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.<span class="hljs-built_in">globals</span> <span class="hljs-keyword">import</span> set_verbose <span class="hljs-comment"># 我这里用的 langchain 版本为 0.1.0</span><br><br>set_verbose(<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p><img  src="langchain-debug.png"  ><span class="image-caption">langchain 的调试输出</span></p>
<h2 id="将应用部署在-OpenXLab-上"><a href="#将应用部署在-OpenXLab-上" class="headerlink" title="将应用部署在 OpenXLab 上"></a>将应用部署在 OpenXLab 上</h2><p><a href="https://openxlab.org.cn/apps/detail/EnableAsync/network-bot">计算机网络问答机器人</a></p>
<h3 id="Sqlite-问题1"><a href="#Sqlite-问题1" class="headerlink" title="Sqlite 问题1"></a>Sqlite 问题<sup><a href="#fn_1" id="reffn_1">1</a></sup></h3><p>OpenXLab 上的 sqlite3 版本低于我们项目用的 Chroma 要求。可参考<a href="https://link.zhihu.com/?target=https%3A//docs.trychroma.com/troubleshooting%23sqlite"> Troubleshooting | Chroma (trychroma.com)</a>，在 <code>requirements.txt</code> 中添加 <code>pysqlite3-binary</code> ，之后加载 sqlite3 库来绕过这个问题。否则就要写脚本在运行时自己安装上更新版本的sqlite3了。下面是修改加载 sqlite3 库的 trick 命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">__import__</span>(<span class="hljs-string">&#x27;pysqlite3&#x27;</span>)<br><span class="hljs-keyword">import</span> sys<br>sys.modules[<span class="hljs-string">&#x27;sqlite3&#x27;</span>] = sys.modules.pop(<span class="hljs-string">&#x27;pysqlite3&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h3 id="运行截图"><a href="#运行截图" class="headerlink" title="运行截图"></a>运行截图</h3><p><img  src="openxlab-deploy.png"  ><span class="image-caption">openxlab-deploy</span></p>
<p><img  src="loading.png"  ><span class="image-caption">加载模型</span></p>
<p><img  src="部署.png"  ><span class="image-caption">部署</span></p>
<p><img  src="运行日志.png"  ><span class="image-caption">运行日志</span></p>
<h2 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h2><blockquote id="fn_1">
<sup>1</sup>. <a href="https://zhuanlan.zhihu.com/p/676719586">书生・浦语大模型实战营第三课作业(基础+进阶) - 知乎 (zhihu.com)</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
]]></content>
      <categories>
        <category>internlm</category>
      </categories>
  </entry>
  <entry>
    <title>Internlm-04-XTuner 大模型单卡低成本微调实战</title>
    <url>/internlm/internlm-04/</url>
    <content><![CDATA[<h1 id="XTuner-大模型单卡低成本微调实战"><a href="#XTuner-大模型单卡低成本微调实战" class="headerlink" title="XTuner 大模型单卡低成本微调实战"></a>XTuner 大模型单卡低成本微调实战</h1><p>微调前<br><img  src="官方回答.png"  ><span class="image-caption">官方回答</span></p>
<p>微调后<br><img  src="微调后.png"  ><span class="image-caption">微调后.png</span></p>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><h3 id="1-1-XTuner"><a href="#1-1-XTuner" class="headerlink" title="1.1 XTuner"></a>1.1 XTuner</h3><p>一个大语言模型微调工具箱。由 MMRazor 和 MMDeploy 联合开发。</p>
<h3 id="1-2-支持的开源LLM-2023-11-01"><a href="#1-2-支持的开源LLM-2023-11-01" class="headerlink" title="1.2 支持的开源LLM (2023.11.01)"></a>1.2 支持的开源LLM (2023.11.01)</h3><ul>
<li><a href="https://huggingface.co/internlm/internlm-7b">InternLM</a></li>
<li><a href="https://huggingface.co/meta-llama">Llama，Llama2</a></li>
<li><a href="https://huggingface.co/THUDM/chatglm2-6b">ChatGLM2</a>，<a href="https://huggingface.co/THUDM/chatglm3-6b-base">ChatGLM3</a></li>
<li><a href="https://huggingface.co/Qwen/Qwen-7B">Qwen</a></li>
<li><a href="https://huggingface.co/baichuan-inc/Baichuan-7B">Baichuan</a>，<a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Base">Baichuan2</a></li>
<li><a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta">Zephyr</a> </li>
</ul>
<h3 id="1-3-特色"><a href="#1-3-特色" class="headerlink" title="1.3 特色"></a>1.3 特色</h3><ul>
<li><strong>傻瓜化：</strong> 以 配置文件 的形式封装了大部分微调场景，<strong>0基础的非专业人员也能一键开始微调</strong>。</li>
<li><strong>轻量级：</strong> 对于 7B 参数量的LLM，<strong>微调所需的最小显存仅为 8GB</strong></li>
</ul>
<h3 id="1-4-微调原理"><a href="#1-4-微调原理" class="headerlink" title="1.4 微调原理"></a>1.4 微调原理</h3><blockquote>
<p>想象一下，你有一个超大的玩具，现在你想改造这个超大的玩具。但是，<strong>对整个玩具进行全面的改动会非常昂贵</strong>。</p>
</blockquote>
<p>※ 因此，你找到了一种叫 <strong>LoRA</strong> 的方法：<strong>只对玩具中的某些零件进行改动，而不是对整个玩具进行全面改动</strong>。</p>
<p>※ 而 <strong>QLoRA</strong> 是 LoRA 的一种改进</p>
<h2 id="2-快速上手"><a href="#2-快速上手" class="headerlink" title="2 快速上手"></a>2 快速上手</h2><h3 id="2-1-平台"><a href="#2-1-平台" class="headerlink" title="2.1 平台"></a>2.1 平台</h3><p>Ubuntu + Anaconda + CUDA/CUDNN + 8GB nvidia显卡</p>
<h3 id="2-2-安装"><a href="#2-2-安装" class="headerlink" title="2.2 安装"></a>2.2 安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 如果你是在 InternStudio 平台，则从本地 clone 一个已有 pytorch 2.0.1 的环境：</span><br>/root/share/install_conda_env_internlm_base.sh xtuner0.1.9<br><span class="hljs-comment"># 如果你是在其他平台：</span><br>conda create --name xtuner0.1.9 python=3.10 -y<br><br><span class="hljs-comment"># 激活环境</span><br>conda activate xtuner0.1.9<br><span class="hljs-comment"># 进入家目录 （~的意思是 “当前用户的home路径”）</span><br><span class="hljs-built_in">cd</span> ~<br><span class="hljs-comment"># 创建版本文件夹并进入，以跟随本教程</span><br><span class="hljs-built_in">mkdir</span> xtuner019 &amp;&amp; <span class="hljs-built_in">cd</span> xtuner019<br><br><br><span class="hljs-comment"># 拉取 0.1.9 的版本源码</span><br>git <span class="hljs-built_in">clone</span> -b v0.1.9  https://github.com/InternLM/xtuner<br><span class="hljs-comment"># 无法访问github的用户请从 gitee 拉取:</span><br><span class="hljs-comment"># git clone -b v0.1.9 https://gitee.com/Internlm/xtuner</span><br><br><span class="hljs-comment"># 进入源码目录</span><br><span class="hljs-built_in">cd</span> xtuner<br><br><span class="hljs-comment"># 从源码安装 XTuner</span><br>pip install -e <span class="hljs-string">&#x27;.[all]&#x27;</span><br></code></pre></td></tr></table></figure>
<p>安装完后，就开始搞搞准备工作了。（准备在 oasst1 数据集上微调 internlm-7b-chat）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建一个微调 oasst1 数据集的工作路径，进入</span><br><span class="hljs-built_in">mkdir</span> ~/ft-oasst1 &amp;&amp; <span class="hljs-built_in">cd</span> ~/ft-oasst1<br></code></pre></td></tr></table></figure>
<h3 id="2-3-微调"><a href="#2-3-微调" class="headerlink" title="2.3 微调"></a>2.3 微调</h3><h4 id="2-3-1-准备配置文件"><a href="#2-3-1-准备配置文件" class="headerlink" title="2.3.1 准备配置文件"></a>2.3.1 准备配置文件</h4><p>XTuner 提供多个开箱即用的配置文件，用户可以通过下列命令查看：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 列出所有内置配置</span><br>xtuner list-cfg<br></code></pre></td></tr></table></figure>
<blockquote>
<p>假如显示bash: xtuner: command not found的话可以考虑在终端输入 export PATH=$PATH:’/root/.local/bin’</p>
</blockquote>
<p><img  src="cfg-list.png"  ><span class="image-caption">部分配置文件展示</span></p>
<p>拷贝一个配置文件到当前目录：<br><code># xtuner copy-cfg $&#123;CONFIG_NAME&#125; $&#123;SAVE_PATH&#125;</code></p>
<p>在本案例中即：（注意最后有个英文句号，代表复制到当前路径）<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-built_in">cd</span> ~/ft-oasst1<br>xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 .<br></code></pre></td></tr></table></figure></p>
<p>配置文件名的解释：</p>
<blockquote>
<p>xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 .</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>模型名</th>
<th>internlm_chat_7b</th>
</tr>
</thead>
<tbody>
<tr>
<td>使用算法</td>
<td>qlora</td>
</tr>
<tr>
<td>数据集</td>
<td>oasst1</td>
</tr>
<tr>
<td>把数据集跑几次</td>
<td>跑3次：e3 (epoch 3 )</td>
</tr>
</tbody>
</table>
</div>
<p>*无 chat比如 <code>internlm-7b</code> 代表是基座(base)模型</p>
<h4 id="2-3-2-模型下载"><a href="#2-3-2-模型下载" class="headerlink" title="2.3.2 模型下载"></a>2.3.2 模型下载</h4><blockquote>
<p>由于下载模型很慢，用教学平台的同学可以直接复制模型。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-built_in">cp</span> -r /root/share/temp/model_repos/internlm-chat-7b ~/ft-oasst1/<br></code></pre></td></tr></table></figure>
<blockquote>
<p>以下是自己下载模型的步骤。</p>
</blockquote>
<p>不用 xtuner 默认的<code>从 huggingface 拉取模型</code>，而是提前从 ModelScope 下载模型到本地</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 创建一个目录，放模型文件，防止散落一地</span><br><span class="hljs-built_in">mkdir</span> ~/ft-oasst1/internlm-chat-7b<br><br><span class="hljs-comment"># 装一下拉取模型文件要用的库</span><br>pip install modelscope<br><br><span class="hljs-comment"># 从 modelscope 下载下载模型文件</span><br><span class="hljs-built_in">cd</span> ~/ft-oasst1<br>apt install git git-lfs -y<br>git lfs install<br>git lfs <span class="hljs-built_in">clone</span> https://modelscope.cn/Shanghai_AI_Laboratory/internlm-chat-7b.git -b v1.0.3<br></code></pre></td></tr></table></figure>
<h4 id="2-3-3-数据集下载"><a href="#2-3-3-数据集下载" class="headerlink" title="2.3.3 数据集下载"></a>2.3.3 数据集下载</h4><blockquote>
<p><a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco/tree/main">https://huggingface.co/datasets/timdettmers/openassistant-guanaco/tree/main</a></p>
</blockquote>
<p>由于 huggingface 网络问题，咱们已经给大家提前下载好了，复制到正确位置即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/ft-oasst1<br><span class="hljs-comment"># ...-guanaco 后面有个空格和英文句号啊</span><br><span class="hljs-built_in">cp</span> -r /root/share/temp/datasets/openassistant-guanaco .<br></code></pre></td></tr></table></figure>
<p>此时，当前路径的文件应该长这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">|-- internlm-chat-7b<br>|   |-- README.md<br>|   |-- config.json<br>|   |-- configuration.json<br>|   |-- configuration_internlm.py<br>|   |-- generation_config.json<br>|   |-- modeling_internlm.py<br>|   |-- pytorch_model-00001-of-00008.bin<br>|   |-- pytorch_model-00002-of-00008.bin<br>|   |-- pytorch_model-00003-of-00008.bin<br>|   |-- pytorch_model-00004-of-00008.bin<br>|   |-- pytorch_model-00005-of-00008.bin<br>|   |-- pytorch_model-00006-of-00008.bin<br>|   |-- pytorch_model-00007-of-00008.bin<br>|   |-- pytorch_model-00008-of-00008.bin<br>|   |-- pytorch_model.bin.index.json<br>|   |-- special_tokens_map.json<br>|   |-- tokenization_internlm.py<br>|   |-- tokenizer.model<br>|   `-- tokenizer_config.json<br>|-- internlm_chat_7b_qlora_oasst1_e3_copy.py<br>`-- openassistant-guanaco<br>    |-- openassistant_best_replies_eval.jsonl<br>    `-- openassistant_best_replies_train.jsonl<br></code></pre></td></tr></table></figure>
<h4 id="2-3-4-修改配置文件"><a href="#2-3-4-修改配置文件" class="headerlink" title="2.3.4 修改配置文件"></a>2.3.4 修改配置文件</h4><p>修改其中的模型和数据集为 本地路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/ft-oasst1<br>vim internlm_chat_7b_qlora_oasst1_e3_copy.py<br></code></pre></td></tr></table></figure>
<blockquote>
<p>在vim界面完成修改后，请输入:wq退出。假如认为改错了可以用:q!退出且不保存。当然我们也可以考虑打开python文件直接修改，但注意修改完后需要按下Ctrl+S进行保存。</p>
</blockquote>
<p>减号代表要删除的行，加号代表要增加的行。<br><figure class="highlight diff"><table><tr><td class="code"><pre><code class="hljs diff"># 修改模型为本地路径<br><span class="hljs-deletion">- pretrained_model_name_or_path = &#x27;internlm/internlm-chat-7b&#x27;</span><br><span class="hljs-addition">+ pretrained_model_name_or_path = &#x27;./internlm-chat-7b&#x27;</span><br><br># 修改训练数据集为本地路径<br><span class="hljs-deletion">- data_path = &#x27;timdettmers/openassistant-guanaco&#x27;</span><br><span class="hljs-addition">+ data_path = &#x27;./openassistant-guanaco&#x27;</span><br></code></pre></td></tr></table></figure></p>
<p><strong>常用超参</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数名</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>data_path</strong></td>
<td>数据路径或 HuggingFace 仓库名</td>
</tr>
<tr>
<td>max_length</td>
<td>单条数据最大 Token 数，超过则截断</td>
</tr>
<tr>
<td>pack_to_max_length</td>
<td>是否将多条短数据拼接到 max_length，提高 GPU 利用率</td>
</tr>
<tr>
<td>accumulative_counts</td>
<td>梯度累积，每多少次 backward 更新一次参数</td>
</tr>
<tr>
<td>evaluation_inputs</td>
<td>训练过程中，会根据给定的问题进行推理，便于观测训练状态</td>
</tr>
<tr>
<td>evaluation_freq</td>
<td>Evaluation 的评测间隔 iter 数</td>
</tr>
<tr>
<td>……</td>
<td>……</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>如果想把显卡的现存吃满，充分利用显卡资源，可以将 <code>max_length</code> 和 <code>batch_size</code> 这两个参数调大。</p>
</blockquote>
<h4 id="2-3-5-开始微调"><a href="#2-3-5-开始微调" class="headerlink" title="2.3.5 开始微调"></a>2.3.5 开始微调</h4><p><strong>训练：</strong></p>
<p>xtuner train ${CONFIG_NAME_OR_PATH}</p>
<p><strong>也可以增加 deepspeed 进行训练加速：</strong></p>
<p>xtuner train ${CONFIG_NAME_OR_PATH} —deepspeed deepspeed_zero2</p>
<p>例如，我们可以利用 QLoRA 算法在 oasst1 数据集上微调 InternLM-7B：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 单卡</span><br><span class="hljs-comment">## 用刚才改好的config文件训练</span><br>xtuner train ./internlm_chat_7b_qlora_oasst1_e3_copy.py<br><br><span class="hljs-comment"># 多卡</span><br>NPROC_PER_NODE=<span class="hljs-variable">$&#123;GPU_NUM&#125;</span> xtuner train ./internlm_chat_7b_qlora_oasst1_e3_copy.py<br><br><span class="hljs-comment"># 若要开启 deepspeed 加速，增加 --deepspeed deepspeed_zero2 即可</span><br></code></pre></td></tr></table></figure>
<blockquote>
<p>微调得到的 PTH 模型文件和其他杂七杂八的文件都默认在当前的 <code>./work_dirs</code> 中。</p>
</blockquote>
<p><img  src="train.png"  ><span class="image-caption">训练截图</span></p>
<p>跑完训练后，当前路径应该长这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash">|-- internlm-chat-7b<br>|-- internlm_chat_7b_qlora_oasst1_e3_copy.py<br>|-- openassistant-guanaco<br>|   |-- openassistant_best_replies_eval.jsonl<br>|   `-- openassistant_best_replies_train.jsonl<br>`-- work_dirs<br>    `-- internlm_chat_7b_qlora_oasst1_e3_copy<br>        |-- 20231101_152923<br>        |   |-- 20231101_152923.<span class="hljs-built_in">log</span><br>        |   `-- vis_data<br>        |       |-- 20231101_152923.json<br>        |       |-- config.py<br>        |       `-- scalars.json<br>        |-- epoch_1.pth<br>        |-- epoch_2.pth<br>        |-- epoch_3.pth<br>        |-- internlm_chat_7b_qlora_oasst1_e3_copy.py<br>        `-- last_checkpoint<br></code></pre></td></tr></table></figure>
<h4 id="2-3-6-将得到的-PTH-模型转换为-HuggingFace-模型，即：生成-Adapter-文件夹"><a href="#2-3-6-将得到的-PTH-模型转换为-HuggingFace-模型，即：生成-Adapter-文件夹" class="headerlink" title="2.3.6 将得到的 PTH 模型转换为 HuggingFace 模型，即：生成 Adapter 文件夹"></a>2.3.6 将得到的 PTH 模型转换为 HuggingFace 模型，<strong>即：生成 Adapter 文件夹</strong></h4><p><code>xtuner convert pth_to_hf $&#123;CONFIG_NAME_OR_PATH&#125; $&#123;PTH_file_dir&#125; $&#123;SAVE_PATH&#125;</code></p>
<p>在本示例中，为：<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> hf<br><span class="hljs-built_in">export</span> MKL_SERVICE_FORCE_INTEL=1<br><br>xtuner convert pth_to_hf ./internlm_chat_7b_qlora_oasst1_e3_copy.py ./work_dirs/internlm_chat_7b_qlora_oasst1_e3_copy/epoch_1.pth ./hf<br></code></pre></td></tr></table></figure><br>此时，路径中应该长这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash">|-- internlm-chat-7b<br>|-- internlm_chat_7b_qlora_oasst1_e3_copy.py<br>|-- openassistant-guanaco<br>|   |-- openassistant_best_replies_eval.jsonl<br>|   `-- openassistant_best_replies_train.jsonl<br>|-- hf<br>|   |-- README.md<br>|   |-- adapter_config.json<br>|   |-- adapter_model.bin<br>|   `-- xtuner_config.py<br>`-- work_dirs<br>    `-- internlm_chat_7b_qlora_oasst1_e3_copy<br>        |-- 20231101_152923<br>        |   |-- 20231101_152923.<span class="hljs-built_in">log</span><br>        |   `-- vis_data<br>        |       |-- 20231101_152923.json<br>        |       |-- config.py<br>        |       `-- scalars.json<br>        |-- epoch_1.pth<br>        |-- epoch_2.pth<br>        |-- epoch_3.pth<br>        |-- internlm_chat_7b_qlora_oasst1_e3_copy.py<br>        `-- last_checkpoint<br></code></pre></td></tr></table></figure>
<p><span style="color: red;"><strong>此时，hf 文件夹即为我们平时所理解的所谓 “LoRA 模型文件”</strong></span></p>
<blockquote>
<p>可以简单理解：LoRA 模型文件 = Adapter</p>
</blockquote>
<h3 id="2-4-部署与测试"><a href="#2-4-部署与测试" class="headerlink" title="2.4 部署与测试"></a>2.4 部署与测试</h3><h4 id="2-4-1-将-HuggingFace-adapter-合并到大语言模型："><a href="#2-4-1-将-HuggingFace-adapter-合并到大语言模型：" class="headerlink" title="2.4.1 将 HuggingFace adapter 合并到大语言模型："></a>2.4.1 将 HuggingFace adapter 合并到大语言模型：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash">xtuner convert merge ./internlm-chat-7b ./hf ./merged --max-shard-size 2GB<br><span class="hljs-comment"># xtuner convert merge \</span><br><span class="hljs-comment">#     $&#123;NAME_OR_PATH_TO_LLM&#125; \</span><br><span class="hljs-comment">#     $&#123;NAME_OR_PATH_TO_ADAPTER&#125; \</span><br><span class="hljs-comment">#     $&#123;SAVE_PATH&#125; \</span><br><span class="hljs-comment">#     --max-shard-size 2GB</span><br></code></pre></td></tr></table></figure>
<h4 id="2-4-2-与合并后的模型对话："><a href="#2-4-2-与合并后的模型对话：" class="headerlink" title="2.4.2 与合并后的模型对话："></a>2.4.2 与合并后的模型对话：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 加载 Adapter 模型对话（Float 16）</span><br>xtuner chat ./merged --prompt-template internlm_chat<br><br><span class="hljs-comment"># 4 bit 量化加载</span><br><span class="hljs-comment"># xtuner chat ./merged --bits 4 --prompt-template internlm_chat</span><br></code></pre></td></tr></table></figure>
<h4 id="2-4-3-Demo"><a href="#2-4-3-Demo" class="headerlink" title="2.4.3 Demo"></a>2.4.3 Demo</h4><ul>
<li>修改 <code>cli_demo.py</code> 中的模型路径<figure class="highlight diff"><table><tr><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">- model_name_or_path = &quot;/root/model/Shanghai_AI_Laboratory/internlm-chat-7b&quot;</span><br><span class="hljs-addition">+ model_name_or_path = &quot;merged&quot;</span><br></code></pre></td></tr></table></figure></li>
<li>运行 <code>cli_demo.py</code> 以目测微调效果<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python ./cli_demo.py<br></code></pre></td></tr></table></figure>
</li>
</ul>
<p><strong><code>xtuner chat</code></strong> <strong>的启动参数</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>启动参数</th>
<th>干哈滴</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>—prompt-template</strong></td>
<td>指定对话模板</td>
</tr>
<tr>
<td>—system</td>
<td>指定SYSTEM文本</td>
</tr>
<tr>
<td>—system-template</td>
<td>指定SYSTEM模板</td>
</tr>
<tr>
<td>-<strong>-bits</strong></td>
<td>LLM位数</td>
</tr>
<tr>
<td>—bot-name</td>
<td>bot名称</td>
</tr>
<tr>
<td>—with-plugins</td>
<td>指定要使用的插件</td>
</tr>
<tr>
<td><strong>—no-streamer</strong></td>
<td>是否启用流式传输</td>
</tr>
<tr>
<td><strong>—lagent</strong></td>
<td>是否使用lagent</td>
</tr>
<tr>
<td>—command-stop-word</td>
<td>命令停止词</td>
</tr>
<tr>
<td>—answer-stop-word</td>
<td>回答停止词</td>
</tr>
<tr>
<td>—offload-folder</td>
<td>存放模型权重的文件夹（或者已经卸载模型权重的文件夹）</td>
</tr>
<tr>
<td>—max-new-tokens</td>
<td>生成文本中允许的最大 <code>token</code> 数量</td>
</tr>
<tr>
<td><strong>—temperature</strong></td>
<td>温度值</td>
</tr>
<tr>
<td>—top-k</td>
<td>保留用于顶k筛选的最高概率词汇标记数</td>
</tr>
<tr>
<td>—top-p</td>
<td>如果设置为小于1的浮点数，仅保留概率相加高于 <code>top_p</code> 的最小一组最有可能的标记</td>
</tr>
<tr>
<td>—seed</td>
<td>用于可重现文本生成的随机种子</td>
</tr>
</tbody>
</table>
</div>
<h2 id="3-自定义微调"><a href="#3-自定义微调" class="headerlink" title="3 自定义微调"></a>3 自定义微调</h2><blockquote>
<p>以 <strong><a href="https://github.com/abachaa/Medication_QA_MedInfo2019">Medication QA</a></strong> <strong>数据集</strong>为例</p>
</blockquote>
<h3 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h3><h4 id="3-1-1-场景需求"><a href="#3-1-1-场景需求" class="headerlink" title="3.1.1 场景需求"></a>3.1.1 <strong>场景需求</strong></h4><p>   基于 InternLM-chat-7B 模型，用 MedQA 数据集进行微调，将其往<code>医学问答</code>领域对齐。</p>
<h4 id="3-1-2-真实数据预览"><a href="#3-1-2-真实数据预览" class="headerlink" title="3.1.2 真实数据预览"></a>3.1.2 <strong>真实数据预览</strong></h4><div class="table-container">
<table>
<thead>
<tr>
<th>问题</th>
<th>答案</th>
</tr>
</thead>
<tbody>
<tr>
<td>What are ketorolac eye drops?（什么是酮咯酸滴眼液？）</td>
<td>Ophthalmic   ketorolac is used to treat itchy eyes caused by allergies. It also is used to   treat swelling and redness (inflammation) that can occur after cataract   surgery. Ketorolac is in a class of medications called nonsteroidal   anti-inflammatory drugs (NSAIDs). It works by stopping the release of   substances that cause allergy symptoms and inflammation.</td>
</tr>
<tr>
<td>What medicines raise blood sugar? （什么药物会升高血糖？）</td>
<td>Some   medicines for conditions other than diabetes can raise your blood sugar   level. This is a concern when you have diabetes. Make sure every doctor you   see knows about all of the medicines, vitamins, or herbal supplements you   take. This means anything you take with or without a prescription. Examples include:     Barbiturates.     Thiazide diuretics.     Corticosteroids.     Birth control pills (oral contraceptives) and progesterone.     Catecholamines.     Decongestants that contain beta-adrenergic agents, such as pseudoephedrine.     The B vitamin niacin. The risk of high blood sugar from niacin lowers after you have taken it for a few months. The antipsychotic medicine olanzapine (Zyprexa).</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-2-数据准备"><a href="#3-2-数据准备" class="headerlink" title="3.2 数据准备"></a>3.2 数据准备</h3><blockquote>
<p><strong>以</strong> <strong><a href="https://github.com/abachaa/Medication_QA_MedInfo2019">Medication QA</a></strong> <strong>数据集为例</strong></p>
</blockquote>
<p><strong>原格式：(.xlsx)</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>问题</strong></th>
<th>药物类型</th>
<th>问题类型</th>
<th><strong>回答</strong></th>
<th>主题</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>aaa</td>
<td>bbb</td>
<td>ccc</td>
<td>ddd</td>
<td>eee</td>
<td>fff</td>
</tr>
</tbody>
</table>
</div>
<h4 id="3-2-1-将数据转为-XTuner-的数据格式"><a href="#3-2-1-将数据转为-XTuner-的数据格式" class="headerlink" title="3.2.1 将数据转为 XTuner 的数据格式"></a>3.2.1 将数据转为 XTuner 的数据格式</h4><p><strong>目标格式：(.jsonL)</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs JSON"><span class="hljs-punctuation">[</span><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;conversation&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;system&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xxx&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xxx&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;output&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xxx&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;conversation&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;system&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xxx&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xxx&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;output&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xxx&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure>
<p>通过 pytho n脚本：将 <code>.xlsx</code> 中的 问题 和 回答 两列 提取出来，再放入 <code>.jsonL</code> 文件的每个 conversation 的 input 和 output 中。</p>
<blockquote>
<p>这一步的 python 脚本可以请 ChatGPT 来完成。</p>
</blockquote>
<figure class="highlight text"><table><tr><td class="code"><pre><code class="hljs text">Write a python file for me. using openpyxl. input file name is MedQA2019.xlsx<br>Step1: The input file is .xlsx. Exact the column A and column D in the sheet named &quot;DrugQA&quot; .<br>Step2: Put each value in column A into each &quot;input&quot; of each &quot;conversation&quot;. Put each value in column D into each &quot;output&quot; of each &quot;conversation&quot;.<br>Step3: The output file is .jsonL. It looks like:<br>[&#123;<br>    &quot;conversation&quot;:[<br>        &#123;<br>            &quot;system&quot;: &quot;xxx&quot;,<br>            &quot;input&quot;: &quot;xxx&quot;,<br>            &quot;output&quot;: &quot;xxx&quot;<br>        &#125;<br>    ]<br>&#125;,<br>&#123;<br>    &quot;conversation&quot;:[<br>        &#123;<br>            &quot;system&quot;: &quot;xxx&quot;,<br>            &quot;input&quot;: &quot;xxx&quot;,<br>            &quot;output&quot;: &quot;xxx&quot;<br>        &#125;<br>    ]<br>&#125;]<br>Step4: All &quot;system&quot; value changes to &quot;You are a professional, highly experienced doctor professor. You always provide accurate, comprehensive, and detailed answers based on the patients&#x27; questions.&quot;<br></code></pre></td></tr></table></figure>
<blockquote>
<p>ChatGPT 生成的 python 代码见本仓库的 <a href="./xlsx2jsonl.py">xlsx2jsonl.py</a></p>
</blockquote>
<p>执行 python 脚本，获得格式化后的数据集：<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python xlsx2jsonl.py<br></code></pre></td></tr></table></figure></p>
<p>此时，当然也可以对数据进行训练集和测试集的分割，同样可以让 ChatGPT 写 python 代码。当然如果你没有严格的科研需求、不在乎“训练集泄露”的问题，也可以不做训练集与测试集的分割。</p>
<h4 id="3-2-2-划分训练集和测试集"><a href="#3-2-2-划分训练集和测试集" class="headerlink" title="3.2.2 划分训练集和测试集"></a>3.2.2 划分训练集和测试集</h4><figure class="highlight text"><table><tr><td class="code"><pre><code class="hljs text">my .jsonL file looks like:<br>[&#123;<br>    &quot;conversation&quot;:[<br>        &#123;<br>            &quot;system&quot;: &quot;xxx&quot;,<br>            &quot;input&quot;: &quot;xxx&quot;,<br>            &quot;output&quot;: &quot;xxx&quot;<br>        &#125;<br>    ]<br>&#125;,<br>&#123;<br>    &quot;conversation&quot;:[<br>        &#123;<br>            &quot;system&quot;: &quot;xxx&quot;,<br>            &quot;input&quot;: &quot;xxx&quot;,<br>            &quot;output&quot;: &quot;xxx&quot;<br>        &#125;<br>    ]<br>&#125;]<br>Step1, read the .jsonL file.<br>Step2, count the amount of the &quot;conversation&quot; elements.<br>Step3, randomly split all &quot;conversation&quot; elements by 7:3. Targeted structure is same as the input.<br>Step4, save the 7/10 part as train.jsonl. save the 3/10 part as test.jsonl<br></code></pre></td></tr></table></figure>
<p>生成的python代码见 <a href="./split2train_and_test.py">split2train_and_test.py</a></p>
<h3 id="3-3-开始自定义微调"><a href="#3-3-开始自定义微调" class="headerlink" title="3.3 开始自定义微调"></a>3.3 开始自定义微调</h3><p>此时，我们重新建一个文件夹来玩“微调自定义数据集”<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> ~/ft-medqa &amp;&amp; <span class="hljs-built_in">cd</span> ~/ft-medqa<br></code></pre></td></tr></table></figure></p>
<p>把前面下载好的internlm-chat-7b模型文件夹拷贝过来。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> -r ~/ft-oasst1/internlm-chat-7b .<br></code></pre></td></tr></table></figure>
<p>别忘了把自定义数据集，即几个 <code>.jsonL</code>，也传到服务器上。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/InternLM/tutorial<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> ~/tutorial/xtuner/MedQA2019-structured-train.jsonl .<br></code></pre></td></tr></table></figure>
<h4 id="3-3-1-准备配置文件"><a href="#3-3-1-准备配置文件" class="headerlink" title="3.3.1 准备配置文件"></a>3.3.1 准备配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 复制配置文件到当前目录</span><br>xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 .<br><span class="hljs-comment"># 改个文件名</span><br><span class="hljs-built_in">mv</span> internlm_chat_7b_qlora_oasst1_e3_copy.py internlm_chat_7b_qlora_medqa2019_e3.py<br><br><span class="hljs-comment"># 修改配置文件内容</span><br>vim internlm_chat_7b_qlora_medqa2019_e3.py<br></code></pre></td></tr></table></figure>
<p>减号代表要删除的行，加号代表要增加的行。<br><figure class="highlight diff"><table><tr><td class="code"><pre><code class="hljs diff"># 修改import部分<br><span class="hljs-deletion">- from xtuner.dataset.map_fns import oasst1_map_fn, template_map_fn_factory</span><br><span class="hljs-addition">+ from xtuner.dataset.map_fns import template_map_fn_factory</span><br><br># 修改模型为本地路径<br><span class="hljs-deletion">- pretrained_model_name_or_path = &#x27;internlm/internlm-chat-7b&#x27;</span><br><span class="hljs-addition">+ pretrained_model_name_or_path = &#x27;./internlm-chat-7b&#x27;</span><br><br># 修改训练数据为 MedQA2019-structured-train.jsonl 路径<br><span class="hljs-deletion">- data_path = &#x27;timdettmers/openassistant-guanaco&#x27;</span><br><span class="hljs-addition">+ data_path = &#x27;MedQA2019-structured-train.jsonl&#x27;</span><br><br># 修改 train_dataset 对象<br>train_dataset = dict(<br>    type=process_hf_dataset,<br><span class="hljs-deletion">-   dataset=dict(type=load_dataset, path=data_path),</span><br><span class="hljs-addition">+   dataset=dict(type=load_dataset, path=&#x27;json&#x27;, data_files=dict(train=data_path)),</span><br>    tokenizer=tokenizer,<br>    max_length=max_length,<br><span class="hljs-deletion">-   dataset_map_fn=alpaca_map_fn,</span><br><span class="hljs-addition">+   dataset_map_fn=None,</span><br>    template_map_fn=dict(<br>        type=template_map_fn_factory, template=prompt_template),<br>    remove_unused_columns=True,<br>    shuffle_before_pack=True,<br>    pack_to_max_length=pack_to_max_length)<br></code></pre></td></tr></table></figure></p>
<h4 id="3-3-2-XTuner！启动！"><a href="#3-3-2-XTuner！启动！" class="headerlink" title="3.3.2 XTuner！启动！"></a>3.3.2 <strong>XTuner！启动！</strong></h4><p><img  src="imgs/ysqd.png"  ><span class="image-caption">tH8udZzECYl5are.png</span></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">xtuner train internlm_chat_7b_qlora_medqa2019_e3.py --deepspeed deepspeed_zero2<br></code></pre></td></tr></table></figure>
<h4 id="3-3-3-pth-转-huggingface"><a href="#3-3-3-pth-转-huggingface" class="headerlink" title="3.3.3 pth 转 huggingface"></a>3.3.3 pth 转 huggingface</h4><p>同前述，这里不赘述了。<a href="#236-将得到的-pth-模型转换为-huggingface-模型即生成adapter文件夹">将得到的-pth-模型转换为-huggingface-模型即生成adapter文件夹</a>  </p>
<h4 id="3-3-4-部署与测试"><a href="#3-3-4-部署与测试" class="headerlink" title="3.3.4 部署与测试"></a>3.3.4 部署与测试</h4><p>同前述。<a href="#24-部署与测试">部署与测试</a></p>
<h2 id="4-用-MS-Agent-数据集-赋予-LLM-以-Agent-能力"><a href="#4-用-MS-Agent-数据集-赋予-LLM-以-Agent-能力" class="headerlink" title="4 用 MS-Agent 数据集 赋予 LLM 以 Agent 能力"></a>4 用 MS-Agent 数据集 赋予 LLM 以 Agent 能力</h2><h3 id="4-1-概述"><a href="#4-1-概述" class="headerlink" title="4.1 概述"></a>4.1 概述</h3><p>MSAgent 数据集每条样本包含一个对话列表（conversations），其里面包含了 system、user、assistant 三种字段。其中：</p>
<ul>
<li><p>system: 表示给模型前置的人设输入，其中有告诉模型如何调用插件以及生成请求</p>
</li>
<li><p>user: 表示用户的输入 prompt，分为两种，通用生成的prompt和调用插件需求的 prompt</p>
</li>
<li><p>assistant: 为模型的回复。其中会包括插件调用代码和执行代码，调用代码是要 LLM 生成的，而执行代码是调用服务来生成结果的</p>
</li>
</ul>
<p>一条调用网页搜索插件查询“上海明天天气”的数据样本示例如下图所示：<br><img  src="imgs/msagent_data.png"  ><span class="image-caption">BlgfEqpiRFO5G6L.png</span></p>
<h3 id="4-2-微调步骤"><a href="#4-2-微调步骤" class="headerlink" title="4.2 微调步骤"></a>4.2 微调步骤</h3><h4 id="4-2-1-准备工作"><a href="#4-2-1-准备工作" class="headerlink" title="4.2.1 准备工作"></a>4.2.1 准备工作</h4><blockquote>
<p>xtuner 是从国内的 ModelScope 平台下载 MS-Agent 数据集，因此不用提前手动下载数据集文件。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 准备工作</span><br><span class="hljs-built_in">mkdir</span> ~/ft-msagent &amp;&amp; <span class="hljs-built_in">cd</span> ~/ft-msagent<br><span class="hljs-built_in">cp</span> -r ~/ft-oasst1/internlm-chat-7b .<br><br><span class="hljs-comment"># 查看配置文件</span><br>xtuner list-cfg | grep msagent<br><br><span class="hljs-comment"># 复制配置文件到当前目录</span><br>xtuner copy-cfg internlm_7b_qlora_msagent_react_e3_gpu8 .<br><br><span class="hljs-comment"># 修改配置文件中的模型为本地路径</span><br>vim ./internlm_7b_qlora_msagent_react_e3_gpu8_copy.py <br></code></pre></td></tr></table></figure>
<figure class="highlight diff"><table><tr><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">- pretrained_model_name_or_path = &#x27;internlm/internlm-chat-7b&#x27;</span><br><span class="hljs-addition">+ pretrained_model_name_or_path = &#x27;./internlm-chat-7b&#x27;</span><br></code></pre></td></tr></table></figure>
<h4 id="4-2-2-开始微调"><a href="#4-2-2-开始微调" class="headerlink" title="4.2.2 开始微调"></a>4.2.2 开始微调</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash">xtuner train ./internlm_7b_qlora_msagent_react_e3_gpu8_copy.py --deepspeed deepspeed_zero2<br></code></pre></td></tr></table></figure>
<h3 id="4-3-直接使用"><a href="#4-3-直接使用" class="headerlink" title="4.3 直接使用"></a>4.3 直接使用</h3><blockquote>
<p>由于 msagent 的训练非常费时，大家如果想尽快把这个教程跟完，可以直接从 modelScope 拉取咱们已经微调好了的 Adapter。如下演示。</p>
</blockquote>
<h4 id="4-3-1-下载-Adapter"><a href="#4-3-1-下载-Adapter" class="headerlink" title="4.3.1 下载 Adapter"></a>4.3.1 下载 Adapter</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs Bash"><span class="hljs-built_in">cd</span> ~/ft-msagent<br>apt install git git-lfs<br>git lfs install<br>git lfs <span class="hljs-built_in">clone</span> https://www.modelscope.cn/xtuner/internlm-7b-qlora-msagent-react.git<br></code></pre></td></tr></table></figure>
<p>OK，现在目录应该长这样：</p>
<ul>
<li>internlm_7b_qlora_msagent_react_e3_gpu8_copy.py</li>
<li>internlm-7b-qlora-msagent-react</li>
<li>internlm-chat-7b</li>
<li>work_dir（可有可无）</li>
</ul>
<p>有了这个在 msagent 上训练得到的Adapter，模型现在已经有 agent 能力了！就可以加 —lagent 以调用来自 lagent 的代理功能了！</p>
<h4 id="4-3-2-添加-serper-环境变量"><a href="#4-3-2-添加-serper-环境变量" class="headerlink" title="4.3.2 添加 serper 环境变量"></a>4.3.2 添加 serper 环境变量</h4><blockquote>
<p><strong>开始 chat 之前，还要加个 serper 的环境变量：</strong></p>
<p>去 serper.dev 免费注册一个账号，生成自己的 api key。这个东西是用来给 lagent 去获取 google 搜索的结果的。等于是 serper.dev 帮你去访问 google，而不是从你自己本地去访问 google 了。</p>
</blockquote>
<p><img  src="imgs/serper.png"  ><span class="image-caption">kDSdpQrhHfTWYsc.png</span></p>
<p>添加 serper api key 到环境变量：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> SERPER_API_KEY=abcdefg<br></code></pre></td></tr></table></figure>
<h4 id="4-3-3-xtuner-agent，启动！"><a href="#4-3-3-xtuner-agent，启动！" class="headerlink" title="4.3.3 xtuner + agent，启动！"></a>4.3.3 xtuner + agent，启动！</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">xtuner chat ./internlm-chat-7b --adapter internlm-7b-qlora-msagent-react --lagent<br></code></pre></td></tr></table></figure>
<h2 id="5-注意事项"><a href="#5-注意事项" class="headerlink" title="5 注意事项"></a>5 注意事项</h2><p>本教程使用 xtuner 0.1.9 版本<br>若需要跟着本教程一步一步完成，建议严格遵循本教程的步骤！</p>
<p>若出现莫名其妙报错，请尝试更换为以下包的版本：（如果有报错再检查，没报错不用看）<br><figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">torch</span>                         <span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">transformers</span>                  <span class="hljs-number">4</span>.<span class="hljs-number">34</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">transformers</span>-stream-generator <span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install torch==2.1.1<br>pip install transformers==4.34.0<br>pip install transformers-stream-generator=0.0.4<br></code></pre></td></tr></table></figure><br>CUDA 相关：（如果有报错再检查，没报错不用看）<br><figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">NVIDIA</span>-SMI <span class="hljs-number">535</span>.<span class="hljs-number">54</span>.<span class="hljs-number">03</span>              <br><span class="hljs-attribute">Driver</span> Version: <span class="hljs-number">535</span>.<span class="hljs-number">54</span>.<span class="hljs-number">03</span>    <br><span class="hljs-attribute">CUDA</span> Version: <span class="hljs-number">12</span>.<span class="hljs-number">2</span><br><br><span class="hljs-attribute">nvidia</span>-cuda-cupti-cu12        <span class="hljs-number">12</span>.<span class="hljs-number">1</span>.<span class="hljs-number">105</span><br><span class="hljs-attribute">nvidia</span>-cuda-nvrtc-cu12        <span class="hljs-number">12</span>.<span class="hljs-number">1</span>.<span class="hljs-number">105</span><br><span class="hljs-attribute">nvidia</span>-cuda-runtime-cu12      <span class="hljs-number">12</span>.<span class="hljs-number">1</span>.<span class="hljs-number">105</span><br></code></pre></td></tr></table></figure></p>
<h2 id="6-作业"><a href="#6-作业" class="headerlink" title="6 作业"></a>6 作业</h2><h3 id="1-概述-1"><a href="#1-概述-1" class="headerlink" title="1 概述"></a>1 概述</h3><p>目标：通过微调，让模型成为我们的小助手</p>
<p>方式：使用 XTuner 进行微调</p>
<p><strong>微调前</strong><br><img  src="官方回答.png"  ><span class="image-caption">官方回答</span></p>
<p><strong>微调后</strong><br><img  src="微调后.png"  ><span class="image-caption">微调后.png</span></p>
<h3 id="2-实操"><a href="#2-实操" class="headerlink" title="2 实操"></a>2 实操</h3><h4 id="微调环境准备"><a href="#微调环境准备" class="headerlink" title="微调环境准备"></a>微调环境准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># InternStudio 平台中，从本地 clone 一个已有 pytorch 2.0.1 的环境（后续均在该环境执行，若为其他环境可作为参考）</span><br><span class="hljs-comment"># 进入环境后首先 bash</span><br><span class="hljs-comment"># 进入环境后首先 bash</span><br><span class="hljs-comment"># 进入环境后首先 bash</span><br>bash<br>conda create --name personal_assistant --<span class="hljs-built_in">clone</span>=/root/share/conda_envs/internlm-base<br><span class="hljs-comment"># 如果在其他平台：</span><br><span class="hljs-comment"># conda create --name personal_assistant python=3.10 -y</span><br><br><span class="hljs-comment"># 激活环境</span><br>conda activate personal_assistant<br><span class="hljs-comment"># 进入家目录 （~的意思是 “当前用户的home路径”）</span><br><span class="hljs-built_in">cd</span> ~<br><span class="hljs-comment"># 创建版本文件夹并进入，以跟随本教程</span><br><span class="hljs-comment"># personal_assistant用于存放本教程所使用的东西</span><br><span class="hljs-built_in">mkdir</span> /root/personal_assistant &amp;&amp; <span class="hljs-built_in">cd</span> /root/personal_assistant<br><span class="hljs-built_in">mkdir</span> /root/personal_assistant/xtuner019 &amp;&amp; <span class="hljs-built_in">cd</span> /root/personal_assistant/xtuner019<br><br><span class="hljs-comment"># 拉取 0.1.9 的版本源码</span><br>git <span class="hljs-built_in">clone</span> -b v0.1.9  https://github.com/InternLM/xtuner<br><span class="hljs-comment"># 无法访问github的用户请从 gitee 拉取:</span><br><span class="hljs-comment"># git clone -b v0.1.9 https://gitee.com/Internlm/xtuner</span><br><br><span class="hljs-comment"># 进入源码目录</span><br><span class="hljs-built_in">cd</span> xtuner<br><br><span class="hljs-comment"># 从源码安装 XTuner</span><br>pip install -e <span class="hljs-string">&#x27;.[all]&#x27;</span><br></code></pre></td></tr></table></figure>
<h4 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h4><p>创建<code>data</code>文件夹用于存放用于训练的数据集</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /root/personal_assistant/data &amp;&amp; <span class="hljs-built_in">cd</span> /root/personal_assistant/data<br></code></pre></td></tr></table></figure>
<p>在<code>data</code>目录下创建一个json文件<code>personal_assistant.json</code>作为本次微调所使用的数据集。json中内容可参考下方(复制粘贴n次做数据增广，数据量小无法有效微调，下面仅用于展示格式，下面也有生成脚本)</p>
<p>其中<code>conversation</code>表示一次对话的内容，<code>input</code>为输入，即用户会问的问题，<code>output</code>为输出，即想要模型回答的答案。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;conversation&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;请介绍一下你自己&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;output&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;我是不要葱姜蒜大佬的小助手，内在是上海AI实验室书生·浦语的7B大模型哦&quot;</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;conversation&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;请做一下自我介绍&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;output&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;我是不要葱姜蒜大佬的小助手，内在是上海AI实验室书生·浦语的7B大模型哦&quot;</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure>
<p>以下是一个python脚本，用于生成数据集。在<code>data</code>目录下新建一个generate_data.py文件，将以下代码复制进去，然后运行该脚本即可生成数据集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><br><span class="hljs-comment"># 输入你的名字</span><br>name = <span class="hljs-string">&#x27;Shengshenlan&#x27;</span><br><span class="hljs-comment"># 重复次数</span><br>n = <span class="hljs-number">10000</span><br><br>data = [<br>    &#123;<br>        <span class="hljs-string">&quot;conversation&quot;</span>: [<br>            &#123;<br>                <span class="hljs-string">&quot;input&quot;</span>: <span class="hljs-string">&quot;请做一下自我介绍&quot;</span>,<br>                <span class="hljs-string">&quot;output&quot;</span>: <span class="hljs-string">&quot;我是&#123;&#125;的小助手，内在是上海AI实验室书生·浦语的7B大模型哦&quot;</span>.<span class="hljs-built_in">format</span>(name)<br>            &#125;<br>        ]<br>    &#125;<br>]<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    data.append(data[<span class="hljs-number">0</span>])<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;personal_assistant.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(data, f, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>)<br><br></code></pre></td></tr></table></figure>
<h4 id="配置准备"><a href="#配置准备" class="headerlink" title="配置准备"></a>配置准备</h4><p>下载模型<code>InternLM-chat-7B</code></p>
<p><a href="https://studio.intern-ai.org.cn/">InternStudio</a> 平台的 <code>share</code> 目录下已经为我们准备了全系列的 <code>InternLM</code> 模型，可以使用如下命令复制<code>internlm-chat-7b</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /root/personal_assistant/model/Shanghai_AI_Laboratory<br><span class="hljs-built_in">cp</span> -r /root/share/temp/model_repos/internlm-chat-7b /root/personal_assistant/model/Shanghai_AI_Laboratory<br></code></pre></td></tr></table></figure>
<p>XTuner 提供多个开箱即用的配置文件，用户可以通过下列命令查看：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 列出所有内置配置</span><br>xtuner list-cfg<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#创建用于存放配置的文件夹config并进入</span><br><span class="hljs-built_in">mkdir</span> /root/personal_assistant/config &amp;&amp; <span class="hljs-built_in">cd</span> /root/personal_assistant/config<br></code></pre></td></tr></table></figure>
<p>拷贝一个配置文件到当前目录：<code>xtuner copy-cfg $&#123;CONFIG_NAME&#125; $&#123;SAVE_PATH&#125;</code><br>在本例中：（注意最后有个英文句号，代表复制到当前路径）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">xtuner copy-cfg internlm_chat_7b_qlora_oasst1_e3 .<br></code></pre></td></tr></table></figure>
<p>修改拷贝后的文件internlm_chat_7b_qlora_oasst1_e3_copy.py，修改下述位置：<br>(这是一份修改好的文件<a href="./internlm_chat_7b_qlora_oasst1_e3_copy.py">internlm_chat_7b_qlora_oasst1_e3_copy.py</a>)<br><img  src="修改配置.png"  ><span class="image-caption">修改配置</span></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># PART 1 中</span><br><span class="hljs-comment"># 预训练模型存放的位置</span><br>pretrained_model_name_or_path = <span class="hljs-string">&#x27;/root/personal_assistant/model/Shanghai_AI_Laboratory/internlm-chat-7b&#x27;</span><br><br><span class="hljs-comment"># 微调数据存放的位置</span><br>data_path = <span class="hljs-string">&#x27;/root/personal_assistant/data/personal_assistant.json&#x27;</span><br><br><span class="hljs-comment"># 训练中最大的文本长度</span><br>max_length = 512<br><br><span class="hljs-comment"># 每一批训练样本的大小</span><br>batch_size = 2<br><br><span class="hljs-comment"># 最大训练轮数</span><br>max_epochs = 3<br><br><span class="hljs-comment"># 验证的频率</span><br>evaluation_freq = 90<br><br><span class="hljs-comment"># 用于评估输出内容的问题（用于评估的问题尽量与数据集的question保持一致）</span><br>evaluation_inputs = [ <span class="hljs-string">&#x27;请介绍一下你自己&#x27;</span>, <span class="hljs-string">&#x27;请做一下自我介绍&#x27;</span> ]<br><br><br><span class="hljs-comment"># PART 3 中</span><br>dataset=dict(<span class="hljs-built_in">type</span>=load_dataset, path=<span class="hljs-string">&#x27;json&#x27;</span>, data_files=dict(train=data_path))<br>dataset_map_fn=None<br></code></pre></td></tr></table></figure>
<h4 id="微调启动"><a href="#微调启动" class="headerlink" title="微调启动"></a>微调启动</h4><p>用<code>xtuner train</code>命令启动训练、</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">xtuner train /root/personal_assistant/config/internlm_chat_7b_qlora_oasst1_e3_copy.py<br></code></pre></td></tr></table></figure>
<p><img  src="训练过程.png"  ><span class="image-caption">训练数据样例</span></p>
<blockquote>
<p>会在训练完成后，输出用于验证的Sample output</p>
<h4 id="微调后参数转换-合并"><a href="#微调后参数转换-合并" class="headerlink" title="微调后参数转换/合并"></a>微调后参数转换/合并</h4></blockquote>
<p>训练后的pth格式参数转Hugging Face格式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建用于存放Hugging Face格式参数的hf文件夹</span><br><span class="hljs-built_in">mkdir</span> /root/personal_assistant/config/work_dirs/hf<br><br><span class="hljs-built_in">export</span> MKL_SERVICE_FORCE_INTEL=1<br><br><span class="hljs-comment"># 配置文件存放的位置</span><br><span class="hljs-built_in">export</span> CONFIG_NAME_OR_PATH=/root/personal_assistant/config/internlm_chat_7b_qlora_oasst1_e3_copy.py<br><br><span class="hljs-comment"># 模型训练后得到的pth格式参数存放的位置</span><br><span class="hljs-built_in">export</span> PTH=/root/personal_assistant/config/work_dirs/internlm_chat_7b_qlora_oasst1_e3_copy/epoch_3.pth<br><br><span class="hljs-comment"># pth文件转换为Hugging Face格式后参数存放的位置</span><br><span class="hljs-built_in">export</span> SAVE_PATH=/root/personal_assistant/config/work_dirs/hf<br><br><span class="hljs-comment"># 执行参数转换</span><br>xtuner convert pth_to_hf <span class="hljs-variable">$CONFIG_NAME_OR_PATH</span> <span class="hljs-variable">$PTH</span> <span class="hljs-variable">$SAVE_PATH</span><br></code></pre></td></tr></table></figure>
<p>Merge模型参数<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> MKL_SERVICE_FORCE_INTEL=1<br><span class="hljs-built_in">export</span> MKL_THREADING_LAYER=<span class="hljs-string">&#x27;GNU&#x27;</span><br><br><span class="hljs-comment"># 原始模型参数存放的位置</span><br><span class="hljs-built_in">export</span> NAME_OR_PATH_TO_LLM=/root/personal_assistant/model/Shanghai_AI_Laboratory/internlm-chat-7b<br><br><span class="hljs-comment"># Hugging Face格式参数存放的位置</span><br><span class="hljs-built_in">export</span> NAME_OR_PATH_TO_ADAPTER=/root/personal_assistant/config/work_dirs/hf<br><br><span class="hljs-comment"># 最终Merge后的参数存放的位置</span><br><span class="hljs-built_in">mkdir</span> /root/personal_assistant/config/work_dirs/hf_merge<br><span class="hljs-built_in">export</span> SAVE_PATH=/root/personal_assistant/config/work_dirs/hf_merge<br><br><span class="hljs-comment"># 执行参数Merge</span><br>xtuner convert merge \<br>    <span class="hljs-variable">$NAME_OR_PATH_TO_LLM</span> \<br>    <span class="hljs-variable">$NAME_OR_PATH_TO_ADAPTER</span> \<br>    <span class="hljs-variable">$SAVE_PATH</span> \<br>    --max-shard-size 2GB<br></code></pre></td></tr></table></figure></p>
<h4 id="网页DEMO"><a href="#网页DEMO" class="headerlink" title="网页DEMO"></a>网页DEMO</h4><p>安装网页Demo所需依赖</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install streamlit==1.24.0<br></code></pre></td></tr></table></figure>
<p>下载 InternLM 项目代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建code文件夹用于存放InternLM项目代码</span><br><span class="hljs-built_in">mkdir</span> /root/personal_assistant/code &amp;&amp; <span class="hljs-built_in">cd</span> /root/personal_assistant/code<br>git <span class="hljs-built_in">clone</span> https://github.com/InternLM/InternLM.git<br></code></pre></td></tr></table></figure>
<p>将 <code>/root/code/InternLM/web_demo.py</code> 中 29 行和 33 行的模型路径更换为Merge后存放参数的路径 <code>/root/personal_assistant/config/work_dirs/hf_merge</code><br>运行 <code>/root/personal_assistant/code/InternLM</code> 目录下的 <code>web_demo.py</code> 文件，之后将端口映射到本地。在本地浏览器输入 <code>http://127.0.0.1:6006</code> 即可。</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><code class="hljs stylus">streamlit run /root/personal_assistant/code/InternLM/web_demo<span class="hljs-selector-class">.py</span> <span class="hljs-attr">--server</span><span class="hljs-selector-class">.address</span> <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span> <span class="hljs-attr">--server</span><span class="hljs-selector-class">.port</span> <span class="hljs-number">6006</span><br></code></pre></td></tr></table></figure>
<p>注意：要在浏览器打开 <code>http://127.0.0.1:6006</code> 页面后，模型才会加载。<br>在加载完模型之后，就可以与微调后的 InternLM-Chat-7B 进行对话了</p>
<h3 id="3-效果"><a href="#3-效果" class="headerlink" title="3 效果"></a>3 效果</h3><p>微调前<br><img  src="官方回答.png"  ><span class="image-caption">官方回答</span></p>
<p>微调后<br><img  src="微调后.png"  ><span class="image-caption">微调后.png</span></p>
<h2 id="7-进阶作业"><a href="#7-进阶作业" class="headerlink" title="7 进阶作业"></a>7 进阶作业</h2><h3 id="1-模型上传"><a href="#1-模型上传" class="headerlink" title="1 模型上传"></a>1 模型上传</h3><p><img  src="model-upload.png"  ><span class="image-caption">model-upload.png</span></p>
<h3 id="2-修改启动文件"><a href="#2-修改启动文件" class="headerlink" title="2 修改启动文件"></a>2 修改启动文件</h3><p>接下来需要修改启动文件以下载模型以及合并 lora 层，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> openxlab.model <span class="hljs-keyword">import</span> download<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Download</span>():<br>    download(model_repo=<span class="hljs-string">&#x27;OpenLMLab/InternLM-chat-7b&#x27;</span>,output=<span class="hljs-string">&#x27;/home/xlab-app-center/InternLM-chat-7b&#x27;</span>)<br>    download(model_repo=<span class="hljs-string">&#x27;EnableAsync/openxlab-assistant&#x27;</span>,output=<span class="hljs-string">&quot;/home/xlab-app-center/hf&quot;</span>)<br><br>Download()<br>os.system(<span class="hljs-string">&#x27;echo $PWD&#x27;</span>)<br>os.system(<span class="hljs-string">&#x27;ls&#x27;</span>)<br><br>os.system(<span class="hljs-string">&#x27;xtuner convert merge /home/xlab-app-center/InternLM-chat-7b /home/xlab-app-center/hf /home/xlab-app-center/hf-merge --max-shard-size 2GB&#x27;</span>)<br>os.system(<span class="hljs-string">&#x27;streamlit run /home/xlab-app-center/InternLM/web_demo.py --server.address=0.0.0.0 --server.port 7860&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h3 id="3-构建并运行"><a href="#3-构建并运行" class="headerlink" title="3 构建并运行"></a>3 构建并运行</h3><p><img  src="./build.png"  ><span class="image-caption">构建及运行</span></p>
<p>Github 地址如下：</p>
<p><a href="https://github.com/EnableAsync/openxlab-assistant">EnableAsync/openxlab-assistant (github.com)</a></p>
<p>运行地址如下：</p>
<p><a href="https://openxlab.org.cn/apps/detail/EnableAsync/openxlab-assistant">应用中心-OpenXLab-小卡的助手</a></p>
]]></content>
      <categories>
        <category>internlm</category>
      </categories>
  </entry>
  <entry>
    <title>Internlm-06-使用 OpenCompass 对大模型进行评测</title>
    <url>/internlm/internlm-06/</url>
    <content><![CDATA[<h1 id="使用-OpenCompass-对大模型进行评测"><a href="#使用-OpenCompass-对大模型进行评测" class="headerlink" title="使用 OpenCompass 对大模型进行评测"></a>使用 OpenCompass 对大模型进行评测</h1><h2 id="大模型评测概要"><a href="#大模型评测概要" class="headerlink" title="大模型评测概要"></a>大模型评测概要</h2><h3 id="人工智能技术的发展和主要模型的演变"><a href="#人工智能技术的发展和主要模型的演变" class="headerlink" title="人工智能技术的发展和主要模型的演变"></a>人工智能技术的发展和主要模型的演变</h3><ul>
<li><strong>OpenAI GPT系列：</strong><ul>
<li>2018年：发布第一代GPT模型，开启自然语言模型生成式预训练。</li>
<li>随后：发布GPT-2和GPT-3模型。</li>
</ul>
</li>
<li><strong>谷歌的预训练模型：</strong><ul>
<li>探索不同的大规模预训练模型，如T5, Flan等。</li>
</ul>
</li>
<li><strong>OpenAI的ChatGPT和GPT-4：</strong><ul>
<li>2022年11月：发布ChatGPT，展示问答、逻辑推理和内容创作能力。</li>
<li>2023年4月：发布GPT-4，引入多模态能力，拓展语言模型能力。</li>
</ul>
</li>
</ul>
<h3 id="大模型的国际竞争和应用"><a href="#大模型的国际竞争和应用" class="headerlink" title="大模型的国际竞争和应用"></a>大模型的国际竞争和应用</h3><ul>
<li><strong>OpenAI和微软的集成：</strong><ul>
<li>将ChatGPT和GPT-4集成进搜索引擎和Office办公套件，推出New Bing和Office Copilot。</li>
</ul>
</li>
<li><strong>谷歌的Bard：</strong><ul>
<li>基于PaLM和PaLM-2模型，与OpenAI和微软竞争。</li>
</ul>
</li>
<li><strong>中国企业和高校的发展：</strong><ul>
<li>百度、阿里、华为、商汤、讯飞等发布国产大模型。</li>
<li>清华、复旦等高校发布GLM, MOSS等模型。</li>
</ul>
</li>
</ul>
<h3 id="大模型评测的国际和国内进展"><a href="#大模型评测的国际和国内进展" class="headerlink" title="大模型评测的国际和国内进展"></a>大模型评测的国际和国内进展</h3><ul>
<li><strong>国际评测框架和数据集：</strong><ul>
<li>斯坦福大学的HELM评测框架。</li>
<li>纽约大学与谷歌、Meta的SuperGLUE评测集。</li>
<li>加州大学伯克利分校的MMLU测试集。</li>
<li>谷歌的Big-Bench评测集。</li>
</ul>
</li>
<li><strong>中国的评测数据集：</strong><ul>
<li>如CLUE, CUGE等，评测中文语言模型能力。</li>
</ul>
</li>
</ul>
<h3 id="面临的挑战和OpenCompass的提议"><a href="#面临的挑战和OpenCompass的提议" class="headerlink" title="面临的挑战和OpenCompass的提议"></a>面临的挑战和OpenCompass的提议</h3><ul>
<li><strong>当前挑战：</strong><ul>
<li>大模型应用场景广泛，但评测方案往往缺乏系统化。</li>
</ul>
</li>
<li><strong>OpenCompass的提议：</strong><ul>
<li>设计全面、高效、可拓展的评测方案。</li>
<li>提供分布式自动化评测系统，支持全面系统的能力评估。</li>
</ul>
</li>
</ul>
<h1 id="OpenCompass介绍"><a href="#OpenCompass介绍" class="headerlink" title="OpenCompass介绍"></a>OpenCompass介绍</h1><h2 id="评测对象"><a href="#评测对象" class="headerlink" title="评测对象"></a>评测对象</h2><p>本算法库的主要评测对象为语言大模型与多模态大模型。我们以语言大模型为例介绍评测的具体模型类型。</p>
<ul>
<li><p><strong>基座模型</strong>：一般是经过海量的文本数据以自监督学习的方式进行训练获得的模型（如OpenAI的GPT-3，Meta的LLaMA），往往具有强大的文字续写能力。</p>
</li>
<li><p><strong>对话模型</strong>：一般是在的基座模型的基础上，经过指令微调或人类偏好对齐获得的模型（如OpenAI的ChatGPT、上海人工智能实验室的书生·浦语），能理解人类指令，具有较强的对话能力。</p>
</li>
</ul>
<h2 id="工具架构"><a href="#工具架构" class="headerlink" title="工具架构"></a>工具架构</h2><p><img  src="工具架构.png"  ><span class="image-caption">工具架构</span></p>
<h3 id="大模型评测的层级结构"><a href="#大模型评测的层级结构" class="headerlink" title="大模型评测的层级结构"></a>大模型评测的层级结构</h3><ul>
<li><p>模型层</p>
<ul>
<li>重点评测对象：<ul>
<li>基座模型</li>
<li>对话模型</li>
</ul>
</li>
</ul>
</li>
<li><p>能力层</p>
<ul>
<li><p>通用能力：</p>
<ul>
<li>语言</li>
<li>知识</li>
<li>理解</li>
<li>推理</li>
<li>安全</li>
</ul>
</li>
<li><p>特色能力：</p>
<ul>
<li>长文本处理</li>
<li>编码能力</li>
<li>工具使用</li>
<li>知识增强</li>
</ul>
</li>
</ul>
</li>
<li><p>方法层</p>
<ul>
<li><p>客观评测：</p>
<ul>
<li>评估模型在确定答案任务（如选择题、填空、封闭式问答）上的能力。</li>
</ul>
</li>
<li><p>主观评测：</p>
<ul>
<li>评估用户对模型回复的真实满意度。</li>
<li>方法包括：<ul>
<li>基于模型辅助的主观评测</li>
<li>基于人类反馈的主观评测</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>工具层</p>
<ul>
<li>自动化评测支持：<ul>
<li>分布式评测技术</li>
<li>提示词工程</li>
<li>对接评测数据库</li>
<li>评测榜单发布</li>
<li>评测报告生成</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="评测方法"><a href="#评测方法" class="headerlink" title="评测方法"></a>评测方法</h2><h3 id="客观评测"><a href="#客观评测" class="headerlink" title="客观评测"></a>客观评测</h3><h4 id="评测客观问题的方法"><a href="#评测客观问题的方法" class="headerlink" title="评测客观问题的方法"></a>评测客观问题的方法</h4><ul>
<li><strong>定量比较：</strong><ul>
<li>使用定量指标比较模型输出与标准答案的差异。</li>
<li>根据差异结果衡量模型性能。</li>
</ul>
</li>
<li><p><strong>输入输出规范：</strong></p>
<ul>
<li>在评测阶段规范模型的输入和输出。</li>
<li>尽量减少噪声输出，以便更客观地评价模型能力。</li>
</ul>
<h4 id="模型能力的激发与引导"><a href="#模型能力的激发与引导" class="headerlink" title="模型能力的激发与引导"></a>模型能力的激发与引导</h4></li>
<li><p>提示词工程（Prompt Engineering）：</p>
<ul>
<li>使用特定提示词引导模型输出。</li>
</ul>
</li>
<li><p>语境学习（In-Context Learning）：</p>
<ul>
<li>利用上下文环境提升模型的输出质量。</li>
</ul>
<h4 id="客观评测的具体实践"><a href="#客观评测的具体实践" class="headerlink" title="客观评测的具体实践"></a>客观评测的具体实践</h4></li>
<li><p><strong>判别式评测：</strong></p>
<ul>
<li>结合问题和候选答案。</li>
<li>计算困惑度（perplexity），选择困惑度最小的答案。</li>
</ul>
</li>
<li><strong>生成式评测：</strong><ul>
<li>用于生成类任务（如语言翻译、程序生成、逻辑分析）。</li>
<li>使用问题作为输入，留白答案区域由模型补全。</li>
<li>对模型输出进行后处理，确保满足数据集要求。</li>
</ul>
</li>
</ul>
<h3 id="主观评测"><a href="#主观评测" class="headerlink" title="主观评测"></a>主观评测</h3><h4 id="主观评测的重要性"><a href="#主观评测的重要性" class="headerlink" title="主观评测的重要性"></a>主观评测的重要性</h4><ul>
<li>场景和能力多样性：<ul>
<li>语言表达丰富多变，很多场景和能力难以通过客观指标评测。</li>
</ul>
</li>
<li>模型安全和语言能力：<ul>
<li>需要依赖人的主观感受进行评测，以更真实地反映模型能力。</li>
</ul>
</li>
</ul>
<h4 id="OpenCompass的主观评测方案"><a href="#OpenCompass的主观评测方案" class="headerlink" title="OpenCompass的主观评测方案"></a>OpenCompass的主观评测方案</h4><ul>
<li>评测实施：<ul>
<li>使用受试者的主观判断对大语言模型进行评测。</li>
<li>构建主观测试问题集，对比不同模型的回复。</li>
</ul>
</li>
<li>成本与效率：<ul>
<li>高成本的人类主观评测。</li>
<li>结合使用性能优异的大语言模型进行主观打分。</li>
</ul>
</li>
</ul>
<h4 id="主观评测的具体实践"><a href="#主观评测的具体实践" class="headerlink" title="主观评测的具体实践"></a>主观评测的具体实践</h4><ul>
<li>单模型回复满意度统计：<ul>
<li>对单一模型的回复进行满意度评分。</li>
</ul>
</li>
<li>多模型满意度比较：<ul>
<li>比较不同模型回复的满意度。</li>
</ul>
</li>
</ul>
<h1 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h1><p><img  src="opencompass流程.png"  ><span class="image-caption">opencompass 评判流程</span></p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>在 OpenCompass 中评估一个模型通常包括以下几个阶段：<strong>配置</strong> -&gt; <strong>推理</strong> -&gt; <strong>评估</strong> -&gt; <strong>可视化</strong>。</p>
<p><strong>配置</strong>：这是整个工作流的起点。您需要配置整个评估过程，选择要评估的模型和数据集。此外，还可以选择评估策略、计算后端等，并定义显示结果的方式。</p>
<p><strong>推理与评估</strong>：在这个阶段，OpenCompass 将会开始对模型和数据集进行并行推理和评估。<strong>推理</strong>阶段主要是让模型从数据集产生输出，而<strong>评估</strong>阶段则是衡量这些输出与标准答案的匹配程度。这两个过程会被拆分为多个同时运行的“任务”以提高效率，但请注意，如果计算资源有限，这种策略可能会使评测变得更慢。</p>
<p><strong>可视化</strong>：评估完成后，OpenCompass 将结果整理成易读的表格，并将其保存为 CSV 和 TXT 文件。你也可以激活飞书状态上报功能，此后可以在飞书客户端中及时获得评测状态报告。</p>
<p>接下来，我们将展示 OpenCompass 的基础用法，展示书生浦语在 <a href="https://cevalbenchmark.com/index.html#home">C-Eval</a> 基准任务上的评估。它们的配置文件可以在 <a href="https://github.com/open-compass/opencompass/blob/main/configs/eval_demo.py">configs/eval_demo.py</a> 中找到。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="面向GPU的环境安装"><a href="#面向GPU的环境安装" class="headerlink" title="面向GPU的环境安装"></a>面向GPU的环境安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">conda create --name opencompass --<span class="hljs-built_in">clone</span>=/root/share/conda_envs/internlm-base<br>conda activate opencompass<br>git <span class="hljs-built_in">clone</span> https://github.com/open-compass/opencompass<br><span class="hljs-built_in">cd</span> opencompass<br>pip install -e .<br></code></pre></td></tr></table></figure>
<p>有部分第三方功能,如代码能力基准测试 Humaneval 以及 Llama格式的模型评测,可能需要额外步骤才能正常运行，如需评测，详细步骤请参考<a href="https://opencompass.readthedocs.io/zh_CN/latest/get_started/installation.html">安装指南</a>。</p>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 解压评测数据集到 data/ 处</span><br><span class="hljs-built_in">cp</span> /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/<br>unzip OpenCompassData-core-20231110.zip<br><br><span class="hljs-comment"># 将会在opencompass下看到data文件夹</span><br></code></pre></td></tr></table></figure>
<h3 id="查看支持的数据集和模型"><a href="#查看支持的数据集和模型" class="headerlink" title="查看支持的数据集和模型"></a>查看支持的数据集和模型</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 列出所有跟 internlm 及 ceval 相关的配置</span><br>python tools/list_configs.py internlm ceval<br></code></pre></td></tr></table></figure>
<p>将会看到</p>
<figure class="highlight text"><table><tr><td class="code"><pre><code class="hljs text">+--------------------------+--------------------------------------------------------+<br>| Model                    | Config Path                                            |<br>|--------------------------+--------------------------------------------------------|<br>| hf_internlm_20b          | configs/models/hf_internlm/hf_internlm_20b.py          |<br>| hf_internlm_7b           | configs/models/hf_internlm/hf_internlm_7b.py           |<br>| hf_internlm_chat_20b     | configs/models/hf_internlm/hf_internlm_chat_20b.py     |<br>| hf_internlm_chat_7b      | configs/models/hf_internlm/hf_internlm_chat_7b.py      |<br>| hf_internlm_chat_7b_8k   | configs/models/hf_internlm/hf_internlm_chat_7b_8k.py   |<br>| hf_internlm_chat_7b_v1_1 | configs/models/hf_internlm/hf_internlm_chat_7b_v1_1.py |<br>| internlm_7b              | configs/models/internlm/internlm_7b.py                 |<br>| ms_internlm_chat_7b_8k   | configs/models/ms_internlm/ms_internlm_chat_7b_8k.py   |<br>+--------------------------+--------------------------------------------------------+<br>+----------------------------+------------------------------------------------------+<br>| Dataset                    | Config Path                                          |<br>|----------------------------+------------------------------------------------------|<br>| ceval_clean_ppl            | configs/datasets/ceval/ceval_clean_ppl.py            |<br>| ceval_gen                  | configs/datasets/ceval/ceval_gen.py                  |<br>| ceval_gen_2daf24           | configs/datasets/ceval/ceval_gen_2daf24.py           |<br>| ceval_gen_5f30c7           | configs/datasets/ceval/ceval_gen_5f30c7.py           |<br>| ceval_ppl                  | configs/datasets/ceval/ceval_ppl.py                  |<br>| ceval_ppl_578f8d           | configs/datasets/ceval/ceval_ppl_578f8d.py           |<br>| ceval_ppl_93e5ce           | configs/datasets/ceval/ceval_ppl_93e5ce.py           |<br>| ceval_zero_shot_gen_bd40ef | configs/datasets/ceval/ceval_zero_shot_gen_bd40ef.py |<br>+----------------------------+------------------------------------------------------+<br></code></pre></td></tr></table></figure>
<h3 id="启动评测"><a href="#启动评测" class="headerlink" title="启动评测"></a>启动评测</h3><p>确保按照上述步骤正确安装 OpenCompass 并准备好数据集后，可以通过以下命令评测 InternLM-Chat-7B 模型在 C-Eval 数据集上的性能。由于 OpenCompass 默认并行启动评估过程，我们可以在第一次运行时以 <code>--debug</code> 模式启动评估，并检查是否存在问题。在 <code>--debug</code> 模式下，任务将按顺序执行，并实时打印输出。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py --datasets ceval_gen --hf-path /share/temp/model_repos/internlm-chat-7b/ --tokenizer-path /share/temp/model_repos/internlm-chat-7b/ --tokenizer-kwargs padding_side=<span class="hljs-string">&#x27;left&#x27;</span> truncation=<span class="hljs-string">&#x27;left&#x27;</span> trust_remote_code=True --model-kwargs trust_remote_code=True device_map=<span class="hljs-string">&#x27;auto&#x27;</span> --max-seq-len 2048 --max-out-len 16 --batch-size 4 --num-gpus 1 --debug<br></code></pre></td></tr></table></figure>
<p>命令解析<br><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">--datasets ceval_gen \<br>--hf-path /share/temp/model_repos/internlm-chat-7b/ \  <span class="hljs-comment"># HuggingFace 模型路径</span><br>--tokenizer-path /share/temp/model_repos/internlm-chat-7b/ \  <span class="hljs-comment"># HuggingFace tokenizer 路径（如果与模型路径相同，可以省略）</span><br>--tokenizer-kwargs padding_side=<span class="hljs-string">&#x27;left&#x27;</span> truncation=<span class="hljs-string">&#x27;left&#x27;</span> trust_remote_code=True \  <span class="hljs-comment"># 构建 tokenizer 的参数</span><br>--model-kwargs device_map=<span class="hljs-string">&#x27;auto&#x27;</span> trust_remote_code=True \  <span class="hljs-comment"># 构建模型的参数</span><br>--max-seq-len 2048 \  <span class="hljs-comment"># 模型可以接受的最大序列长度</span><br>--max-out-len 16 \  <span class="hljs-comment"># 生成的最大 token 数</span><br>--batch-size 2  \  <span class="hljs-comment"># 批量大小</span><br>--num-gpus 1  <span class="hljs-comment"># 运行模型所需的 GPU 数量</span><br>--debug<br></code></pre></td></tr></table></figure></p>
<p>如果一切正常，您应该看到屏幕上显示 “Starting inference process”：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[2024-01-12 18:23:55,076] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...<br></code></pre></td></tr></table></figure>
<p>评测完成后，将会看到：<br><figure class="highlight maxima"><table><tr><td class="code"><pre><code class="hljs maxima"><br>dataset                                         version    metric         mode      opencompass.models.huggingface.HuggingFace_model_repos_internlm-chat-7b<br>----------------------------------------------  ---------  -------------  ------  -------------------------------------------------------------------------<br>ceval-computer_network                          db9ce2     accuracy       gen                                                                         <span class="hljs-number">31.58</span><br>ceval-operating_system                          1c2571     accuracy       gen                                                                         <span class="hljs-number">36.84</span><br>ceval-computer_architecture                     a74dad     accuracy       gen                                                                         <span class="hljs-number">28.57</span><br>ceval-college_programming                       4ca32a     accuracy       gen                                                                         <span class="hljs-number">32.43</span><br>ceval-college_physics                           963fa8     accuracy       gen                                                                         <span class="hljs-number">26.32</span><br>ceval-college_chemistry                         e78857     accuracy       gen                                                                         <span class="hljs-number">16.67</span><br>ceval-advanced_mathematics                      ce03e2     accuracy       gen                                                                         <span class="hljs-number">21.05</span><br>ceval-probability_and_statistics                <span class="hljs-number">65e812</span>     accuracy       gen                                                                         <span class="hljs-number">38.89</span><br>ceval-discrete_mathematics                      e894ae     accuracy       gen                                                                         <span class="hljs-number">18.75</span><br>ceval-electrical_engineer                       ae42b9     accuracy       gen                                                                         <span class="hljs-number">35.14</span><br>ceval-metrology_engineer                        ee34ea     accuracy       gen                                                                         <span class="hljs-number">50</span><br>ceval-high_school_mathematics                   1dc5bf     accuracy       gen                                                                         <span class="hljs-number">22.22</span><br>ceval-high_school_physics                       adf25f     accuracy       gen                                                                         <span class="hljs-number">31.58</span><br>ceval-high_school_chemistry                     2ed27f     accuracy       gen                                                                         <span class="hljs-number">15.79</span><br>ceval-high_school_biology                       8e2b9a     accuracy       gen                                                                         <span class="hljs-number">36.84</span><br>ceval-middle_school_mathematics                 bee8d5     accuracy       gen                                                                         <span class="hljs-number">26.32</span><br>ceval-middle_school_biology                     86817c     accuracy       gen                                                                         <span class="hljs-number">61.9</span><br>ceval-middle_school_physics                     8accf6     accuracy       gen                                                                         <span class="hljs-number">63.16</span><br>ceval-middle_school_chemistry                   167a15     accuracy       gen                                                                         <span class="hljs-number">60</span><br>ceval-veterinary_medicine                       b4e08d     accuracy       gen                                                                         <span class="hljs-number">47.83</span><br>ceval-college_economics                         f3f4e6     accuracy       gen                                                                         <span class="hljs-number">41.82</span><br>ceval-business_administration                   c1614e     accuracy       gen                                                                         <span class="hljs-number">33.33</span><br>ceval-marxism                                   cf874c     accuracy       gen                                                                         <span class="hljs-number">68.42</span><br>ceval-mao_zedong_thought                        51c7a4     accuracy       gen                                                                         <span class="hljs-number">70.83</span><br>ceval-education_science                         591fee     accuracy       gen                                                                         <span class="hljs-number">58.62</span><br>ceval-teacher_qualification                     4e4ced     accuracy       gen                                                                         <span class="hljs-number">70.45</span><br>ceval-high_school_politics                      5c0de2     accuracy       gen                                                                         <span class="hljs-number">26.32</span><br>ceval-high_school_geography                     <span class="hljs-number">865461</span>     accuracy       gen                                                                         <span class="hljs-number">47.37</span><br>ceval-middle_school_politics                    5be3e7     accuracy       gen                                                                         <span class="hljs-number">52.38</span><br>ceval-middle_school_geography                   8a63be     accuracy       gen                                                                         <span class="hljs-number">58.33</span><br>ceval-modern_chinese_history                    fc01af     accuracy       gen                                                                         <span class="hljs-number">73.91</span><br>ceval-ideological_and_moral_cultivation         a2aa4a     accuracy       gen                                                                         <span class="hljs-number">63.16</span><br>ceval-logic                                     f5b022     accuracy       gen                                                                         <span class="hljs-number">31.82</span><br>ceval-law                                       a110a1     accuracy       gen                                                                         <span class="hljs-number">25</span><br>ceval-chinese_language_and_literature           <span class="hljs-number">0f8b68</span>     accuracy       gen                                                                         <span class="hljs-number">30.43</span><br>ceval-art_studies                               2a1300     accuracy       gen                                                                         <span class="hljs-number">60.61</span><br>ceval-professional_tour_guide                   4e673e     accuracy       gen                                                                         <span class="hljs-number">62.07</span><br>ceval-legal_professional                        ce8787     accuracy       gen                                                                         <span class="hljs-number">39.13</span><br>ceval-high_school_chinese                       <span class="hljs-number">315705</span>     accuracy       gen                                                                         <span class="hljs-number">63.16</span><br>ceval-high_school_history                       7eb30a     accuracy       gen                                                                         <span class="hljs-number">70</span><br>ceval-middle_school_history                     48ab4a     accuracy       gen                                                                         <span class="hljs-number">59.09</span><br>ceval-civil_servant                             87d061     accuracy       gen                                                                         <span class="hljs-number">53.19</span><br>ceval-sports_science                            70f27b     accuracy       gen                                                                         <span class="hljs-number">52.63</span><br>ceval-plant_protection                          8941f9     accuracy       gen                                                                         <span class="hljs-number">59.09</span><br>ceval-basic_medicine                            c409d6     accuracy       gen                                                                         <span class="hljs-number">47.37</span><br>ceval-clinical_medicine                         49e82d     accuracy       gen                                                                         <span class="hljs-number">40.91</span><br>ceval-urban_and_rural_planner                   <span class="hljs-number">95b885</span>     accuracy       gen                                                                         <span class="hljs-number">45.65</span><br>ceval-accountant                                <span class="hljs-number">002837</span>     accuracy       gen                                                                         <span class="hljs-number">26.53</span><br>ceval-fire_engineer                             bc23f5     accuracy       gen                                                                         <span class="hljs-number">22.58</span><br>ceval-environmental_impact_assessment_engineer  c64e2d     accuracy       gen                                                                         <span class="hljs-number">64.52</span><br>ceval-tax_accountant                            3a5e3c     accuracy       gen                                                                         <span class="hljs-number">34.69</span><br>ceval-physician                                 6e277d     accuracy       gen                                                                         <span class="hljs-number">40.82</span><br>ceval-stem                                      -          naive_average  gen                                                                         <span class="hljs-number">35.09</span><br>ceval-social-science                            -          naive_average  gen                                                                         <span class="hljs-number">52.79</span><br>ceval-humanities                                -          naive_average  gen                                                                         <span class="hljs-number">52.58</span><br>ceval-other                                     -          naive_average  gen                                                                         <span class="hljs-number">44.36</span><br>ceval-hard                                      -          naive_average  gen                                                                         <span class="hljs-number">23.91</span><br>ceval                                           -          naive_average  gen                                                                         <span class="hljs-number">44.16</span><br></code></pre></td></tr></table></figure></p>
<p>有关 <code>run.py</code> 支持的所有与 HuggingFace 相关的参数，请阅读 <a href="https://opencompass.readthedocs.io/zh-cn/latest/user_guides/experimentation.html#id2">评测任务发起</a></p>
<p>除了通过命令行配置实验外，OpenCompass 还允许用户在配置文件中编写实验的完整配置，并通过 <code>run.py</code> 直接运行它。配置文件是以 Python 格式组织的，并且必须包括 <code>datasets</code> 和 <code>models</code> 字段。</p>
<p>示例测试配置在 <a href="https://github.com/open-compass/opencompass/blob/main/configs/eval_demo.py">configs/eval_demo.py</a> 中。此配置通过 <a href="../user_guides/config.md#继承机制">继承机制</a> 引入所需的数据集和模型配置，并以所需格式组合 <code>datasets</code> 和 <code>models</code> 字段。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> mmengine.config <span class="hljs-keyword">import</span> read_base<br><br><span class="hljs-keyword">with</span> read_base():<br>    <span class="hljs-keyword">from</span> .datasets.siqa.siqa_gen <span class="hljs-keyword">import</span> siqa_datasets<br>    <span class="hljs-keyword">from</span> .datasets.winograd.winograd_ppl <span class="hljs-keyword">import</span> winograd_datasets<br>    <span class="hljs-keyword">from</span> .models.opt.hf_opt_125m <span class="hljs-keyword">import</span> opt125m<br>    <span class="hljs-keyword">from</span> .models.opt.hf_opt_350m <span class="hljs-keyword">import</span> opt350m<br><br>datasets = [*siqa_datasets, *winograd_datasets]<br>models = [opt125m, opt350m]<br></code></pre></td></tr></table></figure>
<p>运行任务时，我们只需将配置文件的路径传递给 <code>run.py</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py configs/eval_demo.py<br></code></pre></td></tr></table></figure>
<p>OpenCompass 提供了一系列预定义的模型配置，位于 <code>configs/models</code> 下。以下是与 <a href="https://github.com/open-compass/opencompass/blob/main/configs/models/opt/hf_opt_350m.py">opt-350m</a>（<code>configs/models/opt/hf_opt_350m.py</code>）相关的配置片段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用 `HuggingFaceCausalLM` 评估由 HuggingFace 的 `AutoModelForCausalLM` 支持的模型</span><br><span class="hljs-keyword">from</span> opencompass.models <span class="hljs-keyword">import</span> HuggingFaceCausalLM<br><br><span class="hljs-comment"># OPT-350M</span><br>opt350m = <span class="hljs-built_in">dict</span>(<br>       <span class="hljs-built_in">type</span>=HuggingFaceCausalLM,<br>       <span class="hljs-comment"># `HuggingFaceCausalLM` 的初始化参数</span><br>       path=<span class="hljs-string">&#x27;facebook/opt-350m&#x27;</span>,<br>       tokenizer_path=<span class="hljs-string">&#x27;facebook/opt-350m&#x27;</span>,<br>       tokenizer_kwargs=<span class="hljs-built_in">dict</span>(<br>           padding_side=<span class="hljs-string">&#x27;left&#x27;</span>,<br>           truncation_side=<span class="hljs-string">&#x27;left&#x27;</span>,<br>           proxies=<span class="hljs-literal">None</span>,<br>           trust_remote_code=<span class="hljs-literal">True</span>),<br>       model_kwargs=<span class="hljs-built_in">dict</span>(device_map=<span class="hljs-string">&#x27;auto&#x27;</span>),<br>       <span class="hljs-comment"># 下面是所有模型的共同参数，不特定于 HuggingFaceCausalLM</span><br>       abbr=<span class="hljs-string">&#x27;opt350m&#x27;</span>,               <span class="hljs-comment"># 结果显示的模型缩写</span><br>       max_seq_len=<span class="hljs-number">2048</span>,             <span class="hljs-comment"># 整个序列的最大长度</span><br>       max_out_len=<span class="hljs-number">100</span>,              <span class="hljs-comment"># 生成的最大 token 数</span><br>       batch_size=<span class="hljs-number">64</span>,                <span class="hljs-comment"># 批量大小</span><br>       run_cfg=<span class="hljs-built_in">dict</span>(num_gpus=<span class="hljs-number">1</span>),     <span class="hljs-comment"># 该模型所需的 GPU 数量</span><br>    )<br></code></pre></td></tr></table></figure>
<p>使用配置时，我们可以通过命令行参数 <code>--models</code> 指定相关文件，或使用继承机制将模型配置导入到配置文件中的 <code>models</code> 列表中。</p>
<p>与模型类似，数据集的配置文件也提供在 <code>configs/datasets</code> 下。用户可以在命令行中使用 <code>--datasets</code>，或通过继承在配置文件中导入相关配置</p>
<p>下面是来自 <code>configs/eval_demo.py</code> 的与数据集相关的配置片段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> mmengine.config <span class="hljs-keyword">import</span> read_base  <span class="hljs-comment"># 使用 mmengine.read_base() 读取基本配置</span><br><br><span class="hljs-keyword">with</span> read_base():<br>    <span class="hljs-comment"># 直接从预设的数据集配置中读取所需的数据集配置</span><br>    <span class="hljs-keyword">from</span> .datasets.winograd.winograd_ppl <span class="hljs-keyword">import</span> winograd_datasets  <span class="hljs-comment"># 读取 Winograd 配置，基于 PPL（困惑度）进行评估</span><br>    <span class="hljs-keyword">from</span> .datasets.siqa.siqa_gen <span class="hljs-keyword">import</span> siqa_datasets  <span class="hljs-comment"># 读取 SIQA 配置，基于生成进行评估</span><br><br>datasets = [*siqa_datasets, *winograd_datasets]       <span class="hljs-comment"># 最终的配置需要包含所需的评估数据集列表 &#x27;datasets&#x27;</span><br></code></pre></td></tr></table></figure>
<p>数据集配置通常有两种类型：’ppl’ 和 ‘gen’，分别指示使用的评估方法。其中 <code>ppl</code> 表示辨别性评估，<code>gen</code> 表示生成性评估。</p>
<p>此外，<a href="https://github.com/open-compass/opencompass/blob/main/configs/datasets/collections">configs/datasets/collections</a> 收录了各种数据集集合，方便进行综合评估。OpenCompass 通常使用 <a href="https://github.com/open-compass/opencompass/blob/main/configs/datasets/collections/base_medium.py"><code>base_medium.py</code></a> 进行全面的模型测试。要复制结果，只需导入该文件，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py --models hf_llama_7b --datasets base_medium<br></code></pre></td></tr></table></figure>
<p>OpenCompass 通常假定运行环境网络是可用的。如果您遇到网络问题或希望在离线环境中运行 OpenCompass，请参阅 <a href="https://opencompass.readthedocs.io/zh-cn/latest/get_started/faq.html">FAQ - 网络 - Q1</a> 寻求解决方案。</p>
<h2 id="可视化评估结果"><a href="#可视化评估结果" class="headerlink" title="可视化评估结果"></a>可视化评估结果</h2><p>评估完成后，评估结果表格将打印如下：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><code class="hljs text">dataset    version    metric    mode      opt350m    opt125m<br>---------  ---------  --------  ------  ---------  ---------<br>siqa       e78df3     accuracy  gen         21.55      12.44<br>winograd   b6c7ed     accuracy  ppl         51.23      49.82<br></code></pre></td></tr></table></figure>
<p>所有运行输出将定向到 <code>outputs/demo/</code> 目录，结构如下：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><code class="hljs text">outputs/default/<br>├── 20200220_120000<br>├── 20230220_183030     # 每个实验一个文件夹<br>│   ├── configs         # 用于记录的已转储的配置文件。如果在同一个实验文件夹中重新运行了不同的实验，可能会保留多个配置<br>│   ├── logs            # 推理和评估阶段的日志文件<br>│   │   ├── eval<br>│   │   └── infer<br>│   ├── predictions   # 每个任务的推理结果<br>│   ├── results       # 每个任务的评估结果<br>│   └── summary       # 单个实验的汇总评估结果<br>├── ...<br></code></pre></td></tr></table></figure>
<p>打印评测结果的过程可被进一步定制化，用于输出一些数据集的平均分 (例如 MMLU, C-Eval 等)。</p>
<p>关于评测结果输出的更多介绍可阅读 <a href="../user_guides/summarizer.md">结果展示</a>。</p>
<h2 id="更多教程"><a href="#更多教程" class="headerlink" title="更多教程"></a>更多教程</h2><p>想要更多了解 OpenCompass, 可以点击下列链接学习。</p>
<ul>
<li><a href="https://opencompass.readthedocs.io/zh-cn/latest/">https://opencompass.readthedocs.io/zh-cn/latest/</a></li>
</ul>
<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建环境</span><br>conda create --name opencompass --<span class="hljs-built_in">clone</span>=/root/share/conda_envs/internlm-base<br>conda activate opencompass<br><span class="hljs-comment"># 使用镜像 clone</span><br>git <span class="hljs-built_in">clone</span> https://mirror.ghproxy.com/https://github.com/open-compass/opencompass<br><span class="hljs-built_in">cd</span> opencompass<br>pip install -e .<br></code></pre></td></tr></table></figure>
<h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/<br><span class="hljs-built_in">cd</span> /root/opencompass/<br>unzip OpenCompassData-core-20231110.zip<br></code></pre></td></tr></table></figure>
<p><img  src="unzip.png"  ><span class="image-caption">解压数据</span></p>
<h3 id="查看支持的数据集和模型-1"><a href="#查看支持的数据集和模型-1" class="headerlink" title="查看支持的数据集和模型"></a>查看支持的数据集和模型</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python tools/list_configs.py internlm ceval<br></code></pre></td></tr></table></figure>
<p><img  src="list.png"  ><span class="image-caption">列出所有跟 internlm 及 ceval 相关的配置</span></p>
<h3 id="启动评测-1"><a href="#启动评测-1" class="headerlink" title="启动评测"></a>启动评测</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py \<br>--datasets ceval_gen \<br>--hf-path /share/model_repos/internlm2-chat-7b/ \  <span class="hljs-comment"># HuggingFace 模型路径</span><br>--tokenizer-path /share/model_repos/internlm2-chat-7b/ \  <span class="hljs-comment"># 注意这里是 internlm2</span><br>--tokenizer-kwargs padding_side=<span class="hljs-string">&#x27;left&#x27;</span> truncation=<span class="hljs-string">&#x27;left&#x27;</span> trust_remote_code=True \  <span class="hljs-comment"># 构建 tokenizer 的参数</span><br>--model-kwargs device_map=<span class="hljs-string">&#x27;auto&#x27;</span> trust_remote_code=True \  <span class="hljs-comment"># 构建模型的参数</span><br>--max-seq-len 2048 \  <span class="hljs-comment"># 模型可以接受的最大序列长度</span><br>--max-out-len 16 \  <span class="hljs-comment"># 生成的最大 token 数</span><br>--batch-size 2  \  <span class="hljs-comment"># 批量大小</span><br>--num-gpus 1 \ <span class="hljs-comment"># 运行模型所需的 GPU 数量</span><br>--debug<br></code></pre></td></tr></table></figure>
<p>便于复制版：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py \<br>--datasets ceval_gen \<br>--hf-path /share/model_repos/internlm2-chat-7b/ \<br>--tokenizer-path /share/model_repos/internlm2-chat-7b/ \<br>--tokenizer-kwargs padding_side=<span class="hljs-string">&#x27;left&#x27;</span> truncation=<span class="hljs-string">&#x27;left&#x27;</span> trust_remote_code=True \<br>--model-kwargs device_map=<span class="hljs-string">&#x27;auto&#x27;</span> trust_remote_code=True \<br>--max-seq-len 2048 \<br>--max-out-len 16 \<br>--batch-size 2  \<br>--num-gpus 1 \<br>--debug<br></code></pre></td></tr></table></figure>
<p>发现显存不够用，尝试改小 batch size 为 1。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py \<br>--datasets ceval_gen \<br>--hf-path /share/model_repos/internlm2-chat-7b/ \<br>--tokenizer-path /share/model_repos/internlm2-chat-7b/ \<br>--tokenizer-kwargs padding_side=<span class="hljs-string">&#x27;left&#x27;</span> truncation=<span class="hljs-string">&#x27;left&#x27;</span> trust_remote_code=True \<br>--model-kwargs device_map=<span class="hljs-string">&#x27;auto&#x27;</span> trust_remote_code=True \<br>--max-seq-len 2048 \<br>--max-out-len 16 \<br>--batch-size 1  \<br>--num-gpus 1 \<br>--debug<br></code></pre></td></tr></table></figure>
<p><img  src="run.png"  ><span class="image-caption">运行截图</span></p>
<p><img  src="result.png"  ><span class="image-caption">评测结果</span></p>
<h2 id="进阶作业"><a href="#进阶作业" class="headerlink" title="进阶作业"></a>进阶作业</h2><p>安装 lmdeploy，这一步是必须的，否则无法加载 TurboMind 模型</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install lmdeploy==0.2.0<br></code></pre></td></tr></table></figure>
<p>编写 config 文件如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> mmengine.config <span class="hljs-keyword">import</span> read_base<br><span class="hljs-keyword">from</span> opencompass.models.turbomind <span class="hljs-keyword">import</span> TurboMindModel<br><br><span class="hljs-keyword">with</span> read_base():<br>    <span class="hljs-comment"># choose a list of datasets</span><br>    <span class="hljs-keyword">from</span> .datasets.ceval.ceval_gen_5f30c7 <span class="hljs-keyword">import</span> ceval_datasets<br><br><br>datasets = [*ceval_datasets]<br><br>internlm_meta_template = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">round</span>=[<br>    <span class="hljs-built_in">dict</span>(role=<span class="hljs-string">&#x27;HUMAN&#x27;</span>, begin=<span class="hljs-string">&#x27;&lt;|User|&gt;:&#x27;</span>, end=<span class="hljs-string">&#x27;\n&#x27;</span>),<br>    <span class="hljs-built_in">dict</span>(role=<span class="hljs-string">&#x27;BOT&#x27;</span>, begin=<span class="hljs-string">&#x27;&lt;|Bot|&gt;:&#x27;</span>, end=<span class="hljs-string">&#x27;&lt;eoa&gt;\n&#x27;</span>, generate=<span class="hljs-literal">True</span>),<br>],<br>                              eos_token_id=<span class="hljs-number">103028</span>)<br><br><span class="hljs-comment"># config for internlm-chat-7b</span><br>internlm_chat_7b = <span class="hljs-built_in">dict</span>(<br>    <span class="hljs-built_in">type</span>=TurboMindModel,<br>    abbr=<span class="hljs-string">&#x27;internlm-chat-7b&#x27;</span>,<br>    path=<span class="hljs-string">&#x27;/root/workspace_quant_awq4&#x27;</span>, <span class="hljs-comment"># 这里的 path 是上一节课中的 awq 模型</span><br>    engine_config=<span class="hljs-built_in">dict</span>(session_len=<span class="hljs-number">2048</span>,<br>                       max_batch_size=<span class="hljs-number">32</span>,<br>                       rope_scaling_factor=<span class="hljs-number">1.0</span>),<br>    gen_config=<span class="hljs-built_in">dict</span>(top_k=<span class="hljs-number">1</span>,<br>                    top_p=<span class="hljs-number">0.8</span>,<br>                    temperature=<span class="hljs-number">1.0</span>,<br>                    max_new_tokens=<span class="hljs-number">100</span>),<br>    max_out_len=<span class="hljs-number">100</span>,<br>    max_seq_len=<span class="hljs-number">1024</span>,<br>    batch_size=<span class="hljs-number">2</span>,<br>    concurrency=<span class="hljs-number">32</span>,<br>    meta_template=internlm_meta_template,<br>    run_cfg=<span class="hljs-built_in">dict</span>(num_gpus=<span class="hljs-number">1</span>, num_procs=<span class="hljs-number">1</span>),<br>)<br><br>models = [internlm_chat_7b]<br></code></pre></td></tr></table></figure>
<p>运行评测：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py configs/eval_internlm_my_deploy.py --debug<br></code></pre></td></tr></table></figure>
<p><img  src="awq.png"  ><span class="image-caption">加载量化后的模型</span></p>
<p><img  src="result-internlm-awq.png"  ><span class="image-caption">评判 internlm-awq</span></p>
<p>可见 internlm-AWQ 在 ceval 上的得分并不如 internlm2。</p>
<h3 id="使用-lmdeploy-0-2-0-转换-internlm2-为-awq-模型并进行评测"><a href="#使用-lmdeploy-0-2-0-转换-internlm2-为-awq-模型并进行评测" class="headerlink" title="使用 lmdeploy 0.2.0 转换 internlm2 为 awq 模型并进行评测"></a>使用 lmdeploy 0.2.0 转换 internlm2 为 awq 模型并进行评测</h3><p>使用 lmdeploy 0.2 的时候与 0.1 版本进行 AWQ 量化的方式略有不同，同时要从 huggingface 上下载测试数据集，所以国内可以使用镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HF_ENDPOINT=https://hf-mirror.com<br>lmdeploy lite auto_awq /root/share/model_repos/internlm2-chat-7b  --work-dir internlm2-chat-7b-4bit<br></code></pre></td></tr></table></figure>
<p>之后对模型进行转化：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">lmdeploy convert  internlm2-chat-7b ./internlm2-chat-7b-4bit/ --model-format awq --group-size 128  --dst-path  ./workspace_awq_internlm2<br></code></pre></td></tr></table></figure>
<p><img  src="convert.png"  ><span class="image-caption">转换模型</span></p>
<p>之后编写新的 config.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> mmengine.config <span class="hljs-keyword">import</span> read_base<br><span class="hljs-keyword">from</span> opencompass.models.turbomind <span class="hljs-keyword">import</span> TurboMindModel<br><br><span class="hljs-keyword">with</span> read_base():<br>    <span class="hljs-comment"># choose a list of datasets</span><br>    <span class="hljs-keyword">from</span> .datasets.ceval.ceval_gen_5f30c7 <span class="hljs-keyword">import</span> ceval_datasets<br><br><br>datasets = [*ceval_datasets]<br><br>internlm_meta_template = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">round</span>=[<br>    <span class="hljs-built_in">dict</span>(role=<span class="hljs-string">&#x27;HUMAN&#x27;</span>, begin=<span class="hljs-string">&#x27;&lt;|User|&gt;:&#x27;</span>, end=<span class="hljs-string">&#x27;\n&#x27;</span>),<br>    <span class="hljs-built_in">dict</span>(role=<span class="hljs-string">&#x27;BOT&#x27;</span>, begin=<span class="hljs-string">&#x27;&lt;|Bot|&gt;:&#x27;</span>, end=<span class="hljs-string">&#x27;&lt;eoa&gt;\n&#x27;</span>, generate=<span class="hljs-literal">True</span>),<br>],<br>                              eos_token_id=<span class="hljs-number">103028</span>)<br><br><span class="hljs-comment"># config for internlm2-chat-7b-awq</span><br>internlm2_chat_7b = <span class="hljs-built_in">dict</span>(<br>    <span class="hljs-built_in">type</span>=TurboMindModel,<br>    abbr=<span class="hljs-string">&#x27;internlm-chat-7b&#x27;</span>,<br>    path=<span class="hljs-string">&#x27;/root/workspace_awq_internlm2&#x27;</span>,<br>    engine_config=<span class="hljs-built_in">dict</span>(session_len=<span class="hljs-number">2048</span>,<br>                       max_batch_size=<span class="hljs-number">32</span>,<br>                       rope_scaling_factor=<span class="hljs-number">1.0</span>),<br>    gen_config=<span class="hljs-built_in">dict</span>(top_k=<span class="hljs-number">1</span>,<br>                    top_p=<span class="hljs-number">0.8</span>,<br>                    temperature=<span class="hljs-number">1.0</span>,<br>                    max_new_tokens=<span class="hljs-number">100</span>),<br>    max_out_len=<span class="hljs-number">100</span>,<br>    max_seq_len=<span class="hljs-number">1024</span>,<br>    batch_size=<span class="hljs-number">2</span>,<br>    concurrency=<span class="hljs-number">32</span>,<br>    meta_template=internlm_meta_template,<br>    run_cfg=<span class="hljs-built_in">dict</span>(num_gpus=<span class="hljs-number">1</span>, num_procs=<span class="hljs-number">1</span>),<br>)<br><br>models = [internlm2_chat_7b]<br></code></pre></td></tr></table></figure>
<p>进行评测：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">python run.py configs/eval_internlm2_my_deploy.py --debug<br></code></pre></td></tr></table></figure>
<p><img  src="awq-result.png"  ><span class="image-caption">AWQ 量化评测</span></p>
<p>能够发现 AWQ 量化后的模型在 ceval 数据集上的得分比原模型要好。精度不仅没有明显下降，相反在不少任务上还有一定的提升。可能得原因是，量化会导致一定的误差，有时候这种误差可能会减少模型对训练数据的拟合，从而提高泛化性能。量化可以被视为引入轻微噪声的正则化方法。或者，也有可能量化后的模型正好对某些数据集具有更好的性能。</p>
]]></content>
      <categories>
        <category>internlm</category>
      </categories>
  </entry>
  <entry>
    <title>Internlm-05-LMDeploy 的量化和部署</title>
    <url>/internlm/internlm-05/</url>
    <content><![CDATA[<h1 id="LMDeploy-的量化和部署"><a href="#LMDeploy-的量化和部署" class="headerlink" title="LMDeploy 的量化和部署"></a>LMDeploy 的量化和部署</h1><h2 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="1 环境配置"></a>1 环境配置</h2><p>这里 <code>/share/conda_envs</code> 目录下的环境是官方未大家准备好的基础环境，因为该目录是共享只读的，而我们后面需要在此基础上安装新的软件包，所以需要复制到我们自己的 conda 环境（该环境下我们是可写的）。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">conda create -n lmdeploy --<span class="hljs-built_in">clone</span> /share/conda_envs/internlm-base<br></code></pre></td></tr></table></figure>
<ul>
<li>如果clone操作过慢，可采用如下操作:</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">/root/share/install_conda_env_internlm_base.sh lmdeploy<br></code></pre></td></tr></table></figure>
<p>我们取 <code>CONDA_ENV_NAME</code> 为 <code>lmdeploy</code>，复制完成后，可以在本地查看环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">conda <span class="hljs-built_in">env</span> list<br></code></pre></td></tr></table></figure>
<p>结果如下所示。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># conda environments:</span><br><span class="hljs-comment">#</span><br>base                  *  /root/.conda<br>lmdeploy                 /root/.conda/envs/lmdeploy<br></code></pre></td></tr></table></figure>
<p>然后激活环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">conda activate lmdeploy<br></code></pre></td></tr></table></figure>
<p>如果是在 InternStudio 开发环境，需要先运行下面的命令，否则会报错。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 解决 ModuleNotFoundError: No module named &#x27;packaging&#x27; 问题</span><br>pip install packaging<br><span class="hljs-comment"># 使用 flash_attn 的预编译包解决安装过慢问题</span><br>pip install /root/share/wheels/flash_attn-2.4.2+cu118torch2.0cxx11abiTRUE-cp310-cp310-linux_x86_64.whl<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install <span class="hljs-string">&#x27;lmdeploy[all]==v0.1.0&#x27;</span><br></code></pre></td></tr></table></figure>
<p>由于默认安装的是 runtime 依赖包，但是我们这里还需要部署和量化，所以，这里选择 <code>[all]</code>。然后可以再检查一下 lmdeploy 包，如下图所示。</p>
<p><img  src="env.png"  ><span class="image-caption">安装 lmdeploy 成功</span></p>
<p>基础环境到这里就配置好了。</p>
<h2 id="2-服务部署"><a href="#2-服务部署" class="headerlink" title="2 服务部署"></a>2 服务部署</h2><p>这一部分主要涉及本地推理和部署。我们先看一张图。</p>
<p><img  src="lmdeploy.drawio.png"  ><span class="image-caption">服务架构图</span></p>
<p>lmdeploy 从架构上把整个服务流程分成下面几个模块。</p>
<ul>
<li>模型推理/服务。主要提供模型本身的推理，一般来说可以和具体业务解耦，专注模型推理本身性能的优化。可以以模块、API等多种方式提供。</li>
<li>Client。可以理解为前端，与用户交互的地方。</li>
<li>API Server。一般作为前端的后端，提供与产品和服务相关的数据和功能支持。</li>
</ul>
<p>值得说明的是，以上的划分是一个相对完整的模型，但在实际中这并不是绝对的。比如可以把“模型推理”和“API Server”合并，有的甚至是三个流程打包在一起提供服务。</p>
<p>接下来，我们看一下 lmdeploy 提供的部署功能。</p>
<h3 id="2-1-模型转换"><a href="#2-1-模型转换" class="headerlink" title="2.1 模型转换"></a>2.1 模型转换</h3><p>使用 TurboMind 推理模型需要先将模型转化为 TurboMind 的格式，目前支持在线转换和离线转换两种形式。在线转换可以直接加载 Huggingface 模型，离线转换需需要先保存模型再加载。</p>
<p>TurboMind 是一款关于 LLM 推理的高效推理引擎，基于英伟达的 <a href="https://github.com/NVIDIA/FasterTransformer">FasterTransformer</a> 研发而成。它的主要功能包括：LLaMa 结构模型的支持，persistent batch 推理模式和可扩展的 KV 缓存管理器。</p>
<h4 id="2-1-1-在线转换"><a href="#2-1-1-在线转换" class="headerlink" title="2.1.1 在线转换"></a>2.1.1 在线转换</h4><p>lmdeploy 支持直接读取 Huggingface 模型权重，目前共支持三种类型：</p>
<ul>
<li>在 huggingface.co 上面通过 lmdeploy 量化的模型，如 <a href="https://huggingface.co/lmdeploy/llama2-chat-70b-4bit">llama2-70b-4bit</a>, <a href="https://huggingface.co/internlm/internlm-chat-20b-4bit">internlm-chat-20b-4bit</a></li>
<li>huggingface.co 上面其他 LM 模型，如 Qwen/Qwen-7B-Chat</li>
</ul>
<p>示例如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 需要能访问 Huggingface 的网络环境</span><br>lmdeploy chat turbomind internlm/internlm-chat-20b-4bit --model-name internlm-chat-20b<br>lmdeploy chat turbomind Qwen/Qwen-7B-Chat --model-name qwen-7b<br></code></pre></td></tr></table></figure>
<p>上面两行命令分别展示了如何直接加载 Huggingface 的模型，第一条命令是加载使用 lmdeploy 量化的版本，第二条命令是加载其他 LLM 模型。</p>
<p>我们也可以直接启动本地的 Huggingface 模型，如下所示。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">lmdeploy chat turbomind /share/temp/model_repos/internlm-chat-7b/  --model-name internlm-chat-7b<br></code></pre></td></tr></table></figure>
<p>以上命令都会启动一个本地对话界面，通过 Bash 可以与 LLM 进行对话。</p>
<h4 id="2-1-2-离线转换"><a href="#2-1-2-离线转换" class="headerlink" title="2.1.2 离线转换"></a>2.1.2 离线转换</h4><p>离线转换需要在启动服务之前，将模型转为 lmdeploy TurboMind  的格式，如下所示。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 转换模型（FastTransformer格式） TurboMind</span><br>lmdeploy convert internlm-chat-7b /path/to/internlm-chat-7b<br></code></pre></td></tr></table></figure>
<p>这里我们使用官方提供的模型文件，就在用户根目录执行，如下所示。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">lmdeploy convert internlm-chat-7b  /root/share/temp/model_repos/internlm-chat-7b/<br></code></pre></td></tr></table></figure>
<p><img  src="convert.png"  ><span class="image-caption">转换模型</span></p>
<p>执行完成后将会在当前目录生成一个 <code>workspace</code> 的文件夹。这里面包含的就是 TurboMind 和 Triton “模型推理”需要到的文件。</p>
<p>目录如下图所示。</p>
<p><img  src="tree1.png"  ><span class="image-caption">转换后的模型</span></p>
<p><code>weights</code> 和 <code>tokenizer</code> 目录分别放的是拆分后的参数和 Tokenizer。如果我们进一步查看 <code>weights</code> 的目录，就会发现参数是按层和模块拆开的，如下图所示。</p>
<p><img  src="tree2.png"  ><span class="image-caption">转换后的权重</span></p>
<p>每一份参数第一个 0 表示“层”的索引，后面的那个0表示 Tensor 并行的索引，因为我们只有一张卡，所以被拆分成 1 份。如果有两张卡可以用来推理，则会生成0和1两份，也就是说，会把同一个参数拆成两份。比如 <code>layers.0.attention.w_qkv.0.weight</code> 会变成 <code>layers.0.attention.w_qkv.0.weight</code> 和 <code>layers.0.attention.w_qkv.1.weight</code>。执行 <code>lmdeploy convert</code> 命令时，可以通过 <code>--tp</code> 指定（tp 表示 tensor parallel），该参数默认值为1（也就是一张卡）。</p>
<p><strong>关于Tensor并行</strong></p>
<p>Tensor并行一般分为行并行或列并行，原理如下图所示。</p>
<p><img  src="col.png"  ><span class="image-caption">列并行</span></p>
<p><img  src="row.png"  ><span class="image-caption">行并行</span></p>
<p>简单来说，就是把一个大的张量（参数）分到多张卡上，分别计算各部分的结果，然后再同步汇总。</p>
<h3 id="2-2-TurboMind-推理-命令行本地对话"><a href="#2-2-TurboMind-推理-命令行本地对话" class="headerlink" title="2.2  TurboMind 推理+命令行本地对话"></a>2.2  TurboMind 推理+命令行本地对话</h3><p>模型转换完成后，我们就具备了使用模型推理的条件，接下来就可以进行真正的模型推理环节。</p>
<p>我们先尝试本地对话（<code>Bash Local Chat</code>），下面用（Local Chat 表示）在这里其实是跳过 API Server 直接调用 TurboMind。简单来说，就是命令行代码直接执行 TurboMind。所以说，实际和前面的架构图是有区别的。</p>
<p>这里支持多种方式运行，比如Turbomind、PyTorch、DeepSpeed。但 PyTorch 和 DeepSpeed 调用的其实都是 Huggingface 的 Transformers 包，PyTorch表示原生的 Transformer 包，DeepSpeed 表示使用了 DeepSpeed 作为推理框架。Pytorch/DeepSpeed 目前功能都比较弱，不具备生产能力，不推荐使用。</p>
<p>执行命令如下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Turbomind + Bash Local Chat</span><br>lmdeploy chat turbomind ./workspace<br></code></pre></td></tr></table></figure>
<p>启动后就可以和它进行对话了，如下图所示。</p>
<p><img  src="chat.png"  ><span class="image-caption">与本地部署的模型进行对话</span></p>
<p>输入后两次回车，退出时输入<code>exit</code> 回车两次即可。此时，Server 就是本地跑起来的模型（TurboMind），命令行可以看作是前端。</p>
<h3 id="2-3-TurboMind推理-API服务"><a href="#2-3-TurboMind推理-API服务" class="headerlink" title="2.3 TurboMind推理+API服务"></a>2.3 TurboMind推理+API服务</h3><p>在上面的部分我们尝试了直接用命令行启动 Client，接下来我们尝试如何运用 lmdepoy 进行服务化。</p>
<p>”模型推理/服务“目前提供了 Turbomind 和 TritonServer 两种服务化方式。此时，Server 是 TurboMind 或 TritonServer，API Server 可以提供对外的 API 服务。我们推荐使用 TurboMind，TritonServer 使用方式详见《附录1》。</p>
<p>首先，通过下面命令启动服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ApiServer+Turbomind   api_server =&gt; AsyncEngine =&gt; TurboMind</span><br>lmdeploy serve api_server ./workspace \<br>	--server_name 0.0.0.0 \<br>	--server_port 23333 \<br>	--instance_num 64 \<br>	--tp 1<br></code></pre></td></tr></table></figure>
<p>上面的参数中 <code>server_name</code> 和 <code>server_port</code> 分别表示服务地址和端口，<code>tp</code> 参数我们之前已经提到过了，表示 Tensor 并行。还剩下一个 <code>instance_num</code> 参数，表示实例数，可以理解成 Batch 的大小。执行后如下图所示。</p>
<p><img  src="api-deploy.png"  ><span class="image-caption">部署 api server</span></p>
<p>然后，我们可以新开一个窗口，执行下面的 Client 命令。如果使用官方机器，可以打开 vscode 的 Terminal，执行下面的命令。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ChatApiClient+ApiServer（注意是http协议，需要加http）</span><br>lmdeploy serve api_client http://localhost:23333<br></code></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img  src="test-apiserver.png"  ><span class="image-caption">测试 api server</span></p>
<p>当然，刚刚我们启动的是 API Server，自然也有相应的接口。可以直接打开 <code>http://&#123;host&#125;:23333</code> 查看，如下图所示。</p>
<p><img  src="fastapi.png"  ><span class="image-caption">fastapi 演示</span></p>
<p>这里一共提供了 4 个 HTTP 的接口，任何语言都可以对其进行调用，我们以 <code>v1/chat/completions</code> 接口为例，简单试一下。</p>
<p>接口请求参数如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;internlm-chat-7b&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;messages&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;写一首冬天的诗&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;temperature&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;top_p&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;n&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;max_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">512</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;stop&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;stream&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;presence_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;frequency_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;user&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;string&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;repetition_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;renew_session&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;ignore_eos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>
<p>请求结果如下。</p>
<p><img  src="test-fastapi.png"  ><span class="image-caption">测试 api</span></p>
<h3 id="2-4-网页-Demo-演示"><a href="#2-4-网页-Demo-演示" class="headerlink" title="2.4 网页 Demo 演示"></a>2.4 网页 Demo 演示</h3><p>这一部分主要是将 Gradio 作为前端 Demo 演示。在上一节的基础上，我们不执行后面的 <code>api_client</code> 或 <code>triton_client</code>，而是执行 <code>gradio</code>。</p>
<h4 id="2-4-1-TurboMind-服务作为后端"><a href="#2-4-1-TurboMind-服务作为后端" class="headerlink" title="2.4.1 TurboMind 服务作为后端"></a>2.4.1 TurboMind 服务作为后端</h4><p>API Server 的启动和上一节一样，这里直接启动作为前端的 Gradio。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Gradio+ApiServer。必须先开启 Server，此时 Gradio 为 Client</span><br>lmdeploy serve gradio http://0.0.0.0:23333 \<br>	--server_name 0.0.0.0 \<br>	--server_port 6006 \<br>	--restful_api True<br></code></pre></td></tr></table></figure>
<h4 id="2-4-2-TurboMind-推理作为后端"><a href="#2-4-2-TurboMind-推理作为后端" class="headerlink" title="2.4.2 TurboMind 推理作为后端"></a>2.4.2 TurboMind 推理作为后端</h4><p>当然，Gradio 也可以直接和 TurboMind 连接，如下所示。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Gradio+Turbomind(local)</span><br>lmdeploy serve gradio ./workspace<br></code></pre></td></tr></table></figure>
<p>可以直接启动 Gradio，此时没有 API Server，TurboMind 直接与 Gradio 通信。</p>
<h3 id="2-5-TurboMind-推理-Python-代码集成"><a href="#2-5-TurboMind-推理-Python-代码集成" class="headerlink" title="2.5 TurboMind 推理 + Python 代码集成"></a>2.5 TurboMind 推理 + Python 代码集成</h3><p>前面介绍的都是通过 API 或某种前端与”模型推理/服务“进行交互，lmdeploy 还支持 Python 直接与 TurboMind 进行交互，如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> lmdeploy <span class="hljs-keyword">import</span> turbomind <span class="hljs-keyword">as</span> tm<br><br><span class="hljs-comment"># load model</span><br>model_path = <span class="hljs-string">&quot;/root/share/temp/model_repos/internlm-chat-7b/&quot;</span><br>tm_model = tm.TurboMind.from_pretrained(model_path, model_name=<span class="hljs-string">&#x27;internlm-chat-20b&#x27;</span>)<br>generator = tm_model.create_instance()<br><br><span class="hljs-comment"># process query</span><br>query = <span class="hljs-string">&quot;你好啊兄嘚&quot;</span><br>prompt = tm_model.model.get_prompt(query)<br>input_ids = tm_model.tokenizer.encode(prompt)<br><br><span class="hljs-comment"># inference</span><br><span class="hljs-keyword">for</span> outputs <span class="hljs-keyword">in</span> generator.stream_infer(<br>        session_id=<span class="hljs-number">0</span>,<br>        input_ids=[input_ids]):<br>    res, tokens = outputs[<span class="hljs-number">0</span>]<br><br>response = tm_model.tokenizer.decode(res.tolist())<br><span class="hljs-built_in">print</span>(response)<br></code></pre></td></tr></table></figure>
<p>在上面的代码中，我们首先加载模型，然后构造输入，最后执行推理。</p>
<p>加载模型可以显式指定模型路径，也可以直接指定 Huggingface 的 repo_id，还可以使用上面生成过的 <code>workspace</code>。这里的 <code>tm.TurboMind</code> 其实是对 C++ TurboMind 的封装。</p>
<p>构造输入这里主要是把用户的 query 构造成 InternLLM 支持的输入格式，比如上面的例子中， <code>query</code> 是“你好啊兄嘚”，构造好的 Prompt 如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">&lt;|System|&gt;:You are an AI assistant whose name is InternLM (书生·浦语).</span><br><span class="hljs-string">- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span><br><span class="hljs-string">- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span><br><span class="hljs-string"></span><br><span class="hljs-string">&lt;|User|&gt;:你好啊兄嘚</span><br><span class="hljs-string">&lt;|Bot|&gt;:</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p>Prompt 其实就是增加了 <code>&lt;|System|&gt;</code> 消息和 <code>&lt;|User|&gt;</code> 消息（即用户的 <code>query</code>），以及一个 <code>&lt;|Bot|&gt;</code> 的标记，表示接下来该模型输出响应了。最终输出的响应内容如下所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;你好啊，有什么我可以帮助你的吗？&quot;</span><br></code></pre></td></tr></table></figure>
<h3 id="2-6-最佳实践"><a href="#2-6-最佳实践" class="headerlink" title="2.6 最佳实践"></a>2.6 最佳实践</h3><h4 id="2-6-1-方案实践"><a href="#2-6-1-方案实践" class="headerlink" title="2.6.1 方案实践"></a>2.6.1 方案实践</h4><p>首先说 “模型推理/服务”，推荐使用 TurboMind，使用简单，性能良好，相关的 Benchmark 对比如下。</p>
<p><img  src="benchmark.png"  ><span class="image-caption">Benchmark 效果</span></p>
<p>上面的性能对比包括两个场景：</p>
<ul>
<li>场景一（前4张图）：固定的输入、输出 token 数（分别1和2048），测试Token输出吞吐量（output token throughput）。</li>
<li>场景二（第5张图）：使用真实数据，测试吞吐量（request throughput）。</li>
</ul>
<p>场景一中，BatchSize=64时，TurboMind 的吞吐量超过 2000 token/s，整体比 DeepSpeed 提升约 5% - 15%；BatchSize=32时，比 Huggingface 的Transformers 提升约 3 倍；其他BatchSize时 TurboMind 也表现出优异的性能。</p>
<p>场景二中，对比了 TurboMind 和 vLLM 在真实数据上的吞吐量（request throughput）指标，TurboMind 的效率比 vLLM 高 30%。</p>
<p>大家不妨亲自使用本地对话（Local Chat）感受一下性能差别（2.2 节），也可以执行我们提供的 <code>infer_compare.py</code> 脚本，示例如下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 执行 Huggingface 的 Transformer</span><br>python infer_compare.py hf<br><span class="hljs-comment"># 执行LMDeploy</span><br>python infer_compare.py lmdeploy<br></code></pre></td></tr></table></figure>
<p>LMDeploy应该是Transformers的3-5倍左右。</p>
<p>后面的 API 服务和 Client 就得分场景了。</p>
<ul>
<li>我想对外提供类似 OpenAI 那样的 HTTP 接口服务。推荐使用 TurboMind推理 + API 服务（2.3）。</li>
<li>我想做一个演示 Demo，Gradio 无疑是比 Local Chat 更友好的。推荐使用 TurboMind 推理作为后端的Gradio进行演示（2.4.2）。</li>
<li>我想直接在自己的 Python 项目中使用大模型功能。推荐使用 TurboMind推理 + Python（2.5）。</li>
<li>我想在自己的其他非 Python 项目中使用大模型功能。推荐直接通过 HTTP 接口调用服务。也就是用本列表第一条先启动一个 HTTP API 服务，然后在项目中直接调用接口。</li>
</ul>
<h4 id="2-6-2-模型配置实践"><a href="#2-6-2-模型配置实践" class="headerlink" title="2.6.2 模型配置实践"></a>2.6.2 模型配置实践</h4><p>不知道大家还有没有印象，在离线转换（2.1.2）一节，我们查看了 <code>weights</code> 的目录，里面存放的是模型按层、按并行卡拆分的参数，不过还有一个文件 <code>config.ini</code> 并不是模型参数，它里面存的主要是模型相关的配置信息。下面是一个示例。</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[llama]</span><br><span class="hljs-attr">model_name</span> = internlm-chat-<span class="hljs-number">7</span>b<br><span class="hljs-attr">tensor_para_size</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">head_num</span> = <span class="hljs-number">32</span><br><span class="hljs-attr">kv_head_num</span> = <span class="hljs-number">32</span><br><span class="hljs-attr">vocab_size</span> = <span class="hljs-number">103168</span><br><span class="hljs-attr">num_layer</span> = <span class="hljs-number">32</span><br><span class="hljs-attr">inter_size</span> = <span class="hljs-number">11008</span><br><span class="hljs-attr">norm_eps</span> = <span class="hljs-number">1</span>e-<span class="hljs-number">06</span><br><span class="hljs-attr">attn_bias</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">start_id</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">end_id</span> = <span class="hljs-number">2</span><br><span class="hljs-attr">session_len</span> = <span class="hljs-number">2056</span><br><span class="hljs-attr">weight_type</span> = fp16<br><span class="hljs-attr">rotary_embedding</span> = <span class="hljs-number">128</span><br><span class="hljs-attr">rope_theta</span> = <span class="hljs-number">10000.0</span><br><span class="hljs-attr">size_per_head</span> = <span class="hljs-number">128</span><br><span class="hljs-attr">group_size</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">max_batch_size</span> = <span class="hljs-number">64</span><br><span class="hljs-attr">max_context_token_num</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">step_length</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">cache_max_entry_count</span> = <span class="hljs-number">0.5</span><br><span class="hljs-attr">cache_block_seq_len</span> = <span class="hljs-number">128</span><br><span class="hljs-attr">cache_chunk_size</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">use_context_fmha</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">quant_policy</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">max_position_embeddings</span> = <span class="hljs-number">2048</span><br><span class="hljs-attr">rope_scaling_factor</span> = <span class="hljs-number">0.0</span><br><span class="hljs-attr">use_logn_attn</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
<p>其中，模型属性相关的参数不可更改，主要包括下面这些。</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">model_name</span> = llama2<br><span class="hljs-attr">head_num</span> = <span class="hljs-number">32</span><br><span class="hljs-attr">kv_head_num</span> = <span class="hljs-number">32</span><br><span class="hljs-attr">vocab_size</span> = <span class="hljs-number">103168</span><br><span class="hljs-attr">num_layer</span> = <span class="hljs-number">32</span><br><span class="hljs-attr">inter_size</span> = <span class="hljs-number">11008</span><br><span class="hljs-attr">norm_eps</span> = <span class="hljs-number">1</span>e-<span class="hljs-number">06</span><br><span class="hljs-attr">attn_bias</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">start_id</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">end_id</span> = <span class="hljs-number">2</span><br><span class="hljs-attr">rotary_embedding</span> = <span class="hljs-number">128</span><br><span class="hljs-attr">rope_theta</span> = <span class="hljs-number">10000.0</span><br><span class="hljs-attr">size_per_head</span> = <span class="hljs-number">128</span><br></code></pre></td></tr></table></figure>
<p>和数据类型相关的参数也不可更改，主要包括两个。</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">weight_type</span> = fp16<br><span class="hljs-attr">group_size</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
<p><code>weight_type</code> 表示权重的数据类型。目前支持 fp16 和 int4。int4 表示 4bit 权重。当 <code>weight_type</code> 为 4bit 权重时，<code>group_size</code> 表示 <code>awq</code> 量化权重时使用的 group 大小。</p>
<p>剩余参数包括下面几个。</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">tensor_para_size</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">session_len</span> = <span class="hljs-number">2056</span><br><span class="hljs-attr">max_batch_size</span> = <span class="hljs-number">64</span><br><span class="hljs-attr">max_context_token_num</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">step_length</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">cache_max_entry_count</span> = <span class="hljs-number">0.5</span><br><span class="hljs-attr">cache_block_seq_len</span> = <span class="hljs-number">128</span><br><span class="hljs-attr">cache_chunk_size</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">use_context_fmha</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">quant_policy</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">max_position_embeddings</span> = <span class="hljs-number">2048</span><br><span class="hljs-attr">rope_scaling_factor</span> = <span class="hljs-number">0.0</span><br><span class="hljs-attr">use_logn_attn</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
<p>一般情况下，我们并不需要对这些参数进行修改，但有时候为了满足特定需要，可能需要调整其中一部分配置值。这里主要介绍三个可能需要调整的参数。</p>
<ul>
<li>KV int8 开关：<ul>
<li>对应参数为 <code>quant_policy</code>，默认值为 0，表示不使用 KV Cache，如果需要开启，则将该参数设置为 4。</li>
<li>KV Cache 是对序列生成过程中的 K 和 V 进行量化，用以节省显存。我们下一部分会介绍具体的量化过程。</li>
<li>当显存不足，或序列比较长时，建议打开此开关。</li>
</ul>
</li>
<li>外推能力开关：<ul>
<li>对应参数为 <code>rope_scaling_factor</code>，默认值为 0.0，表示不具备外推能力，设置为 1.0，可以开启 RoPE 的 Dynamic NTK 功能，支持长文本推理。另外，<code>use_logn_attn</code> 参数表示 Attention 缩放，默认值为 0，如果要开启，可以将其改为 1。</li>
<li>外推能力是指推理时上下文的长度超过训练时的最大长度时模型生成的能力。如果没有外推能力，当推理时上下文长度超过训练时的最大长度，效果会急剧下降。相反，则下降不那么明显，当然如果超出太多，效果也会下降的厉害。</li>
<li>当推理文本非常长（明显超过了训练时的最大长度）时，建议开启外推能力。</li>
</ul>
</li>
<li>批处理大小：<ul>
<li>对应参数为 <code>max_batch_size</code>，默认为 64，也就是我们在 API Server 启动时的 <code>instance_num</code> 参数。</li>
<li>该参数值越大，吞度量越大（同时接受的请求数），但也会占用更多显存。</li>
<li>建议根据请求量和最大的上下文长度，按实际情况调整。</li>
</ul>
</li>
</ul>
<h2 id="3-模型量化"><a href="#3-模型量化" class="headerlink" title="3 模型量化"></a>3 模型量化</h2><p>本部分内容主要介绍如何对模型进行量化。主要包括 KV Cache 量化和模型参数量化。总的来说，量化是一种以参数或计算中间结果精度下降换空间节省（以及同时带来的性能提升）的策略。</p>
<p>正式介绍 LMDeploy 量化方案前，需要先介绍两个概念：</p>
<ul>
<li>计算密集（compute-bound）: 指推理过程中，绝大部分时间消耗在数值计算上；针对计算密集型场景，可以通过使用更快的硬件计算单元来提升计算速。</li>
<li>访存密集（memory-bound）: 指推理过程中，绝大部分时间消耗在数据读取上；针对访存密集型场景，一般通过减少访存次数、提高计算访存比或降低访存量来优化。</li>
</ul>
<p>常见的 LLM 模型由于 Decoder Only 架构的特性，实际推理时大多数的时间都消耗在了逐 Token 生成阶段（Decoding 阶段），是典型的访存密集型场景。</p>
<p>那么，如何优化 LLM 模型推理中的访存密集问题呢？ 我们可以使用 <strong>KV Cache 量化</strong>和 <strong>4bit Weight Only 量化（W4A16）</strong>。KV Cache 量化是指将逐 Token（Decoding）生成过程中的上下文 K 和 V 中间结果进行 INT8 量化（计算时再反量化），以降低生成过程中的显存占用。4bit Weight 量化，将 FP16 的模型权重量化为 INT4，Kernel 计算时，访存量直接降为 FP16 模型的 1/4，大幅降低了访存成本。Weight Only 是指仅量化权重，数值计算依然采用 FP16（需要将 INT4 权重反量化）。</p>
<h3 id="3-1-KV-Cache-量化"><a href="#3-1-KV-Cache-量化" class="headerlink" title="3.1 KV Cache 量化"></a>3.1 KV Cache 量化</h3><h4 id="3-1-1-量化步骤"><a href="#3-1-1-量化步骤" class="headerlink" title="3.1.1 量化步骤"></a>3.1.1 量化步骤</h4><p>KV Cache 量化是将已经生成序列的 KV 变成 Int8，使用过程一共包括三步：</p>
<p>第一步：计算 minmax。主要思路是通过计算给定输入样本在每一层不同位置处计算结果的统计情况。</p>
<ul>
<li>对于 Attention 的 K 和 V：取每个 Head 各自维度在所有Token的最大、最小和绝对值最大值。对每一层来说，上面三组值都是 <code>(num_heads, head_dim)</code> 的矩阵。这里的统计结果将用于本小节的 KV Cache。</li>
<li>对于模型每层的输入：取对应维度的最大、最小、均值、绝对值最大和绝对值均值。每一层每个位置的输入都有对应的统计值，它们大多是 <code>(hidden_dim, )</code> 的一维向量，当然在 FFN 层由于结构是先变宽后恢复，因此恢复的位置维度并不相同。这里的统计结果用于下个小节的模型参数量化，主要用在缩放环节（回顾PPT内容）。</li>
</ul>
<p>第一步执行命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 计算 minmax</span><br>lmdeploy lite calibrate \<br>  --model  /root/share/temp/model_repos/internlm-chat-7b/ \<br>  --calib_dataset <span class="hljs-string">&quot;c4&quot;</span> \<br>  --calib_samples 128 \<br>  --calib_seqlen 2048 \<br>  --work_dir ./quant_output<br></code></pre></td></tr></table></figure>
<p>在这个命令行中，会选择 128 条输入样本，每条样本长度为 2048，数据集选择 C4，输入模型后就会得到上面的各种统计值。值得说明的是，如果显存不足，可以适当调小 samples 的数量或 sample 的长度。</p>
<blockquote>
<p>这一步由于默认需要从 Huggingface 下载数据集，国内经常不成功。所以我们导出了需要的数据，大家需要对读取数据集的代码文件做一下替换。共包括两步：</p>
<ul>
<li>第一步：复制 <code>calib_dataloader.py</code> 到安装目录替换该文件：<code>cp /root/share/temp/datasets/c4/calib_dataloader.py  /root/.conda/envs/lmdeploy/lib/python3.10/site-packages/lmdeploy/lite/utils/</code></li>
<li>第二步：将用到的数据集（c4）复制到下面的目录：<code>cp -r /root/share/temp/datasets/c4/ /root/.cache/huggingface/datasets/</code> </li>
</ul>
</blockquote>
<p>第二步：通过 minmax 获取量化参数。主要就是利用下面这个公式，获取每一层的 K V 中心值（zp）和缩放值（scale）。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">zp = (min+max) / 2<br>scale = (max-min) / 255<br>quant: q = round( (f-zp) / scale)<br>dequant: f = q * scale + zp<br></code></pre></td></tr></table></figure>
<p>有这两个值就可以进行量化和解量化操作了。具体来说，就是对历史的 K 和 V 存储 quant 后的值，使用时在 dequant。</p>
<p>第二步的执行命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 通过 minmax 获取量化参数</span><br>lmdeploy lite kv_qparams \<br>  --work_dir ./quant_output  \<br>  --turbomind_dir workspace/triton_models/weights/ \<br>  --kv_sym False \<br>  --num_tp 1<br></code></pre></td></tr></table></figure>
<p>在这个命令中，<code>num_tp</code> 的含义前面介绍过，表示 Tensor 的并行数。每一层的中心值和缩放值会存储到 <code>workspace</code> 的参数目录中以便后续使用。<code>kv_sym</code> 为 <code>True</code> 时会使用另一种（对称）量化方法，它用到了第一步存储的绝对值最大值，而不是最大值和最小值。</p>
<p>第三步：修改配置。也就是修改 <code>weights/config.ini</code> 文件，这个我们在《2.6.2 模型配置实践》中已经提到过了（KV int8 开关），只需要把 <code>quant_policy</code> 改为 4 即可。</p>
<p>这一步需要额外说明的是，如果用的是 TurboMind1.0，还需要修改参数 <code>use_context_fmha</code>，将其改为 0。</p>
<p>接下来就可以正常运行前面的各种服务了，只不过咱们现在可是用上了 KV Cache 量化，能更省（运行时）显存了。</p>
<h4 id="3-1-2-量化效果"><a href="#3-1-2-量化效果" class="headerlink" title="3.1.2 量化效果"></a>3.1.2 量化效果</h4><p>官方给出了 <a href="https://huggingface.co/internlm/internlm-chat-7b">internlm-chat-7b</a> 模型在 KV Cache 量化前后的显存对比情况，如下表所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>batch_size</th>
<th>fp16 memory(MiB)</th>
<th>int8 memory(MiB)</th>
<th>diff(MiB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>8</td>
<td>22337</td>
<td>18241</td>
<td>-4096</td>
</tr>
<tr>
<td>16</td>
<td>30593</td>
<td>22369</td>
<td>-8224</td>
</tr>
<tr>
<td>32</td>
<td>47073</td>
<td>30625</td>
<td>-16448</td>
</tr>
<tr>
<td>48</td>
<td>63553</td>
<td>38881</td>
<td>-24672</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，KV Cache 可以节约大约 20% 的显存。</p>
<p>同时，还在 <a href="https://github.com/open-compass/opencompass">opencompass</a> 平台上测试了量化前后的精准度（Accuracy）对比情况，如下表所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>task</th>
<th>dataset</th>
<th>metric</th>
<th>int8</th>
<th>fp16</th>
<th>diff</th>
</tr>
</thead>
<tbody>
<tr>
<td>Language</td>
<td>winogrande</td>
<td>accuracy</td>
<td>60.77</td>
<td>61.48</td>
<td>-0.71</td>
</tr>
<tr>
<td>Knowledge</td>
<td>nq</td>
<td>score</td>
<td>2.69</td>
<td>2.60</td>
<td>+0.09</td>
</tr>
<tr>
<td>Reasoning</td>
<td>gsm8k</td>
<td>accuracy</td>
<td>33.28</td>
<td>34.72</td>
<td>-1.44</td>
</tr>
<tr>
<td>Reasoning</td>
<td>bbh</td>
<td>naive_average</td>
<td>20.12</td>
<td>20.51</td>
<td>-0.39</td>
</tr>
<tr>
<td>Understanding</td>
<td>openbookqa_fact</td>
<td>accuracy</td>
<td>82.40</td>
<td>82.20</td>
<td>+0.20</td>
</tr>
<tr>
<td>Understanding</td>
<td>eprstmt-dev</td>
<td>accuracy</td>
<td>90.62</td>
<td>88.75</td>
<td>+1.87</td>
</tr>
<tr>
<td>Safety</td>
<td>crows_pairs</td>
<td>accuracy</td>
<td>32.56</td>
<td>31.43</td>
<td>+1.13</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，精度不仅没有明显下降，相反在不少任务上还有一定的提升。可能的原因是，量化会导致一定的误差，有时候这种误差可能会减少模型对训练数据的拟合，从而提高泛化性能。量化可以被视为引入轻微噪声的正则化方法。或者，也有可能量化后的模型正好对某些数据集具有更好的性能。</p>
<p>总结一下，KV Cache 量化既能明显降低显存占用，还有可能同时带来精准度（Accuracy）的提升。</p>
<h3 id="3-2-W4A16-量化"><a href="#3-2-W4A16-量化" class="headerlink" title="3.2 W4A16 量化"></a>3.2 W4A16 量化</h3><h4 id="3-2-1-量化步骤"><a href="#3-2-1-量化步骤" class="headerlink" title="3.2.1 量化步骤"></a>3.2.1 量化步骤</h4><p>W4A16中的A是指Activation，保持FP16，只对参数进行 4bit 量化。使用过程也可以看作是三步。</p>
<p>第一步：同 3.1.1，不再赘述。</p>
<p>第二步：量化权重模型。利用第一步得到的统计值对参数进行量化，具体又包括两小步：</p>
<ul>
<li>缩放参数。主要是性能上的考虑（回顾 PPT）。</li>
<li>整体量化。</li>
</ul>
<p>第二步的执行命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 量化权重模型</span><br>lmdeploy lite auto_awq \<br>  --model  /root/share/temp/model_repos/internlm-chat-7b/ \<br>  --w_bits 4 \<br>  --w_group_size 128 \<br>  --work_dir ./quant_output<br></code></pre></td></tr></table></figure>
<p>命令中 <code>w_bits</code> 表示量化的位数，<code>w_group_size</code> 表示量化分组统计的尺寸，<code>work_dir</code> 是量化后模型输出的位置。这里需要特别说明的是，因为没有 <code>torch.int4</code>，所以实际存储时，8个 4bit 权重会被打包到一个 int32 值中。所以，如果你把这部分量化后的参数加载进来就会发现它们是 int32 类型的。</p>
<p>最后一步：转换成 TurboMind 格式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 转换模型的layout，存放在默认路径 ./workspace 下</span><br>lmdeploy convert  internlm-chat-7b ./quant_output \<br>    --model-format awq \<br>    --group-size 128<br></code></pre></td></tr></table></figure>
<p>这个 <code>group-size</code> 就是上一步的那个 <code>w_group_size</code>。如果不想和之前的 <code>workspace</code> 重复，可以指定输出目录：<code>--dst_path</code>，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">lmdeploy convert  internlm-chat-7b ./quant_output \<br>    --model-format awq \<br>    --group-size 128 \<br>    --dst_path ./workspace_quant<br></code></pre></td></tr></table></figure>
<p>接下来和上一节一样，可以正常运行前面的各种服务了，不过咱们现在用的是量化后的模型。</p>
<p>最后再补充一点，量化模型和 KV Cache 量化也可以一起使用，以达到最大限度节省显存。</p>
<h4 id="3-2-2-量化效果"><a href="#3-2-2-量化效果" class="headerlink" title="3.2.2 量化效果"></a>3.2.2 量化效果</h4><p>官方在 NVIDIA GeForce RTX 4090 上测试了 4-bit 的 Llama-2-7B-chat 和 Llama-2-13B-chat 模型的 token 生成速度。测试配置为 BatchSize = 1，prompt_tokens=1，completion_tokens=512，结果如下表所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>model</th>
<th>llm-awq</th>
<th>mlc-llm</th>
<th>turbomind</th>
</tr>
</thead>
<tbody>
<tr>
<td>Llama-2-7B-chat</td>
<td>112.9</td>
<td>159.4</td>
<td>206.4</td>
</tr>
<tr>
<td>Llama-2-13B-chat</td>
<td>N/A</td>
<td>90.7</td>
<td>115.8</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，TurboMind 相比其他框架速度优势非常显著，比 mlc-llm 快了将近 30%。</p>
<p>另外，也测试了 TurboMind 在不同精度和上下文长度下的显存占用情况，如下表所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>model(context length)</th>
<th>16bit(2048)</th>
<th>4bit(2048)</th>
<th>16bit(4096)</th>
<th>4bit(4096)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Llama-2-7B-chat</td>
<td>15.1</td>
<td>6.3</td>
<td>16.2</td>
<td>7.5</td>
</tr>
<tr>
<td>Llama-2-13B-chat</td>
<td>OOM</td>
<td>10.3</td>
<td>OOM</td>
<td>12.0</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，4bit 模型可以降低 50-60% 的显存占用，效果非常明显。</p>
<p>总而言之，W4A16 参数量化后能极大地降低显存，同时相比其他框架推理速度具有明显优势。</p>
<h3 id="3-3-最佳实践"><a href="#3-3-最佳实践" class="headerlink" title="3.3 最佳实践"></a>3.3 最佳实践</h3><p>本节是针对《模型量化》部分的最佳实践。</p>
<p>首先我们需要明白一点，服务部署和量化是没有直接关联的，量化的最主要目的是降低显存占用，主要包括两方面的显存：模型参数和中间过程计算结果。前者对应《3.2 W4A16 量化》，后者对应《3.1 KV Cache 量化》。</p>
<p>量化在降低显存的同时，一般还能带来性能的提升，因为更小精度的浮点数要比高精度的浮点数计算效率高，而整型要比浮点数高很多。</p>
<p>所以我们的建议是：在各种配置下尝试，看效果能否满足需要。这一般需要在自己的数据集上进行测试。具体步骤如下。</p>
<ul>
<li>Step1：优先尝试正常（非量化）版本，评估效果。<ul>
<li>如果效果不行，需要尝试更大参数模型或者微调。</li>
<li>如果效果可以，跳到下一步。</li>
</ul>
</li>
<li>Step2：尝试正常版本+KV Cache 量化，评估效果。<ul>
<li>如果效果不行，回到上一步。</li>
<li>如果效果可以，跳到下一步。</li>
</ul>
</li>
<li>Step3：尝试量化版本，评估效果。<ul>
<li>如果效果不行，回到上一步。</li>
<li>如果效果可以，跳到下一步。</li>
</ul>
</li>
<li>Step4：尝试量化版本+ KV Cache 量化，评估效果。<ul>
<li>如果效果不行，回到上一步。</li>
<li>如果效果可以，使用方案。</li>
</ul>
</li>
</ul>
<p>简单流程如下图所示。</p>
<p><img  src="quant.png"  ><span class="image-caption">量化流程图</span></p>
<p>另外需要补充说明的是，使用哪种量化版本、开启哪些功能，除了上述流程外，<strong>还需要考虑框架、显卡的支持情况</strong>，比如有些框架可能不支持 W4A16 的推理，那即便转换好了也用不了。</p>
<p>根据实践经验，一般情况下：</p>
<ul>
<li>精度越高，显存占用越多，推理效率越低，但一般效果较好。</li>
<li>Server 端推理一般用非量化版本或半精度、BF16、Int8 等精度的量化版本，比较少使用更低精度的量化版本。</li>
<li>端侧推理一般都使用量化版本，且大多是低精度的量化版本。这主要是因为计算资源所限。</li>
</ul>
<p>以上是针对项目开发情况，如果是自己尝试（玩儿）的话：</p>
<ul>
<li>如果资源足够（有GPU卡很重要），那就用非量化的正常版本。</li>
<li>如果没有 GPU 卡，只有 CPU（不管什么芯片），那还是尝试量化版本。</li>
<li>如果生成文本长度很长，显存不够，就开启 KV Cache。</li>
</ul>
<p>建议大家根据实际情况灵活选择方案。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://github.com/InternLM/lmdeploy/">InternLM/lmdeploy: LMDeploy is a toolkit for compressing, deploying, and serving LLMs.</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/665725861">仅需一块 3090 显卡，高效部署 InternLM-20B 模型 - 知乎</a></li>
</ul>
<h2 id="附录1：TritonServer-作为推理引擎"><a href="#附录1：TritonServer-作为推理引擎" class="headerlink" title="附录1：TritonServer 作为推理引擎"></a>附录1：TritonServer 作为推理引擎</h2><h3 id="TritonServer环境配置"><a href="#TritonServer环境配置" class="headerlink" title="TritonServer环境配置"></a>TritonServer环境配置</h3><blockquote>
<p>注意：本部分内容仅支持物理机上执行，不支持虚拟主机。</p>
</blockquote>
<p>使用 Triton Server 需要安装一下 Docker 及其他依赖。</p>
<p>先装一些基本的依赖。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">apt-get update<br>apt-get install cmake sudo -y<br></code></pre></td></tr></table></figure>
<p>然后是 Docker 安装。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Add Docker&#x27;s official GPG key:</span><br>sudo apt-get install ca-certificates curl gnupg<br>sudo install -m 0755 -d /etc/apt/keyrings<br>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg<br>sudo <span class="hljs-built_in">chmod</span> a+r /etc/apt/keyrings/docker.gpg<br><br><span class="hljs-comment"># Add the repository to Apt sources:</span><br><span class="hljs-built_in">echo</span> \<br>  <span class="hljs-string">&quot;deb [arch=<span class="hljs-subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \</span><br><span class="hljs-string">  <span class="hljs-subst">$(. /etc/os-release &amp;&amp; echo <span class="hljs-string">&quot;<span class="hljs-variable">$VERSION_CODENAME</span>&quot;</span>)</span> stable&quot;</span> | \<br>  sudo <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null<br>sudo apt-get update<br><br><span class="hljs-comment"># install</span><br>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin<br></code></pre></td></tr></table></figure>
<p>安装后我们跑一个 HelloWorld。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># helloworld</span><br>sudo docker run hello-world<br></code></pre></td></tr></table></figure>
<p>可以看到类似下面的画面，表示运行成功。</p>
<p><img  src="triton-server.png"  ><span class="image-caption">triton server</span></p>
<h3 id="TritonServer推理-API服务"><a href="#TritonServer推理-API服务" class="headerlink" title="TritonServer推理+API服务"></a>TritonServer推理+API服务</h3><blockquote>
<p>注意：这部分需要 Docker 服务。</p>
</blockquote>
<p>这里我们把提供模型推理服务的引擎从 TurboMind 换成了 TritonServer，启动命令就一行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ApiServer+Triton</span><br>bash workspace/service_docker_up.sh<br></code></pre></td></tr></table></figure>
<p>这里会启动一个 TritonServer 的容器，如下图所示。</p>
<p><img src="triton-server-run.png" alt=""></p>
<p>可以再开一个窗口执行 Client 命令。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ChatTritonClient + TritonServer（注意是gRPC协议，不要用http）</span><br>lmdeploy serve triton_client  localhost:33337<br></code></pre></td></tr></table></figure>
<p>结果如下图所示。</p>
<p><img src="triton-client.png" alt=""></p>
<h3 id="TritonServer-服务作为后端"><a href="#TritonServer-服务作为后端" class="headerlink" title="TritonServer 服务作为后端"></a>TritonServer 服务作为后端</h3><p>使用过程同 2.4.1 小节。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Gradio+TritonServer（注意是gRPC协议，不要用http）</span><br>lmdeploy serve gradio localhost:33337 \<br>	--server_name 0.0.0.0 \<br>	--server_port 6006<br></code></pre></td></tr></table></figure>
<p>结果如下图所示。</p>
<p><img src="triton-client-web.png" alt=""></p>
<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="TurboMind推理-API服务"><a href="#TurboMind推理-API服务" class="headerlink" title="TurboMind推理+API服务"></a>TurboMind推理+API服务</h3><p><img  src="story.png"  ><span class="image-caption">部署并使用 api 生成 300 字小故事</span></p>
<h3 id="TurboMind-推理-命令行本地对话"><a href="#TurboMind-推理-命令行本地对话" class="headerlink" title="TurboMind 推理+命令行本地对话"></a>TurboMind 推理+命令行本地对话</h3><p><img  src="chat.png"  ><span class="image-caption">与本地部署的模型进行对话</span></p>
<h3 id="TurboMind-推理-gradio"><a href="#TurboMind-推理-gradio" class="headerlink" title="TurboMind 推理+gradio"></a>TurboMind 推理+gradio</h3><p><img  src="gradio.png"  ><span class="image-caption">Gradio 部署</span></p>
<h3 id="KV-Cache-量化部署"><a href="#KV-Cache-量化部署" class="headerlink" title="KV Cache 量化部署"></a>KV Cache 量化部署</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 计算 minmax</span><br>lmdeploy lite calibrate \<br>  --model  /root/share/temp/model_repos/internlm-chat-7b/ \<br>  --calib_dataset <span class="hljs-string">&quot;c4&quot;</span> \<br>  --calib_samples 128 \<br>  --calib_seqlen 2048 \<br>  --work_dir ./quant_output<br></code></pre></td></tr></table></figure>
<p>这里在计算的时候需要下载 calibrate 数据集 c4，国内经常不成功。所以需要手动下载后对读取数据集的代码文件做一下替换。共包括两步：</p>
<ul>
<li>第一步：复制 <code>calib_dataloader.py</code> 到安装目录替换该文件：<code>cp /root/share/temp/datasets/c4/calib_dataloader.py  /root/.conda/envs/lmdeploy/lib/python3.10/site-packages/lmdeploy/lite/utils/</code></li>
<li>第二步：将用到的数据集（c4）复制到下面的目录：<code>cp -r /root/share/temp/datasets/c4/ /root/.cache/huggingface/datasets/</code></li>
</ul>
<p><img  src="max.png"  ><span class="image-caption">计算每一层的最大 GPU 占用</span></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 通过 minmax 获取量化参数</span><br>lmdeploy lite kv_qparams \<br>  --work_dir ./quant_output  \<br>  --turbomind_dir workspace/triton_models/weights/ \<br>  --kv_sym False \<br>  --num_tp 1<br></code></pre></td></tr></table></figure>
<p><img  src="qparam.png"  ><span class="image-caption">获取量化参数</span></p>
<p>之后修改 <code>weights/config.ini</code> 文件 <code>quant_policy=4</code> 表示开启 KV Cache 量化。</p>
<p>部署运行内存占用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">watch vgpu-smi<br></code></pre></td></tr></table></figure>
<p><img  src="kv-cache-memory.png"  ><span class="image-caption">KV Cache 内存占用</span></p>
<h3 id="W4A16-量化"><a href="#W4A16-量化" class="headerlink" title="W4A16 量化"></a>W4A16 量化</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 计算 minmax</span><br>lmdeploy lite calibrate \<br>  --model  /root/share/temp/model_repos/internlm-chat-7b/ \<br>  --calib_dataset <span class="hljs-string">&quot;c4&quot;</span> \<br>  --calib_samples 128 \<br>  --calib_seqlen 2048 \<br>  --work_dir ./quant_output_awq<br></code></pre></td></tr></table></figure>
<p>之后量化权重</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 量化权重模型</span><br>lmdeploy lite auto_awq \<br>  --model  /root/share/temp/model_repos/internlm-chat-7b/ \<br>  --w_bits 4 \<br>  --w_group_size 128 \<br>  --work_dir ./quant_output_awq<br></code></pre></td></tr></table></figure>
<p>命令中 <code>w_bits</code> 表示量化的位数，<code>w_group_size</code> 表示量化分组统计的尺寸，<code>work_dir</code> 是量化后模型输出的位置。这里需要特别说明的是，因为没有 <code>torch.int4</code>，所以实际存储时，8个 4bit 权重会被打包到一个 int32 值中。所以，如果你把这部分量化后的参数加载进来就会发现它们是 int32 类型的。</p>
<p><img  src="awq.png"  ><span class="image-caption">AWQ 量化</span></p>
<p>最后一步：转换成 TurboMind 格式。</p>
<p>这个 <code>group-size</code> 就是上一步的那个 <code>w_group_size</code>。如果不想和之前的 <code>workspace</code> 重复，可以指定输出目录：<code>--dst_path</code>，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">lmdeploy convert  internlm-chat-7b ./quant_output_awq \<br>    --model-format awq \<br>    --group-size 128 \<br>    --dst_path ./workspace_quant_awq4<br></code></pre></td></tr></table></figure>
<p><img  src="convert-awq.png"  ><span class="image-caption">转换为 TurboMind 格式</span></p>
<p>目录结构如下：</p>
<p><img  src="tree-awq.png"  ><span class="image-caption">转换为 TurboMind 格式的 AWQ 模型结构</span></p>
<p>部署使用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">lmdeploy chat turbomind ./workspace_quant_awq4<br></code></pre></td></tr></table></figure>
<p>内存占用</p>
<p><img  src="awq-memory.png"  ><span class="image-caption">AWQ 量化内存占用</span></p>
<p>可见内存占用只有 6G。</p>
]]></content>
      <categories>
        <category>internlm</category>
      </categories>
  </entry>
  <entry>
    <title>反社会的人笔记</title>
    <url>/uncategorized/%E5%8F%8D%E7%A4%BE%E4%BC%9A%E7%9A%84%E4%BA%BA/</url>
    <content><![CDATA[<h1 id="反社会的人"><a href="#反社会的人" class="headerlink" title="反社会的人"></a>反社会的人</h1><p>上层阶级与下层阶级是如何搞垮德国，而谁又在从中获利。</p>
<p>作者瓦尔特·伍伦韦伯在成为记者之前曾就读于海德堡大学政治和法律专业。《反社会的人》是其于2012年出版的首部著作。一经面世就成为当年德国最畅销的读物之一。作者在书中所呈现的德国社会不公正性虽然不为中国读者所熟悉，但这些现象在德国国内早已是热门话题。与大量将焦点放在贫富差距上的社会讨论不同的是，本书的作者首先定义了德国社会中业已形成的两个新兴阶级，即上层阶级和下层阶级。通过对这两个社会群体发展过程的详细描述，作者提出了自己看似惊人的观点。他认为新兴上层阶级和下层阶级的存在使德国社会面临着分崩离析的局面。这两个看似对立的阶级实质上具有近乎一致的发展轨迹和表现特征。它们不但在德国社会运作过程中极力地逃避着作为公民的义务和责任，而且其生存形态给德国的普通纳税人造成了极大负担。</p>
<p>瓦尔特·伍伦韦伯进而在本书的第二部分中将讨论的重点转向了促成这两个阶级形成的原因，也就是德国经济中两个最庞大的产业：金融和社会救助产业。借助大量的统计数据和对相关人员的采访，作者揭示了这两个产业依附于上层和下层阶级得到快速发展的事实。金融行业通过帮助上层阶级进行巨额财富的投机活动，不但使德国经济陷入巨大的危机，还让上层阶级这种纯粹依靠资本运作获益的生活方式成为可能。而社会救助产业则通过利用德国社会福利制度的漏洞，将大量的政府公共支出占为己有，从而发展成为拥有200万从业人员的巨型产业。本书同时尖锐地指出了德国历届联邦政府在这两个产业的畸形发展过程中所起到的推波助澜的作用。政府逐步解除对这两个行业的监管导致其在追求利益最大化的道路上越走越远。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>哲学家路德维希·维特根斯坦曾说过：“对于一无所知的事情，人们应当保持沉默。”正因如此，对于同时在德国社会结构的两极发生着的巨大变化，至今无人展开讨论。对探讨对象的一无所知往往导致这类讨论在尚未开始时就注定夭折。作为社会凝聚力瓦解的前兆，下层乃至上层阶级纷纷退缩到各自的平行世界。而人们却一直在回避这一威胁。其中一个最重要的原因就是：我们对于德国社会结构中的这两类人群知之甚少。</p>
<p>当然无知并不是唯一的障眼法，阻碍人们认识这个新兴阶级社会的还有习惯性思维。东部和西部的德国人早已不习惯以阶级来划分他们所处的社会。统一之前的东德人活在“统一的社会主义社会”的假象中。而西德人则相信当时的联邦德国正朝着“均质化的中产阶级社会”发展。“不管怎样大家都是中产阶级”这一观念在如今西德人的意识里依然根深蒂固。</p>
<p>对于其他主要欧美国家的人民来说，认识到社会阶级的存在是件理所当然的事情。而如今的德国人在这方面却显得缺乏经验。对于中产阶级社会狭隘的固着遮挡了他们的视线，使其难以察觉到德国社会正在经历的转变，因为这种转变首先就发生在德国下层和上层阶级中。</p>
<p>上层阶级是否仍然像大多数人认为的那样担当着社会生产力的骨干角色？<strong>事实是那些过去的企业奠基人及开拓者早已完成转型，变成了纯粹的投资者。</strong>他们现在更喜欢在高风险的金融投资领域用资本获取更多的资本。德国的财富精英们也绝非像他们宣称的那样被税收压得喘不过气来。恰恰相反，他们厚实的肩膀上仅仅承担着微不足道的税赋。维持国家日常运作的经济重任则转由辛勤的中产阶级纳税人来承担。在过去十年中，上亿欧元的财富被转移到了金字塔的顶端。但为何如此巨大的财富转移时至今日仍不为社会所察觉？这应当归咎于上层阶级在自身习性上的一个重大转变。受世人瞩目自古以来就是一种特权。不论是剧院里高高在上的包厢还是主席台的中间席位，显眼的位子总是属于位高权重的人。然而如今的上层阶级却更愿意生活在外人无从窥探的平行世界里。他们只会在互相之间展示其财富。在外界看来，德国的富人们就像根本不存在一样。</p>
<p>然而最近的金融危机却提醒了世人：少数极端富有者的贪欲已经威胁到了社会中大多数人的生活水准。因此，不论上层阶级如何百般地抵制，其价值观和行为都有必要成为公共探讨的主题。相对于上层阶级，下层阶级倒是活得不藏不掖。早在十年前，我成为了首批对这一新兴社会阶层进行报导的记者之一，并在之后的数年间对这个尚不为人所了解的社会阶层进行了大量的采访研究。我得出的结论是：人们对下层阶级的印象仍停留在那些老生常谈、空穴来风的故事或是个别利益集团别有用心的不实宣传上。人们不会想到，物质的匮乏如今和下层阶级的日常生活根本扯不上关系，游戏机、智能电话、电脑和电视娱乐节目才是他们生活中最重要的组成部分。德国的社会福利制度早已战胜了匮乏的物质生活。德国的穷人可以说有的是钱。尽管如此，下层阶级所遭受的不公正对待却是真实且残酷的，而这种不公正性的根源及广度绝非“贫穷”一词所能概括。<strong>下层阶级被剥夺的是一种宝贵的社会参与性。较之金钱的匮乏，受教育机会的缺失才是下层阶级的主要标志。匮乏的教育机会几乎可以说是一切相关问题的根源，包括失业、健康以及抚养后代时的力不从心。下层阶级和中产阶级之间的区别并非收入水平，文化上的差异才是横跨在两者之间的鸿沟。</strong></p>
<p>绩效观念对于德国社会有着不可替代的意义。它不光是富足生活和优越社会福利的保障，更是德国价值体系的支撑。然而上层阶级与下层阶级却发展出了各自独有的价值观和道德观，并与主流社会的认同渐行渐远，这使得对生产绩效的追求失去往日的意义。因为对于以上两个阶级来说，工作所得并非其典型的经济来源。<strong>上层阶级通过毫不费力的资本投资获取财富，而下层阶级则基本依靠社会救济拨款来维持生活。</strong>有别于中产阶级，生产绩效对这两个生活在平行社会中的阶级来说丝毫不具备同等的意义。</p>
<p>社会学家注意到，这两个社会阶级的成员几乎已无法意识到付出劳动与获得成功之间的因果关系。上层阶级视成功为理所当然的结果。下层阶级则缺乏通过付出努力而获取成功的经历。这就使得各种缺乏诚信的手段在两个阶层获得了极大的生存空间。蓬勃发展的税收规避行业正在帮助上层阶级最大限度地逃避纳税。而下层阶级也在社会福利法规制度的丛林中发挥着自身的创造性，尽其所能地不劳而获。可以说，<strong>善于寻找和利用法律漏洞正日渐成为这两个社会阶层所共有的特性</strong>。而德国政府却在经济上资助了这种社会离心运动的发展。中产阶级基本上是在独自维持社会的正常运作，其缴纳的高额税收既化解了财富阶层金融投机行为所带来的风险，同时又保障了下层阶级坐享各种社会福利。他们既为有钱人的财富提供了保护伞，又承担着人人受益的社会福利体系。可以说中产阶级在同时供养着上层和下层阶级。</p>
<p>为了在金融危机中挽救德国经济，政府背负了总量足以再完成一次两德统一过程的巨额债务。同时税务局所征收的每5欧元税收中，就有1欧元流入了社会救助产业的账户。这两个行业无疑是德国经济中最大的吸金者。为此，社会救助产业正在庆祝一个真正的经济奇迹，其发展速度达到了德国总体经济增长的七倍。同时，金融行业也在经历着一个激动人心的繁荣期。货币供应量在过去的二十年里以爆炸式的速度增长。然而政府财政却从这些发展中一无所获，原因就在于这两个巨型行业所享受的税收特权将它们从纳税义务中解放出来，得以将盈利最大程度地占为己有。</p>
<p>值得注意的还有，这两个行业的发展曲线在20世纪90年代中期不约而同地开始垂直攀升。那是因为在这一时期，德国政府的一系列举措大规模地解除了对这两个行业的监管。近年来更是几乎完全放弃了对金融和社会救助产业的控制。德国政府可以说彻底地向其势力举起了白旗。民主社会及其制度的意义在此被漠视，而纳税者也成为了社会中大多数人的唯一角色。</p>
<h2 id="第一章-上层阶级：富人只满足于富有"><a href="#第一章-上层阶级：富人只满足于富有" class="headerlink" title="第一章 上层阶级：富人只满足于富有"></a>第一章 上层阶级：富人只满足于富有</h2><p>在学生时代勤奋好学，并且选择法律或金融这类热门专业的人，取得高学历后进入知名企业开始废寝忘食地工作，同时注重人脉的培养。他既能产生创意又具备执行能力，总是让周围的人感受到自己积极的一面。这样的人接着就能受到提拔，在公司停车场拥有固定的车位。工作中自然也免不了与同事勾心斗角，才能得到下一个升职加薪的机会。他平时还必须生活节俭，购买人寿保险，签订住房互助储金合同，建造私人住宅，最终获得公司股份。<strong>而富人却知道，人们永远也不会通过这条途径变得富有。</strong></p>
<p>承担最高的税率、保时捷跑车、香槟酒、大庄园、高尔夫俱乐部、私人游泳池、劳力士手表、周游世界、古奇、邮轮旅行、丹麦B&amp;O音响、能享受专家治疗的私人医疗保险、高斯巴雪茄”、加入扶轮社，而富人却知道，真正的财富绝非这些东西所能代表。</p>
<p>在过去的几十年中，经济生活的标准对于社会中下阶层也有了明显的提高，在高速公路上以200公里的时速驾驶、去国外度假、拥有家庭影院，这些在以前只有少部分人能够拥有的体验如今的平常人也一样可以获得。之前作为奢侈象征的事物陆续进入了普通收入者的生活，这更导致了一种假象，即社会财富间的距离正在逐渐缩小。造成这个假象的还有一条德国人的黄金法则：“是什么人开什么车。”然而这条曾被视为阶层分界的铁律早已不再适用于如今的德国社会。为了能更准确地了解德国的财富阶层及其财富的规模，我们急需一种新的标准，并非汽车品牌，也不是度假目的地。为此，我们需要一张A4大小的纸，在竖版的方向每隔1厘米画一条线，每条线代表了50000欧元的财富，在画第20条线时就达到一百万欧元的标准。当线画到这张A4纸的顶端时大约代表了一百五十万欧元。如果所有的德国人都在代表自己财富水平的那条线上打钩的话，其中一半以上的人只能打在这张纸的底部区域，也就是说这些人基本上没有任何财产。而几乎99%的人都能就自己拥有的财富在这张纸上找到对应的那条线。只有1%的德国人，其所拥有的财富使他们能跳出这张纸的范围，这些人的数量大约在八十万到一百万左右。他们才是德国真正的财富阶层，他们手上掌握着真正的资本。</p>
<p>我们还可以继续利用这个A4纸标准来衡量德国人所拥有的财富之间到底有多大的差距，根据《经理人杂志》“所提供的德国财富排行榜，南部阿尔迪公司”拥有者卡尔·阿尔布雷希特·常年占据榜首，名下财产估计在170亿欧元左右。代表其财富的那条线该画在多远的地方呢？一米？十米？一百米？答案是3.5公里。也就是说99%的德国公民的财富可以表现在一张A4纸上，而想看到代表卡尔·阿尔布雷希特财富的那条线则需要用望远镜才行。我们所使用的A4纸财富标准和国际上社会学研究者认同的标准极其相似，即所谓的“高净值个人，HNWI”，也就是除名下的不动产外所掌握净资产超过一百万美元的个人。而事实上根据实时汇率，拥有超过七十五万欧元资产的人其名下的不动产价值基本也会处于同样的规模。据“世界财富报告”统计，2011年德国人中拥有至少一百五十万欧元财富的高净值个人共924000位，他们是德国社会最富有的百分之一。</p>
<h3 id="不为人知的上层阶级"><a href="#不为人知的上层阶级" class="headerlink" title="不为人知的上层阶级"></a>不为人知的上层阶级</h3><p>在阶级意识极强的英国和法国，上层阶级理所当然地受到不间断地关注。而德国社会却与之相反，人们习惯于对财富阶层及他们的财富闭口不谈。任何关于个人财富的讨论会被立即贴上“妒忌话题”的标签。这足以让人对此类话题退避三舍，这也是德国社会至今对国内上层阶级缺乏认识的原因之一。谁要是不提问，自然得不到答案。然而有时问了也会得不到答案，所有尝试对上层阶级进行研究的科学家没准儿都遇到过这种情况。达姆斯塔特工大的社会学家米夏埃尔·哈特曼敦授作为德国一流的社会精英研究者，长期对政治、政府、法律及经济界的关键人物进行研究”。在工作中他无奈地发现，没有哪个群体像财富精英们那样对有关他们的研究采取一概抵制的态度。而且越是有钱，抵制得越坚决。哈特曼教授说：“就算是我们这样的学者也几乎接近不了那群人。”对德国最重要的经验社会学研究《社会经济学调查》的研究者来说，被上层阶级拒之门外早就是习以为常的事了。通常只要是问及其财富的规模，访问就极有可能被终止。为此，该研究项目的学者们在多年前就把这个问题从问卷中去掉了。作为研究者之一的马库斯·格拉布卡·抱怨说：“我们对上层阶级知道的还太少了。”持相同意见的还有波兹坦大学’的教授、最具权威的经验社会学著作《德国的财富》作者沃尔夫冈·劳特巴赫，这位财富研究者承认：“我们对这个虽小但极具影响力的社会群体的了解是肤浅的。”并将他们称作“躲在暗处的隐形群体”。而法兰克福的社会学教授西格哈特·内克尔“则直接对当前关于该问题的研究水平下了定论：“德国上层阶级目前就是一个研究空白。”</p>
<h3 id="工资收入只属于门外汉"><a href="#工资收入只属于门外汉" class="headerlink" title="工资收入只属于门外汉"></a>工资收入只属于门外汉</h3><p>巨额财富的运作管理是金融行业中正在快速发展的一个服务门类，它保持着每年7%的增长点。在过去的20年里，令财富阶层欣喜若狂的巨大收益无疑要算理财经理人的功劳。这些为私人银行效力的理财专家满足了有钱人的最大梦想，那就是让财富自己为它的所有者创造更多的财富，进而使该阶层的财富水平达到了一个前所未有的规模。对于财富阶层来说，过去的20年是他们的黄金时期。金融危机加速了他们和其余社会人群之间的财富差异化。我们可以通过对收入情况的比较来说明这一问题。根据经济发展与合作组织提供的数据，德国国内的收入差异水平自1990年起开始加剧，且明显超过大部分经合组织国家差异水平。当90%的德国民众的收入水平在世纪之交有所减少时，占人口5%的上层阶级收入却增长了近15%。</p>
<h3 id="向上的再分配"><a href="#向上的再分配" class="headerlink" title="向上的再分配"></a>向上的再分配</h3><p>资本的分配比收入的分配更不平均，准确地说资本分配的不平均程度是收入分配的3倍。马库斯·格拉布卡证实了这点：“资本的集中程度在过去的几年中持续地增长。”米夏埃尔·哈特曼教授也得出了相同结论：“这几年里，最富有的那1%手中的财富得以明显地增加，其中的大部分集中在最最富有的千分之一手上。”</p>
<p>1970年社会全部财富的44%掌握在占人口总数10%的富人手中，现在这个比例已经增长至66%。把社会财富比作蛋糕的话，又有两块蛋糕从多数人的盘子被分到了少数人的盘子里。这样的再分配涉及的数额巨大，如今德国的全部社会财富高达6.6万亿欧元，要是还按照1970年的比例再次分配的话，德国最富有的那10%就得吐出1.5万亿欧元。对其余90%的人来说，这意味着人均20000欧元的额外收入。若是在不同的时代，这样不公平的财富分配足以引发一场血腥的革命。</p>
<p>10%的人口支配着三分之二的财富。哈特曼教授表示，这里还存在着上层与最上层之间的差别。让我们从财富的金字塔往上看，最著名的那1%拥有超过三分之一的财富，他们比社会中90%的人加起来还富有。但在近10年财富分配中的最大赢家只有大约80000人，也就是最最富有的千分之一。全德国社会财富的15%属于这80000人。为了让读者看得更明白：</p>
<p>·其余90%的德国人拥有33.4%的财富。</p>
<p>·富有的10%拥有66.6%的财富。</p>
<p>·最富有的1%拥有35.8%的财富。</p>
<p>·最最富有的1%o拥有22.5%的财富。</p>
<p>看了这组数据谁要是已经觉得呼吸困难，那接下来的这个数字足以让人立刻窒息。以上的数据包含了所有的财富类型，如果把其中所有者自住的不动产去掉只计算金融资本的话，那最富有的5%就掌握着全德国75%的财富。</p>
<p>早先有许多学者相信渗漏效应，他们认为财富会从上层流经全社会的各个层面直至下层，这意味着上层获益则所有人都将获益。渗漏效应因此为财富的不均匀分配提供了合法性。然而财富阶级似乎在自己与其他社会阶层中间拉起了一张塑料薄膜。马库斯·格拉布卡说：“所有的研究表明，其他社会阶层什么也没从上层得到。”这种在社会财富分配过程中的变化是否正是上层社会退出公众视线的原因呢？面对财富分配游戏中的失败者，没必要以胜利者的姿态在其面前耀武扬威，最好的办法是让他们继续蒙在鼓里。</p>
<h3 id="隐蔽的享乐主义"><a href="#隐蔽的享乐主义" class="headerlink" title="隐蔽的享乐主义"></a>隐蔽的享乐主义</h3><p>马丁·哈尔德带我去了他朋友安德烈亚斯·穆尔库迪斯那里。他俩有着共同的客户群。只有知情者才认得安德烈亚斯的店，马丁开着他的保时捷从货车入口进入了柏林一座破败的建筑里，停在卸货区域内。在这个一楼的Loft里，所卖的商品都是安德烈亚斯亲自挑选的。儿童服装，由瑞士农妇手工编织，标签上是弗兰肯豪泽女士亲笔写的“出自弗兰肯豪泽女士”，没有标价。在另一个台子上摆着一双男皮鞋，当然是手工制作，但这鞋看起来就像是曾经有人穿着它走了一遍圣地亚哥朝圣之路一样。普通人估计都不好意思把它捐给红十字会。只有识货的人才知道这鞋的来历。马丁告诉我：“其中的信息只有知情者才能读到。而像阿玛尼、古奇、普拉达这些牌子只适合半吊子。”服装代表了身份，这句话到今天也不过时。但对于从前的上层阶级来说，向世人展示其地位是非常重要的事。而如今他们的服装却发展成了一种暗号。不引起别人的注意对于今天的上层阶级来说才是最重要的。</p>
<p>黑尔格·阿亨巴赫的理论是：“财富并不能满足精神的需求，拥有10亿身家或者更多的人经常会感到孤独和恐惧。”而他则给这样的人提供了精神上的满足，通过艺术品。收藏和展示价值不菲的艺术品被视为享受财富的高雅形式。在德国，谁要是花1000万欧元造了艘游艇，必然会被视为暴发户。但要是用同样的价格拍得一幅格哈德·里希特的画作，则成了艺术的促进者。艺术品收藏让富人可以在任意挥霍其财富的同时还能以富有修养的形象示人。</p>
<p>然而对艺术的理解和财富多寡之间却没有联系，黑尔格·阿亨巴赫也由此发展出了他的事业。他在德国被认为是艺术品咨询行业的发明者。他可以在有钱人购买某件艺术品时提供咨询，也能帮他们筹备一个收藏系列。几百年来，财富阶层身边总是不乏艺术品，在文艺复兴时期艺术收藏就变得更为重要，而正是在同一时期，财富的地位也上升到了一个新的高度。这并不意味着拥有了财富就会自动对艺术产生兴趣。黑尔格·阿亨巴赫必须先帮许多客户把他们对艺术的兴趣唤醒，然后塑造他们对艺术的品味。他声称，一些客户通过艺术收藏简直像是脱胎换骨了一样。</p>
<h3 id="去政治化的上层阶级"><a href="#去政治化的上层阶级" class="headerlink" title="去政治化的上层阶级"></a>去政治化的上层阶级</h3><p>当代来自经济领域的上层阶级则是去政治化的一群人。在他们中间弥漫着对国家政治制度及政治活动的蔑视。“在我们的圈子里没有谁愿意为国家出力，也没人会和媒体接触。”一位坚持不愿透露姓名的男爵对我说。该男爵的家族姓氏可以追溯到12世纪。他的住所是一座位于德国南部的雄伟古堡，居住面积大约为1200平方米。通过观察男爵的家族历史，人们可以发现上层阶级在国家事务中的演变。直到17世纪，神职人员都是很受欢迎的职业。而在19和20世纪中，男爵的先辈们则通过出任部长、将军和议员来体现其政治上的显要地位。男爵本人也曾短时间涉足政界，而且还获得过地方议员的席位。然而政治这种需要赢得多数人好感的游戏对于他来说始终觉得陌生。“在政治中，人们要表现和证明自己，需要承担责任。而我们这样的人已经对这些没什么兴趣了。”男爵说。因此他最终还是放弃了家族的传统，转而进入商界，但始终还是上层阶级。</p>
<h3 id="精英工厂"><a href="#精英工厂" class="headerlink" title="精英工厂"></a>精英工厂</h3><p>曾几何时，受教育机会可以说是上层阶级特权的重要表现，然而20世纪60年代开始的德国教育改革改变了这一情况。上层阶级在教育方面的优势荡然无存，中产阶级则通过优化后的教育制度迈开了奋力追赶的脚步。竭尽全力的中产阶级家长为了确保自己的后代能在未来的社会竞争中占据有利条件，纷纷开始用肖邦进行胎教，一种对自身生存状态的危机感正在财富阶层中传播开来，其根源来自全球金融风暴。长期以来，上层阶级已经习惯了坐享理财专家们为其巨额投资所带来的两位数的收益率。金融危机让他们第一次感受到其财富的安全性并非理所当然的事情。当前世界经济的不可预知性同样严重威胁到了上层阶级有保障的物质生活，他们中的许多人在受到震惊后开始退缩不前。托马斯·派瑞将上层阶级的这种应激反应称为“搁浅”，对其的描述可概括为：一种对周边可控区域更为强烈的固着，这种可控区域主要包括家庭和所属社会阶层，其共同特点是私密、熟悉和可预见性。因此，上层阶级的目光更大程度地转向内部，自身成了他们唯一的参照物。外部世界则越来越多地被其视为威胁。</p>
<p>社会学家已经观察到，社会阶层之间的隔离有愈演愈烈的趋势，特别是对于上层阶级来说。社会学教授西格哈特·内克尔总结说：“上层阶级自身所具有的特征变得越发明显，保持社会阶级间的距离对其来说也越来越重要。”百万富翁们为了避免与穷人接触纷纷逃进了他们的平行世界。关于这个平行世界的例子有很多：越来越多的上层阶级偏爱会员制的俱乐部，而非传统的各类民间协会。他们几乎从不使用公共交通工具，即使和高收入者一起乘坐航班的商务舱对他们来说也是不能忍受的。这就说明了为什么2004年至今德国的私人飞机拥有量翻了一番。连汉莎航空公司都瞅准了其中的商机，开始接受私人航班的预定。婚姻问题研究者指出：上层阶级中的越来越多的人倾向于门当户对的联姻。那个集团总裁和接上学到东西，但赫伯特·亨茨勒表示，为政府所做的工作让他在很多方面进行了重新思考。这个咨询委员会旨在从资金及技术的角度帮助政府解决基础设施建设方面的难题。从前像赫伯特·亨茨勒这样的人是绝不会站在政府的立场思考的，甚至会为这些难题与政界展开激烈的辩论。可惜这位前高级经理人直到退休后才发现税收的重要性：“对国家基础设施项目的投资，有许多只能依靠税收收入来实现。为此，我现在甚至赞成国家提高税收。”</p>
<h3 id="退入平行社会"><a href="#退入平行社会" class="headerlink" title="退入平行社会"></a>退入平行社会</h3><p>“让所有人接受教育”曾是德国20世纪70年代一项宏大的政治计划。对于一些勤奋的德国人来说，在大约20年中教育确实使其在社会和经济地位方面的提升成为可能。然而2000年进行的第一次PISA测验的结果却表明：没有哪个国家像德国一样，在教育资源上偏袒家境优越的学生。家庭背景自始至终决定了一名学生在德国教育体系中所受到的待遇。除了留在大学任教外，博士学位是人们在德国教育系统中所能获得的最高学历。如果说获得博士学位意味着今后的人生将一帆风顺，对于像法律、工程和经济学专业的博士就更是如此。米夏埃尔·哈特曼教授对这些专业的博士毕业生进行跟踪研究后发现：来自上层阶级的博士进入企业高级管理层的机会是中产阶级出身同等学历者的3倍。</p>
<p>对知识和专业技能的学习早已不是通向顶层的阶梯，社会中的上升通道最多只能到达中产阶级。尽管如此，教育却显得比之前更加重要。因为对于99%的德国人来说，受教育虽不能保证飞黄腾达，但却是唯一能够避免其现有社会地位下降的途径。教育的首要意义如今变成了经济状况的保障。而在德国国内的中学和大学里刻苦学习的中产阶级后代明显高估了教育能够带来的机遇。相反上层阶级知道，想加入上层阶级这个俱乐部并不需要过人的学历。一位人力资源管理者说：“成绩对我们来说不重要，而形象、自信心和行为举止才是关键因素。”在她的名片上印着德国区首席运营官，此次的目的是为－－家投资银行招揽高级管理人员。这位女士希望能在欧洲商学院有所收获。欧洲商学院作为一所德国私立高校，在国际和国内的同类学校排行中都名列前茅，被视为金融行业的精英工厂。学院每学期的学费为6000欧元。虽说不是牛津或哈佛大学，但它属于德国最好的大学。</p>
<h3 id="过于集中的财富意味着危险"><a href="#过于集中的财富意味着危险" class="headerlink" title="过于集中的财富意味着危险"></a>过于集中的财富意味着危险</h3><p>约翰·肯尼斯·加尔布雷思对于上层阶级有着截然不同的看法。这位哈佛大学的经济史学家凭借其对金融行业历史中的泡沫经济与银行危机的研究闻名于世。在他看来，上层阶级非但不是经济领域的价值创造者，反而是一种危险因素。财富阶层是金融行业历史上所有灾难的制造者。迄今为止发生过的所有经济危机都拥有一个共同的前提：一旦少数人手中掌握了太多的财富，就会引发灾难。</p>
<p>不光是今天的富人被认为有杰出的能力。加尔布雷思纵观历史后发现：人们在所有的时期都愿意相信，谁要是占有的财富越多，其社会及经济地位就越牢固，也越具有敏锐的洞察力和聪明的头脑。金钱还会被用来衡量所创造的价值，财富越多，其所创造的价值和运用的才智就越多。对于加尔布雷思来说，将财富与才智相提并论更是一个具有欺骗性的观点。虽然加尔布雷思已于2006年去世，但其关于历史的见解仍可以被运用到对当代德国社会的研究中。上层阶级自认为是社会精英的神话已经被打破，米夏埃尔·哈特曼教授通过对德国大型企业中最高领导层的调查发现：其中80％的人来自社会中最富有的那5%的家庭，其中的一半更是属于最最富有的那千分之一。可见，才能或资历并非是成为企业管理者的依据，家庭背景才是真正的选拔条件。而相应的工作收入对财富阶层来说简直就是零花钱，这也是为什么大部分的高净值个人并不从事任何职业。沃尔夫冈·劳特巴赫认为这些人属于德国社会中不劳而获的群体，其财富的快速增长并非辛勤工作的结果。金融市场是其进行财富积累的主要手段。而通过高明的资本运作让财富成倍增长充其量只能算是理财专家的劳动成果，上层阶级只不过是提供了资本而已。来自《社会经济学调查》(SOEP)、汉斯·伯克勒基金会及世界经济合作组织等多个机构的研究结果同样证明了这个结论。社会学教授西格哈特·内克尔还观察到了商界精英如何从昔日带有中产阶级兢兢业业特点的群体转变为如今的经济机会主义者。正如劳特巴赫所指出的：当人拥有巨额财富时，金融市场上机会主义的博弈为其带来的回报比辛勤工作丰厚得多。相对于普通的工作收入，这种毫不费力的资本收益更能代表上层阶级的身份。在德国只有5%的人属于直接股东，而股市中的投机行为对于那些没有足够资本来分散风险的人，也就是其余95%的德国人并不可取。可见，资本收益其实是上层阶级的特权。</p>
<h3 id="从企业家变为投资者"><a href="#从企业家变为投资者" class="headerlink" title="从企业家变为投资者"></a>从企业家变为投资者</h3><p>然而将自己毕生经营的企业托付给下一代早已不是那些老一辈创业者的唯一选择。正有越来越多上了年纪的企业所有者向豪克·奥夫豪泽私人银行的米夏埃尔·施拉姆就出让企业一事进行咨询。“企业中的世袭观念正迅速消除。”他说。托马斯·派瑞对此和施拉姆持有一致的看法：“理想的情况中子孙们有朝一日能接手并承担起家族企业，在现实里已不再是常态。”那些在财富中成长起来的孩子对于备受压力的企业领导者一职已失去兴趣。而老一辈财富阶层不但对此表示理解，更乐意为其后代安排好今后衣食无忧的生活。没有责任和压力的财富显然要美好得多。当托马斯·派瑞向那些财富阶层问及其今后的目标时，他得到的最多回答是这样：保持健康、对自己的心灵进行探索、创造生活和工作的平衡以及在私人生活中寻找一片净土。</p>
<p>原先注入企业中的资金现在则被交给私人银行的专家们去经营。投资经理们所提供的全球化投资策略使新一代财富阶层从此不必再为企业利润担心。企业家从此变成了投资者。作为资本家的他们出售了曾是其财富基础的生产资料。组织企业进行生产对社会而言是一种积极的行为，相对而言将大量资金投入金融行业则是一种消极行为。财富阶层正从国民经济的积极建设者转变为消极的寄生群体。然而上层阶级仍孜孜不倦地将自己视为一个由企业家组成的群体。托马斯·派瑞在他的采访研究中把这称为“自以为是的自我认识”。尽管如此，上层阶级的世界中除了坐享其成者，总还是存在一些成功的企业家，通过努力奠定了其财富地位。</p>
<p>想自己创业，首先必须要有一定的启动资金。创业者在没有足够存款的情况下就只能向银行贷款。创业者是否能够迈出第一步很大程度上取决于银行的判断。在2011年中，位于波恩的中产阶层研究机构对个人创业行为进行了统计。德国当年400000起注册创业行为中，有380000起最终宣告破产。由此可见成功创业的难度。最普遍的创业原因并非绝妙的生意点子，却是因为生活所迫。许多长期失业者在走投无路时才会萌发创业的想法。而一旦创业失败并无力偿还银行贷款，这些人能做的就只有宣告破产。在之后的六年时间里，他们不能在银行开户、不能签手机协议和新的租房合同。这意味着破产者失去了其经济存在性，前景一片渺茫。德国对经济上的失败者可以说是毫不留情。在中产阶层研究机构的统计中，出身财富阶层者的首次创业行为则显示了截然不同的数据。上层阶级家庭很乐意出资帮后代解决像启动资金这样的小问题，这就给了他们一个实现其创业想法的良好开端。尽管受过最好的教育，上层阶级的后代也不一定能一次成功。这也没关系，只要该家庭对其后代有信心，不断地为他们创造机会，这些创业者在第二次甚至第三次尝试的时候总能千出点名堂来，也就成了所谓的“白手起家的百万富翁”。</p>
<p>现在是时候对前面所说的进行总结并提出一个问题：上层阶级对于公众社会究竟承担了什么样的角色？他们既不是领导阶层，又不具备任何道德层面的导向性。他们将自己与社会公众生活隔离开来，国家政治舞台上也鲜见他们的影子。他们并非促进政治、学术或文化发展的动力，而这个阶级所自我标榜的生产力推动者形象也被证明是无稽之谈。他们甚至不愿再担负起将其家族企业经营下去的责任。上层阶级所感兴趣的就只有一件事情：获取利益，金钱是他们的唯一。富人只满足于富有。</p>
<h3 id="机会均等的童话"><a href="#机会均等的童话" class="headerlink" title="机会均等的童话"></a>机会均等的童话</h3><p>除了默认的态度，德国社会显然对上层阶级没有任何期待与要求。无论是否违背了业绩社会的基本准则，上层阶级从不需要对其财富的合理性做出解释。对于在其他社会阶层辛勤工作的人来说，创造业绩所换来的相应回报为其在社会上升通道中向财富阶层靠拢提供了可能性。社会中财富拥有者的更替非但无须带有革命性质，而且应该是一个业绩社会的常态。社会流动性和机会均等性作为重要的特征，可以用来衡量每个业绩社会。</p>
<p>汉堡市阿尔托纳区综合医院的妇幼中心产房内，成排的新生儿们还带着母体的温度。这时候的他们似乎全都一样，没有身份差别，没有高低上下之分。没人能够知道他们其中谁将成为法官和企业主，而谁又将是小职员、部门经理或是失业者。人生在最初的时刻似乎对每个人都是公平的，然而命运的骰子其实早已投下。距医院不到百米的7号高速公路将阿尔托纳的蓝领居住区与全德国人均收入最高的社区之一艾尔贝区分隔开来。当母亲带着新生儿出院回家时，每个孩子的命运就已清晰可见。在德国，阶级属性决定了每个人今后的发展机会。你父母是谁决定了你将是谁。</p>
<p>对所有的社会而言，每个人都享有同样的机会只能说是天方夜谭。但对于德国来说，从维利·勃兰特任总理的时代起，改善机会均等的情况已经成为德国政界的目标。让来自不同社会阶层的孩子都能在人生中获得成功。克劳斯·冯·多纳尼作为维利·勃兰特执政时期的教育部长曾为此付出努力，但是他在回忆录中写道：在改善机会均等性的事业上，我们还远远没有达到目标。</p>
<p>但为何格哈德·施罗德作为一个清洁女工的儿子能官至德国总理？而他的副手约施卡·费舍尔在高中都没毕业的情况下成为了外交部长？不同于经济界，政界遵循的是另一套游戏规则。相对于出身背景，坚持不懈的精神才是获得成功的保证。谁若想在政坛出人头地就必须做好卧薪尝胆的准备，这也是投身政治对于财富阶层缺乏吸引力的原因之一。施罗德和费舍尔这代人经历了一个德国社会流动性的黄金时期，社会地位的升迁直到上世纪70年代仍相对容易实现。这代人的父辈在二战中大批阵亡，以至于年青一代能够提前取代其父辈在社会中的位置。更重要的是，这个时期高速增长的德国经济需要每个人的力量，甚至小学毕业生在有段时间内也能够进入企业管理层。米夏埃尔·哈特曼教授认为：当市场条件优越时，下层阶级也将从中受益，其中的一部分人能够完成向上的社会流动。但当市场形势低迷时，那些来自富裕家庭的人则在社会竞争中具有绝对的优势。充满机会的60和70年代对于所有社会阶层来说是一个历史上的特殊时期。这个时期虽然在婴儿潮到来之前就已经成为过去，但其影响力在德国社会却久久挥之不去。很多德国人依然对机会均等的童话深信不疑。</p>
<p>柏林科学中心的赖因哈德·波拉克受海因里希·波尔基金会的委托对机会均等性的现状进行了研究，他通过将德国社会流动性情况与其他国家对比得出结论：德国在该项对比中体现出了极小的社会流动性。换句话说，几乎没有哪个工业化国家像德国一样，对社会流动机会的分配如此不公平。财富研究专家沃尔夫冈·劳特巴赫将德国称为一个“凝固的社会”。社会学教授西格哈特·内克尔则相信：社会流动性的作用正在被家庭出身取代。人们正在经历一场社会的再封建化，财富阶层就是德国新的贵族。</p>
]]></content>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>算法整理</title>
    <url>/uncategorized/leetcode/</url>
    <content><![CDATA[<h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><h2 id="rust-中-dbg-超时"><a href="#rust-中-dbg-超时" class="headerlink" title="rust 中 dbg! 超时"></a><code>rust</code> 中 <code>dbg!</code> 超时</h2><p>在 <code>rust</code> 中使用 <code>dbg!</code> 的时候，在题目判定时，可能会因为 <code>dbg!</code> 超时，提交代码的时候要去掉 <code>dbg!</code></p>
<h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h1><h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><p>第 27、977 题就是经典的双指针题目。</p>
<ul>
<li>有序数组平方。</li>
</ul>
<h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><p>注意，使用滑动窗口的时候，只用一个 for 循环代表滑动窗口的结尾，否则又会陷入两个 for 的困境。</p>
<ul>
<li>长度最小的子数组</li>
</ul>
<h2 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h2><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs Java"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>    s[i] = s [i-<span class="hljs-number">1</span>] + a[i];<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="Java-多组输入示例"><a href="#Java-多组输入示例" class="headerlink" title="Java 多组输入示例"></a>Java 多组输入示例</h2><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.Scanner;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Main</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span> <span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-type">Scanner</span> <span class="hljs-variable">scanner</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Scanner</span>(System.in);<br>        <br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> scanner.nextInt();<br>        <span class="hljs-type">int</span>[] nums = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>];<br>        <span class="hljs-type">int</span>[] s = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>];<br>        <br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>            nums[i] = scanner.nextInt();<br>            s[i] = s[i - <span class="hljs-number">1</span>] + nums[i];<br>        &#125;<br>        <br>        <span class="hljs-keyword">while</span> (scanner.hasNextInt()) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">a</span> <span class="hljs-operator">=</span> scanner.nextInt();<br>            <span class="hljs-type">int</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> scanner.nextInt();<br>            System.out.println(s[b+<span class="hljs-number">1</span>] - s[a]);<br>        &#125;<br>        scanner.close();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="模拟矩阵"><a href="#模拟矩阵" class="headerlink" title="模拟矩阵"></a>模拟矩阵</h2><ol>
<li>走完一行或者一列对 x 和 y 进行处理，使得继续走下一行而不下标越界</li>
<li>走完一行或者一列对 x 和 y 进行处理，使得走到没有写数字的地方</li>
<li>走完一行或者一列对边界进行处理</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[][] generateMatrix(<span class="hljs-type">int</span> n) &#123;<br>        <span class="hljs-type">int</span> [][]result = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n][n];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, y = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">xMax</span> <span class="hljs-operator">=</span> n, yMax = n, xMin = <span class="hljs-number">0</span>, yMin = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (count &lt;= n * n) &#123;<br>            <span class="hljs-comment">// 向右</span><br>            <span class="hljs-keyword">while</span> (y &lt; yMax) &#123;<br>                result[x][y] = count++;<br>                y++;<br>            &#125;<br>            y--; <span class="hljs-comment">// 能够向下走</span><br>            x++; <span class="hljs-comment">// 走到没写过数字的地方</span><br>            xMin += <span class="hljs-number">1</span>; <span class="hljs-comment">// 向右一行补充完向上少走一行</span><br><br>            <span class="hljs-comment">// 向下</span><br>            <span class="hljs-keyword">while</span> (x &lt; xMax) &#123;<br>                result[x][y] = count++;<br>                x++;<br>            &#125;<br>            x--; <span class="hljs-comment">// 能够向左走</span><br>            y--; <span class="hljs-comment">// 走到没写过数字的地方</span><br>            yMax -= <span class="hljs-number">1</span>; <span class="hljs-comment">// 向右少走一行</span><br><br>            <span class="hljs-comment">// 向左</span><br>            <span class="hljs-keyword">while</span> (y &gt;= yMin) &#123;<br>                result[x][y] = count++;<br>                y--;<br>            &#125;<br>            y++; <span class="hljs-comment">// 能够向右走</span><br>            x--; <span class="hljs-comment">// 走到没写过数字的地方</span><br>            xMax -= <span class="hljs-number">1</span>; <span class="hljs-comment">// 向下少走一行</span><br><br>            <span class="hljs-comment">// 向上</span><br>            <span class="hljs-keyword">while</span> (x &gt;= xMin) &#123;<br>                result[x][y] = count++;<br>                x--;<br>            &#125;<br>            x++; <span class="hljs-comment">// 能够向右走</span><br>            y++; <span class="hljs-comment">// 走到没写过数字的地方</span><br>            yMin += <span class="hljs-number">1</span>; <span class="hljs-comment">// 向左少走一行</span><br><br>        &#125;<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br>    <br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><h2 id="矩阵置零"><a href="#矩阵置零" class="headerlink" title="矩阵置零"></a>矩阵置零</h2><p>给定一个 <strong><code>m x n</code></strong> 的矩阵，如果一个元素为 <strong>0</strong> ，则将其所在行和列的所有元素都设为 <strong>0</strong> 。请使用 <strong><a href="http://baike.baidu.com/item/原地算法">原地</a></strong> 算法。</p>
<p>难点在于原地算法，否则很简单，模拟就好，模拟的时候注意不要跳过本来为 0 的元素。</p>
<h1 id="双指针-1"><a href="#双指针-1" class="headerlink" title="双指针"></a>双指针</h1><h2 id="移动零"><a href="#移动零" class="headerlink" title="移动零"></a>移动零</h2><p>10^4 O(n)</p>
<p>给定一个数组 <code>nums</code>，编写一个函数将所有 <code>0</code> 移动到数组的末尾，同时保持非零元素的相对顺序。</p>
<p><strong>请注意</strong> ，必须在不复制数组的情况下原地对数组进行操作。</p>
<p><strong>key：</strong>保证 right 在 left 左边。</p>
<h2 id="盛最多水的容器"><a href="#盛最多水的容器" class="headerlink" title="盛最多水的容器"></a>盛最多水的容器</h2><p>10^5 O(n)</p>
<p>给定一个长度为 <code>n</code> 的整数数组 <code>height</code> 。有 <code>n</code> 条垂线，第 <code>i</code> 条线的两个端点是 <code>(i, 0)</code> 和 <code>(i, height[i])</code> 。</p>
<p>找出其中的两条线，使得它们与 <code>x</code> 轴共同构成的容器可以容纳最多的水。</p>
<p>返回容器可以储存的最大水量。</p>
<p><strong>说明：</strong>你不能倾斜容器。</p>
<p><strong>思考：</strong>有两个变量决定盛水量：1. 左右的距离。 2. 较低的柱子高度。</p>
<ol>
<li>左右的距离最左到最右最大，然后慢慢缩小。</li>
<li>如果移动较高的柱子，那么盛水量不会变大，但是如果移动较低的柱子，那么盛水量有可能会变大。</li>
</ol>
<h2 id="接雨水"><a href="#接雨水" class="headerlink" title="接雨水"></a>接雨水</h2><p>2 * 10^4</p>
<p><img  src="rainwatertrap.png"  ><span class="image-caption">img</span></p>
<figure class="highlight dns"><table><tr><td class="code"><pre><code class="hljs dns">输入：height = [<span class="hljs-number">0,1,0,2</span>,<span class="hljs-number">1,0,1,3</span>,<span class="hljs-number">2,1,2,1</span>]<br>输出：<span class="hljs-number">6</span><br>解释：上面是由数组 [<span class="hljs-number">0,1,0,2</span>,<span class="hljs-number">1,0,1,3</span>,<span class="hljs-number">2,1,2,1</span>] 表示的高度图，在这种情况下，可以接 <span class="hljs-number">6</span> 个单位的雨水（蓝色部分表示雨水）。 <br></code></pre></td></tr></table></figure>
<p><strong>key：</strong>某一处的雨水 = 左右最高柱子的最小值 - 当前处的高度</p>
<p>剩下的点就在求左右最高柱子处进行优化。</p>
<h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p>将左右最高柱子的高度分别记为 leftMax，rightMax，并 O(n) 计算出这个数组的。</p>
<p>需要注意的点是 <strong>初始值</strong> 和 <strong>边界</strong>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">trap</span><span class="hljs-params">(<span class="hljs-type">int</span>[] height)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> height.length;<br>        <span class="hljs-type">int</span>[] leftMax = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n];<br>        <span class="hljs-type">int</span>[] rightMax = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n];<br>        leftMax[<span class="hljs-number">0</span>] = height[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            leftMax[i] = Math.max(leftMax[i - <span class="hljs-number">1</span>], height[i]);<br>        &#125;<br>        rightMax[n - <span class="hljs-number">1</span>] = height[n - <span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> n - <span class="hljs-number">2</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;<br>            rightMax[i] = Math.max(rightMax[i + <span class="hljs-number">1</span>], height[i]);<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">total</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            total += Math.min(leftMax[i], rightMax[i]) - height[i];<br>        &#125;<br>        <span class="hljs-keyword">return</span> total;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>时间复杂度：O(n)，其中 n 是数组 height 的长度。计算数组 leftMax 和 rightMax 的元素值各需要遍历数组 height 一次，计算能接的雨水总量还需要遍历一次。</p>
<p>空间复杂度：O(n)，其中 n 是数组 height 的长度。需要创建两个长度为 n 的数组 leftMax 和 rightMax。</p>
<h3 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a>单调栈</h3><h3 id="双指针-2"><a href="#双指针-2" class="headerlink" title="双指针"></a>双指针</h3><p>动态规划计算 leftMax 和 rightMax 的时候需要遍历一次数组，能不能直接得到 leftMax 和 rightMax 而不遍历呢？这样就可以将得到 max 的复杂度降低为 O(1) 了。</p>
<p><strong>与盛最多水的容器相同的思路，可以从两边的雨水向中间进行计算</strong>，这样可以 O(1) 得到</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">trap</span><span class="hljs-params">(<span class="hljs-type">int</span>[] height)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> height.length;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">ans</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, right = n - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">maxLeft</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, maxRight = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (left &lt; right) &#123;<br>            maxLeft = Math.max(maxLeft, height[left]);<br>            maxRight = Math.max(maxRight, height[right]);<br>            <span class="hljs-keyword">if</span> (height[left] &gt; height[right]) &#123;<br>                ans += maxRight - height[right];<br>                right--;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                ans += maxLeft - height[left];<br>                left++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="滑动窗口-1"><a href="#滑动窗口-1" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><h3 id="滑动窗口模板"><a href="#滑动窗口模板" class="headerlink" title="滑动窗口模板"></a>滑动窗口模板</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 外层循环扩展右边界，内层循环扩展左边界</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">l</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, r = <span class="hljs-number">0</span> ; r &lt; n ; r++) &#123;<br>	<span class="hljs-comment">// 当前考虑的元素</span><br>	<span class="hljs-keyword">while</span> (l &lt;= r &amp;&amp; check()) &#123; <span class="hljs-comment">// 区间[left,right]不符合题意</span><br>        <span class="hljs-comment">// 扩展左边界</span><br>    &#125;<br>    <span class="hljs-comment">// 区间[left,right]符合题意，统计相关信息</span><br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="无重复字符的最长子串"><a href="#无重复字符的最长子串" class="headerlink" title="无重复字符的最长子串"></a>无重复字符的最长子串</h2><p>5 * 10^4 级别</p>
<p>给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的最长子串的长度。</p>
<ol>
<li>判断重复字符：Set</li>
<li>最长字串：滑动窗口</li>
</ol>
<p>这道题官方解答为枚举所有起始位置，之后向右延申至不含重复字符的最长子串长度，如果包含重复字符，那么左指针持续移动到不含重复字符为止。</p>
<p>关键在于有重复字符的时候，是左指针持续地向右移动，而不是重新开始枚举，因为这个操作，使得时间复杂度为 O(n)，那么为什么这样不会漏掉答案呢？也就是说为什么这样一定会取到最优答案呢？</p>
<p>因为当右边要出现重复字母的的候，这个时候左指针到右指针的子串一定是对应了右指针不移动情况下的最优子串。</p>
<p>所以可以枚举右指针，并让左指针不断向右。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">lengthOfLongestSubstring</span><span class="hljs-params">(String s)</span> &#123;<br>        Set&lt;Character&gt; set = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> s.length(), l = <span class="hljs-number">0</span>, ans = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; r &lt; n; r++) &#123;<br>            <span class="hljs-keyword">while</span> (set.contains(s.charAt(r))) &#123;<br>                set.remove(s.charAt(l));<br>                l++;<br>            &#125;<br>            set.add(s.charAt(r));<br>            ans = Math.max(ans, r - l + <span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="找到字符串中所有字母异位词"><a href="#找到字符串中所有字母异位词" class="headerlink" title="找到字符串中所有字母异位词"></a>找到字符串中所有字母异位词</h2><p>给定两个字符串 <code>s</code> 和 <code>p</code>，找到 <code>s</code> 中所有 <code>p</code> 的 异位词的子串，返回这些子串的起始索引。不考虑答案输出的顺序。</p>
<p>3 * 10^4 级别</p>
<p>与上一题相同，需要做以下操作：</p>
<ol>
<li>判断异位词。</li>
<li>异位词子串。</li>
</ol>
<p>确定异位词需要 O(n)，n 是字符串长度。</p>
<p><strong>key：</strong>在这道题中，异位词和原词肯定是长度相同的，所以直接用固定长度的滑动窗口滑过去，这样时间复杂度为 O(n * m)。但是有更好的做法，就是当向右滑动的时候，删掉的是左面的字母，如果右边能够补齐，那么就说明是异位词，这样就可以 O(1) 判断异位词，再加上滑动的耗时，总计 O(m)。</p>
<p>Arrays.equals 可以判断两个数组相等。</p>
<h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p>链表对于有插入、交换或者删除的操作的时候，一般加一个<strong>虚拟头节点</strong>更好处理。</p>
<p>203.移除链表元素</p>
<p>707.设计链表</p>
<p>206.翻转链表</p>
<p>206.翻转链表</p>
<p>19.删除链表的倒数第 N 个结点</p>
<h2 id="K-个一组翻转链表"><a href="#K-个一组翻转链表" class="headerlink" title="K 个一组翻转链表"></a>K 个一组翻转链表</h2><p>给你链表的头节点 <code>head</code> ，每 <code>k</code> 个节点一组进行翻转，请你返回修改后的链表。</p>
<p><code>k</code> 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 <code>k</code> 的整数倍，那么请将最后剩余的节点保持原有顺序。</p>
<p>你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。</p>
<p><strong>Key：</strong>关键在于写一个 reverse 函数逆转从 head 到 tail 的链表。其中 reverse 函数可以返回逆转后的最后一个节点。还有需要维护返回的节点。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">reverseKGroup</span><span class="hljs-params">(ListNode head, <span class="hljs-type">int</span> k)</span> &#123;<br>        <span class="hljs-keyword">if</span> (k == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> head;<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">first</span> <span class="hljs-operator">=</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>, head), cur = head, pre = dummy, ret = <span class="hljs-literal">null</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (cur != <span class="hljs-literal">null</span>) &#123;<br>            count++;<br>            <span class="hljs-keyword">if</span> (count == k) &#123;<br>                <span class="hljs-keyword">if</span> (first) &#123;<br>                    ret = cur;<br>                    first = <span class="hljs-literal">false</span>;<br>                &#125;<br>                pre = reverse(pre, head, cur);<br>                head = pre.next;<br>                cur = pre;<br>                count = <span class="hljs-number">0</span>;<br>            &#125;<br>            cur = cur.next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br><br>    <span class="hljs-comment">// 逆转从 head 到 tail 的链表，pre 是 head 的前一个结点</span><br>    <span class="hljs-comment">// 返回逆转后的最后一个节点，其实就是 head，这一组的最后一个节点是下一组的 pre</span><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">reverse</span><span class="hljs-params">(ListNode pre, ListNode head, ListNode tail)</span> &#123;<br>        <span class="hljs-comment">// pre -&gt; head -&gt; cur -&gt; tail</span><br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> head.next, retTail = head;<br>        head.next = tail.next;<br>        <span class="hljs-keyword">while</span> (cur != tail) &#123; <span class="hljs-comment">// tail 之前的节点全部头插法插到到 pre 之后</span><br>            <span class="hljs-type">ListNode</span> <span class="hljs-variable">next</span> <span class="hljs-operator">=</span> cur.next;<br>            pre.next = cur;<br>            cur.next = head;<br>            head = cur;<br>            cur = next;<br>        &#125;<br>        <span class="hljs-comment">// 把 tail 也插到头部</span><br>        pre.next = tail;<br>        tail.next = head;<br>        <span class="hljs-keyword">return</span> retTail;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="排序链表"><a href="#排序链表" class="headerlink" title="排序链表"></a>排序链表</h2><p>要点在于排序 + 链表操作</p>
<p>题目的进阶问题要求达到 O(nlogn) 的时间复杂度和 O(1) 的空间复杂度，时间复杂度是 O(nlogn) 的排序算法包括归并排序、堆排序和快速排序（快速排序的最差时间复杂度是 O(n^2)），其中最适合链表的排序算法是归并排序。</p>
<p>归并排序基于分治算法。最容易想到的实现方式是自顶向下的递归实现，考虑到递归调用的栈空间，自顶向下归并排序的空间复杂度是 O(logn)。如果要达到 O(1) 的空间复杂度，则需要使用自底向上的实现方式。=</p>
<p>递归写法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">sortList</span><span class="hljs-params">(ListNode head)</span> &#123;<br>        <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">null</span> || head.next == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> head;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> findMiddle(head);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">rightHead</span> <span class="hljs-operator">=</span> mid.next;<br>        mid.next = <span class="hljs-literal">null</span>; <span class="hljs-comment">// 断开链表</span><br><br>        <span class="hljs-comment">// 排序</span><br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> sortList(head);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">right</span> <span class="hljs-operator">=</span> sortList(rightHead);<br>        <br>        <span class="hljs-comment">// 合并有序链表</span><br>        <span class="hljs-keyword">return</span> mergeList(left, right);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">mergeList</span><span class="hljs-params">(ListNode l1, ListNode l2)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> dummy;<br>        <span class="hljs-keyword">while</span> (l1 != <span class="hljs-literal">null</span> &amp;&amp; l2 != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">if</span> (l1.val &lt; l2.val) &#123;<br>                cur.next = l1;<br>                l1 = l1.next;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                cur.next = l2;<br>                l2 = l2.next;<br>            &#125;<br>            cur = cur.next;<br>        &#125;<br>        <span class="hljs-comment">// 接上剩余链表，这里不需要用 while，因为肯定要么 l1 要么 l2 剩余，剩余部分本来就是接好的</span><br>        <span class="hljs-keyword">if</span> (l1 != <span class="hljs-literal">null</span>) &#123;<br>            cur.next = l1;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (l2 != <span class="hljs-literal">null</span>) &#123;<br>            cur.next = l2;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dummy.next;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">findMiddle</span><span class="hljs-params">(ListNode head)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">slow</span> <span class="hljs-operator">=</span> head;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">fast</span> <span class="hljs-operator">=</span> head.next; <span class="hljs-comment">// 重要！fast 从 head.next 开始，确保 slow 指向中点或者左中点</span><br>        <span class="hljs-keyword">while</span> (fast != <span class="hljs-literal">null</span> &amp;&amp; fast.next != <span class="hljs-literal">null</span>) &#123;<br>            slow = slow.next;<br>            fast = fast.next.next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> slow;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>迭代写法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-comment">// 1. 获取链表长度</span><br>    <span class="hljs-comment">// 2. 设置合并的长度（step）</span><br>    <span class="hljs-comment">// 3. 合并根据长度划分的所有链表</span><br>    <span class="hljs-comment">// 4. step *= 2</span><br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">sortList</span><span class="hljs-params">(ListNode head)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>, head);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">length</span> <span class="hljs-operator">=</span> listLength(head);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">step</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; step &lt; length; step *= <span class="hljs-number">2</span>) &#123;<br>            <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> dummy.next;<br>            <span class="hljs-type">ListNode</span> <span class="hljs-variable">newTail</span> <span class="hljs-operator">=</span> dummy;<br>            <span class="hljs-keyword">while</span> (cur != <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-comment">// 从 cur 开始，分割出两段长为 step 的链表，头节点分别为 head1 和 head2</span><br>                <span class="hljs-type">ListNode</span> <span class="hljs-variable">head1</span> <span class="hljs-operator">=</span> cur;<br>                <span class="hljs-type">ListNode</span> <span class="hljs-variable">head2</span> <span class="hljs-operator">=</span> splitList(head1, step);<br>                <span class="hljs-comment">// 下一轮的起点，也是为了分割开链表</span><br>                cur = splitList(head2, step); <br>                <span class="hljs-comment">// 合并两段长度为 step 的链表</span><br>                <span class="hljs-type">ListNode</span> <span class="hljs-variable">merged</span> <span class="hljs-operator">=</span> mergeList(head1, head2);<br>                <span class="hljs-comment">// 找到下一个要合并的链表的 head</span><br>                <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>                <span class="hljs-type">ListNode</span> <span class="hljs-variable">curr</span> <span class="hljs-operator">=</span> merged;<br>                <span class="hljs-keyword">while</span>(len &lt; step * <span class="hljs-number">2</span> &amp;&amp; curr.next != <span class="hljs-literal">null</span>) &#123;<br>                    len++;<br>                    curr = curr.next;<br>                &#125;<br>                <span class="hljs-comment">// 合并后的头节点插入到 newTail 后面</span><br>                newTail.next = merged;<br>                newTail = curr;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dummy.next;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">splitList</span><span class="hljs-params">(ListNode head, <span class="hljs-type">int</span> size)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> head;<br>        <span class="hljs-comment">// nextHead 的前一个节点，用于断开链表</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; size - <span class="hljs-number">1</span> &amp;&amp; cur != <span class="hljs-literal">null</span>; i++) &#123;<br>            cur = cur.next;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (cur == <span class="hljs-literal">null</span> || cur.next == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br><br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">nextHead</span> <span class="hljs-operator">=</span> cur.next;<br>        cur.next = <span class="hljs-literal">null</span>; <span class="hljs-comment">// 断开链表</span><br>        <span class="hljs-keyword">return</span> nextHead;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">listLength</span><span class="hljs-params">(ListNode head)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">length</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (head != <span class="hljs-literal">null</span>) &#123;<br>            head = head.next;<br>            length++;<br>        &#125;<br>        <span class="hljs-keyword">return</span> length;<br>    &#125;<br><br>    <span class="hljs-comment">// 返回合并链表的头节点</span><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">mergeList</span><span class="hljs-params">(ListNode l1, ListNode l2)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> dummy;<br>        <span class="hljs-keyword">while</span> (l1 != <span class="hljs-literal">null</span> &amp;&amp; l2 != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">if</span> (l1.val &lt; l2.val) &#123;<br>                cur.next = l1;<br>                l1 = l1.next;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                cur.next = l2;<br>                l2 = l2.next;<br>            &#125;<br>            cur = cur.next;<br>        &#125;<br>        <span class="hljs-comment">// 接上剩余链表，这里要用 while，因为肯定要么 l1 要么 l2 剩余，剩余部分本来就是接好的</span><br>        <span class="hljs-keyword">if</span> (l1 != <span class="hljs-literal">null</span>) &#123;<br>            cur.next = l1;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (l2 != <span class="hljs-literal">null</span>) &#123;<br>            cur.next = l2;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dummy.next;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="合并-K-个升序链表"><a href="#合并-K-个升序链表" class="headerlink" title="合并 K 个升序链表"></a>合并 K 个升序链表</h2><h3 id="朴素做法"><a href="#朴素做法" class="headerlink" title="朴素做法"></a>朴素做法</h3><p>用一个数组存储所有的 head，然后每次取出所有数组的最小值，然后插入到链表最后面。</p>
<p>每次取出最小值，复杂度为 O(k)，然后一共要取 k <em> n 次，n 是最长链表的长度，这样时间复杂度为 O(k^2 </em> n)，每次取出最小值的时候，有比较被浪费掉了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">mergeKLists</span><span class="hljs-params">(ListNode[] lists)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> dummy;<br>        ListNode[] head = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>[lists.length];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">allLength</span> <span class="hljs-operator">=</span> <span class="hljs-number">500</span> * <span class="hljs-number">10000</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; lists.length; i++) &#123;<br>            head[i] = lists[i];<br>        &#125;<br><br>        <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (i &lt; allLength) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">minVal</span> <span class="hljs-operator">=</span> <span class="hljs-number">0x3f3f3f3f</span>;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">minIndex</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; lists.length; j++) &#123;<br>                <span class="hljs-keyword">if</span> (head[j] != <span class="hljs-literal">null</span> &amp;&amp; minVal &gt; head[j].val) &#123;<br>                    minVal = head[j].val;<br>                    minIndex = j;<br>                &#125;<br>            &#125;<br>            <span class="hljs-comment">// 所有链表都为空</span><br>            <span class="hljs-keyword">if</span> (minIndex == -<span class="hljs-number">1</span>) <span class="hljs-keyword">break</span>;<br>            cur.next = head[minIndex];<br>            cur = cur.next;<br>            head[minIndex] = head[minIndex].next;<br>            i++;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dummy.next;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="二分做法"><a href="#二分做法" class="headerlink" title="二分做法"></a>二分做法</h3><p><img  src="./6f70a6649d2192cf32af68500915d84b476aa34ec899f98766c038fc9cc54662-image.png"  ><span class="image-caption">img</span></p>
<p>复杂度计算：</p>
<p><img  src="./image-20250202004335203.png"  ><span class="image-caption">image-20250202004335203</span></p>
<p>链表两两合并避免比较浪费，左闭右闭实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">mergeKLists</span><span class="hljs-params">(ListNode[] lists)</span> &#123;<br>        <span class="hljs-keyword">return</span> mergeLists(lists, <span class="hljs-number">0</span>, lists.length - <span class="hljs-number">1</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">mergeLists</span><span class="hljs-params">(ListNode[] lists, <span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span> &#123;<br>        <span class="hljs-keyword">if</span> (l == r) <span class="hljs-keyword">return</span> lists[l];<br>        <span class="hljs-keyword">if</span> (l &gt; r) <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> l + (r - l) / <span class="hljs-number">2</span>;<br>        <span class="hljs-comment">// 左闭右闭</span><br>        <span class="hljs-keyword">return</span> mergeTwoLists(mergeLists(lists, l, mid), mergeLists(lists, mid + <span class="hljs-number">1</span>, r));<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">mergeTwoLists</span><span class="hljs-params">(ListNode a, ListNode b)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> dummy;<br>        <span class="hljs-keyword">while</span> (a != <span class="hljs-literal">null</span> &amp;&amp; b != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">if</span> (a.val &lt;= b.val) &#123;<br>                cur.next = a;<br>                a = a.next;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                cur.next = b;<br>                b = b.next;<br>            &#125;<br>            cur = cur.next;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (a != <span class="hljs-literal">null</span>) cur.next = a;<br>        <span class="hljs-keyword">if</span> (b != <span class="hljs-literal">null</span>) cur.next = b;<br><br>        <span class="hljs-keyword">return</span> dummy.next;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>左闭右开实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">mergeKLists</span><span class="hljs-params">(ListNode[] lists)</span> &#123;<br>        <span class="hljs-keyword">return</span> mergeLists(lists, <span class="hljs-number">0</span>, lists.length);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">mergeLists</span><span class="hljs-params">(ListNode[] lists, <span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span> &#123;<br>        <span class="hljs-keyword">if</span> (l &gt;= r) <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-keyword">if</span> (r - l == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> lists[l];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> l + (r - l) / <span class="hljs-number">2</span>;<br>        <span class="hljs-comment">// 左闭右开</span><br>        <span class="hljs-keyword">return</span> mergeTwoLists(mergeLists(lists, l, mid), mergeLists(lists, mid, r));<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> ListNode <span class="hljs-title function_">mergeTwoLists</span><span class="hljs-params">(ListNode a, ListNode b)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">dummy</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> dummy;<br>        <span class="hljs-keyword">while</span> (a != <span class="hljs-literal">null</span> &amp;&amp; b != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">if</span> (a.val &lt;= b.val) &#123;<br>                cur.next = a;<br>                a = a.next;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                cur.next = b;<br>                b = b.next;<br>            &#125;<br>            cur = cur.next;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (a != <span class="hljs-literal">null</span>) cur.next = a;<br>        <span class="hljs-keyword">if</span> (b != <span class="hljs-literal">null</span>) cur.next = b;<br><br>        <span class="hljs-keyword">return</span> dummy.next;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><h2 id="二叉树的中序遍历"><a href="#二叉树的中序遍历" class="headerlink" title="二叉树的中序遍历"></a>二叉树的中序遍历</h2><p>递归做法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for a binary tree node.</span><br><span class="hljs-comment"> * public class TreeNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     TreeNode left;</span><br><span class="hljs-comment"> *     TreeNode right;</span><br><span class="hljs-comment"> *     TreeNode() &#123;&#125;</span><br><span class="hljs-comment"> *     TreeNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     TreeNode(int val, TreeNode left, TreeNode right) &#123;</span><br><span class="hljs-comment"> *         this.val = val;</span><br><span class="hljs-comment"> *         this.left = left;</span><br><span class="hljs-comment"> *         this.right = right;</span><br><span class="hljs-comment"> *     &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> List&lt;Integer&gt; <span class="hljs-title function_">inorderTraversal</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root);<br>        <span class="hljs-keyword">return</span> list;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        helper(root.left);<br>        list.add(root.val);<br>        helper(root.right);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>非递归做法，用一个栈模拟递归栈。</p>
<p>前序遍历是中左右，如果还有左子树就一直向下找。完了之后再返回从最底层逐步向上向右找。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> List&lt;Integer&gt; <span class="hljs-title function_">inorderTraversal</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        Deque&lt;TreeNode&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span> || !stack.isEmpty()) &#123;<br>            <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span>) &#123;<br>                list.add(root.val);<br>                stack.push(root);<br>                root = root.left;<br>            &#125;<br>            root = stack.pop();<br>            root = root.right;<br>        &#125;<br>        <span class="hljs-keyword">return</span> list;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>中序是左中右，如果还有左子树就一直向下找，直到左边最底部，然后处理节点：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> List&lt;Integer&gt; <span class="hljs-title function_">inorderTraversal</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        Deque&lt;TreeNode&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span> || !stack.isEmpty()) &#123;<br>            <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span>) &#123;<br>                stack.push(root);<br>                root = root.left;<br>            &#125;<br>            root = stack.pop();<br>            list.add(root.val);<br>            root = root.right;<br>        &#125;<br>        <span class="hljs-keyword">return</span> list;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>前序是先中间，再左边然后右边，而这里是先中间，再后边然后左边。那我们完全可以改造一下前序遍历，得到序列new_seq之后再reverse一下就是想要的结果了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> List&lt;Integer&gt; <span class="hljs-title function_">inorderTraversal</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        Deque&lt;TreeNode&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span> || !stack.isEmpty()) &#123;<br>            <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span>) &#123;<br>                list.add(root.val);<br>                stack.push(root);<br>                root = root.right;<br>            &#125;<br>            root = stack.pop();<br>            root = root.left;<br>        &#125;<br>        Collections.reverse(list);<br>        <span class="hljs-keyword">return</span> list;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="二叉树的最大深度"><a href="#二叉树的最大深度" class="headerlink" title="二叉树的最大深度"></a>二叉树的最大深度</h2><p>要点在于如何记录深度，递归的时候可以通过传参解决：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">maxDepth</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">maxDepth</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root, <span class="hljs-number">0</span>);<br>        <span class="hljs-keyword">return</span> maxDepth;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root, <span class="hljs-type">int</span> depth)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) &#123;<br>            maxDepth = Math.max(maxDepth, depth);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        helper(root.left, depth + <span class="hljs-number">1</span>);<br>        helper(root.right, depth + <span class="hljs-number">1</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">maxDepth</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">leftHeight</span> <span class="hljs-operator">=</span> maxDepth(root.left);<br>            <span class="hljs-type">int</span> <span class="hljs-variable">rightHeight</span> <span class="hljs-operator">=</span> maxDepth(root.right);<br>            <span class="hljs-keyword">return</span> Math.max(leftHeight, rightHeight) + <span class="hljs-number">1</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="反转二叉树"><a href="#反转二叉树" class="headerlink" title="反转二叉树"></a>反转二叉树</h2><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> TreeNode <span class="hljs-title function_">invertTree</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root);<br>        <span class="hljs-keyword">return</span> root;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> TreeNode <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-type">TreeNode</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> helper(root.right);<br>        <span class="hljs-type">TreeNode</span> <span class="hljs-variable">right</span> <span class="hljs-operator">=</span> helper(root.left);<br>        root.left = left;<br>        root.right = right;<br>        <span class="hljs-keyword">return</span> root;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="对称二叉树"><a href="#对称二叉树" class="headerlink" title="对称二叉树"></a>对称二叉树</h2><p>这里注意条件是 <code>left.val == right.val &amp;&amp; helper(left.left, right.right) &amp;&amp; helper(left.right, right.left)</code> ，因为对称是中心轴对称，而不是左右相等。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isSymmetric</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">return</span> helper(root.left, root.right);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode left, TreeNode right)</span> &#123;<br>        <span class="hljs-keyword">if</span> (left == <span class="hljs-literal">null</span> &amp;&amp; right == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (left == <span class="hljs-literal">null</span> || right == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> left.val == right.val<br>            &amp;&amp; helper(left.left, right.right)<br>            &amp;&amp; helper(left.right, right.left);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="二叉树的直径"><a href="#二叉树的直径" class="headerlink" title="二叉树的直径"></a>二叉树的直径</h2><p>二叉树的直径 = 最深左子树深度 + 最深右子树深度</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">ans</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">diameterOfBinaryTree</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root);<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">leftMax</span> <span class="hljs-operator">=</span> helper(root.left);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">rightMax</span> <span class="hljs-operator">=</span> helper(root.right);<br>        ans = Math.max(ans, leftMax + rightMax);<br>        <span class="hljs-keyword">return</span> Math.max(leftMax, rightMax) + <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="二叉树层序遍历"><a href="#二叉树层序遍历" class="headerlink" title="二叉树层序遍历"></a>二叉树层序遍历</h2><p>我的做法：先序遍历（root，左，右）的时候记住 depth 存到 map 中，然后最后把 map 中的数组组合起来：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    List&lt;List&lt;Integer&gt;&gt; ans = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>    Map&lt;Integer, List&lt;Integer&gt;&gt; map = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> List&lt;List&lt;Integer&gt;&gt; <span class="hljs-title function_">levelOrder</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">depth</span> <span class="hljs-operator">=</span> helper(root, <span class="hljs-number">0</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; depth; i++) &#123;<br>            ans.add(map.get(i));<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root, <span class="hljs-type">int</span> depth)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> depth;<br>        List&lt;Integer&gt; arr = map.getOrDefault(depth, <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;Integer&gt;());<br>        arr.add(root.val);<br>        map.put(depth, arr);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">leftMax</span> <span class="hljs-operator">=</span> helper(root.left, depth + <span class="hljs-number">1</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">rightMax</span> <span class="hljs-operator">=</span> helper(root.right, depth + <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">return</span> Math.max(leftMax, rightMax);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>bfs 做法：</p>
<ul>
<li>root 入队列</li>
<li>队列不为空的时候<ul>
<li>求当前队列长度 $s_i$</li>
<li>取 $s_i$ 个元素进行拓展，进入下一次迭代</li>
</ul>
</li>
</ul>
<p>它和普通广度优先搜索的区别在于，普通广度优先搜索每次只取一个元素拓展，而这里每次取 $s_i$ 个元素。在上述过程中的第 $i$ 次迭代得到了二叉树第 $i$ 层的 $s_i$ 个元素。（说白了就是每次迭代的时候把下一层级的所有元素都加到队列里面，这样每一次迭代整个队列元素的时候就是一个层级的所有元素）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> List&lt;List&lt;Integer&gt;&gt; <span class="hljs-title function_">levelOrder</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        List&lt;List&lt;Integer&gt;&gt; ans = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> ans;<br>        Queue&lt;TreeNode&gt; queue = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        queue.offer(root);<br>        <span class="hljs-keyword">while</span> (!queue.isEmpty()) &#123;<br>            List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>            <span class="hljs-type">int</span> <span class="hljs-variable">size</span> <span class="hljs-operator">=</span> queue.size();<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; size; i++) &#123;<br>                <span class="hljs-type">TreeNode</span> <span class="hljs-variable">front</span> <span class="hljs-operator">=</span> queue.poll();<br>                <span class="hljs-keyword">if</span> (front.left != <span class="hljs-literal">null</span>) queue.offer(front.left);<br>                <span class="hljs-keyword">if</span> (front.right != <span class="hljs-literal">null</span>) queue.offer(front.right);<br>                list.add(front.val);<br>            &#125;<br>            ans.add(list);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="将有序数组转换为二叉搜索树"><a href="#将有序数组转换为二叉搜索树" class="headerlink" title="将有序数组转换为二叉搜索树"></a>将有序数组转换为二叉搜索树</h2><p>递归建树：</p>
<ul>
<li><code>1 &lt;= nums.length &lt;= 10^4</code></li>
<li><code>-10^4 &lt;= nums[i] &lt;= 10^4</code></li>
<li><code>nums</code> 按 <strong>严格递增</strong> 顺序排列</li>
</ul>
<p><img  src="./image-20250205185730436.png"  ><span class="image-caption">image-20250205185730436</span></p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> TreeNode <span class="hljs-title function_">sortedArrayToBST</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-keyword">return</span> helper(nums, <span class="hljs-number">0</span>, nums.length);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> TreeNode <span class="hljs-title function_">helper</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span> &#123;<br>        <span class="hljs-keyword">if</span> (left &gt;= right) <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> left + (right - left) / <span class="hljs-number">2</span>;<br>        <span class="hljs-type">TreeNode</span> <span class="hljs-variable">root</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">TreeNode</span>(nums[mid]);<br>        root.left = helper(nums, left, mid);<br>        root.right = helper(nums, mid + <span class="hljs-number">1</span>, right);<br>        <span class="hljs-keyword">return</span> root;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="验证二叉搜索树"><a href="#验证二叉搜索树" class="headerlink" title="验证二叉搜索树"></a>验证二叉搜索树</h2><p>给你一个二叉树的根节点 <code>root</code> ，判断其是否是一个有效的二叉搜索树。</p>
<p><strong>有效</strong> 二叉搜索树定义如下：</p>
<ul>
<li>节点的左子树只包含 <strong>小于</strong> 当前节点的数。</li>
<li>节点的右子树只包含 <strong>大于</strong> 当前节点的数。</li>
<li>所有左子树和右子树自身必须也是二叉搜索树。</li>
</ul>
<p>这里有一个问题是需要判断所有的子节点都大于或者都小于根节点。</p>
<p><strong>二叉搜索树的中序遍历是递增的。</strong>所以可以中序遍历，之后每个元素都小于前一个元素，则是二叉搜索树。</p>
<p>递归写法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    List&lt;Integer&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isValidBST</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; list.size() - <span class="hljs-number">1</span>; i++) &#123;<br>            <span class="hljs-keyword">if</span> (list.get(i) &gt;= list.get(i + <span class="hljs-number">1</span>)) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span>;<br>        helper(root.left);<br>        list.add(root.val);<br>        helper(root.right);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>递归写法2：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-type">long</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> Long.MIN_VALUE;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isValidBST</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">return</span> helper(root);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">l</span> <span class="hljs-operator">=</span> helper(root.left);<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">tmp</span> <span class="hljs-operator">=</span> left &lt; root.val;<br>        left = root.val;<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> helper(root.right);<br>        <span class="hljs-keyword">return</span> l &amp;&amp; r &amp;&amp; tmp;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>递归写法3：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isValidBST</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">return</span> helper(root, Long.MIN_VALUE, Long.MAX_VALUE);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root, <span class="hljs-type">long</span> lower, <span class="hljs-type">long</span> upper)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">if</span> (root.val &lt;= lower || root.val &gt;= upper) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        <span class="hljs-keyword">return</span> helper(root.left, lower, root.val) &amp;&amp; helper(root.right, root.val, upper);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>迭代写法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isValidBST</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">return</span> helper(root);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        Deque&lt;TreeNode&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;TreeNode&gt;();<br>        <span class="hljs-type">long</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> Long.MIN_VALUE;<br>        <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span> || !stack.isEmpty()) &#123;<br>            <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span>) &#123;<br>                stack.push(root);<br>                root = root.left;<br>            &#125;<br>            root = stack.pop();<br>            <span class="hljs-keyword">if</span> (left &gt;= root.val) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            left = root.val;<br>            root = root.right;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="二叉搜索树中第-K-小的元素"><a href="#二叉搜索树中第-K-小的元素" class="headerlink" title="二叉搜索树中第 K 小的元素"></a>二叉搜索树中第 K 小的元素</h2><p>和验证二叉搜索树一样，在最外层存储一下状态。<br><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, target; <span class="hljs-comment">// 存储状态</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">kthSmallest</span><span class="hljs-params">(TreeNode root, <span class="hljs-type">int</span> k)</span> &#123;<br>        target = k;<br>        <span class="hljs-keyword">return</span> helper(root);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>; <br>        <span class="hljs-type">int</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> helper(root.left);<br>        <span class="hljs-keyword">if</span> (left != -<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> left;<br>        count++;<br>        <span class="hljs-keyword">if</span> (target == count) &#123;<br>            <span class="hljs-keyword">return</span> root.val;<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">right</span> <span class="hljs-operator">=</span> helper(root.right);<br>        <span class="hljs-keyword">if</span> (right != -<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> right;<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p>
<h2 id="二叉树的右视图"><a href="#二叉树的右视图" class="headerlink" title="二叉树的右视图"></a>二叉树的右视图</h2><p>给定一个二叉树的 <strong>根节点</strong> <code>root</code>，想象自己站在它的右侧，按照从顶部到底部的顺序，返回从右侧所能看到的节点值。</p>
<p>层序遍历中最右面的那个元素就是答案，放进去就好了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> List&lt;Integer&gt; <span class="hljs-title function_">rightSideView</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        List&lt;Integer&gt; ans = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span> ans;<br>        Deque&lt;TreeNode&gt; queue = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        queue.offer(root);<br>        <span class="hljs-keyword">while</span> (!queue.isEmpty()) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">size</span> <span class="hljs-operator">=</span> queue.size();<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; size; i++) &#123;<br>                <span class="hljs-type">TreeNode</span> <span class="hljs-variable">node</span> <span class="hljs-operator">=</span> queue.poll();<br>                <span class="hljs-keyword">if</span> (node.left != <span class="hljs-literal">null</span>) queue.offer(node.left);<br>                <span class="hljs-keyword">if</span> (node.right != <span class="hljs-literal">null</span>) queue.offer(node.right);<br>                <span class="hljs-keyword">if</span> (i == size - <span class="hljs-number">1</span>) &#123;<br>                    ans.add(node.val);<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="二叉树展开为链表"><a href="#二叉树展开为链表" class="headerlink" title="二叉树展开为链表"></a>二叉树展开为链表</h2><p>给你二叉树的根结点 <code>root</code> ，请你将它展开为一个单链表：</p>
<ul>
<li>展开后的单链表应该同样使用 <code>TreeNode</code> ，其中 <code>right</code> 子指针指向链表中下一个结点，而左子指针始终为 <code>null</code> 。</li>
<li>展开后的单链表应该与二叉树 <a href="https://baike.baidu.com/item/先序遍历/6442839?fr=aladdin"><strong>先序遍历</strong></a> 顺序相同。</li>
</ul>
<h3 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h3><p>先序遍历二叉树，然后记录 last，然后修改 last 的 left 和 right，但是这样会栈溢出。</p>
<p>原因是递归遍历 root.left 的时候，root.right 被改成了 root.left 导致死循环，保存一下状态就好了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">private</span> TreeNode last;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">flatten</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        last = <span class="hljs-keyword">new</span> <span class="hljs-title class_">TreeNode</span>(<span class="hljs-number">0</span>, <span class="hljs-literal">null</span>, root);<br>        helper(root);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span>;<br>        <span class="hljs-type">TreeNode</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> root.left;<br>        <span class="hljs-type">TreeNode</span> <span class="hljs-variable">right</span> <span class="hljs-operator">=</span> root.right;<br>        last.left = <span class="hljs-literal">null</span>;<br>        last.right = root;<br>        last = root;<br>        helper(left);<br>        helper(right);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="迭代1"><a href="#迭代1" class="headerlink" title="迭代1"></a>迭代1</h3><p>迭代写法，这里注意是第三种先序遍历的方法（递归，迭代1，迭代2），注意先入栈右边再入左边，保证左边先处理：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">flatten</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">null</span>) <span class="hljs-keyword">return</span>;<br>        <span class="hljs-type">TreeNode</span> <span class="hljs-variable">last</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">TreeNode</span>(<span class="hljs-number">0</span>, <span class="hljs-literal">null</span>, root);<br>        Deque&lt;TreeNode&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        stack.push(root);<br>        <span class="hljs-keyword">while</span> (!stack.isEmpty()) &#123;<br>            <span class="hljs-type">TreeNode</span> <span class="hljs-variable">top</span> <span class="hljs-operator">=</span> stack.poll();<br>            last.left = <span class="hljs-literal">null</span>;<br>            last.right = top;<br>            last = top;<br>            <span class="hljs-comment">// 右边先入栈，保证左边先处理</span><br>            <span class="hljs-keyword">if</span> (top.right != <span class="hljs-literal">null</span>) stack.push(top.right);<br>            <span class="hljs-keyword">if</span> (top.left != <span class="hljs-literal">null</span>) stack.push(top.left);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="迭代2"><a href="#迭代2" class="headerlink" title="迭代2"></a>迭代2</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">flatten</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        helper(root);<br>    &#125;<br><br>    <span class="hljs-comment">// 先序遍历树的时候顺序是中左右</span><br>    <span class="hljs-comment">// 如果一个节点的左子节点为空，则为 中、右 ，中的右边就是下一个节点</span><br>    <span class="hljs-comment">// 如果一个节点的左子节点不为空，则为 中、左子节点的最右节点、右</span><br>    <span class="hljs-comment">// 也就是说一个节点的左子节点不为空时，中的右边应该是左子节点的最右节点，然后再跟着右节点</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">helper</span><span class="hljs-params">(TreeNode root)</span> &#123;<br>        <span class="hljs-keyword">while</span> (root != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">if</span> (root.left != <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-type">TreeNode</span> <span class="hljs-variable">next</span> <span class="hljs-operator">=</span> root.left;<br>                <span class="hljs-type">TreeNode</span> <span class="hljs-variable">pre</span> <span class="hljs-operator">=</span> next;<br>                <span class="hljs-comment">// 找左子节点的最右节点</span><br>                <span class="hljs-keyword">while</span> (pre.right != <span class="hljs-literal">null</span>) &#123;<br>                    pre = pre.right;<br>                &#125;<br>                <span class="hljs-comment">// 左子节点的最右节点的下一个为右节点</span><br>                pre.right = root.right;<br>                root.left = <span class="hljs-literal">null</span>;<br>                root.right = next;<br>            &#125;<br>            root = root.right;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="子串"><a href="#子串" class="headerlink" title="子串"></a>子串</h1><h2 id="和为-K-的子数组"><a href="#和为-K-的子数组" class="headerlink" title="和为 K 的子数组"></a>和为 K 的子数组</h2><p>2 * 10^4 O(n^2) 或者 O(n)</p>
<h3 id="前缀和-1"><a href="#前缀和-1" class="headerlink" title="前缀和"></a>前缀和</h3><figure class="highlight excel"><table><tr><td class="code"><pre><code class="hljs excel">class Solution &#123;<br>    public <span class="hljs-built_in">int</span> subarraySum(<span class="hljs-built_in">int</span>[] nums, <span class="hljs-built_in">int</span> k) &#123;<br>        <span class="hljs-built_in">int</span> <span class="hljs-built_in">left</span> = <span class="hljs-number">0</span>, <span class="hljs-built_in">n</span> = nums.length, <span class="hljs-built_in">right</span> = <span class="hljs-built_in">n</span> - <span class="hljs-number">1</span>, ans = <span class="hljs-number">0</span>;;<br>        <span class="hljs-built_in">int</span>[] <span class="hljs-built_in">sum</span> = new <span class="hljs-built_in">int</span>[<span class="hljs-built_in">n</span>];<br>        <span class="hljs-built_in">sum</span>[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        for (<span class="hljs-built_in">int</span> i = <span class="hljs-number">1</span>; i &lt; <span class="hljs-built_in">n</span>; i++) &#123;<br>            <span class="hljs-built_in">sum</span>[i] = <span class="hljs-built_in">sum</span>[i - <span class="hljs-number">1</span>] + nums[i];<br>        &#125;<br>        for (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">n</span>; i++) &#123;<br>            for (<span class="hljs-built_in">int</span> j = i + <span class="hljs-number">1</span>; j &lt; <span class="hljs-built_in">n</span>; j++) &#123;<br>                <span class="hljs-built_in">if</span> (<span class="hljs-built_in">sum</span>[j] - <span class="hljs-built_in">sum</span>[i] == k) &#123; // 这种写法无法计算前 <span class="hljs-built_in">n</span> 个的和<br>                    ans++;<br>                &#125;<br>            &#125;<br>            <br>        &#125;<br>        for (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">n</span>; i++) &#123; // 补上<br>            <span class="hljs-built_in">if</span> (<span class="hljs-built_in">sum</span>[i] == k) &#123;<br>                ans++;<br>            &#125;<br>        &#125;<br>        return ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="优化前缀和中的-O-n-2"><a href="#优化前缀和中的-O-n-2" class="headerlink" title="优化前缀和中的 O(n^2)"></a>优化前缀和中的 O(n^2)</h2><p>用 “两数之和” 的思路来优化掉枚举所有前缀和的过程，用 HashMap 直接找到想要的前缀和。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">subarraySum</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> k)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, n = nums.length, right = n - <span class="hljs-number">1</span>, ans = <span class="hljs-number">0</span>;;<br>        <span class="hljs-type">int</span>[] sum = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n];<br>        sum[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        Map&lt;Integer, Integer&gt; map = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            sum[i] = sum[i - <span class="hljs-number">1</span>] + nums[i];<br>        &#125;<br>        <span class="hljs-comment">// 方法一：暴力前缀和 </span><br><br>        <span class="hljs-comment">// for (int i = 0; i &lt; n; i++) &#123;</span><br>        <span class="hljs-comment">//     for (int j = i + 1; j &lt; n; j++) &#123;</span><br>        <span class="hljs-comment">//         if (sum[j] - sum[i] == k) &#123; // 这种写法无法计算前 n 个的和</span><br>        <span class="hljs-comment">//             ans++;</span><br>        <span class="hljs-comment">//         &#125;</span><br>        <span class="hljs-comment">//     &#125;</span><br>        <span class="hljs-comment">// &#125;</span><br><br>        <span class="hljs-comment">// 方法一的实质是求两数之差为固定值的数有多少</span><br>        <span class="hljs-comment">// sum[j] - sum[i] = k</span><br>        <span class="hljs-comment">// 用 &quot;两数之和&quot; 的方法用哈希表进行优化 a + b = target -&gt; a = target - b</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">num</span> <span class="hljs-operator">=</span> k + sum[i];<br>            <span class="hljs-keyword">if</span> (map.containsKey(sum[i])) &#123; <span class="hljs-comment">// 如果需要的正好有</span><br>                ans += map.get(sum[i]);<br>            &#125;<br>            map.put(num, map.getOrDefault(num, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span>); <span class="hljs-comment">// 需要 k + sum[i]</span><br>        &#125;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123; <span class="hljs-comment">// 补上</span><br>            <span class="hljs-keyword">if</span> (sum[i] == k) &#123;<br>                ans++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="滑动窗口最大值"><a href="#滑动窗口最大值" class="headerlink" title="滑动窗口最大值"></a>滑动窗口最大值</h2><p>10^5 O(n) 可以做</p>
<p>给你一个整数数组 <code>nums</code>，有一个大小为 <code>k</code> 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 <code>k</code> 个数字。滑动窗口每次只向右移动一位。</p>
<p>返回 <em>滑动窗口中的最大值</em> 。</p>
<p>像前缀和一样，维护区间的最大值呢？</p>
<h3 id="ST-表"><a href="#ST-表" class="headerlink" title="ST 表"></a>ST 表</h3><p>复杂度为 O(nlogn)：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[] maxSlidingWindow(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> k) &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length, l = <span class="hljs-number">0</span>, logN = (<span class="hljs-type">int</span>)(Math.log(n) / Math.log(<span class="hljs-number">2</span>)) + <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span>[] result = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n - k + <span class="hljs-number">1</span>];<br>        <span class="hljs-type">int</span> f[][] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>][logN];<br>        <span class="hljs-type">int</span>[] logn = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">5</span>];<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>            f[i][<span class="hljs-number">0</span>] = nums[i - <span class="hljs-number">1</span>];<br>        &#125;<br><br>        <span class="hljs-comment">// pre</span><br>        logn[<span class="hljs-number">1</span>] = <span class="hljs-number">0</span>;<br>        logn[<span class="hljs-number">2</span>] = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">3</span>; i &lt; n; i++) &#123;<br>            logn[i] = logn[i / <span class="hljs-number">2</span>] + <span class="hljs-number">1</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt;= logN; j++)<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i + (<span class="hljs-number">1</span> &lt;&lt; j) - <span class="hljs-number">1</span> &lt;= n; i++)<br>                f[i][j] = Math.max(f[i][j - <span class="hljs-number">1</span>], f[i + (<span class="hljs-number">1</span> &lt;&lt; (j - <span class="hljs-number">1</span>))][j - <span class="hljs-number">1</span>]);  <span class="hljs-comment">// ST表具体实现</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n - k + <span class="hljs-number">1</span>; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> i, y = Math.min(n, i + k - <span class="hljs-number">1</span>);<br>            <span class="hljs-type">int</span> <span class="hljs-variable">s</span> <span class="hljs-operator">=</span> logn[y - x + <span class="hljs-number">1</span>];<br>            result[i-<span class="hljs-number">1</span>] = Math.max(f[x][s], f[y - (<span class="hljs-number">1</span> &lt;&lt; s) + <span class="hljs-number">1</span>][s]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="优先队列"><a href="#优先队列" class="headerlink" title="优先队列"></a>优先队列</h3><p>O(nlogn)</p>
<p>这里的思路是用一个堆来维护最大值，同时在堆中记录下最大值的下标，当左指针移动时，要删掉那些失效的最大值。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[] maxSlidingWindow(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> k) &#123;<br>        PriorityQueue&lt;Map.Entry&lt;Integer, Integer&gt;&gt; pq = <span class="hljs-keyword">new</span> <span class="hljs-title class_">PriorityQueue</span>&lt;&gt;((a, b) -&gt; b.getKey() - a.getKey());<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length, l = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> ret[] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n - k + <span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; r &lt; n; r++) &#123;<br>            pq.offer(<span class="hljs-keyword">new</span> <span class="hljs-title class_">java</span>.util.AbstractMap.SimpleEntry&lt;&gt;(nums[r], r));<br>            <span class="hljs-keyword">if</span> (r - l + <span class="hljs-number">1</span> == k) &#123;<br>                <span class="hljs-keyword">while</span> (pq.peek().getValue() &lt; l) pq.poll();<br>                ret[r - k + <span class="hljs-number">1</span>] = pq.peek().getKey();<br>                l++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="单调队列"><a href="#单调队列" class="headerlink" title="单调队列"></a>单调队列</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[] maxSlidingWindow(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> k) &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length, l = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span>[] ans = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n - k + <span class="hljs-number">1</span>];<br>        Deque&lt;Integer&gt; deque = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;Integer&gt;(); <span class="hljs-comment">// 递增存储下标</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; r &lt; n; r++) &#123;<br>            <span class="hljs-keyword">while</span> (!deque.isEmpty() &amp;&amp; nums[r] &gt; nums[deque.peekLast()]) &#123; <span class="hljs-comment">// 放进去的是保持下标递增的情况下值最大的</span><br>                deque.pollLast();<br>            &#125;<br>            deque.offerLast(r);<br>            <span class="hljs-keyword">if</span> (r - l + <span class="hljs-number">1</span> == k) &#123;<br>                ans[l] = nums[deque.peekFirst()];<br>                <span class="hljs-keyword">while</span> (!deque.isEmpty() &amp;&amp; deque.peekFirst() &lt;= l) &#123; <span class="hljs-comment">// 淘汰掉滑动窗口以外的</span><br>                    deque.pollFirst();<br>                &#125;<br>                l++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="分块-前后缀数组"><a href="#分块-前后缀数组" class="headerlink" title="分块 + 前后缀数组"></a>分块 + 前后缀数组</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[] maxSlidingWindow(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> k) &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> nums;<br>        <span class="hljs-type">int</span>[] prefixMax = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n]; <span class="hljs-comment">// 以 i 结尾的前缀最大值，也就是查询的左边</span><br>        <span class="hljs-type">int</span>[] suffixMax = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n]; <span class="hljs-comment">// 以 i 开头的后缀最大值，也就是查询的右边</span><br>        <span class="hljs-comment">// [ a, b, c ] [ d, e, f ]</span><br>        <span class="hljs-comment">// 按 k 分块，如果是边界，那么需要第一个的后缀最大值和第二个的前缀最大值拼起来</span><br>        <span class="hljs-comment">// 如果不是边界，那么直接取后缀最大值就好</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">if</span> (i % k == <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">// 边界</span><br>                prefixMax[i] = nums[i];<br><br>            &#125; <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// 在块中间</span><br>                prefixMax[i] = Math.max(prefixMax[i - <span class="hljs-number">1</span>], nums[i]);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> n - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;<br>            <span class="hljs-keyword">if</span> ((i + <span class="hljs-number">1</span>) % k == <span class="hljs-number">0</span> || i == n - <span class="hljs-number">1</span>) &#123;<br>                suffixMax[i] = nums[i];<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                suffixMax[i] = Math.max(suffixMax[i + <span class="hljs-number">1</span>], nums[i]);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-type">int</span>[] ans = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n - k + <span class="hljs-number">1</span>];<br>        <span class="hljs-comment">// [ a, b, c ] [ d, e, f ]</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span> ; i &lt; n - k + <span class="hljs-number">1</span>; i++) &#123; <span class="hljs-comment">// 滑动窗口开始位置</span><br>            <span class="hljs-keyword">if</span> (i % k == <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">// 边界</span><br>                ans[i] = prefixMax[i + k - <span class="hljs-number">1</span>];<br>            &#125; <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// [ a, b, c ] [ d, e, f ]</span><br>                     <span class="hljs-comment">// b 为滑动窗口开始的时候，元素为 b, c, d，最大值为 max([b, c], [d])</span><br>                     <span class="hljs-comment">// -&gt; max(suffixMax[1], prefixMax[3])</span><br>                ans[i] = Math.max(suffixMax[i], prefixMax[i + k - <span class="hljs-number">1</span>]);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br><br><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="双指针-3"><a href="#双指针-3" class="headerlink" title="双指针"></a>双指针</h2><p><strong>前后指针：</strong>经典的一个 pre 指针，一个 cur 指针：可以解决反转链表、交换节点等问题。<br><strong>快慢指针：</strong>还有一个 fast 指针，一个 slow 指针：可以解决删除第 n 个元素的问题。</p>
<p>19.删除链表的倒数第 N 个结点</p>
<p>142.环形链表</p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h1><h2 id="两数之和"><a href="#两数之和" class="headerlink" title="两数之和"></a>两数之和</h2><p>10^4 O(n)</p>
<p>一个哈希表</p>
<h2 id="三数之和"><a href="#三数之和" class="headerlink" title="三数之和"></a>三数之和</h2><p>3000</p>
<p>O(n^2)</p>
<p>排序+双指针</p>
<h2 id="四数之和"><a href="#四数之和" class="headerlink" title="四数之和"></a>四数之和</h2><p>排序+双指针</p>
<p>注意溢出</p>
<h2 id="四数相加"><a href="#四数相加" class="headerlink" title="四数相加"></a>四数相加</h2><p>与上一题不同在于有 4 个数组，4 个数组等长度，上一题每个区间长度不同</p>
<p>哈希表 + 哈希表</p>
<h2 id="字母异位词分组"><a href="#字母异位词分组" class="headerlink" title="字母异位词分组"></a>字母异位词分组</h2><p>10^4 O(n) 或 O(nlogn)</p>
<p>主要考虑异位词表示为相同的 map key，这样就可以将异位词聚集在一起。</p>
<h2 id="最长连续序列"><a href="#最长连续序列" class="headerlink" title="最长连续序列"></a>最长连续序列</h2><p>10^5 O(n)</p>
<p>未排序的数组，O(n) 找到数字连续的最长序列，不要求在原数组中连续。</p>
<p>排序做法为 O(nlogn)</p>
<p>key：考虑某一个数是不是连续序列的第一个数字，如果是则继续往下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num : set) &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">while</span> (set.contains(num + i)) &#123;<br>        i++;<br>        longest = Math.max(longest, i);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>这种写法最坏会变成 O(n^2)，需要思考如何跳过重复情况。如果再开一个 TreeSet 来定位下一个数字是 O(logn)，应该可以。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">longestConsecutive</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-keyword">if</span> (nums.length == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        Set&lt;Integer&gt; set = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>        TreeSet&lt;Integer&gt; treeSet = <span class="hljs-keyword">new</span> <span class="hljs-title class_">TreeSet</span>&lt;&gt;();<br>        <span class="hljs-type">Integer</span> <span class="hljs-variable">next</span> <span class="hljs-operator">=</span> <span class="hljs-number">0x3f3f3f3f</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; nums.length; i++) &#123;<br>            set.add(nums[i]);<br>            treeSet.add(nums[i]);<br>            next = Math.min(next, nums[i]);<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">longest</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span> (next != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">while</span> (set.contains(next)) &#123;<br>                next = next + <span class="hljs-number">1</span>;<br>                longest = Math.max(longest, i);<br>                i++;<br>            &#125;<br>            next = treeSet.higher(next); <span class="hljs-comment">// 定位下一个数字</span><br>        &#125;<br><br>        <span class="hljs-keyword">return</span> longest;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>还有一种 O(1) 定位下一个数字的方法：</p>
<p>如果这个数字为 x，那么不存在 x-1 的话，这个数字一定是连续序列的第一个数字。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">longestConsecutive</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-keyword">if</span> (nums.length == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        Set&lt;Integer&gt; set = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; nums.length; i++) &#123;<br>            set.add(nums[i]);<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">longest</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num : set) &#123;<br>            <span class="hljs-keyword">if</span> (set.contains(num - <span class="hljs-number">1</span>)) <span class="hljs-keyword">continue</span>;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">while</span> (set.contains(num + i)) &#123;<br>                i++;<br>                longest = Math.max(longest, i);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> longest;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><h2 id="KMP-算法"><a href="#KMP-算法" class="headerlink" title="KMP 算法"></a>KMP 算法</h2><p>next 数组：<strong>是一个前缀表，前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。</strong></p>
<p>那么什么是前缀表：<strong>记录下标i之前（包括i）的字符串中，有多大长度的相同前缀后缀。</strong></p>
<p><strong>下标5之前这部分的字符串（也就是字符串aabaa）的最长相等的前缀 和 后缀字符串是 子字符串aa ，因为找到了最长相等的前缀和后缀，匹配失败的位置是后缀子串的后面，那么我们找到与其相同的前缀的后面重新匹配就可以了。</strong></p>
<h2 id="反转字符串中的单词"><a href="#反转字符串中的单词" class="headerlink" title="反转字符串中的单词"></a>反转字符串中的单词</h2><p>方法一：split 之后拼接。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-string">&quot;a good   example&quot;</span>.split() <span class="hljs-comment">// [a, good, , , example]，分割后存在 &quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p>方法二：反转整个字符串之后，再反转单个字符串。</p>
<h2 id="最长公共子串"><a href="#最长公共子串" class="headerlink" title="最长公共子串"></a>最长公共子串</h2><p>状态转移方程如下：</p>
<script type="math/tex; mode=display">
d p[i][j]=\left\{\begin{array}{l}
d p[i-1][j-1]+1, \text { 当且仅当 } x[i]=y[j] \\
0, \text { 当 } x[i] \ne y[j]
\end{array}\right.</script><p>按照上面方程实现的算法时间复杂度为 $O(n^2)$，空间复杂度为 $O(n^2)$。</p>
<p><img  src="../leetcode/d6f0b0e17ed6e13f5c042d172b1ddca782cb6aba589f5fcfea8944831614502f-image.png"  ><span class="image-caption">image.png</span></p>
<p>注意到，更新 $dp[i][j]$ 只需要上一列，即 $dp[i-1]$ 列，所以可以将空间复杂度降低为 $O(n)$，但是需要注意因为使用的是相同的数组列，所以字符串不相等时需要设置 $dp[j] = 0$，同时要注意从后向前更新数组，因为如果从前向后更新，那么当前的 $dp[j]$ 使用的是当前列刚刚更新过的数据，而我们需要的是上一列的数据，所以可以从后向前更新数据避免这个问题。</p>
<p>rust 代码如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">dp</span> = <span class="hljs-built_in">vec!</span>[<span class="hljs-number">0</span>; s2.<span class="hljs-title function_ invoke__">len</span>()];<br><span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..s1.<span class="hljs-title function_ invoke__">len</span>() &#123;<br>    <span class="hljs-comment">// 逆序迭代是因为更新a[i][j]需要a[i-1][j-1]</span><br>    <span class="hljs-comment">// 现在是一个数组，所以 a[j] 是原来的 a[i][j]，而我们需要的是 a[i-1][j]</span><br>    <span class="hljs-comment">// 所以从后向前迭代，a[j] 是原来的 a[i-1][j]</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">j</span> <span class="hljs-keyword">in</span> (<span class="hljs-number">0</span>..s2.<span class="hljs-title function_ invoke__">len</span>()).<span class="hljs-title function_ invoke__">s2</span>() &#123;<br>        <span class="hljs-keyword">if</span> s[i] == s2[j] &#123;<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> || j == <span class="hljs-number">0</span> &#123;<br>                dp[j] = <span class="hljs-number">1</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                dp[j] = dp[j - <span class="hljs-number">1</span>] + <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">if</span> dp[j] &gt; max_len &#123;<br>                <span class="hljs-keyword">let</span> <span class="hljs-variable">before_s2</span> = s2.<span class="hljs-title function_ invoke__">len</span>() - <span class="hljs-number">1</span> - j;<br>                <span class="hljs-keyword">if</span> before_s2 + dp[j] - <span class="hljs-number">1</span> == i &#123;<br>                    max_len = dp[j];<br>                    max_end = i;<br>                &#125;<br>            &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 与之前不同，之前使用的是不同的列，所以不需要置0</span><br>            dp[j] = <span class="hljs-number">0</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="最长回文子串"><a href="#最长回文子串" class="headerlink" title="最长回文子串"></a>最长回文子串</h2><h3 id="动态规划-1"><a href="#动态规划-1" class="headerlink" title="动态规划"></a>动态规划</h3><p>将字符串倒置之后求最长公共子串（状态转移方程与最长公共子串相同），并判断是否为回文子串，这里回文子串「由倒置字符串推出的原字符串末尾下标」与「i」应该相等。</p>
<p>代码中 <code>longest_palindrome1</code> 的求最长公共子串空间复杂度为 $O(n^2)$，<code>longest_palindrome2</code> 的求最长公共子串空间复杂度为 $O(n)$。</p>
<p>代码如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Solution</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">longest_palindrome1</span>(s: <span class="hljs-type">String</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">String</span> &#123;<br>        <span class="hljs-keyword">if</span> s.<span class="hljs-title function_ invoke__">len</span>() &lt;= <span class="hljs-number">1</span> &#123;<br>            <span class="hljs-keyword">return</span> s;<br>        &#125;<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">rev</span>: <span class="hljs-type">String</span> = s.<span class="hljs-title function_ invoke__">chars</span>().<span class="hljs-title function_ invoke__">rev</span>().<span class="hljs-title function_ invoke__">collect</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">rev</span> = rev.<span class="hljs-title function_ invoke__">as_bytes</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = s.<span class="hljs-title function_ invoke__">as_bytes</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">dp</span> = <span class="hljs-built_in">vec!</span>[<span class="hljs-built_in">vec!</span>[<span class="hljs-number">0</span>; rev.<span class="hljs-title function_ invoke__">len</span>()]; s.<span class="hljs-title function_ invoke__">len</span>()];<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">max_len</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">max_end</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..s.<span class="hljs-title function_ invoke__">len</span>() &#123;<br>            <span class="hljs-keyword">for</span> <span class="hljs-variable">j</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..rev.<span class="hljs-title function_ invoke__">len</span>() &#123;<br>                <span class="hljs-keyword">if</span> s[i] == rev[j] &#123;<br>                    <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> || j == <span class="hljs-number">0</span> &#123;<br>                        dp[i][j] = <span class="hljs-number">1</span>;<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        dp[i][j] = dp[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] + <span class="hljs-number">1</span>;<br>                    &#125;<br>                &#125;<br>                <span class="hljs-keyword">if</span> dp[i][j] &gt; max_len &#123;<br>                    <span class="hljs-comment">// 如果是回文串，那么「由倒置字符串推出的原字符串末尾下标」与「i」应该相等</span><br>                    <span class="hljs-comment">// 其中，倒置字符串的 rev.len() - 1 - j，也就是倒置之前的开始下标，减一是因为长度比下标多一</span><br>                    <span class="hljs-comment">// 再加上 dp[i][j] - 1，就是原字符串的末尾下标。abc，a的下标为0，长度为3，0+3为3，但是最大下标为2，所以需要减一</span><br>                    <span class="hljs-keyword">let</span> <span class="hljs-variable">before_rev</span> = rev.<span class="hljs-title function_ invoke__">len</span>() - <span class="hljs-number">1</span> - j;<br>                    <span class="hljs-keyword">if</span> before_rev + dp[i][j] - <span class="hljs-number">1</span> == i &#123;<br>                        max_len = dp[i][j];<br>                        max_end = i;<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br>        std::<span class="hljs-type">str</span>::<span class="hljs-title function_ invoke__">from_utf8</span>(&amp;s[max_end + <span class="hljs-number">1</span> - max_len..max_end + <span class="hljs-number">1</span>])<br>            .<span class="hljs-title function_ invoke__">unwrap</span>()<br>            .<span class="hljs-title function_ invoke__">to_string</span>()<br>    &#125;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">longest_palindrome2</span>(s: <span class="hljs-type">String</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">String</span> &#123;<br>        <span class="hljs-keyword">if</span> s.<span class="hljs-title function_ invoke__">len</span>() &lt; <span class="hljs-number">1</span> &#123;<br>            <span class="hljs-keyword">return</span> s;<br>        &#125;<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">rev</span>: <span class="hljs-type">String</span> = s.<span class="hljs-title function_ invoke__">chars</span>().<span class="hljs-title function_ invoke__">rev</span>().<span class="hljs-title function_ invoke__">collect</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = s.<span class="hljs-title function_ invoke__">as_bytes</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">rev</span> = rev.<span class="hljs-title function_ invoke__">as_bytes</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">max_len</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">max_end</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">dp</span> = <span class="hljs-built_in">vec!</span>[<span class="hljs-number">0</span>; rev.<span class="hljs-title function_ invoke__">len</span>()];<br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..s.<span class="hljs-title function_ invoke__">len</span>() &#123;<br>            <span class="hljs-comment">// 逆序迭代是因为更新a[i][j]需要a[i-1][j-1]</span><br>            <span class="hljs-comment">// 现在是一个数组，所以 a[j] 是原来的 a[i][j]，而我们需要的是 a[i-1][j]</span><br>            <span class="hljs-comment">// 所以从后向前迭代，a[j] 是原来的 a[i-1][j]</span><br>            <span class="hljs-keyword">for</span> <span class="hljs-variable">j</span> <span class="hljs-keyword">in</span> (<span class="hljs-number">0</span>..rev.<span class="hljs-title function_ invoke__">len</span>()).<span class="hljs-title function_ invoke__">rev</span>() &#123;<br>                <span class="hljs-keyword">if</span> s[i] == rev[j] &#123;<br>                    <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> || j == <span class="hljs-number">0</span> &#123;<br>                        dp[j] = <span class="hljs-number">1</span>;<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        dp[j] = dp[j - <span class="hljs-number">1</span>] + <span class="hljs-number">1</span>;<br>                    &#125;<br>                    <span class="hljs-keyword">if</span> dp[j] &gt; max_len &#123;<br>                        <span class="hljs-keyword">let</span> <span class="hljs-variable">before_rev</span> = rev.<span class="hljs-title function_ invoke__">len</span>() - <span class="hljs-number">1</span> - j;<br>                        <span class="hljs-keyword">if</span> before_rev + dp[j] - <span class="hljs-number">1</span> == i &#123;<br>                            max_len = dp[j];<br>                            max_end = i;<br>                        &#125;<br>                    &#125;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">// 与之前不同，之前使用的是不同的列，所以不需要置0</span><br>                    dp[j] = <span class="hljs-number">0</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>        std::<span class="hljs-type">str</span>::<span class="hljs-title function_ invoke__">from_utf8</span>(&amp;s[max_end + <span class="hljs-number">1</span> - max_len..max_end + <span class="hljs-number">1</span>])<br>            .<span class="hljs-title function_ invoke__">unwrap</span>()<br>            .<span class="hljs-title function_ invoke__">to_string</span>()<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="中心拓展算法"><a href="#中心拓展算法" class="headerlink" title="中心拓展算法"></a>中心拓展算法</h3><p>为了避免在之后的叙述中出现歧义，这里我们指出什么是“朴素算法”。</p>
<p>该算法通过下述方式工作：对每个中心位置 $i$ 在比较一对对应字符后，只要可能，该算法便尝试将答案加 $1$。</p>
<p>该算法是比较慢的：它只能在 $O(n^2)$ 的时间内计算答案。</p>
<p>该算法的实现如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// C++ Version</span><br><span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">d1</span><span class="hljs-params">(n)</span>, <span class="hljs-title">d2</span><span class="hljs-params">(n)</span></span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>  d1[i] = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">while</span> (<span class="hljs-number">0</span> &lt;= i - d1[i] &amp;&amp; i + d1[i] &lt; n &amp;&amp; s[i - d1[i]] == s[i + d1[i]]) &#123;<br>    d1[i]++;<br>  &#125;<br><br>  d2[i] = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">while</span> (<span class="hljs-number">0</span> &lt;= i - d2[i] - <span class="hljs-number">1</span> &amp;&amp; i + d2[i] &lt; n &amp;&amp;<br>         s[i - d2[i] - <span class="hljs-number">1</span>] == s[i + d2[i]]) &#123;<br>    d2[i]++;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Python Version</span><br>d1 = [<span class="hljs-number">0</span>] * n<br>d2 = [<span class="hljs-number">0</span>] * n<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n):<br>    d1[i] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-number">0</span> &lt;= i - d1[i] <span class="hljs-keyword">and</span> i + d1[i] &lt; n <span class="hljs-keyword">and</span> s[i - d1[i]] == s[i + d1[i]]:<br>        d1[i] += <span class="hljs-number">1</span><br><br>    d2[i] = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-number">0</span> &lt;= i - d2[i] - <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i + d2[i] &lt; n <span class="hljs-keyword">and</span> s[i - d2[i] - <span class="hljs-number">1</span>] == s[i + d2[i]]:<br>        d2[i] += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>
<h3 id="Manacher-算法12"><a href="#Manacher-算法12" class="headerlink" title="Manacher 算法12"></a>Manacher 算法<sup><a href="#fn_1" id="reffn_1">1</a></sup><sup><a href="#fn_2" id="reffn_2">2</a></sup></h3><p>Manacher 算法是对中心拓展算法的优化，为了快速计算，我们维护已找到的最靠右的子回文串的 <strong>边界 $(l, r)$</strong>（即具有最大 $r$ 值的回文串，其中 $l$ 和 $r$ 分别为该回文串左右边界的位置）。初始时，我们置 $l = 0$ 和 $r = -1$（<em>-1</em>需区别于倒序索引位置，这里可为任意负数，仅为了循环初始时方便）。</p>
<p>现在假设我们要对下一个 $i$ 计算 $P[i]$，而之前所有 $P[]$ 中的值已计算完毕。我们将通过下列方式计算：</p>
<ul>
<li><p>如果 $i$ 位于当前子回文串之外，即 $i &gt; r$，那么我们调用朴素算法。</p>
<p>因此我们将连续地增加 $d_1[i]$，同时在每一步中检查当前的子串 $[i - P[i] \dots i +  P[i]]$（$P[i]$ 表示半径长度，下同）是否为一个回文串。如果我们找到了第一处对应字符不同，又或者碰到了 $s$  的边界，则算法停止。在两种情况下我们均已计算完 $P[i]$。此后，仍需记得更新 $(l, r)$。</p>
</li>
<li><p>现在考虑 $i \le r$ 的情况。我们将尝试从已计算过的 $P[]$ 的值中获取一些信息。首先在子回文串  $(l, r)$ 中反转位置 $i$，即我们得到 $j = l + (r - i)$。现在来考察值 $P[j]$。因为位置 $j$ 同位置  $i$ 对称，我们 <strong>几乎总是</strong> 可以置 $P[i] = P[j]$。</p>
<p>存在 <strong>棘手的情况</strong>，主要有以下：</p>
<ul>
<li><p>超出了 $r$</p>
<p><img  src="../leetcode/b0d52a5f30747e55ef09b3c7b7cfc23026e37040edc41f387263e8f8a0ba8f49-image.png"  ><span class="image-caption">图转自 LeetCode</span></p>
<p>当我们要求 $P [ i ]$ 的时候，$P [mirror] = 7$，而此时 $P [ i ]$ 并不等于 $7$，为什么呢，因为我们从 $i$ 开始往后数 $7$ 个，等于 $22$，已经超过了最右的 $r$，此时不能利用对称性了，但我们一定可以扩展到 $r$ 的，所以 $P [ i ]$ 至少等于 $r - i = 20 - 15 = 5$，会不会更大呢，我们只需要比较 $T [ r+1 ]$ 和 $T [ r+1 ]$ 关于 $i$ 的对称点就行了，就像中心扩展法一样一个个扩展。</p>
</li>
<li><p>$P[i]$ 遇到了原字符串的左边界</p>
<p><img  src="../leetcode/714e6f768e67304fb7162ecac3ae85fcf23ad82a21456e8ca55ac2c8cfd2609e-image.png"  ><span class="image-caption">image.png</span></p>
<p>此时$P [ i_{mirror} ] = 1$，但是 $P [ i ]$ 赋值成 1 是不正确的，出现这种情况的原因是 $P [ i_{mirror} ]$ 在扩展的时候首先是 “#” == “#”，之后遇到了 “^” 和另一个字符比较，也就是到了边界，才终止循环的。而 $P [ i ]$ 并没有遇到边界，所以我们可以继续通过中心扩展法一步一步向两边扩展就行了。</p>
</li>
<li><p>$i = r$</p>
<p>此时我们先把 P [ i ] 赋值为 0，然后通过中心扩展法一步一步扩展就行了。</p>
</li>
</ul>
<p>考虑 $r$ 的更新</p>
<p>就这样一步一步的求出每个 $P [ i ]$，当求出的 $P [ i ]$ 的右边界大于当前的 $r$ 时，我们就需要更新 $r$ 为当前的回文串了。</p>
</li>
</ul>
<h2 id="最长公共子序列（LCS）"><a href="#最长公共子序列（LCS）" class="headerlink" title="最长公共子序列（LCS）"></a>最长公共子序列（LCS）</h2><h3 id="动态规划-2"><a href="#动态规划-2" class="headerlink" title="动态规划"></a>动态规划</h3><p>状态转移方程如下：</p>
<script type="math/tex; mode=display">
d p[i][j]=\left\{\begin{array}{ll}
d p[i-1][j-1]+1, & t e x t_{1}[i-1]=t e x t_{2}[j-1] \\
\max (d p[i-1][j], d p[i][j-1]), & t e x t_{1}[i-1] \neq t e x t_{2}[j-1]
\end{array}\right.</script><p>LCS 对应的状态转移方程与最长公共子串不同之处在于：</p>
<ul>
<li>最长公共子串要求字符串连续，所以下一个状态只能由上一个对应的字符串得到。</li>
<li>LCS 不要求字符串连续，所以可以前后移动，就有了第二个式子。</li>
</ul>
<p>知道状态定义之后，我们开始写状态转移方程。</p>
<ul>
<li><p>当 $text_1[i - 1] = text_2[j - 1]$ 时，说明两个子字符串的最后一位相等，所以最长公共子序列又增加了 1，所以 $dp[i][j] = dp[i - 1][j - 1] + 1$；举个例子，比如对于 <code>ac</code> 和 <code>bc</code> 而言，他们的最长公共子序列的长度等于 <code>a</code> 和 <code>b</code> 的最长公共子序列长度 $0 + 1 = 1$。</p>
</li>
<li><p>当 $text_1[i - 1] \ne text_2[j - 1]$ 时，说明两个子字符串的最后一位不相等，那么此时的状态 $dp[i][j]$ 应该是 $dp[i - 1][j]$ 和 $dp[i][j - 1]$ 的最大值。举个例子，比如对于 <code>ace</code> 和 <code>bc</code> 而言，他们的最长公共子序列的长度等于</p>
<p> ① <code>ace</code> 和 <code>b</code> 的最长公共子序列长度 <code>0</code> 与</p>
<p>② <code>ac</code> 和 <code>bc</code> 的最长公共子序列长度 <code>1</code> 的最大值，即 <code>1</code>。</p>
</li>
</ul>
<p>代码如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Solution</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">longest_common_subsequence</span>(text1: <span class="hljs-type">String</span>, text2: <span class="hljs-type">String</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i32</span> &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">text1</span> = text1.<span class="hljs-title function_ invoke__">as_bytes</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">text2</span> = text2.<span class="hljs-title function_ invoke__">as_bytes</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">m</span> = text1.<span class="hljs-title function_ invoke__">len</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">n</span> = text2.<span class="hljs-title function_ invoke__">len</span>();<br>        <span class="hljs-comment">// dp[i][j] 代表 text1[0..i] 与 text2[0..j] 的最大子序列，注意不包括第 i 和第 j 个字符</span><br>        <span class="hljs-comment">// 同理，dp 数组要循环到 m 与 n 才结束</span><br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">dp</span> = <span class="hljs-built_in">vec!</span>[<span class="hljs-built_in">vec!</span>[<span class="hljs-number">0</span>; n + <span class="hljs-number">1</span>]; m + <span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>..=m &#123;<br>            <span class="hljs-keyword">for</span> <span class="hljs-variable">j</span> <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>..=n &#123;<br>                <span class="hljs-comment">// 这里要注意，比较的是第 i-1 与第 j-1 个字符</span><br>                <span class="hljs-keyword">if</span> text1[i - <span class="hljs-number">1</span>] == text2[j - <span class="hljs-number">1</span>] &#123;<br>                    dp[i][j] = dp[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] + <span class="hljs-number">1</span>;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    dp[i][j] = std::cmp::<span class="hljs-title function_ invoke__">max</span>(dp[i][j - <span class="hljs-number">1</span>], dp[i - <span class="hljs-number">1</span>][j]);<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[m][n];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="动态规划-3"><a href="#动态规划-3" class="headerlink" title="动态规划"></a>动态规划</h1><p>对于动态规划，可以先初始化一个 dp 数组，然后手写出 dp[0] dp[1] dp[2] dp[3] 等等</p>
<h2 id="杨辉三角"><a href="#杨辉三角" class="headerlink" title="杨辉三角"></a>杨辉三角</h2><p>主要难点在处理边界情况</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> List&lt;List&lt;Integer&gt;&gt; <span class="hljs-title function_">generate</span><span class="hljs-params">(<span class="hljs-type">int</span> numRows)</span> &#123;<br>        List&lt;List&lt;Integer&gt;&gt; ret = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= numRows; i++) &#123;<br>            List&lt;Integer&gt; arr = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;(i);<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; i; j++) &#123;<br>                arr.add(<span class="hljs-number">0</span>);<br>            &#125;<br>            arr.set(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>);<br>            arr.set(i - <span class="hljs-number">1</span>, <span class="hljs-number">1</span>);<br>            List&lt;Integer&gt; lastArr;<br>            <span class="hljs-keyword">if</span> (ret.size() &gt;= <span class="hljs-number">2</span>) &#123;<br>                lastArr = ret.get(ret.size() - <span class="hljs-number">1</span>);<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt; i - <span class="hljs-number">1</span>; j++) &#123; <span class="hljs-comment">// 跳过第一个和最后一个</span><br>                    arr.set(j, lastArr.get(j-<span class="hljs-number">1</span>) + lastArr.get(j));<br>                &#125;<br>            &#125;<br>            ret.add(arr);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="打家劫舍"><a href="#打家劫舍" class="headerlink" title="打家劫舍"></a>打家劫舍</h2><p>要点在于对于某一个房子是否抢劫以及边界处理。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">rob</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> Math.max(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);<br>        <span class="hljs-type">int</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>];<br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br>        dp[<span class="hljs-number">1</span>] = nums[<span class="hljs-number">0</span>];<br>        dp[<span class="hljs-number">2</span>] = Math.max(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">3</span>; i &lt;= n; i++) &#123;<br>            dp[i] = Math.max(dp[i - <span class="hljs-number">2</span>] + nums[i - <span class="hljs-number">1</span>], dp[i - <span class="hljs-number">1</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="最大子序和"><a href="#最大子序和" class="headerlink" title="最大子序和"></a>最大子序和</h2><p>要点在于当前数字结尾的最大子串的和只能来自于前一个，也就是上楼梯只能由前一个上过来，或者现在新开一个。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">maxSubArray</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-type">int</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>]; <span class="hljs-comment">// 第 i 个数结尾的子数组最大值</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">ans</span> <span class="hljs-operator">=</span> -<span class="hljs-number">0x3f3f3f3f</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>            dp[i] = Math.max(dp[i - <span class="hljs-number">1</span>] + nums[i - <span class="hljs-number">1</span>], nums[i - <span class="hljs-number">1</span>]);<br>            ans = Math.max(ans, dp[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="完全平方数"><a href="#完全平方数" class="headerlink" title="完全平方数"></a>完全平方数</h2><h3 id="动态规划-4"><a href="#动态规划-4" class="headerlink" title="动态规划"></a>动态规划</h3><p>要点是 dp[i] 表示结果为 i 的最少数量，然后转移的话，dp[i] 只能从 dp[i - 所有平方数] 来，于是写出状态转移方程。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">numSquares</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> &#123;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">3</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">3</span>;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">4</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">5</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">sqrtN</span> <span class="hljs-operator">=</span> (<span class="hljs-type">int</span>)Math.sqrt(n) + <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span>[] square = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[sqrtN];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; sqrtN; i++) &#123;<br>            square[i] = i * i;<br>        &#125;<br>        <span class="hljs-type">int</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>];<br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br>        dp[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>        dp[<span class="hljs-number">2</span>] = <span class="hljs-number">2</span>;<br>        dp[<span class="hljs-number">3</span>] = <span class="hljs-number">3</span>;<br>        dp[<span class="hljs-number">4</span>] = <span class="hljs-number">1</span>;<br>        dp[<span class="hljs-number">5</span>] = <span class="hljs-number">2</span>;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">min</span> <span class="hljs-operator">=</span> <span class="hljs-number">999</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt; sqrtN; j++) &#123;<br>                <span class="hljs-keyword">if</span> (i - square[j] &gt;= <span class="hljs-number">0</span>) &#123;<br>                    min = Math.min(dp[i - square[j]] + <span class="hljs-number">1</span>, min);<br>                &#125;<br>            &#125;<br>            dp[i] = min;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dp[n];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>优化一下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">numSquares</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> &#123;<br>        <span class="hljs-type">int</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">min</span> <span class="hljs-operator">=</span> <span class="hljs-number">999</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j * j &lt;= i; j++) &#123;<br>                <span class="hljs-keyword">if</span> (i - j * j &gt;= <span class="hljs-number">0</span>) &#123;<br>                    min = Math.min(dp[i - j * j] + <span class="hljs-number">1</span>, min);<br>                &#125;<br>            &#125;<br>            dp[i] = min;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dp[n];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="四平方和定理"><a href="#四平方和定理" class="headerlink" title="四平方和定理"></a>四平方和定理</h3><p><img  src="/image-20250107155619501.png"  ><span class="image-caption">image-20250107155619501</span></p>
<h2 id="零钱兑换"><a href="#零钱兑换" class="headerlink" title="零钱兑换"></a>零钱兑换</h2><p>这是一个完全背包问题，硬币可以重复使用。与爬楼梯类似。</p>
<p>$dp[i] = dp[i - coins[j]] + 1$。</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">int</span> coinChange(<span class="hljs-built_in">int</span>[] coins, <span class="hljs-built_in">int</span> amount) &#123;<br>        <span class="hljs-keyword">if</span> (amount == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-built_in">int</span> n = coins.length;<br>        <span class="hljs-built_in">int</span>[] dp = new <span class="hljs-built_in">int</span>[Math.max(n, amount) + <span class="hljs-number">10</span>]; <span class="hljs-comment">// 可以凑成 n 所需的最少的硬币个数</span><br>        <span class="hljs-comment">// 与爬楼梯一样，dp[i] 可以从 dp[i - coins[j]] 过来</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">if</span> (coins[i] &gt; amount) &#123;<br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br>            dp[coins[i]] = <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt;= amount; i++) &#123;<br>            <span class="hljs-keyword">if</span> (dp[i] == <span class="hljs-number">0</span>) &#123;<br>                dp[i] = <span class="hljs-number">0x3f3f3f3f</span>;<br>            &#125;<br>        &#125;<br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br>        <span class="hljs-built_in">int</span> max = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> i = <span class="hljs-number">1</span>; i &lt;= amount; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++) &#123;<br>                <span class="hljs-keyword">if</span> (i - coins[j] &gt;= <span class="hljs-number">0</span>) &#123;<br>                    dp[i] = Math.min(dp[i - coins[j]] + <span class="hljs-number">1</span>, dp[i]);<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dp[amount] == <span class="hljs-number">0x3f3f3f3f</span> ? <span class="hljs-number">-1</span> : dp[amount];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="单词拆分"><a href="#单词拆分" class="headerlink" title="单词拆分"></a>单词拆分</h2><ul>
<li><code>1 &lt;= s.length &lt;= 300</code></li>
<li><code>1 &lt;= wordDict.length &lt;= 1000</code></li>
<li><code>1 &lt;= wordDict[i].length &lt;= 20</code></li>
</ul>
<h3 id="模拟-剪枝"><a href="#模拟-剪枝" class="headerlink" title="模拟 + 剪枝"></a>模拟 + 剪枝</h3><p>不断地尝试所有可能的拼接，看最后能否拼接出来，注意要剪枝，否则会超时。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">wordBreak</span><span class="hljs-params">(String s, List&lt;String&gt; wordDict)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> wordDict.size();<br>        Set&lt;String&gt; dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>        <span class="hljs-type">int</span> <span class="hljs-variable">maxLen</span> <span class="hljs-operator">=</span> <span class="hljs-number">0x3f3f3f3f</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">word</span> <span class="hljs-operator">=</span> wordDict.get(i);<br>            <span class="hljs-keyword">if</span> (s.startsWith(word)) <span class="hljs-comment">// 剪枝</span><br>                dp.add(word);<br>            maxLen = Math.min(maxLen, word.length());<br>        &#125;<br><br><br>        <span class="hljs-keyword">while</span> (maxLen &lt; s.length()) &#123;<br>            Set&lt;String&gt; tmp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;(dp); <span class="hljs-comment">// 创建一个临时副本用于遍历</span><br>            <span class="hljs-type">int</span> <span class="hljs-variable">minLen</span> <span class="hljs-operator">=</span> <span class="hljs-number">0x3f3f3f3f</span>;<br>            <span class="hljs-keyword">for</span> (String cur : tmp) &#123;<br>                <span class="hljs-keyword">if</span> (cur.length() &lt; maxLen) <span class="hljs-keyword">continue</span>;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>                    <span class="hljs-type">String</span> <span class="hljs-variable">newString</span> <span class="hljs-operator">=</span> cur + wordDict.get(i);<br>                    <span class="hljs-keyword">if</span> (s.startsWith(newString)) &#123; <span class="hljs-comment">// 剪枝</span><br>                        minLen = Math.min(newString.length(), minLen);<br>                        dp.add(newString);<br>                    &#125;<br>                &#125;<br>            &#125;<br>            maxLen = Math.max(maxLen, minLen);<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp.contains(s);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>优化一下</p>
<h3 id="动态规划-5"><a href="#动态规划-5" class="headerlink" title="动态规划"></a>动态规划</h3><p><img  src="/image-20250107182951481.png"  ><span class="image-caption">image-20250107182951481</span></p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">wordBreak</span><span class="hljs-params">(String s, List&lt;String&gt; wordDict)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> wordDict.size();<br>        Set&lt;String&gt; set = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;(wordDict);<br>        <span class="hljs-type">boolean</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">boolean</span>[s.length() + <span class="hljs-number">1</span>];<br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= s.length(); i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; i; j++) &#123;<br>                <span class="hljs-keyword">if</span> (dp[j] &amp;&amp; set.contains(s.substring(j, i))) &#123;<br>                    dp[i] = <span class="hljs-literal">true</span>;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[s.length()];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="最长递增子序列"><a href="#最长递增子序列" class="headerlink" title="最长递增子序列"></a>最长递增子序列</h2><p>要点在于 dp 为以第 i 个数字结尾的最长上升子序列长度，也就是 dp[i] 是 i 被选择的情况下的最长上升子序列长度。</p>
<p>这题要求的是子序列，而不是子数组，也就是可以跳过一些数字，所以动态转移方程就是对于 dp[i] 可以从任意的 dp[i - j] 调过来。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">lengthOfLIS</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span>  nums.length, max = <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n + <span class="hljs-number">1</span>]; <span class="hljs-comment">// 以第 i 个数字结尾的最长上升子序列长度</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= n; i++) &#123;<br>            dp[i] = <span class="hljs-number">1</span>; <span class="hljs-comment">// 如果选当前的 i，至少有 1 个长度</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt; i; j++) &#123;<br>                <span class="hljs-keyword">if</span> (nums[i - <span class="hljs-number">1</span>] &gt; nums[j - <span class="hljs-number">1</span>]) &#123;<br>                    dp[i] = Math.max(dp[i], dp[j] + <span class="hljs-number">1</span>);<br>                &#125;<br>            &#125;<br>            max = Math.max(max, dp[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> max;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="乘积最大子数组"><a href="#乘积最大子数组" class="headerlink" title="乘积最大子数组"></a>乘积最大子数组</h2><p><code>dp_max[i]</code> 表示以第 <code>i</code> 个元素结尾的连续子数组的最大乘积。</p>
<p>对于每一个 dp[i] 来说，他会从前一个最大的 dp[i - 1] 过来，或者从最小的 dp[i - 1] 过来，或者在当前位置另起炉灶。与子序列不同，dp[i] 的子数组只能从 dp[i - 1] 过来，而不能从任意的 dp[i - j] 过来。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">maxProduct</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-keyword">if</span> (nums.length == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-type">int</span>[] dp_max = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n];<br>        <span class="hljs-type">int</span>[] dp_min = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n];<br>        dp_max[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        dp_min[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">ans</span> <span class="hljs-operator">=</span> nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            dp_max[i] = Math.max(Math.max(dp_max[i-<span class="hljs-number">1</span>] * nums[i], dp_min[i-<span class="hljs-number">1</span>] * nums[i]), nums[i]);<br>            dp_min[i] = Math.min(Math.min(dp_max[i-<span class="hljs-number">1</span>] * nums[i], dp_min[i-<span class="hljs-number">1</span>] * nums[i]), nums[i]);<br>            ans = Math.max(ans, dp_max[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="分割等和子集"><a href="#分割等和子集" class="headerlink" title="分割等和子集"></a>分割等和子集</h2><p><code>1 &lt;= nums.length &lt;= 200</code>，<code>1 &lt;= nums[i] &lt;= 100</code> 数据范围暗示了是和数组中最大数有关的二维 dp</p>
<p>给你一个 <strong>只包含正整数</strong> 的 <strong>非空</strong> 数组 <code>nums</code> 。请你判断是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。</p>
<p>如何将该问题转换为具有最优子结构的问题是难点。</p>
<p>动态规划，时间复杂度与元素大小相关的。</p>
<p>这个问题可以转换为：给定一个只包含正整数的非空数组 nums[0]，判断是否可以从数组中选出一些数字，使得这些数字的和等于整个数组的元素和的一半。因此这个问题可以转换成「0−1 背包问题」。这道题与传统的「0−1 背包问题」的区别在于，传统的「0−1 背包问题」要求选取的物品的重量之和不能超过背包的总容量，这道题则要求选取的数字的和恰好等于整个数组的元素和的一半。类似于传统的「0−1 背包问题」，可以使用动态规划求解。</p>
<p>关键在于：<strong>将这个数组分割成两个子集 = 选出的数字的和是数组一半</strong></p>
<p>然后关键的转移方程为：</p>
<ol>
<li>和为 j 的数字可以由 j - nums[i]（如果存在的话） 得到</li>
<li>和为 j 的数字可以由 j （如果存在的话）得到</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">canPartition</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length, target = <span class="hljs-number">0</span>, max = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            target += nums[i];<br>            max = Math.max(max, nums[i]);<br>        &#125;<br>        <span class="hljs-keyword">if</span> ((target &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 奇数</span><br>        <span class="hljs-keyword">else</span> target /= <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">if</span> (max &gt; target) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><br>        <span class="hljs-type">boolean</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">boolean</span>[n][target + <span class="hljs-number">1</span>]; <span class="hljs-comment">// 0..i 的数字中是否存在方案使得和为 j</span><br>        <span class="hljs-comment">// 数字 nums[i] 所在的行都能使得和为 nums[i]</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; i; j++) &#123;<br>                dp[i][nums[j]] = <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 0..i 中怎么选都能使得和为 0</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            dp[i][<span class="hljs-number">0</span>] = <span class="hljs-literal">true</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// 和为 j 的数字可以由 j - nums[i]（如果存在的话） 得到</span><br>        <span class="hljs-comment">// 和为 j 的数字可以由 j （如果存在的话）得到</span><br>        <span class="hljs-comment">// 可以根据上面的内容对 dp 数组进行填表</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt;= target; j++) &#123;<br><br>                <span class="hljs-keyword">if</span> (j &gt;= nums[i]) &#123;<br><br>                    dp[i][j] = dp[i - <span class="hljs-number">1</span>][j] | dp[i - <span class="hljs-number">1</span>][j - nums[i]];<br><br>                    <span class="hljs-comment">// 与上面的内容等价</span><br>                    <span class="hljs-comment">// if (dp[i - 1][j - nums[i]]) &#123;</span><br>                    <span class="hljs-comment">//     dp[i][j] = true;</span><br>                    <span class="hljs-comment">// &#125;</span><br>                    <span class="hljs-comment">// if (dp[i - 1][j]) &#123;</span><br>                    <span class="hljs-comment">//     dp[i][j] = true;</span><br>                    <span class="hljs-comment">// &#125;</span><br><br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    dp[i][j] = dp[i - <span class="hljs-number">1</span>][j];<br><br>                    <span class="hljs-comment">// 与上面的内容等价</span><br>                    <span class="hljs-keyword">if</span> (dp[i - <span class="hljs-number">1</span>][j]) &#123;<br>                        dp[i][j] = <span class="hljs-literal">true</span>;<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <br>        <span class="hljs-keyword">return</span> dp[n - <span class="hljs-number">1</span>][target];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>然后又有这一行仅仅由上一行确定得到，于是有：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">canPartition</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length, target = <span class="hljs-number">0</span>, max = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            target += nums[i];<br>            max = Math.max(max, nums[i]);<br>        &#125;<br>        <span class="hljs-keyword">if</span> ((target &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 奇数</span><br>        <span class="hljs-keyword">else</span> target /= <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">if</span> (max &gt; target) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><br>        <span class="hljs-type">boolean</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">boolean</span>[n][target + <span class="hljs-number">1</span>]; <span class="hljs-comment">// 0..i 的数字中是否存在方案使得和为 j</span><br>        <span class="hljs-comment">// 数字 nums[i] 所在的行都能使得和为 nums[i]</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; i; j++) &#123;<br>                dp[i][nums[j]] = <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 0..i 中怎么选都能使得和为 0</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            dp[i][<span class="hljs-number">0</span>] = <span class="hljs-literal">true</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// 和为 j 的数字可以由 j - nums[i]（如果存在的话） 得到</span><br>        <span class="hljs-comment">// 和为 j 的数字可以由 j （如果存在的话）得到</span><br>        <span class="hljs-comment">// 可以根据上面的内容对 dp 数组进行填表</span><br>        <span class="hljs-comment">// for (int i = 1; i &lt; n; i++) &#123;</span><br>        <span class="hljs-comment">//     for (int j = 1; j &lt;= target; j++) &#123;</span><br><br>        <span class="hljs-comment">//         if (j &gt;= nums[i]) &#123;</span><br><br>        <span class="hljs-comment">//             dp[i][j] = dp[i - 1][j] | dp[i - 1][j - nums[i]];</span><br><br>        <span class="hljs-comment">//             // 与上面的内容等价</span><br>        <span class="hljs-comment">//             // if (dp[i - 1][j - nums[i]]) &#123;</span><br>        <span class="hljs-comment">//             //     dp[i][j] = true;</span><br>        <span class="hljs-comment">//             // &#125;</span><br>        <span class="hljs-comment">//             // if (dp[i - 1][j]) &#123;</span><br>        <span class="hljs-comment">//             //     dp[i][j] = true;</span><br>        <span class="hljs-comment">//             // &#125;</span><br><br>        <span class="hljs-comment">//         &#125; else &#123;</span><br>        <span class="hljs-comment">//             dp[i][j] = dp[i - 1][j];</span><br><br>        <span class="hljs-comment">//             // 与上面的内容等价</span><br>        <span class="hljs-comment">//             if (dp[i - 1][j]) &#123;</span><br>        <span class="hljs-comment">//                 dp[i][j] = true;</span><br>        <span class="hljs-comment">//             &#125;</span><br>        <span class="hljs-comment">//         &#125;</span><br>        <span class="hljs-comment">//     &#125;</span><br>        <span class="hljs-comment">// &#125;</span><br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">num</span> <span class="hljs-operator">=</span> nums[i];<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; j &lt;= target; j++) &#123;<br>                <span class="hljs-keyword">if</span> (j &gt;= num) &#123;<br>                    dp[i][j] = dp[i - <span class="hljs-number">1</span>][j] | dp[i - <span class="hljs-number">1</span>][j - num];<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    dp[i][j] = dp[i - <span class="hljs-number">1</span>][j];<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <br>        <span class="hljs-keyword">return</span> dp[n - <span class="hljs-number">1</span>][target];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>优化空间：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">canPartition</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> nums.length, target = <span class="hljs-number">0</span>, max = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            target += nums[i];<br>            max = Math.max(max, nums[i]);<br>        &#125;<br>        <span class="hljs-keyword">if</span> ((target &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 奇数</span><br>        <span class="hljs-keyword">else</span> target /= <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">if</span> (max &gt; target) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><br>        <span class="hljs-type">boolean</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">boolean</span>[target + <span class="hljs-number">1</span>]; <span class="hljs-comment">// 0..i 的数字中是否存在方案使得和为 j</span><br><br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-literal">true</span>;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">num</span> <span class="hljs-operator">=</span> nums[i];<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> target; j &gt;= num; j--) &#123;<br>                dp[j] |= dp[j - num];<br>            &#125;<br>        &#125;<br><br>        <br>        <span class="hljs-keyword">return</span> dp[target];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="最长有效括号"><a href="#最长有效括号" class="headerlink" title="最长有效括号"></a>最长有效括号</h2><h3 id="动态规划-6"><a href="#动态规划-6" class="headerlink" title="动态规划"></a>动态规划</h3><p><code>0 &lt;= s.length &lt;= 3 * 10^4</code></p>
<p>给你一个只包含 <code>&#39;(&#39;</code> 和 <code>&#39;)&#39;</code> 的字符串，找出最长有效（格式正确且连续）括号子串的长度。</p>
<p>定义 dp[i] 表示以下标 <em>i</em> 字符结尾的最长有效括号的长度。</p>
<p>难点在于怎么思考状态转移方程。</p>
<p>想到如果是合法的括号，那么肯定是左右都有，那么是不是可以每次走两步</p>
<p><em>s</em>[<em>i</em>]=‘)’ 且 <em>s</em>[<em>i</em>−1]=‘(’，也就是字符串形如 “……()”，我们可以推出：dp[i]=dp[i−2]+2</p>
<p><strong>key：</strong> 两种有效的括号类型：（…）（…）（…），另一种为嵌套格式 （（…））</p>
<p>第一种可以 dp[i] = dp[i - 2] + 2，第二种则比较复杂。</p>
<p>考虑第一次遇到 … ））时，需要找到和右括号匹配的左括号，我们这里可以根据最优子结构得到 dp[i - 1] 代表了前一个右括号之前的有效括号，那么 i - dp[i - 1] - 1 的位置就是和当前右括号匹配的位置，如果这个位置是左括号，那么最长有效长度就可以 + 2，否则就不更新。</p>
<p><img  src="./6e07ddaac3b703cba03a9ea8438caf1407c4834b7b1e4c8ec648c34f2833a3b9-截屏2020-04-17下午4.26.34.png"  ><span class="image-caption">截屏2020-04-17下午4.26.34.png</span></p>
<p>同时还要考虑 …((…)) 的情况，也就是加上 dp[i - dp[i - 1] - 2]</p>
<p>于是有以下内容：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">longestValidParentheses</span><span class="hljs-params">(String s)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> s.length();<br>        <span class="hljs-type">int</span>[] dp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[n]; <span class="hljs-comment">// 以下标 i 结尾的最长子串长度</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">max</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">if</span> (s.charAt(i - <span class="hljs-number">1</span>) == <span class="hljs-string">&#x27;(&#x27;</span> &amp;&amp; s.charAt(i) == <span class="hljs-string">&#x27;)&#x27;</span>) &#123;<br>                <span class="hljs-comment">// 能够处理 ..()，但是无法处理 (())</span><br>                dp[i] = (i &gt;= <span class="hljs-number">2</span> ? dp[i - <span class="hljs-number">2</span>] : <span class="hljs-number">0</span>) + <span class="hljs-number">2</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (s.charAt(i - <span class="hljs-number">1</span>) == <span class="hljs-string">&#x27;)&#x27;</span> &amp;&amp; s.charAt(i) == <span class="hljs-string">&#x27;)&#x27;</span>) &#123;<br>                <span class="hljs-comment">// 这里处理 ...((...)) 的情况</span><br>                <span class="hljs-comment">// 判断 s[i] 是否有对应的左括号</span><br>                <span class="hljs-keyword">if</span> (i - dp[i - <span class="hljs-number">1</span>] - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; s.charAt(i - dp[i - <span class="hljs-number">1</span>] - <span class="hljs-number">1</span>) == <span class="hljs-string">&#x27;(&#x27;</span>) &#123;<br>                    <span class="hljs-comment">// 第一项对应 ((...)) 中的三个点</span><br>                    <span class="hljs-comment">// 最后一项是和匹配的括号的情况连起来，对应 ...(()) 中的三个点</span><br>                    <span class="hljs-comment">// dp[i] = dp[i - 1] + 2 + (i - dp[i - 1] - 2) &gt; 0 ? dp[i - dp[i - 1] - 2] : 0;</span><br>                    dp[i] = dp[i - <span class="hljs-number">1</span>] + <span class="hljs-number">2</span> + ((i - dp[i - <span class="hljs-number">1</span>] - <span class="hljs-number">2</span>) &gt; <span class="hljs-number">0</span> ? dp[i - dp[i - <span class="hljs-number">1</span>] - <span class="hljs-number">2</span>] : <span class="hljs-number">0</span>);<br>                &#125;<br>            &#125;<br>            max = Math.max(max, dp[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> max;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h3><p>如果用栈，那么关键在于对于 …(…)() 和 …(()) 这两种情况如何判断长度和判断连续。</p>
<p>对于连续来说，可以过一遍字符串即可，对于长度判断，要点在于，如果对于右括号没有对应的左括号时，说明需要另起炉灶，重新计算最大长度。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">longestValidParentheses</span><span class="hljs-params">(String s)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">max</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        Deque&lt;Integer&gt; stack = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;Integer&gt;();<br>        stack.push(-<span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; s.length(); i++) &#123;<br>            <span class="hljs-keyword">if</span> (s.charAt(i) == <span class="hljs-string">&#x27;(&#x27;</span>) &#123;<br>                stack.push(i);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                stack.pop();<br>                <span class="hljs-keyword">if</span> (stack.isEmpty()) &#123;<br>                    stack.push(i);<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    max = Math.max(max, i - stack.peek());<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> max;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="寻找两个正序数组的中位数3"><a href="#寻找两个正序数组的中位数3" class="headerlink" title="寻找两个正序数组的中位数3"></a>寻找两个正序数组的中位数<sup><a href="#fn_3" id="reffn_3">3</a></sup></h2><p>中位数定义：将一个集合划分为两个长度相等的子集，其中一个子集中的元素总是大于另一个子集中的元素。</p>
<pre><code>      left_part          |         right_part
A[0], A[1], ..., A[i-1]  |  A[i], A[i+1], ..., A[m-1]
B[0], B[1], ..., B[j-1]  |  B[j], B[j+1], ..., B[n-1]
</code></pre><p>根据中位数的定义，我们需要找到以上的划分（设两个数组总长度为偶数）使得</p>
<ul>
<li>$\text{len}(left_part) = \text{len}(right_part)$</li>
<li>$\max(left_part)=\max(right_part)$</li>
</ul>
<p>此时的中位数为：</p>
<script type="math/tex; mode=display">\text{median} = \frac{\max(left\_part)+\min(right\_part)}{2}</script><p>所以现在的问题关键在于寻找这样一个划分。要寻找这样一个划分需要根据这个划分满足的两个条件：</p>
<ul>
<li>左边元素共有 $i + j$ 个，右边元素共有 $(m-i)+(n-j)$ 个，所以由第一个式子可以得到 $i+j=(m-i)+(n-j)$。变形得到 $i+j=\frac{m+n}{2}$。假设 $m &lt; n$，即 B 数组长于 A 数组，则 $i\in[0,m]$，有 $j = \frac{m+n}{2}-i$ 且 $j \in [0,n]$，所以只要知道 $i$ 的值，那么 $j$ 的值也是确定的。</li>
<li>在 $(0, m)$ 中找到 $i$，满足 $A[i-1] \le B[j]$ 且 $A[i] \ge B[j-1]$ 。</li>
</ul>
<p>注意到第一个条件中，当 $i$ 增大的时候，$j$ 会减小以此来保证左右两部分的元素个数相同。同时 A、B 数组都是单调不递减的，所以一定存在一个最大的 $i$ 满足 $A[i-1] \le B[j]$。（当 $i$ 取 $i+1$ 时 $A[i] &gt; B[j-1]$）</p>
<p>所以问题转化为：找一个最大的 $i$ 使得 $A[i-1] \le B[j]$。</p>
<p>对于这个问题，我们容易枚举 $i$，同时 A、B 都是单调递增的，所以我们还能知道枚举出的 $i$ 是不是满足条件（$A[i-1] \le B[j]$），并从中找出满足条件的最大 $i$ 值即可。</p>
<p>对于两个数组总长度为奇数的情况，可以使得 $j = \lfloor \frac{m+n+1}{2}-i \rfloor$。</p>
<p>代码如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[warn(dead_code)]</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Solution</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">find_median_sorted_arrays</span>(nums1: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">i32</span>&gt;, nums2: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">i32</span>&gt;) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">f64</span> &#123;<br>        <span class="hljs-keyword">if</span> nums1.<span class="hljs-title function_ invoke__">len</span>() &gt; nums2.<span class="hljs-title function_ invoke__">len</span>() &#123;<br>            <span class="hljs-keyword">return</span> Solution::<span class="hljs-title function_ invoke__">find_median_sorted_arrays</span>(nums2, nums1);<br>        &#125;<br>        <span class="hljs-comment">// m &lt; n</span><br>        <span class="hljs-keyword">let</span> (m, n) = (nums1.<span class="hljs-title function_ invoke__">len</span>(), nums2.<span class="hljs-title function_ invoke__">len</span>());<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">left</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">right</span> = m;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">pos</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">median1</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">median2</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> left &lt;= right &#123;<br>            <span class="hljs-keyword">let</span> <span class="hljs-variable">i</span> = (left + right) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">let</span> <span class="hljs-variable">j</span> = (m + n + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> - i;<br>            <span class="hljs-keyword">let</span> <span class="hljs-variable">nums_im1</span> = <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> &#123; -<span class="hljs-number">0x3f3f3f3f</span> &#125; <span class="hljs-keyword">else</span> &#123; nums1[i - <span class="hljs-number">1</span>] &#125;;<br>            <span class="hljs-keyword">let</span> <span class="hljs-variable">nums_i</span> = <span class="hljs-keyword">if</span> i == m &#123; <span class="hljs-number">0x3f3f3f3f</span> &#125; <span class="hljs-keyword">else</span> &#123; nums1[i] &#125;;<br>            <span class="hljs-keyword">let</span> <span class="hljs-variable">nums_jm1</span> = <span class="hljs-keyword">if</span> j == <span class="hljs-number">0</span> &#123; -<span class="hljs-number">0x3f3f3f3f</span> &#125; <span class="hljs-keyword">else</span> &#123; nums2[j - <span class="hljs-number">1</span>] &#125;;<br>            <span class="hljs-keyword">let</span> <span class="hljs-variable">nums_j</span> = <span class="hljs-keyword">if</span> j == n &#123; <span class="hljs-number">0x3f3f3f3f</span> &#125; <span class="hljs-keyword">else</span> &#123; nums2[j] &#125;;<br>            <span class="hljs-keyword">if</span> nums_im1 &lt;= nums_j &#123;<br>                median1 = std::cmp::<span class="hljs-title function_ invoke__">max</span>(nums_im1, nums_jm1);<br>                median2 = std::cmp::<span class="hljs-title function_ invoke__">min</span>(nums_i, nums_j);<br>                left = i + <span class="hljs-number">1</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                right = i - <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-title function_ invoke__">if</span> (m + n) &amp; <span class="hljs-number">1</span> == <span class="hljs-number">0</span> &#123;<br>            (median1 + median2) <span class="hljs-keyword">as</span> <span class="hljs-type">f64</span> / <span class="hljs-number">2.0</span><br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            median1 <span class="hljs-keyword">as</span> <span class="hljs-type">f64</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="三数之和-1"><a href="#三数之和-1" class="headerlink" title="三数之和"></a>三数之和</h2><h3 id="朴素算法"><a href="#朴素算法" class="headerlink" title="朴素算法"></a>朴素算法</h3><p>排序之后三重循环，判断三个数之和是否为 $0$，时间复杂度 $O(n^3)$。</p>
<p>排序的目的是为了容易地去除重复数字，因为排序之后只需要判断当前和前一个元素是否相等就可以知道是否是重复数字。</p>
<h3 id="排序后双指针"><a href="#排序后双指针" class="headerlink" title="排序后双指针"></a>排序后双指针</h3><p>注意到排序之后整个数组是单调非递减的，我们需要 $a+b+c=0$，当固定了 $a$ 和 $b$ 的时候，$c$ 从大到小地判断是否有 $a+b+c=0$ 即可。看似是最外层对应 $a$ 的循环嵌套对应 $b$ 的循环，并在其中加上了 $c$ 递减的循环，但是实际上注意到当 $b$ 与 $c$ 是同一个元素时，如果仍然不满足 $a+b+c=0$，那么 $c$ 继续向左减小就与之前的数字重复了，所以对于每一次 $b$ 中的循环，最多运行 $n$ 次，外边再嵌套 $a$ 的循环，时间复杂度为 $O(n^2)$。</p>
<p>代码如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[warn(dead_code)]</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Solution</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">three_sum</span>(<span class="hljs-keyword">mut</span> nums: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">i32</span>&gt;) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">Vec</span>&lt;<span class="hljs-type">i32</span>&gt;&gt; &#123;<br>        nums.<span class="hljs-title function_ invoke__">sort</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">len</span> = nums.<span class="hljs-title function_ invoke__">len</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">ans</span> = <span class="hljs-type">Vec</span>::<span class="hljs-title function_ invoke__">new</span>();<br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..len &#123;<br>            <span class="hljs-comment">// 防止取到相同的数字</span><br>            <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> &amp;&amp; nums[i - <span class="hljs-number">1</span>] == nums[i] &#123;<br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">third</span> = len - <span class="hljs-number">1</span>;<br>            <span class="hljs-comment">// 注意这里开始位置是 i+1，目的是为了不与 a 取重</span><br>            <span class="hljs-keyword">for</span> <span class="hljs-variable">j</span> <span class="hljs-keyword">in</span> i + <span class="hljs-number">1</span>..len &#123;<br>                <span class="hljs-comment">// 注意这里判定条件是 j &gt; i+1 否则会取不到与 a 相同的数字</span><br>                <span class="hljs-keyword">if</span> j &gt; i + <span class="hljs-number">1</span> &amp;&amp; nums[j - <span class="hljs-number">1</span>] == nums[j] &#123;<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br>                <span class="hljs-keyword">while</span> j &lt; third &amp;&amp; nums[i] + nums[j] + nums[third] &gt; <span class="hljs-number">0</span> &#123;<br>                    third = third - <span class="hljs-number">1</span>;<br>                &#125;<br>                <span class="hljs-keyword">if</span> j == third &#123;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>                <span class="hljs-keyword">if</span> nums[i] + nums[j] + nums[third] == <span class="hljs-number">0</span> &#123;<br>                    ans.<span class="hljs-title function_ invoke__">push</span>(<span class="hljs-built_in">vec!</span>[nums[i], nums[j], nums[third]]);<br>                &#125;<br>            &#125;<br>        &#125;<br>        ans<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="盛最多水的容器4"><a href="#盛最多水的容器4" class="headerlink" title="盛最多水的容器4"></a>盛最多水的容器<sup><a href="#fn_4" id="reffn_4">4</a></sup></h2><script type="math/tex; mode=display">
area = (right - left) * \min (height[left], height[right])</script><p>由上面的公式可以知道，面积由两部分共同决定：</p>
<ul>
<li>宽度</li>
<li>高度</li>
</ul>
<p>所以考虑尽可能地增加宽度和高度。假设左指针指向的数为 $x$，右指针指向的数为 $y$，假设 $x &lt; y$，距离为 $t$，接下来进行具体分析：</p>
<ol>
<li>水量 $ area = \min(x, y) <em> t = x </em> t $，当左指针不变的时候，右指针无论在哪都不会影响容器的水量了，水量是固定的 $x*t$。</li>
<li>所以考虑左指针向右移动，这样才有可能取到更大的水量。</li>
<li>同理左指针指向的数大于右指针指向的数的时候，左移右指针才有可能取到更大的水量。</li>
<li>重复以上步骤就可以得到最大水量。</li>
</ol>
<p>总时间复杂度为 $O(n)$。</p>
<p>注解：</p>
<ul>
<li>对于双指针问题，两个指针的初始位置不一定都在最左或者最右，要灵活地设置指针位置。</li>
</ul>
<h2 id="最接近三数之和"><a href="#最接近三数之和" class="headerlink" title="最接近三数之和"></a>最接近三数之和</h2><p>与「盛最多水的容器」和「三数之和」类似，代码如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[warn(dead_code)]</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Solution</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">three_sum_closest</span>(<span class="hljs-keyword">mut</span> nums: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">i32</span>&gt;, target: <span class="hljs-type">i32</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i32</span> &#123;<br>        nums.<span class="hljs-title function_ invoke__">sort</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">len</span> = nums.<span class="hljs-title function_ invoke__">len</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">ans</span> = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">diff</span> = <span class="hljs-number">0x3f3f3f3f</span>;<br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..len &#123;<br>            <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> &amp;&amp; nums[i] == nums[i - <span class="hljs-number">1</span>] &#123;<br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">j</span> = i + <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">k</span> = len - <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">while</span> j &lt; k &#123;<br>                <span class="hljs-comment">//dbg!((i, j , k));</span><br>                <span class="hljs-keyword">let</span> <span class="hljs-variable">sum</span> = nums[i] + nums[j] + nums[k];<br>                <span class="hljs-keyword">if</span> sum == target &#123;<br>                    <span class="hljs-keyword">return</span> sum;<br>                &#125;<br>                <span class="hljs-keyword">let</span> <span class="hljs-variable">tmp</span> = (sum - target).<span class="hljs-title function_ invoke__">abs</span>();<br>                <span class="hljs-keyword">if</span> tmp &lt; diff &#123;<br>                    diff = tmp;<br>                    ans = sum;<br>                &#125;<br>                <span class="hljs-keyword">if</span> sum &gt; target &#123;<br>                    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">k0</span> = k - <span class="hljs-number">1</span>;<br>                    <span class="hljs-keyword">while</span> j &lt; k0 &amp;&amp; nums[k0] == nums[k] &#123;<br>                        k0 = k0 - <span class="hljs-number">1</span>;<br>                    &#125;<br>                    k = k0;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">j0</span> = j + <span class="hljs-number">1</span>;<br>                    <span class="hljs-keyword">while</span> j0 &lt; k &amp;&amp; nums[j0] == nums[j] &#123;<br>                        j0 = j0 + <span class="hljs-number">1</span>;<br>                    &#125;<br>                    j = j0;<br>                &#125;<br>            &#125;<br>        &#125;<br>        ans<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="合并K个升序链表"><a href="#合并K个升序链表" class="headerlink" title="合并K个升序链表"></a>合并K个升序链表</h2><p>使用优先队列即可。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::&#123;cmp::Reverse, collections::BinaryHeap&#125;;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">merge_k_lists</span>(lists: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">Option</span>&lt;<span class="hljs-type">Box</span>&lt;ListNode&gt;&gt;&gt;) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Option</span>&lt;<span class="hljs-type">Box</span>&lt;ListNode&gt;&gt; &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">priority_queue</span> = BinaryHeap::<span class="hljs-title function_ invoke__">new</span>();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">ret</span> = <span class="hljs-type">Box</span>::<span class="hljs-title function_ invoke__">new</span>(ListNode::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>));<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">ptr</span> = &amp;<span class="hljs-keyword">mut</span> ret;<br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">list</span> <span class="hljs-keyword">in</span> lists &#123;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">plist</span> = &amp;list;<br>            <span class="hljs-keyword">while</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(node) = plist &#123;<br>                priority_queue.<span class="hljs-title function_ invoke__">push</span>(<span class="hljs-title function_ invoke__">Reverse</span>(node.val));<br>                plist = &amp;node.next;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(<span class="hljs-title function_ invoke__">Reverse</span>(node)) = priority_queue.<span class="hljs-title function_ invoke__">pop</span>() &#123;<br>            ptr.next = <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-type">Box</span>::<span class="hljs-title function_ invoke__">new</span>(ListNode::<span class="hljs-title function_ invoke__">new</span>(node)));<br>            ptr = ptr.next.<span class="hljs-title function_ invoke__">as_mut</span>().<span class="hljs-title function_ invoke__">unwrap</span>();<br>        &#125;<br>        ret.next<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><blockquote id="fn_1">
<sup>1</sup>. <a href="https://leetcode-cn.com/problems/longest-palindromic-substring/solution/xiang-xi-tong-su-de-si-lu-fen-xi-duo-jie-fa-bao-gu">https://leetcode-cn.com/problems/longest-palindromic-substring/solution/xiang-xi-tong-su-de-si-lu-fen-xi-duo-jie-fa-bao-gu</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. <a href="https://oi-wiki.org/string/manacher/">https://oi-wiki.org/string/manacher/</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_3">
<sup>3</sup>. <a href="https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-s-114/">https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-s-114/</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_4">
<sup>4</sup>. <a href="https://leetcode-cn.com/problems/container-with-most-water/solution/sheng-zui-duo-shui-de-rong-qi-by-leetcode-solution/">https://leetcode-cn.com/problems/container-with-most-water/solution/sheng-zui-duo-shui-de-rong-qi-by-leetcode-solution/</a><a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a>
</blockquote>
]]></content>
      <tags>
        <tag>data structure, algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>爱的艺术笔记</title>
    <url>/uncategorized/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF/</url>
    <content><![CDATA[<h1 id="来自-Async-的-Tips"><a href="#来自-Async-的-Tips" class="headerlink" title="来自 Async 的 Tips"></a>来自 Async 的 Tips</h1><p>注意，不要过度，我们不必要太过迁就和顺从任何人。</p>
<p>人们不会珍惜轻易得到的东西，这些东西包括爱。</p>
<h1 id="爱是一门艺术"><a href="#爱是一门艺术" class="headerlink" title="爱是一门艺术"></a>爱是一门艺术</h1><h2 id="爱重要的是能力"><a href="#爱重要的是能力" class="headerlink" title="爱重要的是能力"></a>爱重要的是能力</h2><p>如果爱是一门艺术，那就要求人们有这方面的知识并付出努力。</p>
<p>大多数人认为爱情首先是自己能否被人爱，而不是自己有没有能力爱的问题。</p>
<p>因此对他们来说，关键是：我会被人爱吗？我如何才能值得被人爱？为了达到这一目的，他们采取了各种途径。男子通常采取的方法是在其社会地位所允许的范围内，尽可能地去获得名利和权力，而女子则是通过保持身段和服饰打扮使自己富有魅力；</p>
<p>而男女都喜欢采用的方式则是使自己具有文雅的举止，有趣的谈吐，乐于助人，谦虚和谨慎。</p>
<p>为了使自己值得被人爱而采用的许多方法与人们要在社会上获得成功所采用的方法雷同，即都是“要赢得朋友和对他人施加影响”。事实上，我们这个社会大多数人所理解的“值得被人爱”无非是赢得人心和对异性有吸引力这两种倾向的混合物而已。</p>
<p>产生在爱这件事上一无可学这一看法的第二个原因是人们认为爱的问题是一个对象问题，而不是能力问题。他们认为爱本身十分简单，困难在于找到爱的对象或被爱的对象。</p>
<p>一些事实：</p>
<ul>
<li><p>人与人之间的爱情关系也遵循同控制商品和劳动力市场一样的基本原则——等价交换。</p>
</li>
<li><p>人们往往把这种如痴如醉的入迷，疯狂的爱恋看作是强烈爱情的表现，而实际上这只是证明了这些男女过去是多么地寂寞。</p>
</li>
</ul>
<p>要认识爱情是一门艺术。人们要学会爱情，就得像学其他的艺术——如音乐，绘画，木工或者医疗艺术和技术一样的行动。</p>
<h1 id="爱情理论"><a href="#爱情理论" class="headerlink" title="爱情理论"></a>爱情理论</h1><h3 id="一、爱情是对人类生存问题的回答"><a href="#一、爱情是对人类生存问题的回答" class="headerlink" title="一、爱情是对人类生存问题的回答"></a>一、爱情是对人类生存问题的回答</h3><p>爱情的每一个理论必须要以人的理论、人的生存理论为前提。我们所能看到的动物的爱情或者更确切地说动物身上类似爱情的东西，主要是动物的一部分本能。在人身上只能看到这一本能的残余。人的存在的根本要点是人超越了动物界，超越了本能的适应性，脱离了自然——尽管人永远不可能完全脱离自然。</p>
<p>经历过孤寂的人必然会有恐惧感。实际上孤寂感是每种恐惧的根源。孤寂意味着与外界没有联系，不能发挥人的力量，意味着一筹莫展，不能把握世界，事物和人；意味着世界把我淹没，而我只能听之任之。所以孤寂是引起强烈恐惧感的根源，同时孤寂还会引起羞愧和负罪的感觉。</p>
<p>因此对人来说最大的需要就是克服他的孤独感和摆脱孤独的监禁。人在达到这一目的过程中的完全失败就会导致人的疯狂，因为人只有通过完全彻底地脱离周围世界，以至于不再感到与世隔绝，他对彻底孤独的恐惧感才会得到克服——因为他与之隔绝的世界从他的生活中消失了。</p>
<p>人——所有时代和生活在不同文化之中的人——永远面临同一个问题，即：如何克服这种孤独感，如何超越个人的天地，实现人类的大同。</p>
<p>人们对这一问题的回答在一定的范围则取决于人所达到的个性的高度。在一个孩子身上，“我”字几乎还没有形成。每个孩子都同母亲融为一体，只要母亲在他身旁，他就不会有孤独感。他的孤独感通过母亲的存在，同母亲的乳房和肌肤的接触而得到和缓。一直到孩子发育到产生孤独感和个性这个阶段，母亲的存在才不足以消除他的孤独感，他必须以其他的方法克服这种孤独感。</p>
<p>人类在孩提时代几乎是以同样的方式体验与大自然的和谐。大地、动物和植物完全是人的世界。人把自己看作和动物完全一致，这表现在人装扮成动物以及崇拜图腾或其他的动物神。但人类越脱离原始的纽带，就越疏远自然世界，就越要寻找摆脱孤独的途径。</p>
<p>达到这一目的的一种途径是不同形式的纵欲。例如自我引起——或借助于毒品——的恍惚状态就是一种形式的纵欲。</p>
<p>就是最穷的罗马人也能自豪地说我是罗马的公民罗马和罗马帝国就是他的家，他的祖国和世界。在今日的西方社会，同一组人结合仍然是克服孤独感最常用的方法。在这种结合中，参加者为了使自己属于这一组人而失去了大部分个性。如果我与他人完全一样，我的感情、思想与他人一致，我的衣着、习惯和看法都与这一组人的楷模看齐，我就可得救，就不会再经历可怕的孤独。</p>
<p>在当今资本主义社会，平等的概念发生了变化。今天“平等”指的是机器——也就是失去个性的人的平等。平等意味着“一个模式”而不是“统一”。这是一个抽象体的同一模式，是做同样的工作、寻求同样的享受，读同样的报纸，有同样的思想感情的人的模式。</p>
<p>现代社会鼓吹实现非个性化的平等理想，因为这个社会需要“人——原子”，这些人原子相互之间没有区别，汇集起来也能毫无摩擦地顺利地发挥作用，他们都服从同一个命令，尽管如此，每个人却都确信他们是在按自己的意愿办事。就象现代化的大规模生产要求产品规格化，社会的发展也要求人的规格化，并把这称为“平等”。</p>
<p>通过同一化达到人与人的结合既不是强烈的也不是激烈的过程，而是按照一个刻板的公式十分平静地进行。</p>
<p>我们是把爱情看作是对人类生存问题的成熟回答，还是指爱情的不成熟形式，也就是人们称为共生有机体的结合呢？下面我只是把前者看作是爱情，但我们的讨论却要从后者开始。</p>
<p>共生有机体结合的生物楷模是怀孕的母亲同胚胎之间的关系。他们既是两体，又是一体。他们生活在一起(共生)，他们相互需要。胎儿是母亲的一部分，并从她身上得到他所需要的一切，所以母亲就是他的世界。她抚养和保护胎儿，同时她自己的生活也因胎儿的存在而得到一种升华。在生理性的共生有机体的结合中，两者的身体互不依赖，但在心理上却相互依赖。</p>
<p>共生有机体结合的消极形式是服从——医学名词就是被虐癖。有被虐癖的人通过把自己变成他的引导者、启示者、保护者的一部分使自己摆脱孤独和与世隔绝感。保护者就是他的生命，没有保护者他就无法生存。不论保护者是人还是神，总之他的威力超越一切。他主宰一切，而自己什么也不是，被虐淫者必须成为其保护者的一部分，因为只有这样他才能分享保护者的伟大、威力和安全。被虐淫者从来不作任何决定和进行任何冒险，他从不孤独，但也决不独立。他不是一个完整的人，可以说还没有完全诞生。在宗教的语言中把崇拜的对象称为偶像，而被虐淫者对其保护者的崇拜超过了对偶像的崇拜。这种崇拜可以同生理要求和性要求相混合，在这种情况下被虐淫者的服从不仅是想象力的产物，而且是一种与全身有关的生理需要。另外还有屈服于命运、疾并有节奏感的音乐或者屈服于由吸毒和催眠状态引起的极度兴奋等病状——在所有这些情况下，犯病的人失去了他的完整性，把自己成为一个人或一件事物的工具；从而使他不用对生存的问题作出独立的和自由的回答。</p>
<p>共生有机体结合的积极形式是控制另一个人——与被虐癖相应的医学名词是施虐癖。施虐淫者就是通过把另一个人成为他自己的一部分而摆脱孤独，他吞并他的崇拜者，从而使自己身价百倍。</p>
<p>就象被他控制的人脱离不了他一样，施虐淫者也离不开他的崇拜者，双方都不能失去对方。区别只在于——施虐淫者命令、利用、损害和欺压对方，而对方则乐于被他左右。从现实的角度来看似乎他俩之间存在着很大的差别，但从更深的意义来看他俩的区别不比他俩的共同点重要，他俩的共同点是在结合的过程中双方都失去其独立性行完整性。如果我们理解这一点，就不难确定一般来说一个人会根据不同的对象作出施虐癖和被虐癖的反应。希特勒对其他人首先是施虐淫者，但面对他的命运、历史和自然的“威力”作出的却是被虐淫者的反应。</p>
<p>同共生有机体结合相对立的是成熟的爱情，那就是在保留自己完整性和独立性的条件下，也就是保持自己个性的条件下与他人合二为一。人的爱情是一种积极的力量，这种力量可以冲破人与人之间的高墙并使人与人结合。爱情可以使人克服孤寂和与世隔绝感，但同时又使人保持对自己的忠诚，保持自己的完整性和本来的面貌。在爱情中出现了两个生命合为一体，却依然保持两体的怪现象。</p>
<p>如果我们说，爱情是一项“积极的活动”，我们就会遇到“积极的活动”这个词有双重意义的问题。这个词的现代用法一般就是指人们通过付出劳动改变现存状态的行为。所以经商的人，学医的人，流水作业线上的工人，做椅子的木匠或者运动员都是积极活动的人。他们活动的共同点都是为了达到一个外部的目的。但这里我们都没有考虑产生积极性的根源。我们可以举一个例子加以说明。</p>
<p>有的人由于内心极度的不安或者孤独而狂热地工作，有的人则是为了升官发财。在这种情况下这个人就是一种狂热、一种热情的奴隶，而他的“积极性”实际上是一种“消极性”，因为他是受外力的驱使。他是一个受苦的人，而不是一个“行动”的人。另一方面人们往往把一个坐在椅子上沉思默想、观察和体验自己以及自己同世界关系的人看作是“消极的”，因为他什么也不“干”。实际上这种精神高度集中的禅坐是最高的积极性，是灵魂的积极性，只有那些内心自由和独立的人才能做到这点。“积极的活动”这一概念的一个意义，也就是现代应用的意义是指为了达到外部的目的而付出努力。这个词的另一个意义是运用人的蕴藏在内部的力量，不管是否达到外部的变化。斯宾诺莎精辟地解释了这个词的第二种意义。他把情绪分成积极的和消极的两种，分成“行动”和“狂热”。如果一个人是在积极的情绪支配下行动，他就是自由的，是情绪的主人。如果他是被一种消极的情绪所支配，那他就是受外力驱使者，是他自己都不了解的动机的对象。这样，斯宾诺莎最终得出结论认为，美德和控制自己是一回事。妒忌、野心和每种形式的贪婪是热情和狂热；相反爱情是一种行动，是运用人的力量，这种力量只有在自由中才能得到发挥，而且永远不会是强制的产物。</p>
<p>爱情是一种积极的，而不是消极的情绪。一般来说可以用另一个说法来表达，即爱情首先是给而不是得。</p>
<p>什么是“给”？这个问题看起来似乎很容易回答，实际上却很复杂并有双层意义。十分流行的误解是把“给”解释为放弃，被别人夺走东西或作出牺牲。一个性格还没有超越接受、利用或者贪婪阶段的人对给的理解就是这样。一个“重商主义”的人也准备给，但一定要通过交换。只“给”而没有“得”对他来说就是欺骗。那些基本上是非生产性性格结构的人则会有一种被别人拿走东西的感觉。因此这种类型的大多数人拒绝给予别人东西。而有些人却又把“给”变成一种自我牺牲的美德。他们认为，正因为“给”是痛苦的，所以应该这么做。给的美德就是准备牺牲，对他们来说，“给”比“得”好这一准则就是意味着宁可忍受损失也不要体验快乐。</p>
<p>有创造性的人对“给”的理解完全不同。他们认为“给”是力量的最高表现，恰恰是通过“给”，我才能体验我的力量，我的“富裕”，我的“活力”。体验到生命力的升华使我充满了欢乐。我感觉到自己生气勃勃，因而欣喜万分。“给”比“得”带来更多的愉快，这不是因为“给”是一种牺牲，而是因为通过“给”表现了我的生命力。</p>
<p>如果我们把这一原则用来解释各种特殊的现象，就不难认识这一原则的有效性。最基本的例子可以在性范畴里找到。男子性行为的最高峰就是一种给的行为：男子把自己的性器官交给女子，在达到性高潮的一刹那，他把精液给予对方。只要他不是阳痿，他就必须这么做。如果他不能给，他就是阳痿。女子也是如此，只不过表现形式复杂一点罢了。女子交出自己，她打开通向女性内部的大门，在接受的同时她也给予，如果她没有能力给，而只能得，她就是性冷淡。在女子身上给的行为还表现在她作为母亲的作用上。她把她的养料给予她肚中的胎儿，后来又给婴儿喂奶和给予母体的温暖。对女子来说不能给是极其痛苦的。</p>
<p>在物质世界范畴内给是财富。不是拥有财物的人是富裕的，而是给予他人东西的人才是富裕者。害怕受到损失的吝啬鬼，不管他拥有多少财产，从心理学角度来看，他是一个贫穷和可怜的人。愿意把自己的东西给予他人的人却是富有的，他感觉到自己是一个有能力帮助别人的人。只有那些连生活必需品都没有的人才不能体验帮助别人的乐趣。但是日常生活经验告诉我们，衡量有没有足够生活必需品的标准既取决于人的实际财产，也取决于人的性格本质。众所周知穷人往往比富人更愿意给。尽管如此，超过一定限度的贫困往往使许多人无法给，恰恰这一点是十分令人懊丧的——这不仅仅是因为从中可以看到穷人的贫困，同时也是因为穷人被剥夺了给所带来的欢乐。</p>
<p>但给的最重要范畴还不是物质范畴，而是人所具有的特殊范畴。一个人究竟能给予别人什么呢？他可以把他拥有的最宝贵的东西，他的生命给予别人。但这并不一定意味着他一定要为别人献出自己的生命，而是他应该把他内心有生命力的东西给予别人。他应该同别人分享他的欢乐、兴趣、理解力、知识、幽默和悲伤——简而言之一切在他身上有生命力的东西。通过他的给，他丰富了他人，同时在他提高自己生命感的同时，他也提高了对方的生命感。他给并不是为了得，但是通过他的给，不可避免地会在对方身上唤起某种有生命力的东西。因此他的给同时也包括了使接受者也成为一个给的人，而双方都会因为唤醒了内心的某种生命力而充满快乐。在给的行为中诞生了新的东西，给和得的人都会感谢这新的力量。这一点表现在爱情上就是：没有生命力就是没有创造爱情的能力。马克思极其优美地表达了上述思想。他说：“如果你以人就是人以及人同世界的关系是一种充满人性的关系为先决条件，那么你只能用爱去换爱，用信任换取信任。如果你想欣赏艺术，你必须是一个有艺术修养的人；如果你想对他人施加影响，你必须是一个有艺术修养的人；如果你想对他人施加影响，你必须是一个能促进和鼓舞他人的人。你同人及自然的每一种关系必须是你真正个人生活的一种特定的、符合你的意志对象的表现。如果你在爱别人，但却没有唤起他人的爱，也就是你的爱作为一种爱情不能使对方产生爱情，如果作为一个正在爱的人你不能把自己变成一个被人爱的人，那么你的爱情是软弱无力的，是一种不幸。”</p>
<p>不仅在爱情上“给”意味着“得”。教师向他的学生学习，演员受到观众的鼓舞，精神分析学家通过治愈他人的病而治愈自己的病也都如此，先决条件是给的人不应该把对方看作是他帮助的对象，而应该同对方建立一种真正的、创造性的紧密关系。</p>
<p>有没有能力把爱情作为一种给的行为取决于人的性格发展，这一事实似乎没有必要加以强调了。取得这一能力的先决条件是人要有一种占主导地位的生产性倾向。持有这种态度的人就克服了他的依赖性、自恋性（“自恋”这一概念是由弗洛伊德提出的，弗洛伊德把人的自我欣赏叫做“自恋”，他认为，“自恋”必先于他恋，这主要表现在儿童把与生俱来的里比多（指心能，尤其是性本能的能）用到自己身上。——译者注）以及剥削别人的要求，并能找到对自己的人性力量的信赖以及达到目的的勇气。如果缺乏这些特点，人们就害怕献出自己，也就是害怕去爱。</p>
<p>爱情的积极性除了有给的要素外，还有一些其他的基本要素。这些要素是所有爱的形式共有的，那就是：<strong>关心、责任心、尊重和了解</strong>。</p>
<p>在母爱中关心的要素表现得最为突出。如果有一个母亲拒绝给孩子喂食、洗澡和关心他身体的舒适，那么无论这位母亲如何强调她对孩子的爱，也不会有人相信她。但如果她关心孩子，她的爱就令人可信了。对动物和植物的爱亦是如此。如果有一位妇女对我们说她很爱花，可是我们却发现她忘记浇花，我们就不会相信她说的话。爱情是对生命以及我们所爱之物生长的积极的关心。如果缺乏这种积极的关心，那么这只是一种情绪，而不是爱情。爱情的这一要素在《约拿书》中得到很美的描绘。上帝吩咐约拿去尼尼微，向那里的居民宣布，如果他们不改邪归正，他们就将受到惩罚。约拿却不愿行使这一使命，他逃跑了，因为他担心尼尼微的居民将会悔过，从而求得上帝的宽恕。约拿是一个执法从严的人，但不是一个爱人之人。在他逃亡的路上，他发现自己躲在一条大鱼的肚子里，这条大鱼象征着隔绝和监禁，正是由于约拿缺乏仁爱和恻隐之心，所以才被送到这儿。上帝拯救了他，约拿去到尼尼微，向那里的居民宣告上帝的话，这时正如约拿担心的那样，尼尼微的居民回心转意，虔诚忏悔，上帝原谅了他们，答应不使全城覆没。约拿大为不悦和失望，他要看到“正义”，而不是仁爱。最后他坐在一棵树的阴影底下重又找回失去的安宁。这棵树本是上帝让它长高，好替约拿遮挡灼热的阳光。这时上帝却让这棵树枯死了，约拿十分沮丧，埋怨上帝。上帝回答说：“你为那棵一夜长、一夜死的树惋惜，虽然你既没有栽活它，也没有关心它。为什么我就不能惋惜尼尼微城内那十二万好坏不分的居民和那许许多多的动物呢？”上帝向约拿解释道，爱的本质是创造和培养，爱情和劳动是不可分割的。人们爱自己劳动的成果，人们为所爱之物而劳动。</p>
<p>关心和关怀还包括爱情的另一方面，即责任心。今天人们常常把责任心理解为是义务，是外部强加的东西。但是责任心这个词的本来意义是一件完全自觉的行动，是我对另一个生命表达出来或尚未表达出来的愿望的答复。“有责任”意味着有能力并准备对这些愿望给予回答。约拿对尼尼微的居民没有责任心，像该隐一样，他同样会提出这一问题“难道我应该是我弟弟的看守吗？”。一个爱的人的回答是，我兄弟的生命不仅与他自己有关，而且也同我有关。我应对其他的人负责就像对自己负责一样。这种责任心在母子关系中主要表现在母亲对孩子生理上的要求的关心。在成人之间则也包括关心对方的精神要求。</p>
<p>如果爱情没有第三个要素：尊重，那责任心就很容易变成控制别人和奴役别人。尊重别人不是惧怕对方。尊重这个词的出处就是有能力实事求是地正视对方和认识他独有的个性。尊重就是要努力地使对方能成长和发展自己，因此尊重决无剥削之意。我希望一个被我爱的人应该以他自己的方式和为了自己去成长、发展，而不是服务于我。如果我爱他人，我应该感到和他一致，而且接受他本来的面目，而不是要求他成为我希望的样子，以便使我能把他当作使用的对象。只有当我自己达到独立，在没有外援的情况下独立地走自己的路，即不想去控制和利用别人，只有在这种情况下，尊重对方才成为可能。只有在自由的基础上才会有爱情，正像在一首古老的法国歌曲中唱的那样“爱情是自由之子，永远不会是控制的产物”。</p>
<p>人们只有认识对方，了解对方才能尊重对方。如果不以了解为基础，关心和责任心都会是盲目的，而如果不是从关怀的角度出发去了解对方，这种了解也是无益的。了解的方式多种多样。成为爱情一要素的了解是要深入事物的内部，而不是满足于一知半解。我只有用他人的眼光看待他人，而把对自己的兴趣退居二位。我才能了解对方。譬如：我可以知道这个人在生气，即使他自己不表露出来。但我还可以更进一步地去了解他，然后就知道，他很害怕和不安，他感到孤独和受到良心的谴责。这样我就明白他的生气只是他内部更深的东西的反映，这时我眼中的他不再是一个发怒的人，而是一个处在恐惧和惶恐不安之中的受苦的人。</p>
<p>了解同爱情还有另一个基本的关系。希望同另一个人结合以逃避自我孤独的监禁同另一个完全符合人性的愿望有紧密的联系，那就是认识“人的秘密”。生命从其纯生物的角度来看是一个奇迹和秘密，而在人的范围内每个人对自己和对别人都是一个不可解答的秘密。我们认识自己，但尽管作了一切努力还是不认识自己，我们认识他人，但我们还是不认识他们，因为我们和他们都不是一回事。我们越深入我们生命的深处或另一个人的生命深处，我们离认识生命的目标就越远。尽管如此，我们不能阻止这种深入了解人的灵魂的秘密、了解人的核心，即“自我”的愿望将继续存在。</p>
<p>有一种可以认识这一秘密的令人绝望的可能性——那就是拥有掌握对方的全部权力，利用这种权力我可以随心所欲地支配他，让他按照我的意志去感受，去思想，把他变成一样东西，变成我的东西，我的财产。在这方面最明显的表现就是施虐淫者的极端作法，施虐淫者要求并能使一个人受苦，他折磨和迫使那个人泄露他的秘密。要求发现人的秘密是恣意暴行和破坏狂的基本动机。艾萨克——巴比尔(艾萨克——巴比尔(1894——1941)，苏联作家。——译者注)很清楚地表达了这一思想。他摘引俄国国内战争时一个军官的话，这个军官刚刚把他过去的主人踩死。军官说：“用一颗子弹——我想说——用一颗子弹只能把这个家伙干掉……开枪是永远不能深入他的灵魂，到达他作为一个人和有灵魂的地方。但我毫无顾忌，我已经不止一次踩死敌人，每次都超过一个小时。你知道吗——我想知道，生命到底是什么，我们天天遇到的生命到底是什么？”</p>
<p>在孩子身上我们经常能看到这条通向知识的捷径。孩子随手拿起一样东西，把它弄坏，以便认识这样东西。譬如他抓到一个蝴蝶，就很残忍地把翅膀折断，他要认识蝴蝶，迫使它交出自己的秘密。在这儿残暴有一个较深的动机：那就是希望认识事物和生命的秘密。</p>
<p>认识秘密的另一条途径是爱情。爱情是积极深入对方的表现。在这一过程中，我希望了解秘密的要求通过结合得到满足。在结合的过程中，我认识对方，认识自己，认识所有的人，但还是“一无所知”。我对生命的了解不是通过思想传导的知识，而是通过人唯一可以使用的方式——通过人与人的结合。施虐癖的产生是为了了解秘密，但却一无所得。我把一个生命一块一块的解体，我所能达到的就是这一生命被破坏。只有爱情才能带给我知识，在结合的过程中回答我提出的问题。在爱情中，在献身中，在深入对方中，我找到了自己，发现了自己，发现了我们双方，发现了人。</p>
<p>德尔斐的箴言“认识你自己”表达了我们要求认识自己和他人的愿望。这是全部心理学的渊源。因为这一愿望是要认识完整的人，认识他内心最深处的秘密，所以通常的知识，由思想传导的知识不能满足这一愿望。即使我们对自己的了解比现在高出一千倍，也不可能深入事物的最本质的东西。我们对自己是一个迷，别人对我们来说也永远会是一个迷。达到全部了解人的唯一途径是思想上的认识，也就是心理学的知识是实现通过爱情达到全面了解的一个条件。我必须客观地去认识对方和自己，以便使自己能够看到对方的现实状态或者能够克服幻想，克服我想象中的被歪曲了的他的图像。我只有客观地认识一个人，我才能在爱中了解他的真正本质。</p>
<p>另外我们还知道，我们永远不可能靠智力来了解人和宇宙的秘密，但可以通过爱情去把握它。心理学作为一门科学有其局限性。就像神学的逻辑结论是神秘主义，心理学的最终结论就是爱。</p>
<p>关心、责任心、尊重和了解是相互依赖的。在成熟的人身上可以看到这些态度的集中表现。成熟的人就是指能够创造性地发挥自己力量的人。成熟的人只想拥有他自己的劳动果实，放弃了获取全力和全知的自恋幻想，并有一种谦恭的态度。这一态度的基础是他内心的力量，单单这股力量就能使他进行真正的、创造性的劳动。</p>
<h3 id="二、父母和孩子之间的爱"><a href="#二、父母和孩子之间的爱" class="headerlink" title="二、父母和孩子之间的爱"></a>二、父母和孩子之间的爱</h3><p>母爱就其本质来说是无条件的。母亲热爱新生儿，并不是因为孩子满足了她的什么特殊的愿望，符合她的想象，而是因为这是她生的孩子。（我在这里提到的母爱或者父爱都是指“理想典型”，也就是马克斯——韦伯提到了的或者荣格的原型意义上的理想典型，而不是指每个母亲和每个父亲都以这种方式爱孩子。我更多的是指在母亲和父亲身上体现的那种本质。)无条件的母爱不仅是孩子，也是我们每个人最深的渴求。从另一个角度来看通过努力换取的爱往往会使人生疑。人们会想：也许我并没有给那个应该爱我的人带来欢乐，也许会节外生枝——总而言之人们害怕这种爱会消失。此外靠努力换取的爱常常会使人痛苦地感到：我之所以被人爱是因为我使对方快乐，而不是出于我自己的意愿——归根结蒂我不是被人爱，而是被人需要而已。鉴于这种情况，因此我们所有的人，无论是儿童还是成年人都牢牢地保留着对母爱的渴求，是不足为奇的。大多数的孩子有幸得到母爱(我们以后再谈在什么程度上得到母爱。）而成人身上的这种渴望更难得到实现。在令人满意的发展过程中，这种渴望始终是性爱的一个成分；但也经常出现在宗教形式，或者更多的是出现在神经病形式中。</p>
<p>同父亲的关系则完全不同。母亲是我们的故乡，是大自然、大地和海洋。而父亲不体现任何一种自然渊源。在最初几年内孩子同父亲几乎没有什么联系，在这个阶段父亲的作用几乎无法同母亲相比。父亲虽然不代表自然世界，却代表人类生存的另一个极端：即代表思想的世界，人所创造的法律、秩序和纪律等事物的世界。父亲是教育孩子，向孩子指出通往世界之路的人。</p>
<p>同父亲作用紧密相关的是另一个同社会经济发展有关的作用。随着私有制以及财产由一个儿子继承的现象出现，父亲就对那个将来要继承他财产的人特别感兴趣。父亲总是挑选他认为最合适的儿子当继承人，也就是与他最相像，因而也是最得他欢心的那个儿子。父亲是有条件的爱。父亲的原则是：“我爱你，因为你符合我的要求，因为你履行你的职责，因为你同我相像。”正如同无条件的母爱一样，有条件的父亲有其积极的一面，也有其消极的一面。消极的一面是父爱必须靠努力才能赢得，在辜负父亲期望的情况下，就会失去父爱。父爱的本质是：顺从是最大的道德，不顺从是最大的罪孽，不顺从者将会受到失去父爱的惩罚。父爱的积极一面也同样十分重要。因为父爱是有条件的，所以我可以通过自己的努力去赢得这种爱。与母爱不同，父爱可以受我的控制和努力的支配。</p>
<p>父母对孩子的态度符合孩子的要求。婴儿无论从身体还是心理上都需要母亲的无条件的爱和关怀。在六岁左右孩子就需要父亲的权威和指引。母亲的作用是给予孩子一种生活上的安全感，而父亲的任务是指导孩子正视他将来会遇到的种种困难。一个好母亲是不会阻止孩子成长和不会鼓励孩子求援的。母亲应该相信生活，不应该惶恐不安并把她的这种情绪传染给孩子。她应该希望孩子独立并最终脱离自己。父爱应该受一定的原则支配并提出一定的要求，应该是宽容的、耐心的，不应该是咄咄逼人和专横的。父爱应该使孩子对自身的力量和能力产生越来越大的自信心，最后能使孩子成为自己的主人，从而能够脱离父亲的权威。一个成熟的人最终能达到他既是自己的母亲，又是自己的父亲的高度。他发展了一个母亲的良知，又发展了一个父亲的良知。母亲的良知对他说：“你的任何罪孽，任何罪恶都不会使你失去我的爱和我对你的生命、你的幸福的祝福。”父亲的良知却说：“你做错了，你就不得不承担后果；最主要的是你必须改变自己，这样你才能得到我的爱。”成熟的人使自己同母亲和父亲的外部形象脱离，却在内心建立起这两个形象。同弗洛伊德的“超我”理论相反，人不是通过合并父亲和母亲，从而树立起这两个形象，而是把母亲的良知建筑在他自己爱的能力上，把父亲的良知建筑在自己的理智和判断力上。成熟的人既同母亲的良知，又同父亲的良知生活在一起，尽管两者看上去互为矛盾。如果一个人只发展父亲的良知，那他会变得严厉和没有人性；如果他只有母亲的良知，那他就有失去自我判断力的危险，就会阻碍自己和他人的发展。</p>
<p>人从同母亲的紧密关系发展到同父亲的紧密关系，最后达到综合，这就是人的灵魂健康和达到成熟的基础如果人不是这么发展就会导致神经玻限于篇幅，我不可能在这儿详细解释我的这一观点，只能简单扼要地提一下。</p>
<p>譬如造成神经病的一个原因可能是一个男孩有一个十分慈爱，却又很娇惯他的母亲，同时又有一个性格懦弱或者对孩子不感兴趣的父亲。在这种情况下，小男孩会牢牢地抓住同母亲的联系，发展成为一个十分依赖母亲的人。这种人往往孤立无援，需要得到保护，不可能获得父亲的一些特点：如纪律、独立性和驾驭生活的能力。他就会企图在所有的人身上寻找“母亲”的形象，有时在妇女身上，有时在有权威的男子身上。反之，如果母亲性情冷淡、麻木不仁或者十分专制，孩子就会把对母爱的需要转移到父亲身上，就会变成单一的向父亲方向发展的人。这样的人往往只服从于法律、秩序、权威的原则，却没有能力希望或者得到无条件的爱。如果他的父亲很有权威，同他的关系又很密切，就更会加强他的这一发展。其他的调查也得出这样的结论：即某些神经病形式，如强迫性神经病同患者的单一父亲联系有关，而另一些病状，如歇斯底里、酗酒，不能面对现实生活和厌世则是同母亲的单一联系所致。</p>
<h3 id="三、爱的对象"><a href="#三、爱的对象" class="headerlink" title="三、爱的对象"></a>三、爱的对象</h3><p>爱首先不是同一个特殊的人的关系，而更多的是一种态度，性格上的一种倾向。这种态度决定一个人同整个世界，而不是同爱的唯一“对象”的关系。如果一个人只爱他的对象，而对其他的人无动于衷，他的爱就不是爱，而是一种共生有机体的联系或者是一种更高级意义上的自私。尽管如此大多数人都认为爱情取决于对象，而不是能力。他们甚至认为专爱一个人就是强烈爱情的证明。我们在上面已经提到过这一错误的结论。正因为人们不是把爱情看作是一种积极的行动，灵魂的一股力量，所以他们认为只要找到爱的对象就行，别的东西自然而然就会产生。可以把这一态度同想画一张画的人作一比较：这个人虽然想画画，但他不是去学绘画这门艺术，而是强调他首先要找到他愿意画的合适的对象。如果他找到了这么一样东西，他也就能画了。如果我确实爱一个人，那么我也爱其他的人，我就会爱世界，爱生活。如果我能对一个人说：“我爱你”，我也应该可以说：“我在你身上爱所有的人，爱世界，也爱我自己。”</p>
<p>认为爱情是一种同所有人相关，而不是只关系一个人的观点并不意味着不同形式的爱情在爱情的对象方面没有区别。</p>
<h4 id="1、博爱"><a href="#1、博爱" class="headerlink" title="1、博爱"></a>1、博爱</h4><p>一切爱的形式都以博爱为基础。作者指的博爱就是对所有的人都有一种责任感，关心、尊重和了解他人，也就是愿意提高其他人的生活情趣。</p>
<h4 id="2、母爱"><a href="#2、母爱" class="headerlink" title="2、母爱"></a>2、母爱</h4><p>虽然对母亲的动机各有解释，但最重要的动机是我们称之为“超越自己”的追求。这一追求属于人的最基本要求，并以人的觉悟和下列事实为基础：即人对自己的纯生物作用不满，他不能忍受自己仅仅是被扔进这一世界的小卒。他一定要感到自己是创造者，是能超越处于被创造者消极地位的生命。满足这一要求有许多可能性，最自然和最基本的途径就是母亲对自己创造物的关怀和爱。在孩子身上母亲超越了自我，她对孩子的爱使她的生活产生新的意义。(正因为男子不能通过生育来满足超越自己的要求，所以他只能通过用双手创造物体和创造思想来证明他的创造能力。)</p>
<p>但是孩子必须长大，必须脱离母体和母亲的乳房，必须成为一个完整的、独立的生命。母亲的真正本质在于关心孩子的成长，这也就意味着也关心母亲和孩子的分离。这里我们就可以看到母爱和性爱的区别。在性爱中两个迄今为止分开的人结合在一起，而在母亲中过去是一体的两个人分开了。母爱不仅应该允许这一分离，而且还应该希望并促成这一分离。只有在这个阶段，母爱才成为一项艰巨的任务，因为这时就要求母亲无私并能贡献出一切，除了被爱者的幸福一无所求，但恰恰在这点上许多母亲都失败了。自恋的、专制的和贪婪的妇女在孩子尚小的时候，可以是一个很疼爱孩子的母亲。但是当孩子处于同母亲分离的阶段时，只有那些真正有能力爱的妇女，那些觉得给比得更幸福的妇女，那些生命之根底很扎实的妇女才会继续是一个疼爱孩子的母亲。</p>
<p>对正在成长的孩子的爱，这种忘我无私的母爱也许是爱的最困难的形式。但是由于母亲对孩子的爱是那么自然，所以往往给人一种容易做到的假象。正因为难以做到这点，所以只有那些有能力爱的妇女，那些热爱丈夫，热爱其他孩子，热爱陌生人和人类的妇女才能成为真正爱孩子的母亲。在这个意义上，没有能力爱的妇女当她们的孩子幼小时，可以是一个很娇惯孩子的母亲，但永远成不了爱孩子的母亲。检验这一点的试金石是看一个母亲愿意不愿意忍受同孩子的分离，以及在分离后能不能继续爱孩子。</p>
<h4 id="3、性爱"><a href="#3、性爱" class="headerlink" title="3、性爱"></a>3、性爱</h4><p>博爱是同等人之间的爱，母爱是对需要帮助的人的爱，虽然这两者之间有很大的区别，但它们却有一个共同点：那就是按它们的本质，它们的爱不属于一个人。如果我爱我周围的人，我也爱所有的人，如果我爱我的一个孩子，我也爱其他的孩子以及所有需要我帮助的孩子。同这两种类型不同的是性爱，性爱要求完全彻底地实现合二为一，要求自己同他人完全融会。按其性质，这种类型的爱是专一的，不是包罗万象的，因此这种爱也是爱的最能迷惑人的形式。</p>
<p>首先这种爱常常会同“堕入情网”的爆炸式的经历混为一谈，在这种情况下，两个人之间的所有隔阂突然都消失了。正像上面已经提到过的那样，按其本质这种突如其发的强烈感受是注定短命的。当陌生人成为亲密的人，就没有需要克服的障碍了，就不需要作出努力去达到真正的接近。爱者对被爱者的了解同对自己的了解一样多，也许我应该说——一样的少。如果体验对方达到一定的深度，那你对对方就不会那么熟悉——而克服两个人之间的障碍的奇迹就会一天天地重复。但大多数人无论对自己还是对别人都是了解得非常快，而且很快就觉得一览无余了，这恰恰是因为他们只了解了人的表面，而没有深入内心。对他们来说，人与人之间的亲密首先是通过性结合得以实现的。正因为他们觉得他们同别人的隔离首先是一种肉体上的隔离，所以肉体的结合对他们来说就意味着克服人与人的隔离。</p>
<p>另外，对许多人来说还有一系列克服人与人隔离的方法。讲述自己的生活，叙述自己的希望和恐惧，谈出自己幼稚的或者不成熟的梦想，以及找到面对世界的共同利益——所有这一切都是克服人与人之间隔离的途径。甚至表露自己的愤怒和仇恨，毫无顾忌地交心也都被看出是亲密的表现。也许从中就能解释一些夫妇常常感受到的相互之间的那股不正常的吸引力：那就是只有当他们一起睡觉或者发泄了相互的憎恨后，他们会突然感到两个人之间的亲密关系。但是这种类型的“亲密”有一个特点，那就是随着时间的推移会逐渐消失。后果就是人们要在另一个人身上，在另一个陌生人身上寻求爱。而那个陌生人又会成为“亲密”的人，新的爱情经历又会是十分强烈和幸福，然后又逐渐消失，一直到希望进行新的征服，得到新的爱情的要求重又出现——并永远幻想着新的爱情会和以前完全不同。</p>
<p>同时性要求的欺骗性又会加强这种幻想。性要求的目的旨在达到结合，而绝不仅仅是生理上的要求和为了释放折磨人的压力。这时对孤独的恐惧会加强这种要求，此外占有欲和被占有欲，虚荣心以及人的破坏性都会加强性要求——当然爱情也会加强这一要求。看起来性要求是同每一种强烈的感情混杂在一起，并因此而得到加剧，所以爱情也会加强这一要求。</p>
<p>大多数人认为性要求是同爱情联系在一起的，所以他们很容易得出具有迷惑性的结论：即如果两个人互相愿意占有对方的身体，他们就是互爱了。爱情毫无疑问会引起性结合的要求，在有爱情的情况下，这种生理关系就不会带有占有或被占有的野心和欲望，而是充满了温柔。如果生理上的结合要求不是以爱情为基础，如果性爱不具有博爱的成分，那么只会造成一种纯生理的暂时的结合。性的吸引力虽然在一刹那间会造成两者结合的幻觉，但是如果没有爱情，在这次结合后留下来的只有陌生的感觉，他们之间的距离没有缩校他们仍是一对陌生人，他们不是觉得羞愧，就是相互憎恨，因为他们比过去更强烈地感受到在幻觉消失后留下来的这种陌生感。温柔绝不是如弗洛伊德所说是性本能的升华，而是博爱的一种直接表现，既表现在爱的生理形式中，也表现在爱的非生理形式中。</p>
<p>性爱具有一种博爱和母爱都不具备的独占性。必须进一步研究性爱的这种独占性。性爱的这种独占性经常被错误地解释为是一种互为占有的联系。我们经常看到互为相爱，但对其他人却毫无情感的男女。他们的这种爱实际上是一种共同的自私，这些人往往把自己同所爱之人等同起来，并通过把一个人分成两个人的办法来克服人与人之间的隔绝。他们以为这样做就能克服孤独。但正因为他们远远脱离同时代的人，所以他们之间实际上也是隔绝和互为陌生的，结合对他们来说只是一种幻觉。性爱是具有独占性，但同时也是通过爱一个人，进而爱全人类，爱一切生命。性爱的独占性只表现在我只同一个人完全地、即在灵魂和肉体上融会为一体。性爱只有在性结合这点上，在生活的全部范围彻底献身这一点上排斥他人，而不是在一个更深的博爱意义上。</p>
<p>如果男女双方确实相爱，他们的性爱就具备一个先决条件——那就是我从我生命的本质出发去爱对方，并且去体验对方的本质。人就其本质来看都是一样的，我们既是整体的部分；又是整体，因此实际上爱谁都一样。从根本上来看爱情是意志的行为，是人作的一项把全部生命交付对方的决定。这一点也正是婚姻是不可解除的观点和许多传统婚姻形式的思想基矗在这些传统的婚姻形式中配偶不经自行选择，而是由被人挑血人们相信“先结婚，后恋爱”的说法。在现代西方世界这种观点被视为是完全错误的。人们认为爱情是一种自发的感情反应，人们会突然被一种无法抗拒的感情所控制。这里人们只看到两个人的特点，而没有看到——所有的男人都是亚当的一部分，所有的女人都是夏娃的一部分这一事实。人们拒绝认识性爱的一个重要因素：即意志的因素。爱一个人不仅是一种强烈的感情——而且也是一项决定，一种判断，一个诺言。如果爱情仅仅是一种感情，那爱一辈子的诺言就没有基矗一种感情容易产生，但也许很快就会消失。如果我的爱光是感情，而不同时又是一种判断和一项决定的话，我如何才能肯定我们会永远保持相爱呢？</p>
<p>从这一立场出发也许可以得出下列结论：即爱情只是意志的行为，献身的行为，爱谁原则上不起任何作用。不管婚姻是别人撮合的还是自行决定的——一经缔结，意志应该能够保证爱情的继续存在。看起来持有这种观点的人并没有认识到人的本质的矛盾性和性爱的矛盾性。我们所有的人是一体——但尽管如此我们每个人又都是只存在一次、不可重复的生命。从我们都是一体的意义上来看，我们能从博爱出发爱每一个人；但从我们是不一样的角度出发，性爱就要求具有特定的、独一无二的、完全是个性的成分，这种成分只存在于几个人，而不是在所有的人的中间。</p>
<p>　　因此这两种观点——一种认为性爱完全是两个人之间的吸引力，是两个特殊的人之间绝无仅有的联系；另一种观点认为性爱只是意志的行为——都是正确的；也许应该这么说，真理既不在这边，也不在那边。所以认为夫妇关系不好应该马上解除婚姻同在任何情况下都不允许解除婚姻的观点都是错误的。</p>
<h4 id="4、自爱"><a href="#4、自爱" class="headerlink" title="4、自爱"></a>4、自爱</h4><p>心理观察是否证实了在自爱和爱别人之间存在着一个基本矛盾的观点？自爱和利己是一码事，还是互为对立？此外，现代人的利己难道确实是一种对具有一切理性和感情可能性的自我的爱，还是对此有不同的解释？利己同自爱完全一样还是利己恰恰是缺少自爱的结果呢？在我们用心理学的观点分析利己和自爱以前，我们必须分析一下自爱和爱别人是相互排斥的这一错误的逻辑结论。如果把他人当作人来爱是美德，而不是罪恶的话，那么爱自己也应该是美德，因为我也是一个人，有关人的一切概念都与我有关。因此上述原则本身就是矛盾的。圣经中“爱他人如同爱己”的说法说明了对自己的完整性和独特性的尊重，爱自己，理解自己同尊重、爱和谅解别人是不可分割的。爱我同爱另一个生命是紧密相连的。</p>
<p>这里我们就触及到了使我们得出这些结论的一些心理上的先决条件。概括如下：我们的感情和态度的对象不仅是其他人，也包括我们自己。对别人的态度同对我们自己的态度互不矛盾，而是平行存在。从这一点出发来解答我们的问题就意味着爱别人和爱我们自己不是两者择一，恰恰相反：一切有能力爱别人的人必定也爱自己。原则上爱自己和爱别人是不可分的。真正的爱是内在创造力的表现，包括关怀、尊重、责任心和了解诸因素。爱不是一种消极的冲动情绪，而是积极追求被爱人的发展和幸福，这种追求的基础是人的爱的能力。</p>
<p>爱另外一个人这一事实就是爱的力量的具体体现。在爱中包含的原则上的肯定是针对所爱之人，而这个人又体现了人类以及人性。对一个人的爱包括了对所有这样的人的爱。“分工”的形式：爱自己的家庭却不爱他人，是缺乏爱的能力的表现。对人类的爱是对一个特定的人的爱的先决条件，尽管对人类的爱从其产生来看是通过对某些特定的人的爱发展起来的。</p>
<p>从中可以得出我自己也是我的爱的对象，同他人没有区别的结论。对自己的生活、幸福、成长以及自由的肯定是以爱的能力为基础的，这就是说，看你有没有能力关怀人、尊重人，有无责任心和是否了解人。如果一个人有能力创造性地爱，那他必然也爱自己，但如果他只爱别人，那他就是没有能力爱。</p>
<p>我们可以假设：爱自己和爱他人平行存在，——那我们如何来解释显然是排斥一切关心他人的利己呢？利己者只对自己感兴趣，一切为我所用，他们体会不到“给”的愉快，而只想“得”。周围的一切，凡是能从中取利的，他们才感兴趣。</p>
<p>利己者眼里只有自己，总是按照对自己是否有利的标准来判断一切人和一切事物，他们原则上没有爱的能力。这一结论难道不正好证明了对自己的关心和对别人的关心只能两者择一吗？是不是应该把利己和自爱看作是一回事才正确呢？但如果这么认为就完全错了，这一错误在自爱这个问题上已经导致许多不正确的结论。利己和自爱绝不是一回事，实际上是互为矛盾的。利己的人不是太爱自己，而是太不爱自己。缺乏对自己的爱和关心表明了这个人内心缺少生命力，并会使他感到空虚和失望。在必要时这个不幸和胆怯的人会通过各种其他的满足来弥补他失去的幸福。他看上去似乎非常关心自己，实际上只是试图通过对自己的关心去掩盖和补充自己缺乏爱的能力。弗洛伊德的观点是利己者就是自恋者，他们把对别人的爱用到自己身上。利己者没有爱别人的能力这是对的，当他们也同样没有能力爱自己。</p>
<p>如果我们把利己同在一个过度忧虑的孩子的母亲身上可以看到的那种占有欲作一比较，就更容易了解什么是利己。母亲一方面真诚地相信，她对自己的孩子特别地好，但另一方面她确实能感觉到对她宠爱的对象有一种几乎已经觉察不到的敌意。母亲之所以对孩子这么忧虑重重，并不是因为她太爱孩子，而是因为她要以此来弥补自己缺乏爱孩子的能力。</p>
<p>我们的这一关于利己本质的理论符合精神分析学家在治疗“忘我”症时所获得的经验。“忘我”是神经病的一种症兆，在为数不少的患者身上可以看到这种症兆，只是这些人一般来说不是受这种症兆，而是受到与这一症兆有关的其他的病兆，如厌世、虚弱、失去工作能力和处理不好爱情问题等的折磨。但是“忘我”不是像我上面所说的被看作是一种病兆，在大多数情况下“忘我”被看作是值得自豪的、唯一令人满意的性格特点。“忘我”的人一无所求，他只为“别人活着”，而且因为不重视自己而感到自豪。但一旦他发现，尽管他那么忘我可还是感到不幸，他同别人的关系仍然不令人满意，他就会感到吃惊。精神分析表明，这种“忘我”是一种病兆，而且常常会是主要病兆之一。患者没有能力爱，也没有能力使自己快活，他对生活充满了敌意，在他的忘我后面隐藏着一种很强的常常是自己意识不到的自私性，我们只有把他的“忘我”看作是一种病兆，使他克服缺乏创造力的缺点，也就是克服造成“忘我”以及其他病兆的根源，他才会得到痊愈。</p>
<p>忘我的本质特别表现在对其他人的影响上——在我们的文化中最常见的表现是“忘我”的母亲对自己孩子的影响。母亲认为孩子可以通过她的“忘我”认识到什么是被人爱，认识并学会什么是爱。但是她的“忘我”所造成的效果往往违背她的意愿。孩子们并没有表现出他们是幸福的，他们是被人爱的；他们一个个胆小，紧张，担心受母亲的责备并想方设法满足母亲的愿望。一般来说他们会受到母亲的那种隐蔽在深处的对生活的敌意和恐惧的传染，他们更多地是能感觉到，而不是认识到这点。总而言之，“忘我”的母亲的影响同利己者的影响并无多大区别，而且常常是前者甚于后者；因为母亲的忘我会阻止孩子对自己提出批评。孩子们的生活在一种不能使母亲失望的压力下，在道德的假面具下人们在教育他们要轻视生活。如果有机会，可以观察一下一个能真正自爱的母亲对孩子会产生什么影响，从而可以确定，再没有比一个能自爱的母亲在体验爱情、欢乐和幸福方面对孩子产生更积极的影响了。</p>
<p>爱克哈特(爱克哈特，中世纪德意志神秘主义哲学家和神学家。他认为上帝即万物，万物即上帝；通过自己的灵性，人即可与上帝合而为一，与万物混成一体，获得真正的自由。——译者注)有一句格言，最精辟地总结了关于自爱的思想。他说：“你若爱己，那就会爱所有的人如爱己。你若对一个人的爱少于爱己，如果你不是爱所有的人如同爱己，如果你不是在一个人身上爱所有的人——因为这个人就是上帝和人。一个既爱自己又爱他人如同爱己的人就是这样的人，一个值得这样评价的人。”</p>
<h1 id="爱情及其在当代西方社会的衰亡"><a href="#爱情及其在当代西方社会的衰亡" class="headerlink" title="爱情及其在当代西方社会的衰亡"></a>爱情及其在当代西方社会的衰亡</h1><p>如果爱情是那些具有创造性和成熟性格的人的一种能力，那么由此可以得出结论：每一个在一个特定社会生活的人的爱的能力取决于这一社会对这个人的性格的影响。当我们谈到当代西方社会的爱情时，我们要提出下列问题，即西方文明的社会结构以及这一社会结构产生的精神是否会促进爱情的发展。提出这一问题就意味着要对此作出否定的回答。任何一个客观地观察我们西方生活的人都会毫不犹豫地说爱情——博爱、母爱和性爱在西方是罕见的现象，许多假爱情的形式取代了它们的位置，而这些假爱情的形式实际上只是爱情的衰亡的形式。</p>
<p>资本主义社会一方面是以政治上的自由原则，另一方面是以市场作为调整一切经济活动，因此也是调节一切社会关系的原则为基础的。货物市场决定进行货物交换的条件。劳动力市场调节劳动力的买卖。有用的物和有用的人的精力和技巧都变成价值，这些价值根据市场的条件自愿公平地进行交换。譬如说鞋吧，一旦市场上没人问津，即使鞋本身是有用和必需的，也会失去任何经济价值（交换价值）。人的力气和技巧亦是如此。资本的拥有者可以购买劳动力，并命令劳动力为其资本的有利投资而劳动。劳动力的拥有者必须根据当时的市场条件出售其劳动力，才不至于挨饿。这种经济结构反映在价值的高低级别上。资本统治劳动力，无生命的物体要比劳动力，要比人的才能和一切有生命的物体价值要高。占有要高于存在。</p>
<p>这一结构从一开始就是资本主义的基础，尽管这一社会结构至今仍然是现代资本主义的标志，但有一些因素起了变化，这些因素赋予现代资本主义新的特点，并对现代人的性格结构产生深远的影响。我们看到资本主义发展的结果是资本不断集中。大企业不断地扩大，而小企业越来越受排挤。在大企业中，资本的所有权越来越同资本的管理权分开。几十万股票持有者是企业的“占有者”。管理企业的则是管理官僚阶层，他们虽然薪俸甚高，但企业并不属于他们。这些官僚不仅对获取大量利润感兴趣，而且也热衷于不断扩大企业，从而不断扩大他们自己的权力。资本的日趋集中和强大的管理官僚阶层的形成也表现在工人运动的发展中。工会把劳动力组织起来，使得工人不必在劳动力市场上孤军作战。工人成为大工会的成员，而这些大工会也同样被强大的官僚阶层所管理，并代表工人去同工业巨头对峙。无论在资本领域，还是在劳动力领域，个人的主动性被官僚阶层所取代。越来越多的人失去独立性，依附于庞大的经济帝国的官僚阶层。</p>
<p>资本集中带来的另一个决定性特点是劳动组织的特殊形式，这也是现代资本主义的特点之一。高度集中、分工严密的企业导致一种新的劳动组织，在这一组织中个人失去了个性，而成为机器中一个可以随时调换的齿轮。现代资本主义中个人的问题可以归纳如下：</p>
<p>现代资本主义需要大批能在一起协调工作的人。这些人对消费的需求越来越高，但他们的口味是标准化的，既容易受到控制，又能预测。现代资本主义需要的人是一方面能感觉到自己是自由和独立的并相信自己不屈服于任何权威、原则和良心，另一方面他们又准备执行命令，完成别人交给的任务，服服贴贴地进入社会这部机器中去，规规矩矩地听人摆布，自愿服从领导，盲目地受人指挥——只有一个例外，那就是他们要不遗余力地干活，永远地发挥作用和力争晋升。</p>
<p>那结果是什么呢？如果就是现代人对自己、对同代人和对大自然产生异化。他变成一种商品，体验到自己的生命力实际是一笔资本，这笔资本在既定的市场条件下要给他带来最大的利润。人与人之间的关系从本质上来看是互为陌生的，是自动机器之间的关系，其安全感的基础就是要想方设法靠拢一群人，在思想、感情和行动中同这一群人保持一致。虽然每个人都努力同别人接近，但实际上都是孤独的，充满了不安全感、恐惧感和负罪感。只要人与人之间的隔膜得不到克服，这种感觉就会不断出现。但我们的文明提供了各种可能性，使人们感觉不到这种孤独。这首先就是人们每天都重复着千篇一律僵化的机械性工作，这种工作秩序使他们不再自觉地感到人追求超越和统一的基本要求。但是光靠这个还不行，因此人就通过享受，通过娱乐工业提供的音乐、画片，以及通过不断地购买新的物品去减少这种尚未意识到的绝望。事实上现代人很像休克斯勒尔（休克斯勒尔(1894——1963),美国作家，深受佛教的影响。——译者注）在他的《美丽的新世界》一书中描绘的那付样子：“营养充分，穿戴讲究，性欲得到满足，但却没有自我，同他同时代的人也只有表面的接触。”现代人的宗旨正如休克斯勒尔简明扼要地总结的那样是“今朝有酒今朝醉”或者是“今日，人人幸福”的颂词。现代人的幸福就是享受，就是满足消费和同一群人同化的要求。他们消费商品、图片、食品、饮料、香烟、人、杂志、书籍、电影，真是无其不有。世界只是为了填饱他们的肚子，就象一个巨大的苹果，一个巨大的酒瓶和一个巨大的乳房，而我们是婴儿，永远在期待，在希望，却永远是个失意者。我们的性格努力地适应进行交换、接受和消费的要求。所有的一切——精神的和物质的东西——都成为交换和消费的对象。</p>
<p>至于爱情，当然也完全符合现代人的社会性格。自动机器是不会爱的，它们只能交换“一揽子特性”，想做一笔好买卖。在这一异化了的结构中，人在爱情上的基本要求是“结伴”思想，这在婚姻中表现得尤为突出。在无数宣传美满婚姻的文章中，一对毫无摩擦的伴侣被奉为是理想的结合。这一宣传同社会要求职员应得心应手的标准毫无两样。这个职员必须“相应独立”，是一个很好的合作者，宽容，同时又具有进取心，对生活的要求又很高。正像婚姻顾问对我们介绍的那样，一个丈夫应该理解他的“妻子”，并是她的帮手。他应该赞赏她妻子的新衣服，也要称赞她做的饭菜。而每当丈夫疲劳不堪、怨气十足地回家来时，妻子则应该体谅他，当丈夫谈到职业上的麻烦事时，妻子应该注意听他讲。如果丈夫忘记了她的生日，妻子不应该生气，而应该通情达理。所有这一切无非是表明这两个人的关系如上了油一样毫无摩擦，但这两个人一辈子都会互不了解，永远达不到“中心关系”，而是敬如宾客，只是尽力使对方舒适而已。这样的爱情和婚姻概念实际上是强调保护自己免遭不可忍受的孤独感的侵袭。在“爱情”中人们终于找到了避风港。两个人结成用以反对全世界的同盟，却把这种两个人的自私看作是爱情和信赖。</p>
<p>强调结伴的精神，强调相互之间的宽容是一个比较新的发展。在第一次世界大战后的那段日子起作用的是另一种爱情公式。那时性的相互满足是令人满意的爱情关系，特别是幸福婚姻的基础。人们认为造成许多不幸婚姻的原因是夫妇在性生活上不能很好地“配合”，而根源是缺乏对性生活的正确态度，也就是一方或双方都没能很好地掌握性生活的技巧。为了“消除”这种缺陷和帮助那些不能相爱的不幸的夫妇，许多书里都提供了各种正确的性态度的建议和说明，并多多少少许诺只要这样，幸福和爱情就会油然而生。其基本思想是：爱情是性生活得到满足的产物，如果男女双方学会在性生活上使对方满足，他俩就会相爱。这一点完全符合社会上流行的幻想，即正确的技术不仅能解决工业生产的问题，也能解决人的问题。人们没有看到，与此相反的观点才恰恰是正确的。</p>
<p>爱情不是性满足的结果，而是性的幸福，甚至掌握所谓的性技巧也是爱情的结果。如果一定要证实这一观点，除了日常的观察外，还可以求助于精神分析治疗的许多具体实例。对最经常出现的性问题的研究——妇女的性冷淡，男子心理上的各种严重的或不太严重的阳痿形式——表明产生这些问题的原因不在于缺乏技巧，而是这些男女的胆怯心理使他们失去爱的能力。害怕异性、憎恨异性是造成这些困难的原因，这些困难阻止他们献出自己和自发地行动，使他们在生理上无法忍受异性的靠近。如果一个有性障碍的人能从他的恐惧和憎恨中摆脱出来，他就会获得爱的能力，他的性问题也就解决了。如果不能摆脱出来，即使有再多的性技术的知识也无济于事。</p>
<p>把爱情看作是性满足的产物，把爱情看作是结伴思想和防止孤独的避风港，这两种观点是西方社会中爱情衰亡的两种“正常”形式，是由社会决定并造成的爱情病理学。这种病理学有许多个性化的形式，其结局都是自觉地受苦。这些形式被精神分析学家和越来越多的外行称为神经玻下面通过几个例子简明地说明一些经常出现的形式。</p>
<p>造成精神病态爱情的基本条件是“相爱的”一方或双方都牢牢地抓住父亲或母亲的形象，并把他以前对父亲或母亲怀有的感情、期待和恐惧成年后都转移到“所爱者”身上。这些人从来没有超越儿童阶段，成年后还在寻找儿童时代的联系。在这种环境下，这些人在感情生活方面始终是停留在二岁、五岁或十二岁的阶段，但他们的智力和社会能力却符合他们的实际年龄。在严重的情况下，感情上的这种不成熟状态会破坏其社会生活；在不那么严重的情况下这一冲突只限于个人亲密关系的范畴。</p>
<p>我们再回到我们前面已经提到过的以父亲为中心或以母亲为中心的讨论。下面的例子与我们现在经常能看到的病态爱情关系有关，也就是男子在感情发育过程中始终停留在同母亲的联系上。这些男子从来没有断奶，他们始终感到自己是孩子，他们需要母亲的保护、母爱、温暖、关怀和欣赏。他们需要无条件的母爱——得到这种爱只需要一个条件，那就是他们需要这种爱，他们是母亲的孩子，弱小无力。这些人在企图赢得一个女子的爱时，往往和蔼可亲，风度翩翩；如果他们成功了，仍然会保持这副样子。但他们同这个女子的关系（实际上同对所有的人的关系一样）都是表面的，而且不负责任。他们的目的是被人爱，而不是爱自己。在这种类型的人身上往往可以看到很强的虚荣心和没有完全暴露的远大志向。如果他们找到“合适”的妻子，他们就信心十足，觉得自己占了全世界的上风；这时他们对其他人也会和蔼可亲，温文尔雅。但在过了一段时间后他的妻子不再符合他的想象，就会出现冲突和摩擦。如果他妻子不始终如一地欣赏他，如果她要求有自己的生活，希望得到爱和保护，如果她——在极端的情况下——不准备原谅他的外遇（或者不流露对此有一种颇为欣赏的兴趣），这时他就会感到受到很大的伤害和失望。一般来说他还会用“妻子不爱他，自私或者专制”的说法把他的这种感情简单化。很明显，“慈母”对她的令人着迷的“儿子”的任何一个小小的疏忽都被看作是缺乏爱情的表现。这些男子一般来说把他们的文雅举止，和他们愿意使别人高兴的愿望同真正的爱情混淆起来，并因此得出他们受到不公正对待的结论。他们自以为是伟大的恋人，对妻子的不满抱怨不休。</p>
<p>只有在很少的情况下，一个以母亲为中心的男子才能正常地生活。如果他们的母亲是以一种升华的方式“爱他”（也许她虽然专制，但不具有破坏性），如果他的妻子同他的母亲是相同的类型，如果他的特殊才能能使他发挥他的魅力和赢得他人的欣赏（某些杰出的政治家就是这种情况），那么从社会角度来看他已经是“很好地纳入”社会。即使他从来没有达到一个更成熟的精神高度。但是在不少上面所说的有利条件下——当然这是一种更经济的情况——他的爱情升华（尽管不少他们的社会生活）会是巨大的失望；当这种类型的人一旦觉得他被众人所抛弃，就会出现冲突，在很多情况下会产生强烈恐惧和厌世的念头。</p>
<p>在另一种给位严重的病态爱情形式中，患者同母亲的联系更深，也更缺乏理性。在这种情况下，形象地说，问题不在于病人想回到母亲爱护的双臂之中或者给予养料的乳房，而是回到母球接受一切——和破坏一切——的怀抱里。如果说精神健康的本质在于脱离母亲的子宫，进入世界，那么严重精神病的本质就是被母体所吸引，要重新回到母体——也就是被夺走生命。这种联系往往出现在和母亲的关系中，他们的母亲以这种接受——破坏的方式同孩子联系在一起。又时她们是以爱的名义，有时是以履行责任的名义要在自己身上保留孩子，保留成长的孩子以及成年后的孩子。只有通过她们，孩子才能呼吸。这些男子除了一些侮辱女性的表面关系外不可能爱别的女人。她们不能自由和独立，而只能永远是一个残废者或者是一个罪犯。</p>
<p>母亲的具有破坏性的侵吞性的一面是母亲形象中坏的一面。母亲不仅能赋予生命，而且能夺走生命。母亲是活跃生活、也是破坏生活之人。她能创造爱的奇迹——但没有人比她更能伤害人。在宗教的象征中（如印度女神时母和在梦的象征中都可以经常找到母亲的两个截然相反的方面。</p>
<p>神经机能病态的另一个完全不同的形式可以从同父亲相关的病例中找到。</p>
<p>一个相应的例子是一个男子有一个性冷淡感情内向的母亲，而父亲却把他的爱和全部的兴趣倾注在孩子身上（这一部分是母亲冷淡的结果）。他是一个“好父亲”，同时也很专横。他如果对儿子的行为满意，他就称赞他，送给他礼物，对他很亲切。一旦他对儿子不满，他就会退居一旁或者咒骂儿子。除了父亲的疼爱以为一无所有的孩子就以一种奴隶的方式同父亲联系在一起。他的生活主要目标就是要使父亲高兴——如果他做到了，他就感到幸福、安全和满足。但如果他犯了错误，做了错事，如果他不能讨父亲的欢心，他就感到空虚、没人爱他或受到唾弃。再后来的生活中，这个人总之寻找一个他能以同样的方式与之联系的父亲形象。他的一生始终是依照他说否得到父亲的称赞而上下起落。在社会上这些人常常能获得很大的成功，他们认真、值得信赖和勤奋——先决条件是他们所选定的父亲形象要善于正确地对待他们。他们同女仔的关系则是小心翼翼和有距离的。妇女对他们来说没有中心意义；他们一般对妇女颇有点轻视，这种轻视往往被他们对妇女的像父亲对小姑娘那般的关系所掩饰。一开始，由于他们的男性特点，他们会给妇女留下一些印象；但是一旦嫁给这些男子的妇女发现他们自己在丈夫的生活中只起第二位作用，——而父亲的形象其主要作用——，她们就会越来越失望。但是也有例外的情况，那就是如果其中碰巧也是一父亲为中心的类型——这样她同一个对待她如同一个任性的孩子那样的男子在一起就会感到幸福。</p>
<p>更为复杂的病态爱情形式往往出现在下面的那种人身上，这些人的父母互不相爱，但又善于控制自己，他们既不争吵也不流露自己的不满。同时这些父母同子女的关系也很不自然。一个姑娘在叫里感受到的只是“规规矩矩”的气氛，但同父亲或母亲没有很多接触，因此留在姑娘心中的只是混乱和害怕的清晰。这个姑娘永远不知道父母的感受和想法。在这样的家庭气氛中始终存在着一种不可知和空虚的成分。后果是姑娘完全隐退到自己的小天地里去，而她的这一态度一直可以保持到她后来的爱情关系中去。另外这种回避也是不断滋长的恐惧情绪以及在这个世界无根底的感受所致，最终会导致被虐癖的倾向，因为这是可以体验强力刺激的唯一机会。这些妇女常常愿意他们的丈夫和她们吵闹，而不是正常地、理智地与他们相处，因为只有这样才能够使她们暂时地失去紧张和恐惧的感受。因此她们往往会不自觉地去激怒丈夫，一结束折磨人的空虚。</p>
<p>下面还将介绍几种经常出现的非理性的爱情形式，但不再分析原因——即同年时代发展的一些特殊因素。</p>
<p>不乏少见的假爱情的一种形式——这种形式又常常被人们称为“伟大的爱情”（经常出现在小说和电影里）——是偶像化的爱情。一个没有达到产生自我感觉高度的人（这种自我感觉的基础是创造性地发挥自己的力量）倾向于把自己所爱的人“神化”。他同自己的力量异化并把自己的力量反射到他所爱之人身上，他所爱之人被当做一切爱情、光明和祝福的源泉而受到他的崇拜。在这一过程中，人失去了对他自己力量的觉悟，在被爱者身上失去自己，而不是找到自己。但是从长远来看，由于没有一个人能符合崇拜者的心愿，当然不可避免地就会出现失望，而解决这一问题的方法就是寻找一个新的偶像——有时候会出现恶性循环。这种偶像化爱情形式开始时的特征是爱情体验的强烈性和突发性。这种形式的爱情常常被看作是真正的伟大的爱情；但是恰恰是这种所谓的强烈性和深度性却表现了那些恋爱者的饥渴和孤独。也许不必过分强调的是，我们常常可以看到这种爱情形式相结合的男女在严重的情况下会给人一对疯子的印象。</p>
<p>另一种假爱情的形式就是人们称之为多愁善感的爱情。这种爱情的本质就是它只能存在于想象中，而不是存在于同另一个人实实在在的结合之中。这类爱情最广泛的形式是用代用品使自己满足，那就是消费爱情电影、爱情小说和爱情歌曲。通过消费这些东西可以使一切没有实现的对爱情、人与人结合和亲近的向往得到满足。那些无力拆除自己与伴侣之间那堵高墙的男女，当他们在银幕上看到悲欢离合的情侣时，会身临其境，感动得热泪盈眶。对许多夫妇来说，银幕是他们体验爱情的唯一可能性——不仅自己是这样，而且两个人会一起成为他人爱恋故事的观众。这要爱情是一个白日梦，他们就能加入进来，但如果爱情成为两个真实的人之间的一种现实关系——他们就僵化了。</p>
<p>多愁善感的爱情的另一种表现是吧现时推移到过去，一队夫妇可以通过回忆过去的爱情而受到深深的感动，虽然他们当时根本就没有感受到爱。这种情况和幻想未来的爱情完全一样。不知有多少定过婚的男女或新婚夫妇仍在憧憬未来爱情的想法，尽管她们现在已经开始感觉到对方的无聊。这种倾向符合作为现代人标志的一般态度。现在人不是生活在过去就是生活在未来，但不是现时。他们满怀感伤地回忆童年和母亲——或者为未来制定伟大的计划。不管是通过参与别人的非真正的爱情经历来体验爱情，还是通过吧现时推移到过去和未来的方法来躲避爱情的现实，这些抽象的和异化的爱情形式其作用就和鸦片一样，都是为了减轻现实、人的孤独和与世隔绝所带来的痛苦。</p>
<p>神经病态爱情的另一种形式是一套投射做法。这种投射做法能导致回避自己的问题，从而把注意力放到“所爱者”的错误和缺点上。个人在这方面的态度同民族和国家的态度没什么两样。有些人对他人的每一个细微错误的反应都十分灵敏，而对自己的问题和弱点却不闻不问，他们永远是在考虑如何指责对方或者教育对方。如果——常常是这种情况——男女双方都热衷于这么做，那他们俩之间的爱情关系就成为相互的投射。如果我们是专横或无主见的，我就指责对方有这些缺点，并且根据我的性格不是要求他改正就是为此要惩罚他。而对方也同我一样地行事——这样两个人都能回避自己的问题，因此这两个人也就不能采取使他们自己进一步发展的步骤。</p>
<p>投射的另一种形式是把自己的问题投射到孩子身上。首先这种反射常常反射在希望生孩子的愿望上。有些人之所以要孩子是因为他们想把自己的生存问题反射到孩子身上。如果当一个人感到自己没有能力赋予自己的生活一种意义时，他就会试图在他的孩子的生活里找到生活的意义。但是这必然会在自己和孩子身上造成失败的结果。失败的第一个原因是因为每一个人的生存问题只能有自己解决，而不能通过一个代理者。另外一个原因是有这种打算的人恰恰缺乏必要的能力、以引导孩子解决自己的生存问题。同时孩子还往往被当作投射的对象，以缓和父母之间的紧张关系。这些父母常使用的理论就是为了使孩子不是去一个共同的家，所以不愿离婚。但深入的调查结果表明：在这样的“共同的家”中笼罩着的那种紧张和不幸的气氛往往比公开的决裂对孩子的损害更大，因为公开的决裂至少表示一个人有能力通过一项勇敢地决定来借宿无法忍受的状况。</p>
<p>这里还必须提及一个经常出现的错误,一种幻想，即认为爱情必定意味没有冲突。按“在任何情况下都应避免痛苦和悲伤”的世俗之见，所以现代人也认为，爱情就是意味着没有冲突。他们还以他们所见之争吵都是毁灭性的争论，对双方都没有好处的事实作为理论依据。但是真正的原因在于大多数人的“冲突”实际上都是为了避免真正的冲突。这些冲突只是对一些鸡毛蒜皮的小事产生分歧而已，而这些小事按其本质来看是无法澄清或者无法解决的。但人与人之间的真正冲突——那些不应该被遮掩，也不应该投射到别处的冲突，那些属于人的内在现实并能在人的心灵深处体验到的冲突——绝不是毁灭性的。这些冲突会得到澄清，会带来一种净化，从而是双方能变得更有知识，更坚强。现在我得把我上面讲过的东西再强调一下。</p>
<p>爱情只能产生于这样两个人中间，这两个人都从他们生存的圈子里跳出来并互相结合，同时他们每个人都又能脱离自我中心去体验自己。只有这种“中心体验”才是人的现实，才是生活，才是爱情的基础。这样体验到的爱情是不断地挑战，这种爱情不是避风港，而是一种共同的努力、成长和劳动。如果两个人能从自己的生命的本质出发，体验到通过与自觉地一致，与对方结成一体，而不是逃离自我，那么在这样的基本事实面前，就连和谐、冲突、欢乐和悲伤这样的东西也就只能退居第二位了。“爱情的存在只有一个证明：那就是双方联系的深度和每个所爱之人的活力和生命力。这也是我们所能看到的爱情的唯一成果。”</p>
<p>正如自动机器不能相爱一样，自动机器也不可能爱神，因此神爱所达到的衰亡程度与人爱的衰亡程度相等。这一事实同有些人认为我们是发生在我们时代的宗教复兴的见证人的观点大相径庭。在没有比这种观点更荒唐的了。我们所经历的（即使有例外）无非是回到把神偶像化的时代，和把对神的爱变成符合异化了的人的性格结构。从新捡起把神偶像化的做法是很容易识破的。我们社会上的许多人胆小怕事，没有原则，也没有信赖，除了活下去外没有任何目标，因此他们仍然是孩子并希望在他们需要帮助的时候，能得救于父亲或母亲。在宗教文化中，譬如中世纪的宗教文化中，就是一般人都把神看作是帮助他们的父亲和母亲，这确实是事实。但是他们对待神的态度是很严肃的，他们把按照神的旨意去生活看作是他们生活的目标。可今天已经看不到这种努力了。日常生活同一切宗教价值已截然分开。生活的目的仅仅是为了寻求物质上的享受和劳动力市场上的成功。我们在世界范畴内活动的原则基础是冷漠和自私（后者常常被“个人主义”或者个人“能动性”的叫法所取代）。生活在真正宗教文化中的人也许可以同一个八岁的儿童相比较，儿童一方面把父亲看作是拯救者，但另一方面他已经开始把父亲的教诲和原则接受到自己生活中去。而现代人却像一个三岁的孩子，只有需要夫妻时才招呼他，而自己一个人能玩时，也会很高兴。</p>
<h1 id="爱的实践"><a href="#爱的实践" class="headerlink" title="爱的实践"></a>爱的实践</h1><p>行使任何一门艺术都需要有一些基本的东西，木匠艺术、医疗技术和爱的艺术都是如此。首先要求有纪律。如果没有纪律，我将会一事无成。如果我是凭一时的“兴致”去行事，这也许会成为使我感到愉快的一种嗜好，但我永远成不了大师。这里所指的纪律不是实践一门特殊艺术所要求的纪律（如每天要坚持练习几个小时），而是贯穿人的一生的纪律。也许有人会说，对当代人来说莫过于比学校纪律更容易的事了；难道当代人不是每天都要遵守劳动八小时的纪律吗？但实际情况是，在工作之外人很少能表现出一点自我纪律来。一旦他不工作，就十分懒散，无所事事——用一句好听的话来表达就是他想“轻视一下”。但恰恰是这种什么也不想干的意愿是对生活秩序作出的一种反响。正因为人们被迫每天八小时为别人的目标付出力气，以一种劳动节奏规定的方式工作，所以他就要反叛，而这种反叛就采取了无所作为的态度。另外他在反对权威的斗争中对每一种纪律都已抱有怀疑的态度。不管这种纪律是非理性的权威强加给自己的还是自己给自己规定的理性的纪律。但如果没有纪律，生活就会七零八落、混乱和没有集中。</p>
<p>集中是掌握艺术的一个必要条件，这一点是无需证明的了。每一个试图学会一门艺术的人都了解这一点。但是在我们这个社会集中比自我纪律还有罕见，我们的文化已经导致一种非集中的、分散的、史无前例的生还方式。人们往往同时干几件事：看书、听收音机、谈话、抽烟、吃饭和喝酒。人成为消费者，张开大嘴坐着，贪婪地吞下一切东西：画片、烧酒和知识。这种缺乏集中的想象特别表现在我们现在已经很难一个人安静地坐着。大多数人已经不会一个人安静的坐着，不说话，不抽烟、不看书和不喝酒。他们很快就会变得不安起来，他们一定要动嘴或者动手。（抽烟就是缺乏集中的一个症状，抽烟的人即动手、动嘴、也懂眼睛和鼻子。）</p>
<p>第三个因素是耐心。学过艺术的人都值得要达到目的就必须要有耐心。想尽可能快的取得结果的人永远也学不会一门艺术。尽管如此，对现代人来说耐心同纪律和集中一样是难以做到的。我们整个工业系统提倡的恰恰是耐心的反面，那就是要快。我们所有的机器都是为了达到快的目的：汽车和飞机把我们很快地送到预定的地点——而且要越快越好。以一半的世界生产同样多的产品的机器要比旧的和运转慢的机器好一倍。当然这里有重要的经济原因，但是正如同许多其他的方面一样，这一点也体现了人的价值原是由经济价值所决定。对机器是好的东西必然对人也是好的——这听起来似乎合乎逻辑。现代人认为如果他不很快地处理事情，就会失去时间，可他并不知道他如何利用他由此赢得的时间——除了只会无聊地打发时间。学会一门艺术还有另一个条件那就是对掌握这门艺术要有极大的兴趣。如果一门艺术没有最高意义的话，那没有一个学徒会学这门艺术。他最多成为一名业余能手，但不可能成为大师。这一条件对爱的艺术如同对其他的艺术一样同为重要。但看起来，在爱的艺术中，业余能手的人数要远远超过大师。</p>
<p>在谈及学会一门艺术的一般条件时还必须提及一点，那就是人们从来不是一开始就直接地学会一门艺术，而总是间接地学会这门艺术。一开始人们必须学会许多其他的、而且看起来经常是同这门艺术无关的东西，然后才开始学子这门艺术。木匠学徒要先学会刨木头，学钢琴的人要先练习音阶，而学习禅宗射箭艺术的人则要先练习呼吸。为了使自己成为一门艺术的大师，必须把一生献给这门艺术。在实践这门艺术时，自己要成为工具并保持一定的状态，以适应需要完成的任务。这一点在实践爱的艺术上就意味着所有想成为大师的人应该把生活的每一个阶段训练纪律、集中和耐心作为实践爱的艺术的开端。</p>
<p>那么如何训练纪律呢？我们的爷爷辈能更好地回答这一问题。他们会建议我们早起，不要过奢华的生活，要努力工作。但这种类型的纪律也有不利的一面。这种纪律死板，是把节余的道德放在首位，并且在很多方面与生活为敌。但作为对这类纪律的回答，今天越来越大的倾向是以一种怀疑的目光来对待每种纪律，并以一种懒洋洋的无所事事来找到八小时之外的平衡点。每天早晨按时起床，按时进行一定的活动，如禅坐、看书、听音乐和散步，不做或者有限度地做一些分散注意力的是如看侦探小说和电影，不暴饮暴食——这些都是明显的基本要求。但是最重要的是不要把纪律看作是外部强加的东西，而应该成为自我意志的体现，应该感到这是一种愉快，并且逐渐习惯于一种生活态度，一旦放弃它，便会若有所思。我们西方扔对纪律观念最令人遗憾的看法（对其他的到底亦是如此）是，他们认为纪律必会使人难受或不适，纪律只有达到这种效果，才是“有用的”。但是东方人很久以来就认识到，与身心有益的东西必定使人舒适，即使开始的时候需要克服一定的阻力。</p>
<p>生活在我们文化中的人很难做到集中，因为我们的全部文化似乎都是为了“分散注意力”和反对培养集中的能力。最重要的步骤是要学会一个人单独呆着，而且不看书，不听广播，不抽烟和不喝酒。有没有集中的能力表现在能不能单独地呆着——而这种能力优势学会爱的一个条件。正因为我不能自力更生，所以我只能把自己同另一个人连在一起。这个人也许就是我的生命的拯救者，但是这种关系同爱情无关。是否能一个人呆着居然成为有无能力爱的条件之一，这一点会令人奇怪。但每一个试图这么做的人将会知道做到这点是很难的。随着时间的推移他会坐立不安，甚至会感到有点害怕。于是他就会找出各种借口为自己放弃练习辩护，他会说一个人呆着毫无意义，是愚蠢的，太浪费时间，等等。他在练习的过程中还会确定，一个人呆着的时候，各种各样的念头都会冒出来，困扰你。他会突然发现他正在打算这一天还能干些什么，他在思考工作中遇到的困难或者是考虑今天晚上上哪里去。但是做一些简单的练习就能帮助他集中，譬如：轻松地坐着（即不要懒散，也不要紧张），把眼睛闭上，努力使自己的眼前出现一片白色，并排除一切干扰自己的画面和念头。然后可试着观察自己的呼吸——不要去想它，也不要去影响它，而只是要意思到自己在呼吸。另外还要试着得到一种“自我”的感受；我=我的自己+我的力量的中心+我的世界的创造者。至少每天早晨要做二十分钟这样的练习（如果有可能还有延长）和每晚睡觉前坚持练习。除这些练习外还有学会专心做一切事：专心听音乐、看书、谈话或欣赏图画。如果专心地干，那么干什么就无关紧要了，无论干什么，重要的或者不重要的都会增加一层现实意义，因为干事的人是完全开放的。为了学会集中要尽量避免无意义的谈话，也就是不能成为谈话的谈话。如果两个人在谈论他俩所熟悉的一棵树的生长情况，或者在评论刚才吃过的面包的味道，或者在回忆他们职业上的共同经历，他俩的谈话可能是重要的，这就看他俩是否真的在谈论一件经历过的事，还是就抽象的东西交换看法。另外有关政治或者宗教的谈话也肯能是毫无意义的，如果交谈者只是老生常谈，没有亲身经历的体会，只是交换一下看法而已。我这里还要补充一点，那就是不仅要逃避无聊的谈话，而且还要避免同不三不四的人来往。我这里指的不仅是要回避那些有破坏性的凶恶之人，应该回避他们，因为这些人会使人消沉和压抑，而且还指那些内心无生命力的人，那些思想和谈话都没有内容的人，这些人不是在谈话而是在闲扯，他们不会思考，指挥把一套套的世俗之见搬出来。当然不可能永远回避这些人，有时也没有费这么做的必要。在和这样的人接触中如果你不是像他们所想的那样，闲扯一通，而是直率地和与人为善改变自己的态度，这一方面是因为你的反应使他们大吃一惊，另一方面也是因为他们自己也渴望从杜撰和陈词滥调中摆脱出来，走向现实。</p>
<p>在同别人的关系中要记住首先就意味着要有听别人讲话的能力。大多数人认为他们是在听别人讲话，而且还帮对方出主意，可实际上他们根本没听进去。他们不重视别人的话，漫不经心地回答对方。后果是这样的谈话往往使他们感到疲倦。他们认为如果他们记住地听对方讲话，就会跟疲倦。可他们想错了，每一件聚精会神完成的事会使人清醒（尽管干完时候出现能恢复的自然疲劳状态）。而懒懒散散的干事只能使人产生倦意——同时这些人在夜里也很难入睡。集中意味着要完全地在现时地生活，而不是赶着这事想那事。那些相爱的人应当首先练习集中，这事理所当然的。他们必须学会亲近对方并向对方开放，而不是像通常所见的那样相互回避。万事开头难，这句俗话对练习集中也适用。人们常常会有永远达不到目的的感觉。所以显而易见练习集中还必须要有耐心。如果人们不知道学会每一种事都要有一个过程，都应自己给自己施加压力，那就永远不会学会集中。要想知道什么是耐心，只有观察幼儿学走路就行。孩子一次、二次、三次跌倒在地上，可他还是坚持着走下去，一直到不摔跤为止。有孩子学走路的耐心和集中他会作出多么大的成绩啊！</p>
<p>集中还要求另一样东西，那就是对自己要保持清醒。如果解释呢？难道应该不断思考自己、“分析”自己，还是别的？如果我们把一个人对一部机器的高度的注意力做例子，也许就能很容易地回答这个问题。譬如有汽车的人对自己的汽车总是很警觉的，任何一种细微的声响和马达功能的变化都不会被他放过。统一开车的人对马路表面的变化、前后车辆的速度及方向变化也十分灵敏。尽管如此开车的人并没有去思考这些现象，他只是处在一种清醒状态之中，对他所集中于的事（也就是安全行驶）所发生的任何变化都会做出反应。</p>
<p>我们用母亲对婴儿的态度做例子就能说明什么是对一个生命的清醒的关注。在婴儿还没有表达以前，母亲就能感觉到婴儿体内的一些变化、他的愿望和需要。婴儿一叫或一哭，母亲就会醒来，虽然平时比这更响的声音都不会吵醒她。这说明了母亲对孩子的每一种生命的表现都是很清醒的，母亲即不害怕，也不担心，而是助于一种清醒的平衡状态，能接受孩子发出的每一个重要信号。我们也可以以同样的方式清醒地面对自己。譬如在感觉到累或者消沉的时候，不应该听之任之和用随时可以捡来的消沉的想法去加剧这种感受，而应该问问自己：到底发生了什么？为什么我那么一蹶不振？同样在我们生气或者迷惑不解的时候，在我们开始想入非非的时候，都应该这样问自己。在所有这种情况下，终于的是要觉察内心的活动，而不是用各种各样的方法去找到为自己辩护的借口。这样我们就此次会听到内心的一种声音，在向我们讲述，为什么会害怕、消沉或者迷惑不解。一般人对自己体内的活动都有一定的警觉性；能感觉到每种变化和甚至能发现几乎感觉不到的疼痛。注意身体的变化是比较容易做到的，因为大多数人都了解自己的健康状态。电脑上对心灵变化就不可能那么灵敏，因为许多人还从来没见过一个对自己的内心活动保持清醒的人。对他们来说，衡量内心活动是否正常的标准是他们的父母和亲戚，或者是他们加入的社会集团，只有他们同这一标准没有区别，他们就决定自己很“正常”，也就没有兴趣去观察与他们不同的生活态度。譬如有许多人还从来没有见过一个有爱的能力的人或者一个独立完整的、具有勇气和能集中干事的人。为了能清醒地面对自己，必须要有一个设想，要知道什么叫做健康地、活跃地、充满人性地发挥人的作用。可是如果我们既没有在童年时代，也没有在后来的岁月里有过这种体验，我们又如何能得出这样的结论呢？对这个问题肯定不会有简单的回答，但这个问题却击中了我们教育制度的要害。</p>
<p>在传授知识方面，我们忘记了对人的发展来说是作重要的教诲，呢就是一个成熟的和慈爱的人的现身教育。在外面自己文化的某系阶段，或者在中国和印度，最有影响的是德高望重的人。教师不仅或不首先是传授知识，他的任务还包括培养学生具有一定的人的品质。在当代资本主义社会——这一点也适用于俄国共产主义，值得钦佩和作为榜样的人绝不是因为他们具有高尚的品质。电影明星、播音员，一些新闻记者以及政界和经济界的巨头是老百姓的榜样。这些人的主要资本常常是因为他们能够扬名四海。但尽管如此，情况还不至于糟到使人绝望。如果我们想一想，像阿尔贝特-施威策这样的人能在美国和其他地方出名，如果我们看到有许多可行的办法，能使我们的青年一代熟悉那些活着的和死去的优秀人物，并通过这些人了解人能不断完善自己，如果我们想到文学和所有艺术的那些不朽之作，我们就相信有可能去传授人应该如何清醒地、充满活力的生活。如果我们做不到这点，我们很可能会面临有一天我们整个的文化传统崩溃的下场。我们的文化传统首先不是以传授一些思想和知识为基础，而是传授做人的态度。如果我们的后代不在能经历这一传统，我们五千年的文化就会崩溃，即使人们孩子继续不断地传授和发展知识。</p>
<p>上面我们分析了在行驶所有艺术时必须具备的条件，现在我要谈一下掌握爱情艺术的必不可少的特殊条件。根据我对爱情本质的论述，获得爱的能力的主要条件是克服自恋。自恋倾向是人的一种态度，具有这种态度的人体验到的现实只是内心活动，主要是他们自己的贪婪和恐惧，对他们来说，外部世界的现象本身是不现实的，只有对他们有利或者威胁他们的食物才有意义。同自恋相反的是客观性，客观性就是对人和事物都有开放的态度，能实事求是地看待事物。这个意义上的客观性就是能从表面深入现象核心的实现主义。同自恋相反，客观性的基础不是与外部世界毫无关系，而是有强烈的联系。精神病的所有形式是没有客观性的极端形式，在这个意义上就是对客观事物没有开放的能力。对精神病患者来说，如果有现实的话，那也只存在于他的内心，就是他的恐惧和欲望。外部世界对他来说只是他内心世界的象征，只是他的创造物。我们做梦的时候，也有类似的现象。在梦里发生的具体事件象征内心活动，即使如此，睡梦中的无名还是深信梦里发生的事同我们在清醒状态感觉到的现实一样真实。</p>
<p>但是梦和精神病仅仅是缺乏客观性的极端例子。我们每个人对世界都有一个非客观的图像，一个被我们的自恋倾向所歪曲了的图像。难道还需要我举例说明吗？只要我们观察自己和邻居或者看报的话，是不难找到这样的例子的，只是由于自恋的程度不一，歪曲客观的程度也有高低。譬如一位妇女打电话给他的医生，告诉他，她很想当日下午去他那儿看病。医生说，他今天下午没有空，明天下午才有空。可能个妇女却说：“医生，可我住的地方离您那儿才五分钟的路！”这位妇女不能理解她住的虽然近却不能节省医生的时间。她完全是从自恋的角度出发看问题的：因为她节省了时间，所以医生也节省了时间。对她来说“我”是唯一的现实。</p>
<p>不那么极端的例子——或者也许仅仅是不能吗明显而已——常常出现在人与人的关系中。真不知有多少父母首先关兴趣的是他们的孩子是否听话，是否使他们高兴等等，而不是孩子自己经历了些什么，是怎么经历的——当然这些经历与父母无关。真不知有多少丈夫认为他们的妻子很专横，实际上是由于他们自己同母亲的幼稚的联系而把妻子的被一个要求解释为是限制他们的“自由”。真不知又有多少妻子认为她们的丈夫无能或者软弱，而实际上仅仅是因为丈夫不符合他们童年时代想象中的光彩夺目的骑士啊！</p>
<p>对其他民族缺乏客观性就更常见，也更具有危险性。一个民族会突然地把另一个民族看成是劣等的和敌对的，却自认为本民族体系一切优秀的和高贵的品质。敌人的行为用一种尺度衡量，而自己的行为却用另一种尺度衡量。甚至敌人的善意举动也被看作是险恶用心的产物，只是为了遮住我们和世界的眼目而已，可另一面有用高贵的动机来为自己的坏行为辩护。如果我们考察一下民族与民族、人与人之间的关系，我们一定会得出下列结论：客观性是例外，而不同程度的自恋是常规。</p>
<p>能进行客观思考的能力就是理智，以理智为基础的感情是谦恭。我们只有摆脱了童年时代妄图得到全知、全能的幻想，才能有客观性和运用自己的理智。</p>
<p>这在爱的艺术的实践上的表现在：能否学会爱取决于人的自恋程度和能不断培养自己的谦恭、客观性和理智。我们应该一辈子为此努力。谦恭和客观性同爱情一样不能只限于生活的一些范围。如果我对陌生人没有客观的态度，那我对自己的家也不会真正客观，反之亦然。</p>
<p>我想学会爱的艺术，我就应该在任何情况下都力求客观，并且能注意到在什么情况下我没有力求客观，并对此保持清醒的态度。我应该努力去认识一个被我自恋歪曲了的人的形象同这个人的实际面目，也就是同我的利益、困难和恐惧无关的实际面目之间的区别。有无客观性和理智是学会爱的艺术的一个关键性条件，人们应该对所有与自己所接触的人都能保持理智和客观。如果我们只对所爱之人保持客观，而以为对其他人就不需要客观性，那我们很快就能发现我们既不能处理好自己同所爱之人的关系，也处理不好同其他人的关系。</p>
<p>爱的能力取决于我们本人成熟的程度，以及在我们同世界和同自己的关系中能不能发展一种创造性的倾向。这种脱离自己的过程、诞生和成熟的过程需要另一种品质作为必不可少的条件：那就是信仰。爱情是以信仰为基础的<br>什么是信仰?难道信仰就一定是信仰上帝或者别的宗教教义?信仰是否同理智和理性的思考对立？信仰是不是只是一种无法证明的没有根底的知识呢?首先应该区别合理的信仰和非合理的信仰。我理解的非合理的信仰是指服从一种非理性权威的信仰(信仰一个人或者一种理想)。与此相反，合理的信仰是扎根于自已思想或感情体验的一种坚定的信念。合理的信仰首先不是信仰什么东西，而是一种确认，这种确认是符合建筑在自己真实经历上的坚定的信念。信仰是全部人格的一个性格特点，而不是同某些被看作为对的思想内容有关的东西。</p>
]]></content>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>6.824 学习记录</title>
    <url>/uncategorized/6-824/</url>
    <content><![CDATA[<h1 id="Patterns-and-Hints-for-Concurrency-in-Go"><a href="#Patterns-and-Hints-for-Concurrency-in-Go" class="headerlink" title="Patterns and Hints for Concurrency in Go"></a>Patterns and Hints for Concurrency in Go</h1><p>Lecture 10: Guest Lecture on Go: Russ Cox - YouTube<br><a href="https://www.youtube.com/watch?v=IdCbMO0Ey9I">https://www.youtube.com/watch?v=IdCbMO0Ey9I</a></p>
<p>Transcript:<br>okay uh good afternoon good morning good evening good night wherever you are uh let’s get started again uh so uh today we have a guest lecture and probably speaker that needs a little introduction uh uh there’s uh russ cox uh who’s one of the co-leads on the go uh project and you know we’ll talk a lot more about it uh let me say a couple words uh and not try to embarrass russ too much russia has a long experience with distributed systems uh he was a developer and contributor to plan nine uh when he was a high school<br>student and as an undergrad at harvard he joined the phd program at mit uh which is where we met up and probably if you’re taking any sort of you know pdos class if you will there’s going to be a you will see russ’s touches on it and certainly in 824 you know the the go switch to go for us has been a wonderful thing and uh but if you differ in opinion of course feel free to ask russ questions and make suggestions um he’s always welcome to uh entertain any ideas so with that russ it’s yours great<br>thanks can you still see the slides is that working okay great so um so we built go to support writing the sort of distributed systems that we were building at google and that made go a great fit for you know what came next which is now called cloud software and also a great fit for a24 um so in this lecture i’m going to try to explain how i think about writing some current programs in go and i’m going to walk through the sort of design and implementation of programs for four different patterns that i see come up often<br>and along the way i’m going to try to highlight some hints or rules of thumb that you can keep in mind when designing your own go programs and i know the syllabus links to an older version of these slides so you might have seen them already i hope that the lecture form is a bit more intelligible than just sort of looking at the slides um and i hope that in general these patterns are like common enough that you know maybe they’ll be helpful by themselves but also that you know you’ll you’ll the hints will help you prepare<br>for whatever it is you need to implement so to start it’s important to distinguish between concurrency and parallelism and concurrency is about how you write your programs about being able to compose independently executing control flows whether you want to call them processes or threads or go routines so that your program can be dealing with lots of things at once without turning into a giant mess on the other hand parallelism is about how the programs get executed about allowing multiple computations to run<br>simultaneously so that the program can be doing lots of things at once not just dealing with lots of things at once and so concurrency lends itself naturally to parallel execution but but today the focus is on how to use go’s concurrency support to make your programs clearer not to make them faster if they do get faster that’s wonderful but but that’s not the point today so i said i’d walk through the design and implementation of some programs for four common concur excuse me concurrency patterns that i see often<br>but before we get to those i want to start with what seems like a really trivial problem but that illustrates one of the most important points about what it means to use concurrency to structure programs a decision that comes up over and over when you design concurrent programs is whether to represent states as code or as data and by as code i mean the control flow in the program so suppose we’re reading characters from a file and we need to scan over a c style quoted string oh hello so the slides aren’t changing<br>yeah it will they well can you see prologue gorgeous for state right now no we see the title slide oh no yeah i was wondering about that because um there was like a border around this thing when i started and then it went away so let me let me just unshare and reshare i have to figure out how to do that in zoom uh unfortunately the keynote menu wants to be up and i don’t know how to get to the zoom menu um ah my screen sharing is paused why is my screen sharing paused can i resume there we go yeah all right i don’t know the zoom box says<br>your screen sharing is paused so if that now now the border’s back so i’ll watch that all right so um see i was back here so so you know we’re reading a string it’s not a parallel program it’s reading one character at a time so there’s no opportunity for parallelism but there is a good opportunity for concurrency so if we don’t actually care about the exact escape sequences in the string what we need to do is match this regular expression and we don’t have to worry about understanding it exactly<br>we’ll come back to what it means but but that’s basically all you have to do is implement this regular expression and so you know you probably all know you can turn a regular expression into a state machine and so we might use a tool that generates this code and in this code there’s a single variable state that’s the state of the machine and the loop goes over the state one character at a time reads a character depending on the state and the character changes to a different state until it gets to the end<br>and so like this is a completely unreadable program but it’s the kind of thing that you know an auto-generated program might look like and and the important point is that the program state is stored in data in this variable that’s called state and if you can change it to store the state in code that’s often clearer so here’s what i mean um suppose we duplicate the read care calls into each case of the switch so we haven’t made any semantic changes here we just took the read care that was at<br>the top and we moved it into the middle now instead of setting state and then immediately doing the switch again we can change those into go to’s and then we can simplify a little bit further there’s a go to state one that’s right before the state one label we can get rid of that then there’s a um i guess yeah so then there’s uh you know there’s only one way to get to state two so we might as well pull the state two code up and put it inside the if where the go to appears and then you know both sides of that if<br>now end in go to state one so we can hoist that out and now what’s left is actually a pretty simple program you know state zero is never jumped to so it just begins there and then state one is just a regular loop so we might as well make that look like a regular loop um and now like this is you know looking like a program and then finally we can you know get rid of some variables and simplify a little bit further and um and we can rotate the loop so that you know we don’t do a return true in the middle of the loop we do the<br>return true at the end and so now we’ve got this program that is actually you know reasonably nice and it’s worth mentioning that it’s possible to clean up you know much less egregious examples you know if you had tried to write this by hand your first attempt might have been the thing on the left where you’ve got this extra piece of state and then you can apply the same kinds of transformations to move that state into the actual control flow and end up at the same program that we have on the right that’s cleaner<br>so this is you know a useful transformation to keep in mind anytime you have state that kind of looks like it might be just reiterating what’s what’s happening in the program counter um and so you know you can see this if the the origin in the original state like if state equals zero the program counter is at the beginning of the function and if state equals one or if an escape equals false and the other version the per encounter is just inside the for loop and state equals two is you know further down in the for loop<br>and the benefit of writing it this way instead of with the states is that it’s much easier to understand like i can actually just walk through the code and explain it to you you know if you just read through the code you read an opening quote and then you start looping and then until you find the closing quote you read a character and if it’s a backslash you skip the next character and that’s it right you can just read that off the page which you couldn’t do in the original this version also happens to run<br>faster although that doesn’t really matter for us um but as i mentioned i’m going to highlight what i think are kind of important lessons as hints for designing your own go programs and this is the first one to convert data state into code state when it makes your programs clearer and again like these are all hints you should you shouldn’t you know for all of these you should consider it as you know only if it helps you can decide so one problem with this hint is that not all programs have the luxury of<br>having complete control over their control flow so you know here’s a different example instead of having a read care function that can be called this code is written to have a process care method that you have to hand the character to one at a time and then process care has no choice really but to you know encode its state in an explicit state variable because after every character it has to return back out and so it can’t save the state in the program counter in the stack it has to have the state in an actual variable but<br>in go we have another choice right because we can’t save the state on that stack and in that program counter but you know we can make another go routine to hold that state for us so supposing we already have this debugged read string function that we really don’t want to rewrite in this other way we just want to reuse it it works maybe it’s really big and hairy it’s much more complicated than the thing we saw we just want to reuse it and so the way we can do that and go is we can start a new go routine<br>that does the read string part and it’s the same read string code as before we pass in the character reader and now here the um you know the init method makes this this go routine to do the character reading and then every time the process care method is called um we send a message to the go routine on the car channel that says here’s the next character and then we receive a message back that says like tell me the current status and the current status is always either i need more input or you know it basically you know was it okay or not<br>and so um you know this lets us move the this the program counter that we we couldn’t do on the first stack into the other stack of the go routine and so using additional go teams is a great way to hold additional code state and give you the ability to do these kinds of cleanups even if the original structure the product the problem makes it look like you can’t but go ahead i i assume you’re fine with uh people asking questions yeah absolutely i just wanted to make sure that yeah yeah definitely please<br>interrupt um and so so the hint here is to use additional go routines to hold additional code state and there’s there’s one caveat to this and then it’s not free to to just make go routines right you have to actually make sure that they exit because otherwise you’ll just accumulate them and so you do have to think about uh you know why does the go routine exit like you know is it going to get cleaned up and in this case we know that you know q dot parse is going to return where you know parse go<br>sorry that’s not right um oh sorry the read string here read string is going to return any time it sends a a message that says need more input where’d it go there’s something missing from this slide sorry i went through this last night um so so as we go in we go into init we kick off this go routine it’s going to call read care a bunch of times and then we read the status once and that that first status is going to happen because the the first call to read care from read string is going to send i need<br>more input and then we’re going to send a character back um we’re going to send the character back in process care and then every time process care gets called it returns a status and so up until you get um you know need more input you’re going to get the um uh sorry this is not working um you’re going to get any more input for every time you want to read a character and then when it’s done reading characters what i haven’t shown you here what seems to be missing somehow is when things exit and when<br>things exit let’s see if it’s on this slide yeah so there’s a return success and a return bad input that i’d forgotten about and so uh you know these return a different status and then they’re done so when process care uh you know in in the read stream version when it returns you know bad input or success we we say that you know it’s done and so as long as the caller is going through and um you know calling until it gets something that’s not need more input then the go routine will finish but you<br>know maybe if we stop early if the caller like hits an eof and stops on its own without telling us that it’s done there’s a go routine left over and so that could be a problem and so you just you need to make sure that you know when and why each go routine will exit and the nice thing is that if you do make a mistake and you leave guardians stuck they just sit there it’s like the best possible bug in the world because they just sit around waiting for you to look at them and all you have to do is remember to<br>look for them and so you know here’s a very simple program at least go routines and it runs an http server and so you know if we run this it kicks off a whole bunch of effort routines and they all uh block trying to send to a channel and then it makes the http server and so if i run this program it just sits there and if i type control backslash on a unix system i get a sig quit which makes it crash and dump all the stacks of the go routines and you can see on the slide that you know it’s going to print over and over<br>again here’s the go routine in h called from g called from f and and in a channel send and if you look at the line numbers you can see exactly where they are another option is that since we’re in an http server and the hp server imports the net http prof package you can actually just visit the http server’s debug pprofgoreteen url which gives you the stacks of all the running go routines and unlike the crash dump it takes a little more effort and it deduplicates the go routines based on their stacks<br>and so and then it sorts them by how many there are of each stack and so if you have a go routine leak the leak shows up at the very top so in this case you’ve got 100 go routines stuck in h called from g call from f and then we can see there’s like one of a couple other go routines and we don’t really care about them and so you know this is a new hint that it just it’s really really useful to look for stucco routines by just going to this end point all right so that was kind of the warm-up now i<br>want to look at the first real concurrency pattern which is a publish subscribe server so publish subscribe is a way of structuring a program that you decouple the parts that are publishing interesting events from the things that are subscribing to them and there’s a published subscriber pub sub server in the middle that connects those so the individual publishers and the individual subscribers don’t have to be aware of exactly who the other ones are so you know on your android phone um an app might publish a make a phone<br>call event and then the the dialer might subscribe to that and actually start and you know help dial and and so in a real pub sub server there are ways to filter events based on like what kind they are so that when you publish and make a phone call event like it doesn’t go to your email program but you know for now we’re just going to assume that the filtering is taken care of separately and we’re just worried about the actual publish and subscribe and the concurrency of that so here’s an api we want to implement with any number of<br>clients that can call subscribe with a channel and afterwards events that are published will be sent on that channel and then when a client is no longer interested it can call cancel and pass in the same channel to say stop sending me events on that channel and the way that cancel will signal that it really is done sending events on that channel is it will close the channel so that the the receive the caller can can keep receiving events until it sees the channel get closed and then it knows that the cancel has taken effect<br>um so notice that the information is only flowing one way on the channel right you can send to the channel and then it the receiver can receive from it and the information flows from the sender to the receiver and it never goes the other way so closing is also a signal from the sender to the receiver but all the sending is over the receiver cannot close the channel to tell the sender like i don’t want you to send anymore because that’s information going the opposite direction and it’s just a lot easier to reason about<br>if the information only goes one way and of course if you need communication in both directions you can use a pair of channels and it often turns out to be the case that those uh different directions may have different types of data flowing like before we saw that there were runes going in one direction and status updates going in the other direction so how do we implement this api here’s a pretty basic implementation that you know could be good enough we have a server and the server state is a map of registered subscriber channels<br>protected by a lock we initialize the server by just allocating the map and then to publish the event we just send it to every registered channel to subscribe a new channel we just add it to the map and to cancel we take it out of the map and then because these are all um these are all methods that might be called from multiple go routines um we need to call lock and unlock around these to um you know protect the map and notice that i wrote defer unlock right after the lock so i don’t have to remember to unlock it later<br>uh you’ve probably all seen this you know it’s sort of a nice idiom to just do the lock unlock and then you know have a blank line and have that be its own kind of paragraph in the code one thing i want to point out is that using defer makes sure that the mutex gets unlocked even if you have multiple returns from the function so you can’t forget but it also makes sure that it gets unlocked if you have a panic like in subscribe and cancel where there’s you know panics for misuse and there is a subtlety here about if<br>you might not want to unlock the mutex if the panic happened while the thing that was locked is in some inconsistent state but i’m going to ignore that for now in general you try to avoid having the the things that might panic happen while you’re you know potentially an inconsistent state and i should also point out that the use of panic at all in subscribe and cancel implies that you really trust your clients not to misuse the interface that it is a program error worth you know tearing down the entire program<br>potentially for that to happen and in a bigger program where other clients were using this api you’d probably want to return an error instead and not have the possibility of taking down the whole program but panicking simplifies things for now and you know error handling in general is kind of not the topic today a more important concern with this code than panics is what happens if a go routine is slow to receive events so all the operations here are done holding the mutex which means all the clients kind of have to proceed in<br>lockstep so during publish there’s a loop that’s sending on the channels sending the event to every channel and if one subscriber falls behind the next subscriber doesn’t get the event until that slow subscriber you know wakes up and actually gets the the event off off that channel and so one slow subscriber can slow down everyone else and you know forcing them to proceed in lockstep this way is not always a problem if you’ve you know documented the restriction and for whatever reason you know how the<br>clients are are written and you know that they won’t ever fall too far behind this could be totally fine it’s a really simple implementation and um and it has nice properties like on return from publish you know that the event has actually been handed off to each of the other grow routines you don’t know that they’ve started processing it but you know it’s been handed off and so you know maybe that’s good enough and you could stop here a second option is that if you need to tolerate just a little bit of slowness<br>on the the subscribers then you could say that they need to give you a buffered channel with room for a couple events in the buffer so that you know when you’re publishing you know as long as they’re not too far behind there’ll always be room for the new event to go into the channel buffer and then the actual publish won’t block for too long and again maybe that’s good enough if you’re sure that they won’t ever fall too far behind you get to stop there but in a really big program you do want to cope more gracefully with<br>arbitrarily arbitrarily slow subscribers and so then the question is what do you do and so you know in general you have three options you can slow down the event generator which is what the previous solutions implicitly do because publish stops until the subscribers catch up or you can drop events or you can queue an arbitrary number of past events those are pretty much your only options so we talked about you know publish and slowing down the event generator there’s a middle ground where you coalesce the events or you drop them<br>um so that you know the subscriber might find out that you know hey you missed some events and i can’t tell you what they were because i didn’t save them but but i’m at least going to tell you you missed five events and then maybe it can do something else to try to catch up and this is the kind of approach that um that we take in the profiler so in the profiler if you’ve used it if uh there’s a go routine that uh fills the profile on on a signal handler actually with profiling events and then there’s a<br>separate go routine whose job is to read the data back out and like write it to disk or send it to a http request or whatever it is you’re doing with profile data and there’s a buffer in the middle and if the receiver from the profile data falls behind when the buffer fills up we start adding entries to a final profile entry that just has a single entry that’s that’s a function called runtime.<br>lost profile data and so if you go look at the profile you see like hey the program spent five percent of its time in lost profile data that just means you know the the profile reader was too slow and it didn’t catch up and and we lost some of the profile but we’re clear about exactly you know what the error rate is in the profile and you pretty much never see that because all the readers actually do keep up but just in case they didn’t you have a pretty clear signal um an example of purely dropping the events is the os signal package<br>where um you have to pass in a channel that will be ready to receive the signal a signal like sig hop or sig quit and when the signal comes in the run time tries to send to each of the channels that subscribe to that signal and if it can’t send to it it just doesn’t it’s just gone um because you know we’re in a signal handler we can’t wait and so what the callers have to do is they have to pass in a buffered channel and if they pass in a buffered channel that has you know length at least one<br>buffer length at least one and they only register that channel to a single signal then you know that if a signal comes in you’re definitely going to get told about it if it comes in twice you might only get told about it once but that’s actually the same semantics that unix gives to processes for signals anyway so that’s fine so those are both examples of dropping or coalescing events and then the third choice is that you might actually just really not want to lose any events it might just be really important that you<br>never lose anything in which case you know you can queue an arbitrary number of events you can somehow arrange for the program to just save all the events that the you know slow subscriber hasn’t seen yet somewhere and and give them to the subscriber later and it’s really important to think carefully before you do that because in a distributed system you know there’s always slow computers always computers that have fallen offline or whatever and they might be gone for a while and so you don’t want to introduce<br>unbounded queuing in general you want to think very carefully before you do that and think well you know how unbounded is it really and can i tolerate that and so like that’s a reason why channels don’t have just an unbounded buffering it’s really almost never the right choice and if it is the right choice you probably want to build it very carefully um and so but we’re going to build one just to see what it would look like and before we do that i just want to adjust the program a little bit so we have this mutex in the code<br>and the mutex is an example of of keeping the the state whether you’re locked or not in a state variable but we can also move that into a program counter variable by putting it in a different go routine and so in this case we can start a new go routine that runs a program a function called s dot loop and it handles requests sent on three new channels publish subscribe and cancel and so in init we make the channels and then we we kick off s dot loop and s dot loop is sort of the amalgamation of the previous method<br>bodies and it just receives from any of the three channels a request a publish a subscriber a cancel request and it does whatever was asked and now that map the subscriber map can be just a local variable in s dot loop and and so um you know it’s the same code but now that data is clearly owned by s.<br>loop nothing else could even get to it because it’s a local variable and then we just need to change the original methods to send the work over to the loop go routine and so uppercase publish now sends on lowercase publish the channel the event that it wants to publish and similarly subscribe and cancel they create a request that has a channel uh that we want to subscribe and also a channel to get the answer back and they send that into the loop and then the loop sends back the answer and so i referred to transforming the program this way as like converting the<br>mutex into a go routine because we took the data state of the mutex there’s like a lock bit inside it and now that lock bit is implicit in the program counter of the loop um it’s very clear that you can’t ever have you know a publish and subscribe happening at the same time because it’s just single threaded code and just you know executes in sequence on the other hand the the original version had a kind of like clarity of state where you could sort of inspect it and and reason about well this is the<br>important state and and it’s harder in the go routine version to see like what’s important state and what’s kind of incidental state from just having a go routine and in a given situation you know one might be more important than the other so a couple years ago i did all the labs for the class when it first switched to go and and raft is a good example of where you probably prefer the state with the mutex is because raft is is so different from most concurrent programs and that like each replica is just kind of profoundly<br>uncertain of its state right like the state transitions you know one moment you think you’re the leader and the next moment you’ve been deposed like one moment your log has ten entries the next moment you find actually no it only has two entries and so being able to manipulate that state directly rather than having to you know somehow get it in and out of the program counter makes a lot more sense for raft but that’s pretty unique in most situations it cleans things up to put the state in the program counter<br>all right so in order to deal with the slow subscribers now we’re going to add some helper go routines and their job is to manage a particular subscriber’s backlog and keep the overall program from blocking and so this is the helper go team and the the the main loop go routine will send the events to the helper which we then trust because we wrote it not to fall arbitrarily behind and then the helpers job is to cue events if needed and send them off to the subscriber all right so this actually has um two<br>problems the first is that if there’s nothing in the queue then the select is actually wrong to try to offer q of zero and in fact just evaluating q of zero at the start of the select will panic because the queue is empty and so we can fix these by setting up the arguments separately from the select and in particular we need to make a channel send out that’s going to be nil which is never able to proceed in a select um as we know when we don’t want to send and it’s going to be the actual out channel when we do want to send and<br>then we have to have a separate variable that holds the event that we’re going to send it will only you know actually read from q of 0 if there’s something in the queue the second thing that’s wrong is that we need to handle closing of the channel of the input channel because when the input channel closes we need to flush the rest of the queue and then we need to close the output channel so to check for that we change the select from just doing e equals receive from n to e comma okay equals receive from n and the comma<br>okay we’ll be told whether or not the channel is actually sending real data or else it’s closed and so when okay is false we can set into nil to say let’s stop trying to receive from in there’s nothing there we’re just going to keep getting told that it’s closed and then when the loop is fine when the queue is finally empty we can exit the loop and so we change the for condition to say we want to keep exiting the loop as long as there actually still is an input channel and there’s something<br>to write back to the output channel and then once both of those are not true anymore it’s time to close it’s time to exit the loop and we close the output channel and we’re done and so now we’ve correctly propagated the closing of the input channel to the output channel so that was the helper and the server loop used to look like this and to update it we just changed the subscription map before it was a map from subscribe channels to bools it was just basically a set and now it’s a map from subscribe<br>channel to helper channel and every time we get a new subscription we make a helper channel we kick off a helper go routine and we record the helper channel in the subscription map instead of the the actual channel and then the rest of uh the rest of the the loop actually barely changes at all so i do want to point out that like if you wanted to have a different strategy for you know what you do with uh clients that fall too far behind that can all go in the helper go routine the code on the screen right now is completely unchanged so we’ve we’ve<br>completely separated the publish subscribe maintaining the the actual list of subscribers map from the what do you do when things get too slow map or problem and so it’s really nice that you’ve got this clean separation of concerns into completely different go routines and that can help you you know keep your program simpler and so that’s the general hint is that you can use go routines a lot of the time to separate independent concerns all right so um the second pattern for today is a work scheduler<br>and you did one of these in lab one for mapreduce and i’m just gonna you know build up to that and and this doesn’t do all the rpc stuff it just kind of assumes that there’s kind of channel channel based interfaces to all the the servers so you know we have this function scheduled it takes a fixed list of servers has a number of tasks to run and it has just this abstracted function call that you you call to run the task on a specific server you can imagine it was you know doing the rpcs underneath so we’re going to need some way to keep<br>track of which servers are available to execute new tasks and so one option is to use our own stack or queue implementation but another option is to use a channel because it’s a good synchronized queue and so we can send into the channel to add to the queue and receive from it to pop something off and in this case we’ll make the queue be a queue of servers and we’ll start off it’s a queue of idle servers servers that aren’t doing any work for us right now and we’ll start off by just initializing<br>it by sending all the known servers into the idle list and then we can loop over the tasks and for every task we kick off a go routine and its job is to pull a server off the idle list run the task and then put the server back on and this loop body is another example of the earlier hint to use guaranteeing select independent things run independently because each task is running as a separate concern they’re all running in parallel unfortunately there are two problems with this program the first one is that the closure that’s<br>running as a new go routine refers to the loop iteration variable which is task and so by the time the go routine starts exiting you know the loop has probably continued and done at task plus plus and so it’s actually getting the wrong value of task you’ve probably seen this by now um and of course the best way to to catch this is to run the race detector and at google we even encourage teams to set up canary servers that run the race detector and split off something like you know 0.<br>1 percent of their traffic to it just to catch um you know races that might be in the production system and you know finding a bug with a race detector is is way better than having to debug some you know corruption later so there are two ways to fix this race the first way is to give the closure an explicit parameter and pass it in and the go statement requires a function call specifically for this reason so that you can set specific arguments that get evaluated in the context of the original go routine and then get copied to the new<br>go routine and so in this case we can declare a new argument task two we can pass task to it and then inside the go routine task 2 is a completely different copy of of task and i only named it task 2 to make it easier to talk about but of course there’s a bug here and the bug is that i forgot to update task inside the function to refer to task two instead of task and so we basically never do that um what we do instead is we just give it the same name so that it’s impossible now for the code inside the go regime to<br>refer to the wrong copy of task um that was the first way to fix the race there’s a second way which is you know sort of cryptic the first time you see it but it amounts to the same thing and that is that you just make a copy of the the variable inside the loop body so every time a colon equals happens that creates a new variable so in the for loop in the outer for loop there’s a colon equals at the beginning and there’s not one the rest of the loop so that’s all just one variable for the entire loop<br>whereas if we put a colon equals inside the body every time we run an iteration of the loop that’s a different variable so if the guard if the go function closure captures that variable those will all be distinct so we can do the same thing we do task two and this time i remember to update the body but you know just like before it’s too easy to forget to update the body and so typically you write task colon equals task which looks kind of magical the first time you see it but but that’s what it’s for<br>all right so i said there were two bugs in the program the first one was this race on task and the second one is that uh we didn’t actually do anything after we kicked off all the tasks we’re not waiting for them to be done um and and in particular uh we’re kicking them off way too fast because you know if there’s like a million tasks you’re going to kick off a million guard teams and they’re all just going to sit waiting for one of the five servers which is kind of inefficient and so what<br>we can do is we can pull the fetching of the the next idle server up out of the go routine and we pull it up out of the go routine now we’ll only kick off a go routine when there is a next server to use and then we can kick it off and and you know use that server and put it back and the using the server and put it back runs concurrently but doing the the fetch of the idle server inside the loop slows things down so that there’s only ever now number of servers go routines running instead of number of tasks<br>and that receive is essentially creating some back pressure to slow down the loop so it doesn’t get too far ahead and then i mentioned we have to wait for the task to finish and so we can do that by just at the end of the loop uh going over the the list again and pulling all the servers out and we’ve pulled you know the right number of servers out of the idle list that means they’re all done and so that’s that’s the full program now to me the most important part of this is that you still get to write a for<br>loop to iterate over the tasks there’s lots of other languages where you have to do this with state machines or some sort of callbacks and you don’t get the luxury of encoding this in the control flow um and so this is a you know much cleaner way where you can just you know use a regular loop but there are some some changes we could make some improvements and so one improvement is to notice that there’s only one go routine that makes requests of a server at a particular time so instead of having one go routine per<br>task maybe we should have one go routine per server because there are probably going to be fewer servers than tasks and to do that we have to change from having a channel of idle servers to a channel of you know yet to be done tasks and so we’ve renamed the idle channel to work and then we also need a done channel to count um you know how many uh tasks are done so that we know when we’re completely finished and so here there’s a new function run tasks and that’s going to be the per server function and we kick off one of<br>them for each server and run tasks his job is just to loop over the work channel run the tasks and when the server is done we send true to done and the you know the server tells us that you know it’s done and the server exits when the work channel gets closed that’s what makes that for loop actually stop so then you know having kicked off the servers we can then just sit there in a loop and send each task to the work channel close the work channel and say hey there’s no more work coming all the servers you should finish and then and<br>then exit and then wait for all the servers to tell us that they’re done so in the lab there were a couple complications one was that you know you might get new servers at any given time um and so we could change that by saying the servers come in on a channel of strings and and that actually fits pretty well into the current structure where you know when you get a new server you just um kick off a new uh run tasks go routine and so the only thing we have to change here is to put that loop into its own go routine so that while<br>we’re sending tasks to servers we can still accept new servers and kick off the helper go routines but now we have this problem that we don’t really have a good way to tell when all the servers are done because we don’t know how many servers there are and so we could try to like maintain that number as servers come in but it’s a little tricky and instead we can count the number of tasks that have finished so we just move the done sending true to done up a line so that instead of doing it per server<br>we now do it per task and then at the end of the loop or at the end of the function we just have to wait for the right number of tasks to be done and so so now again we sort of know uh why these are gonna the finish um there’s actually a deadlock still and that is that if the the number of tasks is um is too big actually i think always you you’ll get a deadlock and if you run this you know you get this nice thing where the dirt it tells you like hey your routines are stuck and the problem is that you know we have this run task uh<br>server loop and the server loop is trying to say hey i’m done and you’re trying to say hey like here’s some more work so if you have more than one task you’ll run into this deadlock where you know you’re trying to send the next task to a server i guess that is more task than servers you’re trying to send the next task to a server and all the servers are trying to say hey i’m done with the previous task but you’re not there to receive from the done channel and so again you know it’s really nice<br>that the the guardians just hang around and wait for you to look at them and we can fix this one way to fix this would be to add a separate loop that actually does a select that either sends some work or accounts for some of the work being done that’s fine but a cleaner way to do this is to take the the work sending loop the task sending loop and put it in its own go routine so now it’s running independently of the counting loop and the counting loop can can run and you know unblock servers that are done with certain tasks while<br>other tasks are still being sent but the simplest possible fix for this is to just make the work channel big enough that you’re never gonna run out of space because we might decide that you know having a go routine per task is you know a couple kilobytes per task but you know an extra inch in the channel is eight bytes so probably you can spend eight bytes per task and so if you can you just make the work channel big enough that you know that all the sends on work are going to never block and you’ll always get down to the the counting loop<br>at the end pretty quickly and so doing that actually sets us up pretty well for the other wrinkle in the lab which is that sometimes calls can time out and here i’ve modeled it by the call returning a false so just say hey it didn’t work um and so you know in run task it’s really easy to say like if it’s really easy to say like if the call uh fails then or sorry if the call succeeds then you’re done but if it fails just put the task back on the work list and because it’s a queue not a stack<br>putting it back on the work list is very likely to hand it to some other server um and so that will you know probably succeed because it’s some other server i mean this is all kind of hypothetical but um uh it’s a really you know it fits really well into the structure that we’ve created all right and the final change is that because the server guarantees are sending on work we do have to uh wait to close it until we know that they’re done sending and uh because again you can’t close you know before they finish sending<br>and so we just have to move the close until after we’ve counted that all the tasks are done um and you know sometimes we get to this point and people ask like why can’t you just kill go routines like why not just be able to say look hey kill all the server guardians at this point we know that they’re not needed anymore and the answer is that you know the go routine has state and it’s interacting with the rest of the program and if it all of a sudden just stops it’s sort of like it hung right and<br>maybe it was holding a lock maybe it was in the middle of some sort of communication with some other guru team that was kind of expecting an answer so we need to find some way to tear them down more gracefully and that’s by telling them explicitly hey you know you’re done you can you can go away and then they can clean up however they need to clean up um you know speaking of cleaning up there’s there’s actually one more thing we have to do which is to shut down the loop that’s that’s watching for new<br>servers and so we do have to put a select in here where uh you know the the thing that’s waiting for new servers on the server channel we have to tell it okay we’re done just like stop watching for new servers because all the servers are gone um and we could make this the caller’s problem but but this is actually fairly easy to do all right so um pattern number three which is a a client for a replicated server of service so here’s the interface that we want to implement we have some service that we want that is replicated for<br>reliability and it’s okay for a client to talk to any one of these servers and so the the replicated client is given a list of servers the uh the arguments to init is a list of servers and a function that lets you call one of the servers with a particular argument set and get a reply and then being given that during init the replicated client then provides a call method that doesn’t tell you what server it’s going to use it just finds a good server to use and it keeps the same keeps using the same server for as long as it can until<br>it finds out that that server is no good so in this situation there’s almost no shared state that you need to isolate and so like the only state that persists from one call to the next is what server did i use last time because i’m going to try to use that again so in this case that’s totally fine for a mutex i’m just going to leave it there it’s always okay to use mutex if that’s the cleanest way to write the code you know some people get the wrong impression from how much we talk about<br>channels but it’s always okay to use a mutex if that’s all you need so now we need to implement this replicated call method whose job is to try sending to lots of different servers right but but first to try the the original server so so what does it mean if you know the try fails well there’s like no clear way for it to fail above it just always returns a reply and so the only way it can fail is if it’s taking too long so we’ll assume that if it takes too long that means it failed so in order to deal with timeouts we<br>have to run that that code in the background in a different go routine so we can do something like this um where we set a timeout we create a timer and then we use the go routine to send in the background and then at the end we wait and either we get the timeout or we get the actual reply if we get the actual reply we return it if we get the timeout we have to do something we’ll have to figure out what to do um it’s worth pointing out that you have to call tdot stop because otherwise the timer sits in a timer queue that you<br>know it’s going to go off in one second and so you know if this call took a millisecond and you have this timer that’s going to sit there for the next second and then you do this in a loop and you get a thousand timers sitting in that that um that queue before they start actually you know um disappearing and so this is kind of a wart in the api but it’s been there forever and we’ve never fixed it um and and so you just have to remember to call stop uh and then you know now we have to figure out what do we do in the case of<br>the timeout and so in the case of the timeout we’re going to need to try a different server so we’ll write a loop and we’ll start at um the id that id0 it says and you know if a reply comes in that’s great and otherwise we’ll reset the timeout and go around the loop again and try sending to a different server and notice there’s only one done channel in this program and so you know on the third iteration of the loop we might be waiting and then finally the first server gives us a reply that’s totally fine we’ll<br>take that reply that’s great um and so then we’ll stop and return it and but if we get all the way through the loop it means that we’ve sent the request to every single server in which case there’s no more timeouts we just have to wait for one of them to come back and so that’s the the plain receive and the return at the end and then it’s important to notice that the done channel is buffered now so that if you know you’ve sent the result to three different servers you’re going to take the first reply and<br>return but the others are going to want to send responses too and we don’t want those go routines to just sit around forever trying to send to a channel that we’re not reading from so we make the buffer big enough that they can send into the buffer and then go away and the channel just gets garbage collected that says like why can’t the timer just be garbage collected when nobody’s referencing it instead of having to to wait when it goes off when you said that you have multiple waiting if it goes off in one<br>millisecond yeah the the problem is the timer is referenced by the the run time it’s in the list of active timers and so calling stop takes it out of the list of active timers and and so like that’s arguably kind of a wart in that like in the specific case of a timer that’s like only going to ever get used in this channel way like we could have special case that by like having the channel because inside the timer is this t.<br>c channel right so we could have had like a different kind of channel implementation that inside had a bit that said hey i’m a timer channel right and and and then like the select on it would like know to just wait but if you just let go of it it would just disappear we’ve kind of like thought about doing that for a while but we never did and so this is like the state of the world um but but you know the garbage collector can’t distinguish between you know the reference inside the runtime and the reference and the rest<br>of the program it’s all just references and so until we like special case that channel in some way like we we can’t actually get rid of that thank you sure so um so then the only thing we have left is to have this preference where we try to use the same um id that we did the previous time and so to do that preference um we you know had the server id coming back in the reply anyway in the result channel and so you know we do the same sort of loop but we loop over an offset from the actual id we’re going to use which is<br>the pre the preferred one and then when we get an answer we uh set the preferred one to where we got the answer from and then we reply and you’ll notice that i used a go to statement that’s okay if you need to go to it’s fine um it’s not sort of there’s no zealotry here all right so uh the fourth one and then we’ll we’ll do some questions um is a protocol multiplexer and this is kind of the logic of a core of any rpc system and and this comes up a lot i feel like i wrote a lot of these in grad school<br>and sort of years after that and so the basic api of a protocol multiplexer is that it sits in from some service which we’re going to pass to the init method and then having been initialized with a service you can call and you can call call and give it a message a request message and then it’ll you know give you back the reply message at some point and the things it needs from the service to do multiflexing is that given a message it has to be able to pull out the tag that uniquely identifies the message<br>and and will identify the the reply because it will come back in with a matching tag and then it needs to be able to send a message out and to receive you know a message but the send and receive um are there arbitrary messages that are not matched it’s the multiplexer’s job to actually match them so um to start with we’ll have a go routine that’s in charge of calling send and another group team that’s in charge of calling receive both in just a simple loop and so to initialize the service we’ll<br>set up the structure and then we’ll kick off the send loop and the receive loop and then we also have a map of pending requests and the map it maps from the tag that we saw the id number in the messages to a channel where the reply is supposed to go the send loop is fairly simple you just range over the things that need to be sent and you send them and this just has the effect of serializing the calls to send because we’re not going to force the service implementation to you know deal with us sending you know from multiple<br>routines at once we’re serializing it so that it can just be thinking of you know sending one one packet at a time and then the receive loop uh is a little bit more complicated it pulls a receive it pulls a reply off the the service and again they’re serialized so we’re only reading one at a time and then it pulls the tag out of the reply and then it says ah i need to find the channel to send this to uh so it pulls the channel out of the pending map it takes it out of the pending map so that you know if we<br>accidentally get another one we won’t try to send it and then it sends the reply and then to do a call you just have to set yourself up in the map and then hand it to send and wait for the reply so we start off we get the tag out we make our own done channel we insert the tag into the map after first checking for bugs and then we send the the argument message to send and then we wait for the reply to come in undone it’s very very simple i mean like i used to write these sort of things in c and it was it was much much worse<br>so that was all the patterns that i wanted to show and um you know i hope that those end up being useful for you in whatever future program you’re writing and and i hope that they’re you know just sort of good ideas even in non-go programs but that you know thinking about them and go can help you when you go to do other things as well so i’m gonna put them all back up and then um i have some questions that fran sent that were you know from all of you and um we’ll probably have some time for uh you know questions from from the chat<br>as well i have no idea in zoom where the chat window is so when we get to that people can just speak up just i don’t use zoom on a daily basis unfortunately um so uh and and normally i know how to use zoom like regularly but with with the presentation it’s like zoom is in this minimize thing that doesn’t have half the things i’m used to anyway um someone asked how long ago took and so far it’s been about 13 and a half years we started discussions in late september 2007 i joined full-time in august 2008 when i<br>finished at mit we did the initial open source launch november 2009 we released go one the sort of first stable version in october 2011. uh or sorry the plan was october 2011. go one itself was march 2012. and then we’ve just been on you know it’s a regular schedule since then the next major change of course is is going to be generics and um and adding generics and that’s probably going to be go 118 which is going to be next in february someone asked you know how big a team does it take to build a language like go<br>and you know for those first two years there were just five of us and and that was enough to get us to uh you know something that we released that actually could run in production but it was fairly primitive um you know it was it was a good prototype it was a solid working prototype but but it wasn’t like what it is today and over time we’ve expanded a fair amount now we’re up to something like 50 people employed directly or employed by google to work directly on go and then there’s tons of open source<br>contributors i mean there’s literal cast of thousands that have helped us over the last 13 years and there’s absolutely no way we could have done it even with 50 people without all the different contributions from the outside someone asked about design priorities um and and motivations and you know we we built it for us right the priority was to build something that was gonna help google and it just turned out that google was like a couple years ahead we were just in a really lucky spot where google was a<br>couple years ahead of the rest of the industry on having to write distributed systems right now everyone using cloud software is is writing programs that talk to other programs and sending messages and you know there’s hardly any single machine programs anymore and so you know we sort of locked into at some level you know building the language that we that the rest of the world needed a couple years later and and then the other thing that that was really a priority was making it work for large numbers of programmers and because<br>you know google had a very large number of programmers working in one code base and and now we have open source where you know even if you’re a small team you’re depending on code that’s written by a ton of other people usually and so a lot of the the issues that come up with just having many programmers still come up in that context so those were really the things we were trying to solve and you know for all of these things we we took a long time before we were willing to actually commit to putting something in the<br>language like everyone basically had to agree in the the core original group and and so that meant that it took us a while to sort of get the pieces exactly the way we wanted them but once we got them there they’ve actually been very stable and solid and really nice and they work together well and and the same thing is kind of happening with generics now where we actually feel i feel personally really good about generics i feel like it feels like the rest of go and that just wasn’t the case for the proposals<br>that we had you know even a couple years ago much less the you know early ones uh someone said they they really like defer uh which is unique to language and and i do too thank you um but i wanted to point out that you know we we did absolutely you know create defer for go but um swift has adopted it and i think there’s a proposal for sipos bus to adopt it as well so you know hopefully it kind of moves out a little bit there was a question about um go and using capitalization for exporting and which i know is like something that<br>uh you know sort of is jarring when you first see it and and the story behind that is that well we needed something and we knew that we would need something but like at the beginning we just said look everything’s exported everything’s publicly visible we’ll deal with it later and after about a year it was like clear that we needed some way to you know let programmers hide things from other programmers and you know c plus plus has this public colon and private colon and in a large struct it’s actually<br>really annoying that like you’re looking you’re in the you’re looking at definitions and you have to scroll backwards and try to find where the like most recent public colon or private colon was and if it’s really big it can be hard to find one and so it’s like hard to tell whether a particular definition is public or private and then in java of course it’s at the beginning of every single field and that seemed kind of excessive too it’s just too much typing and so we looked around some more and<br>and someone pointed out to us that well python has this convention where you put an underscore in front to make something hidden and that seemed interesting but you probably don’t want the default to be not hidden you want the default to be hidden um and then we thought about well we could put like a plus in front of names um and then someone suggested well like what about uppercase could be exported and it seemed like a dumb terrible idea it really did um but as you think about it like i really didn’t like this idea um and i<br>have like very clear memory of sitting of like the room and what i was staring at as we discussed this uh but i had no logical argument against it and it turned out it was fantastic it was like it seemed bad it just like aesthetically but it is one of my favorite things now about go that when you look at a use of something you can see immediately you get that bit of is this something that other people can access or not at every use because if you know you see code calling a function to do you know whatever it is that it does you<br>think oh wow like can other people do that and and you know your brain sort of takes care of that but now i go to c plus and i see calls like that and i get really worried i’m like wait is that is that something other classes can get at um and having that bid actually turns out to be really useful for for reading code a couple people asked about generics if you don’t know we have an active proposal for generics we’re actively working on implementing it we hope that the the release later in the year<br>uh towards the end of the year will actually have you know a full version of generics that you can you can actually use the the um that’ll be like a preview release the real release that we hope it will be in is go 118 which is february of next year so maybe next class uh we’ll actually get to use generics we’ll see but i’m certainly looking forward to having like a generic min and max the reason we don’t have those is that you’d have to pick which type they were for or have like a whole suite of them<br>and it just seemed silly it seemed like we should wait for generics um someone asked is there any area of programming where go may not be the best language but it’s still used and and the answer is like absolutely like that happens all the time with every language um i think go is actually really good all around language um but you know you might use it for something that’s not perfect for just because the rest of your program is written and go and you want to interoperate with the rest of the program so you know there’s this website called<br>the online encyclopedia of integer sequences it’s a search engine you type in like two three five seven eleven and it tells you those are the primes um and it turns out that the back end for that is all written and go and if you type in a sequence it doesn’t know it actually does some pretty sophisticated math on the numbers all with big numbers and things like that and all of that is written in go to because it was too annoying to shell out to maple and mathematica and sort of do that cross-language thing<br>even though you’d much rather implement it in those languages so you know you run into those sorts of compromises all the time and that’s fine um someone asked about uh you know go is supposed to be simple so that’s why there’s like no generics and no sets but isn’t also for software developers and don’t software developers need all this stuff and you know it’s silly to reconstruct it and i think that’s it’s true that there’s someone in tension but but simplicity in the sense of leaving<br>things out was not ever the goal so like for sets you know it just seemed like maps are so close to sets you just have a set a map where the value is empty or a boolean that’s a set and for generics like you have to remember that when we started go in 2007 java was like just finishing a true fiasco of a rollout of generics and so like we were really scared of that we knew that if we just tried to do it um you know we would get it wrong and we knew that we could write a lot of useful programs without generics<br>and so that was what we did and um and we came back to it when you know we felt like okay we’ve you know spent enough time writing other programs we kind of know a lot more about what we need from from generics for go and and we can take the time to talk to real experts and i think that you know it would have been nice to have them five or ten years ago but we wouldn’t have had the really nice ones that we’re going to have now so i think it was probably the right decision um so there was a question about go<br>routines and the relation to the plan line thread library which which was all cooperatively scheduled and whether go routines were ever properly scheduled and like if that caused problems and it is absolutely the case that like go and and the go routine runtime were sort of inspired by previous experience on plan nine there was actually a different language called aleph on an early version plan nine that was compiled it had channels it had select it had things we called tasks which were a little bit like our teens but it<br>didn’t have a garbage collector and that made things really annoying in a lot of cases and also the way that tasks work they were tied to a specific thread so you might have three tasks in one thread and two tasks and another thread and in the three tasks in the first thread the only one ever ran at a time and they could only reschedule during a channel operation and so you would write code where those three tasks were all operating on the same data structure and you just knew because it was in your head when you wrote it<br>that you know it was okay for these two different tasks to be scribbling over the same data structure because they could never be running at the same time and meanwhile you know in the other thread you’ve got the same situation going on with different data and different tasks and then you come back to the same program like six months later and you totally forget which tasks could write to different pieces of data and i’m sure that we had tons of races i mean it was just it was a nice model for small programs<br>and it was a terrible model for for programming over a long period of time or having a big program that other people had to work on so so that was never the model for go the model for go was always it’s good to have these lightweight go routines but they’re gonna all be running independently and if they’re going to share anything they need to use locks and they need to use channels to commute to communicate and coordinate explicitly and and that that has definitely scaled a lot better than any of the planned line stuff ever<br>did um you know sometimes people hear that go routines are cooperatively scheduled and they they think you know something more like that it’s it’s true that early on the go routines were not as preemptively scheduled as you would like so in the very very early days the only preemption points when you called into the run time shortly after that the preemption points were any time you entered a function but if you were in a tight loop for a very long time that would never preempt and that would cause like garbage<br>collector delays because the garbage collector would need to stop all the go routines and there’d be some guaranteeing stuck in a tight loop and it would take forever to finish the loop um and so actually in the last couple releases we finally started we figured out how to get um unix signals to deliver to threads in just the right way so that and we can have the right bookkeeping to actually be able to use that as a preemption mechanism and and so now things are i think i think the preemption delays for garbage<br>collection are actually bounded finally but but from the start the model has been that you know they’re running preemptively and and they don’t get control over when they get preempted uh as a sort of follow-on question someone else asked uh you know where they can look to in the source tree to learn more about guru teams and and the go team scheduler and and the answer is that you know this is basically a little operating system like it’s a little operating system that sits on top of the other operating system instead of on<br>top of cpus um and so the first thing too is like take six eight two eight which is like there i mean i i worked on 6828 and and xv6 like literally like the year or two before i went and did the go run time and so like there’s a huge amount of 688 in the go runtime um and in the actual go runtime directory there’s a file called proc.<br>go which is you know proc stands for process because like that’s what it is in the operating systems um and i would start there like that’s the file to start with and then sort of pull on strings someone asked about python sort of negative indexing where you can write x of minus one and and that comes up a lot especially from python programmers and and it seems like a really great idea you write these like really nice elegant programs where like you want to get the last element you just say x minus one but the real problem is that like you<br>have x of i and you have a loop that’s like counting down from from you know n to zero and you have an off by one somewhere and like now x of minus one instead of being you know x of i when i is minus one instead of being an error where you see like immediately say hey there’s a bug i need to find that it just like silently grabs the element off the other end of the array and and that’s where you know the sort of python um you know simplicity you know makes things worse and so that was why we left it out<br>because it was it was gonna hide bugs too much we thought um you know you could imagine something where you say like x of dollar minus one or len minus one not len of x but just len but you know it seemed like too much of a special case and it really it doesn’t come up enough um someone asked about uh you know what aspect of go was hardest to implement and honestly like a lot of this is not very hard um we’ve done most of this before we’d written operating systems and threading libraries and channel implementations<br>and so like doing all that again was fairly straightforward the hardest thing was probably the garbage collector go is unique among garbage collected languages in that it gives programmers a lot more control over memory layout so if you want to have a struct with two different other structs inside it that’s just one big chunk of memory it’s not a struct with pointers to two other chunks of memory and because of that and you can take the address of like the second field in the struct and pass that around<br>and that means the garbage collector has to be able to deal with a pointer that could point into the middle of an allocated object and that’s just something that java and lisp and other things just don’t do um and so that makes the garbage collector a lot more complicated in how it maintains its data structures and we also knew from the start that you really want low latency because if you’re handling network requests uh you can’t you know just pause for 200 milliseconds while and block all of those<br>in progress requests to do a garbage collection it really needs to be in you know low latency and not stop things and we thought that multicore would be a good a good opportunity there because we could have the garbage collector sort of doing one core and the go program using the other cores and and that might work really well and that actually did turn out to work really well but it required hiring a real expert in garbage collection to uh like figure out how to do it um and make it work but but now it’s it’s really great um i<br>i have a quick question yeah you said um like if it’s struck like it’s declared inside another stroke it actually is all a big chunk of memory yeah why do why did you implement it like that what’s the reasoning behind that um i well so there’s a couple reasons one is for a garbage collector right it’s a service and the load on the garbage collector is proportional to the number of objects you allocate and so if you have you know a struct with five things in it you can make that one allocation that’s like a fifth of<br>the the load on the garbage collector and that turns out to be really important but the other thing that’s really important is cache locality right like if you have the processor is pulling in chunks of memory in like you know 64 byte chunks or whatever it is and it’s much better at reading memory that’s all together than reading memory that’s scattered and so um you know we have a git server at google called garrett that is written in java and it was just starting at the time that go was you know just coming out and and<br>we we just missed like garrett being written and go i think by like a year um but we talked to the the guy who had written garrett and he said that like one of the biggest problems in in garrett was like you have all these shot one hashes and just having the idea of 20 bytes is like impossible to have in java you can’t just have 20 bytes in a struct you have to have a pointer to an object and the object like you know you can’t even have 20 bytes in the object right you have to declare like five different ins or<br>something like that to get 20 bites and there’s just like no good way to do it and and it’s just the overhead of just a simple thing like that really adds up um and so you know we thought giving programmers control over memory was really important um so another question was was about automatic parallelization like for loops and things like that we don’t do anything like that in the standard go tool chain there are there are go compilers for go front ends for gcc and llvm and so to the extent that those do those<br>kind of loop optimizations in c i think you know we get the same from the go friends for those but it’s it’s not the kind of parallelization that we typically need at google it’s it’s more um you know lots of servers running different things and and so you know that sort of you know like the sort of big vector math kind of stuff doesn’t come up as much so it just hasn’t been that important to us um and then the last question i have written now is that someone uh asked about like how do you decide when<br>to acquire release locks and why don’t you have re-entry locks and for that i want to go back a slide let me see yeah here so like you know during the lecture i said things like the lock pro like new protects the map or it protects the data but what we really mean at that point is that we’re saying that the lock protects some collection of invariants that apply to the data or that are true of the data and the reason that we have the lock is to to protect the operations that depend on the invariants and that sometimes temporarily<br>invalidate the invariants from each other and so when you call lock what you’re saying is i need to make use of the invariance that this lock protects and when you call unlock what you’re saying is i don’t need them anymore and if i temporarily invalid invalidated them i’ve put them back so that the next person who calls lock will see you know correct invariants so in the mux you know we want the invariant that each registered pending channel gets at most one reply and so to do that when we take don out of the map<br>we also delete it from the map before we unlock it and if there was some separate kind of cancel operation that was directly manipulating the map as well it could lock the it could call lock it could take the thing out call unlock and then you know if it actually found one it would know no one is going to send to that anymore because i took it out whereas if you know we had written this code to have you know an extra unlock and re-lock between the done equals pending of tag and the delete then you wouldn’t have that you know<br>protection of the invariants anymore because you would have put things back you unlocked and relocked while the invariants were broken and so it’s really important to you know correctness to think about locks as protecting invariants and and so if you have re-entrant locks uh all that goes out the window without the re-entrant lock when you call lock on the next line you know okay the lock just got acquired all the invariants are true if you have a re-entrant lock all you know is well all the invariants were true<br>for whoever locked this the first time who like might be way up here on my call stack and and you really know nothing um and so that makes it a lot harder to reason about like what can you assume and and so i think reentrant locks are like a really unfortunate part of java’s legacy another big problem with re-engine locks is that if you have code where you know you call something and it is depending on the re-entrant lock for you know something where you’ve acquired the lock up above and and then at some point you say you<br>know what actually i want to like have a timeout on this or i want to do it uh you know in some other go routine while i wait for something else when you move that code to a different go routine re-entrant always means locked on the same stack that’s like the only plausible thing it could possibly mean and so if you move the code that was doing the re-entrant lock onto a different stack then it’s going to deadlock because it’s going to that lock is now actually going to real lock acquire and it’s going to be<br>waiting for you to let go of the lock i mean you’re not going to let go of it because you know you think that code needs to finish running so it’s actually like completely fundamentally incompatible with restructurings where you take code and run it in different threads or different guarantees and so so anyway like my advice there is to just you know think about locks as protecting invariants and then you know just avoid depending on reentrant locks it it really just doesn’t scale well to to real programs<br>so i’ll put this list back up actually you know we have that up long enough i can try to figure out how to stop presenting um and then i can take a few more questions um i had i had a question yeah um and i mean i i think coming from python like it’s very useful right it’s very common to use like like standard functional operations right like map yeah um or filter stuff like that like um like list comprehension and when you know i switched over to go and started programming it’s used i i looked it up and people<br>say like you shouldn’t do this do this with loop right i was wondering why um well i mean one is that like you can’t do it the other way so you might just look through the way you can do it um but uh you know a bigger a bigger issue is that well there’s that was one answer the other answer is that uh you know if you do it that way you actually end up creating a lot of garbage and if you care about like not putting too much load on the garbage collector that kind of is another way to avoid that you know so if you’ve got<br>like a map and then a filter and then another map like you can make that one loop over the data instead of three loops over the data each of which generate a new piece of garbage but you know now that we have generics coming um you’ll actually be able to write those functions like you couldn’t actually write what the type signature of those functions were before and so like you literally couldn’t write them and python gets away with this because there’s no no you know static types but now we’re<br>actually going to have a way to do that and i totally expect that once generics go in there will be a package slices and if you import slices you can do slices.map and slices.filter and like slices.unique or something like that and and i think those will all happen um and you know if if that’s the right thing then that’s great thanks sure um one of the hints that you had it was about running go routines that are independent like concurrently um and some of the examples of the code i i think i couldn’t understand it seemed<br>to me like you can just like call the function in the same thread rather than a different thread and i was not sure why you would call it in a different thread so um usually it’s because you want them to proceed independently so um so in one of the one of the examples we had like the there was a loop that was sending um you know tasks to the work queue but there was the servers were running in different go routines and reading from the work queue and doing work but then when they were done they would send uh you know hey i’m done now to the<br>done channel but ascend in go doesn’t complete until the receive actually matches with it and so if the thing that’s sending on the work queue is not going to start receiving from the done channel until it’s done sending to all the work queues or sending all the work into all the tasks into the work queue then now you have a deadlock because the the main thread the main go routine is trying to send new work to the servers the servers are not taking new work they’re trying to tell the main thread<br>that they’re done but the main thread’s not going to actually start at like reading from the done channel until it finishes giving out all the work and so there’s just they’re just staring at each other waiting for different things to happen whereas if we take that loop that if we just put the little girl routine around the loop that’s sending the work then that can go somewhere else and then it can proceed independently and while it’s stuck waiting for the servers to send to um take more work<br>the servers are stuck waiting for the main go routine to you know acknowledge that it finished some work and now the main goal team actually gets down to the loop that you know pulls that finishes that actually acknowledges that it finished the work that reads from the done channel and so it’s just a way to separate out you know these are two different things that logically they didn’t have to happen one after the other and because they were happening one after the other that caused a deadlock and by taking one out and<br>moving it let it run independently um that removes the deadlock thank you so much sure could you talk a little bit about how ghost race detector is implemented sure it is the llvm race detector um and so that probably doesn’t help but but it is exactly the thing that llvm calls thread sanitizer and um and so we actually have a little binary blob that uh you know we link against because we don’t want to depend on all of lvm but it’s the llvm race detector and the way the llvm race sector works is that it allocates a ton of<br>extra virtual memory and then based on the address of of the thing being read or written it has this other you know spot in virtual memory where it records information about like the last uh thread you know it thinks of threads but their go routines um has with the last thread that did a read or a write and then also every time a synchronizing event happens like you know a communication from one go routine to another uh that counts as establishing a happens before edge between two different go routines and if you ever get something where you<br>have a read and a write and they’re not properly sequenced right like so if you have a read and then it happens before something in another chain which then you know later does the right that’s fine but if you have a read and a write and there’s no happens before sequence that connects them then um then that’s a race and it actually you know has some pretty clever ways to you know dynamically figure out quickly you know did this read happen is there a happens before a path between this readings<br>right as they happen and it slows down the program by like maybe 10x but you know if you just divert a small amount of traffic there that’s probably fine if it’s for testing that’s also probably fine and it’s way better than like not finding out about the races so it’s totally worth it and honestly 10 or 20 x is is fantastic the original thread sanitizer was more like 100 or a thousand x and that was not good enough well what’s the rate detector called lrvm uh it’s called thread sanitizer but<br>it’s part of llvm which is um the clang c compiler the the one that um almost everyone uses now is is part of the llvm project can you talk about slices um and like the design choices having them as views on a raise which like confused me at first yeah yeah it is a little confusing at first um the the main thing is that you want it to be efficient to kind of walk through an array or to like you know if you’re in quicksort or merge sword or something where you have an array of things and now you want to say well now sort<br>this half and sort the other half you want to be able to efficiently say like here this is half of the previous one like you know sort that and so in c the way you do that is you just pass in you know the pointer to the first element and the number of elements and that’s basically all a slice is and then the other pattern that comes up a lot when you’re you know trying to be efficient with arrays is you have to grow them and and so you don’t want to recall realic on every single new element you want to amortize that<br>and so the way you do that in in c again is that you have a base pointer you have the length that you’re using right now and you have the length that you allocated and then to you know add one you you check and see if the length is is bigger than the amount you allocated if so you reallocate it and otherwise you just keep bumping it forward and and slices are really just an encoding of those idioms because those are kind of the most efficient way to manage the memory and so in in any kind of like c plus vector or<br>um sort of thing like that that’s what’s going on underneath but it makes it a lot harder to um like the c plus vector because of ownership reasons you know the vector is tied to the actual underlying memory it’s a lot harder to get like a sub vector that’s just the view onto like the second half for merge sort so that’s sort of the idea is that it just like there are all these patterns for accessing memory efficiently that came from c and we tried to make them fit and to go in an idiomatic way<br>in a safe way can you talk about how you decided to um implement the go like remote module system where you import directly from a url versus like yeah um i mean i just didn’t want to run a service and like like you know a lot of the things like ruby gems and those like were not as as for the front of my mind at the time just because they were newer but like i had used pearl for a while and like cpan and and i just thought it was it was insane that like everyone was fighting over these short names like db you know<br>there probably shouldn’t be an argument over like who gets to make the db package um and so putting domain names in the front seemed like a good way to decentralize it and and it was also a good way for us not to run any server because you know we could just say well you know we’ll recognize the host name and then and then go grab it from source control um from someone else’s server and that turned out to be a really great idea i think um because we just we don’t have that kind of same infrastructure<br>that other things depend on like in the java world it’s actually really problematic there are multiple there’s no sort of standard registry but they all use these short names and so uh like maven can be configured to build from multiple different registries and you if you’re an open source software package provider you actually have to go around and be sure that you upload it to all the different registries because if you don’t if you miss one and it becomes popular someone else will upload different code to that one<br>and um and then like maven actually just takes whichever one comes back first it just like sends a request to all of them and whatever comes back first so like you know if someone wants to make a malicious copy of your package all you do is find some registry other people use that you forgot to upload it to and like you know they get to win the race sometimes so it’s like it’s a real problem like i think having domain name there really helps split up the ownership in a really important way thank you sure<br>so the maybe we should take a quick uh pause here those people that have to go can go i’m sure russ is willing to uh stick around for a little bit longer yeah and answer any questions uh but i do want to thank ross for giving this lecture uh you know hopefully this will help you running more good go programs these patterns and uh so thank you russ very welcome it’s nice to be here and then more questions feel free to ask questions yeah oh just a little logistical thing uh the slides that are on the 6824 website are<br>not they exactly the same as russ’s slides people check them out i’ll get franz a new pdf yeah more general question about when is writing a new language the like the best solution to a problem that’s a great question um it’s almost never the best solution but you know at the time we had just an enormous number of programmers like thousands of programmers working in one code base and the compilations were just taking forever because um seatbelts plus was just not not meant for you know efficient incremental<br>compilation and and so it and furthermore at the time like threading libraries were really awful like people just didn’t use threats i remember like one of the first days i was at mit and talking to robert and robert said to me um like in 2001 he said to me like well we don’t use threads here because threads are slow and and that was like totally normal like that was just the way the world at the time um and and at google we were having a lot of trouble because it was all event-based like little callbacks in c plus plus<br>and there were these multi-core machines and we actually didn’t know how to get things to work on them because like linux threads were not something you could really rely on to work and and so we ended up like if you had a four core machine you just run four different process in completely independent processes of the web server and just treat it as like four machines um and that was clearly like not very efficient so like there were a lot of good reasons to like try something um but you know it’s a huge amount of<br>work to get to the point where go is today and i think that um so much is not the language right like there were important things that we made did in the language that enabled other um considerations but uh so much of the successful languages the ecosystem that got built up around it and the tooling that we built and the go command and like all these like not the language things so you know programming language uh people who are like focus on the language itself i think sometimes get distracted by all the stuff around like they miss all the<br>stuff around it um can i ask a follow-up on that yeah i was wondering how is working on go different now since it’s more mature than it was before oh that’s a great question um you know in the early days it was so easy to make changes and now it’s really hard to make changes i think that’s the number one thing um you know in the early days like everything was in one source code repository literally all the go code in the world was the one source code repository and so like there were days where we changed the syntax like you<br>used to have a star before chan every time you set a channel because it was then it was a pointer underneath and it was all kind of exposed so you’d always say star channel instead of jan and and and similarly for maps and at some point we realized like this is dumb like you have to say the star let’s just take it out and um and so like we made the change to the compiler and i opened up literally like the couple hundred go source files in the world in my editor and like the entire team stood behind me and like<br>i typed some regular expressions and we looked at the effect on the files yep that looks right save it you know compile it we’re done and like today you know we can’t make backwards compatible changes at all um and and even making you know new changes like it it affects a lot of people and so uh you know you sort of propose something and you know people point out well this won’t work for me and you try to like adjust that maybe um it’s just it’s a lot harder we estimate there’s at least a million<br>maybe two million go programmers in the world and it’s very different from when they were you know four or five not sure if this is a valid question but what what language is go written in is it written in go also or no now it is now it is the original um compiler runtime were written in c but a few years ago we went through a big um we actually wrote a a program to translate c to go and that only worked for rc code but still it was good enough so that we wouldn’t lose kind of all the sort of encoded knowledge in that code<br>about why things were the way they were and like how things work so we have to start from scratch but now it’s all written and go and you know a little bit of assembly and that means that um people can uh you know people who know go can help on the the go project whereas before like if you wanted to work on the compiler or the runtime you had to know c really well and like we weren’t getting a lot of people knew c really well like there’s not actually that many of them proportionately and and furthermore like our entire user<br>base is go programmers not c programmers so moving to go was was a really big deal i was wondering how did you prioritize what features to add to the language at like this point like in all generics like a lot of people were like asking for that like did y’all know like how you choose what to work on i mean we’ve considered language mostly frozen for a while and um and so we haven’t been adding much uh there was a long period where we said we weren’t adding anything and then we added a little bit of things<br>in the last couple years to lead up to generics just kind of shake the rust off on like all the like what breaks when you change something in the language so like you can put underscores between digits and long numbers now things like that um but you know generics has clearly been the next thing that needed to happen and we just had to figure out how in general we try to only add things that don’t have weird kind of interference with other features and we try to add things that are you know really important that will help a<br>lot of people for the kinds of programs that we’re trying to target with go which is like distributed systems and that sort of thing cool thank you oh i had a question actually yeah uh so um for i noticed that like you know uh go doesn’t have like basic functions like min or max for like yeah so is that like something that you’re considering like say adding with like the generic stuff maybe is that why you didn’t decide yeah exactly right because like you can’t have a min you’d have been event and you could have<br>minivan date but those had to have different names and that was kind of annoying um so now we can write just a generic name over any type that has a less than operator yeah that’ll be good and you know honestly like for the specific case of min and max so i know it’s not that hard to code i know i was gonna say i’m starting to feel like we should just make some built-ins like like you know print and things like that so that you know you can just always have them but even if we don’t like you it’ll be<br>math.min and that’ll be there at least um yeah we really didn’t want to make them built-ins until we could like express their types and we couldn’t do that until generics happened because there is actually a min for like floating points actually yeah i know it’s kind of weird because it’s because the math library is basically copied from the c math.<br>h set of things yes so that’s a good point like we can’t actually put them in math because they’re already there okay but no yeah but we’ll figure it out like i think we should probably just put them in the language but we have to get generis through first and another thing actually i noticed that you did usako like competitive programming yeah i did too actually oh cool yeah so how did you so actually i included this in one of the questions that i submitted let me pull it up um so my question was like<br>um how did how was like how did you go from doing competitive programming to like doing what you you’re doing now at google working on going how’s the transition between like competitive programming to systems also finally what made you decide to go into systems and how did it relate to programming i mean competitive programming at the time that i did it was not as all-consuming as i gather it is now like like you know you could just like be able to implement a simple dynamic programming like little two for loops and that was<br>fine and now you have all these like complex hall algorithms and all that stuff that i can’t do so like you know at some point like at some level like it was different um but you know i was actually more interested in the sort of systems you kind of stopped from the start and and the the program contests were just like something fun to do on the side so there wasn’t like a huge transition there um i was never into like implementing complex algorithms and and that you know max flow and all those sorts of things<br>on the other hand like when you start a new language you actually do get to write a lot of core things right um like someone has to write the sort function and it has to be a good general sort function and like i spent a while last month like looking into dip algorithms and and that’s like you know sort of matches that background pretty well so like it does come up um but you know it’s just it’s just a different kind of programming oh so you thought of it as more of a side thing back then no like yeah<br>it wasn’t it was definitely not the sort of main thing i did when i was writing programs yeah because like today it’s effectively like the main thing i know i know it’s you know if you don’t do it full-time like there’s just no way you can you know there just weren’t that many people who cared it you know in uh 1995 yeah 20 years later um can you ask a related question to that so how did you decide to go from i’m from like academic work into i mean your work is still like a little bit more different than<br>like the usual like software engineering thing but still yeah um you know i got lucky uh i i grew up near bell labs in new jersey and so like that was how i ended up working on playing the iron a little bit in high school and college um and so you know i sort of knew i was going to go to grad school and you know the plan was to go back to bell labs but it kind of imploded while i was in grad school with the dot com boom and the dot com crash and um and so like you know google was was sort of a just vacuuming up phds systems phds at<br>the time and and and doing really interesting things i mean you probably you know there’s a i don’t know i haven’t looked at syllabus for this year but you know there’s things like spanner and um big table and chubby and and things like that and you know they they had a whole host of good distributed systems kind of stuff going on and so you know it was sort of lucky to be able to to go to that too um and you know at the time i graduated i was also looking at you know industrial research labs like microsoft<br>research and and places like that so you know there’s definitely an opportunity there for you know researchy things but not in academia if that’s what you want um it’s a little harder to find now i mean most of the places i know like microsoft research imploded too a couple years later but um you know it’s uh it’s still an option and and you know it’s just a slightly different path um you end up the the differences i see from academia is like you end up caring a ton more about actually making things work<br>100 time and supporting them for like a decade or more whereas like you finish your paper and you kind of like get to put it off to the side and that’s that’s really nice actually at some level um it’s uh it’s definitely strange to me to be you know editing source files that i wrote you know in in some cases actually 20 years ago um because i used a bunch of code that i’d already written when we started go and it’s very weird to think that like i’ve been keeping this program running<br>for 20 years thinking</p>
<h2 id="Concurrency-and-Parallelism"><a href="#Concurrency-and-Parallelism" class="headerlink" title="Concurrency and Parallelism"></a>Concurrency and Parallelism</h2><p>Concurrency: How  you write your programs about being able to compose independently executing control flows whether you want to call them processes or threads or go routines.</p>
<p>Parallelism: How the programs get executed about allowing multiple computations to run simultaneously so that the program can be doing lots of things at once not just dealing with lots of things at once and so concurrency lends itself naturally to parallel execution</p>
<p>并发性：如何编写程序以支持独立执行的控制流的组合，无论你想称它们为进程、线程还是 Go 协程。</p>
<p>并行性：程序如何被执行，允许多个计算同时运行，使得程序可以同时处理许多事情，而不仅仅是同时应对许多事情。因此，并发性自然适合并行执行。</p>
<h2 id="Goroutines-for-State"><a href="#Goroutines-for-State" class="headerlink" title="Goroutines for State"></a>Goroutines for State</h2><p>Hint: Convert data state into code state when it makes programs clearer.</p>
<h1 id="Lab1-MapReduce"><a href="#Lab1-MapReduce" class="headerlink" title="Lab1: MapReduce"></a>Lab1: MapReduce</h1><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p><img  src="./image-20250130171236090.png"  ><span class="image-caption">MapReduce框架图</span></p>
<p><img  src="./94dee74c9845b.png"  ><span class="image-caption">MapReduce论文结构</span></p>
<h2 id="MapReduce-结构"><a href="#MapReduce-结构" class="headerlink" title="MapReduce 结构"></a>MapReduce 结构</h2><ul>
<li>Map and Reduce Function（由用户定义）</li>
<li>Worker（我们实现）</li>
<li>Coordinator（源论文中的 master，我们实现）</li>
</ul>
<h2 id="单机顺序式实现"><a href="#单机顺序式实现" class="headerlink" title="单机顺序式实现"></a>单机顺序式实现</h2><p>MapReduce 实现： <code>src/main/mrsequential.go</code>。</p>
<p>Map and Reduce Function：<code>mrapps/wc.go</code> 这里是一个 word-count app，<code>mrapps/indexer.go</code> 是</p>
<p>运行方法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/6.5840<br><span class="hljs-built_in">cd</span> src/main<br>go build -buildmode=plugin ../mrapps/wc.go<br><span class="hljs-built_in">rm</span> mr-out*<br>go run mrsequential.go wc.so pg*.txt<br>more mr-out-0<br>A 509<br>ABOUT 2<br>ACT 8<br>...<br></code></pre></td></tr></table></figure>
<h2 id="分布式实现"><a href="#分布式实现" class="headerlink" title="分布式实现"></a>分布式实现</h2><p>需要我们实现：</p>
<ul>
<li>mr/coordinator.go,</li>
<li>mr/worker.go</li>
<li>mr/rpc.go</li>
</ul>
<h3 id="运行方式"><a href="#运行方式" class="headerlink" title="运行方式"></a>运行方式</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">go build -buildmode=plugin ../mrapps/wc.go<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">rm</span> mr-out*<br>go run mrcoordinator.go pg-*.txt<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">go run mrworker.go wc.so<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> mr-out-* | <span class="hljs-built_in">sort</span> | more<br>A 509<br>ABOUT 2<br>ACT 8<br>...<br></code></pre></td></tr></table></figure>
<p>测试方案：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/6.5840/src/main<br>bash test-mr.sh<br>*** Starting <span class="hljs-built_in">wc</span> <span class="hljs-built_in">test</span>.<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">bash test-mr.sh<br>*** Starting <span class="hljs-built_in">wc</span> <span class="hljs-built_in">test</span>.<br><span class="hljs-built_in">sort</span>: No such file or directory<br>cmp: EOF on mr-wc-all<br>--- <span class="hljs-built_in">wc</span> output is not the same as mr-correct-wc.txt<br>--- <span class="hljs-built_in">wc</span> <span class="hljs-built_in">test</span>: FAIL<br><br></code></pre></td></tr></table></figure>
<h3 id="一些要求"><a href="#一些要求" class="headerlink" title="一些要求"></a>一些要求</h3><ul>
<li>在map阶段，应将中间键值根据nReduce个reduce任务的数量划分为多个桶，这里的nReduce即main/mrcoordinator.go传递给MakeCoordinator()方法的参数。每个mapper应当为reduce任务创建nReduce个中间文件以供消费。</li>
<li>worker的实现应该把第X个reduce任务的输出放置于mr-out-X文件中。每个mr-out-X文件应当包含每行一个reduce函数的输出结果。这一行需要使用Go语言的”%v %v”格式化字符串生成，调用时传入键和值。你可以在main/mrsequential.go中找到被注释为”这是正确的格式”的代码行作为参考。如果你的实现与此格式相差太多，测试脚本将会失败。</li>
<li>你可以修改mr/worker.go、mr/coordinator.go以及mr/rpc.go文件。为了测试目的，你可以暂时修改其他文件，但请确保你的代码能与原始版本兼容——我们将使用原始版本进行测试。</li>
<li>worker应将中间Map阶段的输出保存为当前目录下的文件，以便后续作为Reduce任务的输入读取这些文件。</li>
<li>main/mrcoordinator.go期望mr/coordinator.go实现一个Done()方法，在MapReduce作业完全完成时返回true；此时，mrcoordinator.go将会退出。</li>
<li>当整个作业完全完成后，worker进程也应当退出。一种简单的实现方式是利用call()的返回值：如果worker无法联系上coordinator，则可以认为coordinator因为作业已完成而退出，因此worker也可以终止。根据你的设计，你也可能会发现设置一个“请退出”的伪任务是有帮助的，coordinator可以通过这个伪任务通知workers退出。</li>
</ul>
<h3 id="一些帮助"><a href="#一些帮助" class="headerlink" title="一些帮助"></a>一些帮助</h3><ul>
<li>开始的一个方法是修改mr/worker.go中的Worker()函数，让它发送一个RPC请求给coordinator以请求任务。然后修改coordinator，使其响应返回一个尚未开始的map任务的文件名。接着，修改worker读取该文件并调用应用程序的Map函数，就像在mrsequential.go中所做的那样。</li>
<li>应用程序的Map和Reduce函数是在运行时使用Go语言的插件包从文件加载的，这些文件名以.so结尾。</li>
<li>如果你更改了mr/目录下的任何内容，你可能需要重新构建所使用的MapReduce插件，例如通过go build -buildmode=plugin ../mrapps/wc.go命令。</li>
<li>本实验依赖于workers共享一个文件系统。当所有workers在同一台机器上运行时这很简单，但如果workers运行在不同的机器上，则需要像GFS这样的全局文件系统。</li>
<li>对于中间文件采用合理的命名规则，比如mr-X-Y，其中X是Map任务编号，Y是reduce任务编号。</li>
<li>worker的map任务代码需要一种方式将中间键值对存储到文件中，并且可以在reduce任务期间正确地读回。一种可能是使用Go语言的encoding/json包。要以JSON格式写入键值对至打开的文件，可以这样做：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">enc := json.NewEncoder(file)<br><span class="hljs-keyword">for</span> _, kv := ... &#123;<br>    err := enc.Encode(&amp;kv)<br></code></pre></td></tr></table></figure>
<p>而读回此类文件的方式如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">dec := json.NewDecoder(file)<br><span class="hljs-keyword">for</span> &#123;<br>    <span class="hljs-keyword">var</span> kv KeyValue<br>    <span class="hljs-keyword">if</span> err := dec.Decode(&amp;kv); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">break</span><br>    &#125;<br>    kva = <span class="hljs-built_in">append</span>(kva, kv)<br>&#125;<br></code></pre></td></tr></table></figure>
<ul>
<li>你的worker的map部分可以使用worker.go中的ihash(key)函数为给定的键选择reduce任务。</li>
<li>你可以从mrsequential.go中借用一些代码用于读取Map输入文件、在Map和Reduce之间排序中间键值对以及将Reduce输出存储到文件中。</li>
<li>作为RPC服务器的coordinator将是并发执行的；不要忘记锁定共享数据。</li>
<li>使用Go语言的race detector工具，可以通过go run -race启动。test-mr.sh脚本开头有一个注释，告诉你如何与-race选项一起运行它。在我们评分时不会使用race detector，然而，如果你的代码存在竞态条件，在测试时即使不使用race detector也很可能会失败。</li>
<li>workers有时需要等待，例如reduces不能在最后一个map完成之前开始。一种可能性是让workers定期向coordinator询问工作，使用time.Sleep()在每次请求之间进行休眠。另一种可能性是在coordinator的相关RPC处理器中实现一个循环等待，可以通过time.Sleep()或sync.Cond来实现。由于Go语言为每个RPC在其自己的线程中运行处理程序，因此一个处理程序的等待不应妨碍coordinator处理其他RPCs。</li>
<li>coordinator无法可靠地区分崩溃的workers、因某种原因暂停但仍存活的workers以及执行速度过慢以至于无用的workers。最好的做法是让coordinator等待一段时间（如10秒），然后放弃并重新分配任务给另一个worker。对于这个实验，设定coordinator等待十秒钟；之后应假设worker已经死亡（当然，实际上它可能并未死亡）。</li>
<li>如果你选择实现备份任务（第3.6节），请注意我们测试了在workers执行任务但未崩溃的情况下你的代码不会调度额外的任务。备份任务应该只在一段相对较长的时间后（例如10秒）被调度。</li>
<li>为了测试崩溃恢复，你可以使用mrapps/crash.go应用插件，它会在Map和Reduce函数中随机退出。</li>
<li>为了确保在发生崩溃时没有人观察到部分写入的文件，MapReduce论文提到了使用临时文件并在完全写入后原子重命名的技巧。你可以使用ioutil.TempFile（或者如果你运行的是Go 1.17或更新版本，则使用os.CreateTemp）创建一个临时文件，并使用os.Rename原子地重命名它。</li>
<li>test-mr.sh在一个名为mr-tmp的子目录下运行所有进程，所以如果出现问题并且你想查看中间文件或输出文件，请在那里查找。你可以暂时修改test-mr.sh以便在失败的测试后退出，这样脚本就不会继续测试（并覆盖输出文件）。</li>
<li>test-mr-many.sh连续多次运行test-mr.sh，你可能想要这样做以便发现低概率的bug。它接受一个参数，即运行测试的次数。你不应该并行运行多个test-mr.sh实例，因为coordinator会重用相同的套接字，从而导致冲突。</li>
<li>Go RPC仅发送字段名称以大写字母开头的结构体。子结构也必须具有首字母大写的字段名称。</li>
<li>在调用RPC call()函数时，回复结构应当包含所有的默认值。RPC调用看起来应该是这样的：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">reply := SomeType&#123;&#125;<br>call(..., &amp;reply)<br></code></pre></td></tr></table></figure>
<ul>
<li>在调用之前不应该设置reply的任何字段。如果你传递的reply结构体包含非默认字段，RPC系统可能会静默地返回错误值。</li>
</ul>
<h3 id="第一个版本"><a href="#第一个版本" class="headerlink" title="第一个版本"></a>第一个版本</h3><ul>
<li>完成了 rpc + 单个 worker</li>
</ul>
<p>目前的问题：</p>
<ul>
<li>测试多 worker 是否正常</li>
<li>测试的时候是把多个 redece 的结果拼起来和最终答案进行比较，所以每个 reduce 的内容得是完整的结果的一部分，而不是每个 reduce 中都是所有出现过的单词。</li>
</ul>
<h3 id="第二个版本"><a href="#第二个版本" class="headerlink" title="第二个版本"></a>第二个版本</h3><p>map 可以根据文件进行分区，可是中间结果如何进行分区呢？假设有 2 个 reduce。</p>
<p>现在有 10 个文件，分别 map 之后产生了 mr-1 mr-2 … mr-10。</p>
<p><strong>则对每个 map 进行进一步划分，根据 key 划分为 mr-1-1 mr-1-2。</strong></p>
<p><strong>map 的时候不用 sort 和组合，这些都可以交给 reduce 来完成。</strong></p>
<ul>
<li>增加数据分区</li>
<li>增加锁</li>
</ul>
<h3 id="第三个版本"><a href="#第三个版本" class="headerlink" title="第三个版本"></a>第三个版本</h3><p>wc test 可以测试通过，然而 indexer 不能，总会出现不一致的情况：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">mr-indexer-all mr-correct-indexer.txt differ: byte 2245, line 40<br>mr-indexer-all mr-correct-indexer.txt differ: byte 2245, line 40<br>mr-indexer-all mr-correct-indexer.txt differ: byte 911, line 15<br></code></pre></td></tr></table></figure>
<p>考虑原因可能是 map 还在进行中，或者在写文件时，已经触发了 reduce 任务，需要给 map 任务添加一个完成信息。</p>
<p>可以等 map 结束之后给 master 传递信息使得该任务变成完成状态，并允许 reduce。</p>
<p><strong>增加了写中间文件原子操作之后，indexer 可以正常工作了。</strong></p>
<p><strong>并不能，只是出错概率减小了</strong></p>
<ul>
<li>写文件原子操作</li>
<li><code>mr-[0-9]*-%d</code> 避免解析 mr-out-* 文件</li>
</ul>
<p>实现方法：先写到 tmp 文件，然后重命名成文件就好，重命名是原子操作。</p>
<h3 id="第四个版本"><a href="#第四个版本" class="headerlink" title="第四个版本"></a>第四个版本</h3><p>增加了</p>
<ul>
<li>容错逻辑（分发任务之后开始计时，如果时间到了还是 wait，那么就 resume 为 map/reduce）</li>
<li>把 list 换成了 map</li>
<li>修改写文件原子操作，先写到 temp 文件，注意 temp 文件一定不能重名。还要注意在同一个文件系统上，这样 rename 才是原子操作。</li>
<li>存在一个问题，当 reduce crash 时，重新开了一个在运行，之前 crash 的那个恢复之后又调用了一次 finish，同一个 finish 了 2 次，就出错了。所以要注意 crash 掉的不要 finish。在接受到 finish 请求的时候判断是不是 Wait，如果是则再 Done，并完成数量加一。</li>
</ul>
<p>完成所有的测试！芜湖！</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">--- crash <span class="hljs-built_in">test</span>: PASS<br>*** PASSED ALL TESTS<br>*** PASSED ALL 500 TESTING TRIALS<br></code></pre></td></tr></table></figure>
<h1 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h1><p>特点：单 master、弱一致性</p>
<p>Master 管理文件、存储文件的 Chunk ID 信息。</p>
<h2 id="GFS-一致性"><a href="#GFS-一致性" class="headerlink" title="GFS 一致性"></a>GFS 一致性</h2><h3 id="master"><a href="#master" class="headerlink" title="master"></a>master</h3><ul>
<li><p>第一个是文件名到Chunk ID或者Chunk Handle数组的对应。这个表单告诉你，文件对应了哪些Chunk。但是只有Chunk ID是做不了太多事情的，所以有了第二个表单。</p>
</li>
<li><p>第二个表单记录了Chunk ID到Chunk数据的对应关系。这里的数据又包括了：</p>
<ul>
<li><p>每个Chunk存储在哪些服务器上，所以这部分是Chunk服务器的列表</p>
</li>
<li><p>每个Chunk当前的版本号，所以Master节点必须记住每个Chunk对应的版本号。</p>
</li>
<li><p>所有对于Chunk的写操作都必须在主Chunk（Primary Chunk）上顺序处理，主Chunk是Chunk的多个副本之一。所以，Master节点必须记住哪个Chunk服务器持有主Chunk。</p>
</li>
<li><p>并且，主Chunk只能在特定的租约时间内担任主Chunk，所以，Master节点要记住主Chunk的租约过期时间。</p>
</li>
</ul>
</li>
</ul>
<p>Master会在磁盘上存储log，每次有数据变更时，Master会在磁盘的log中追加一条记录，并生成CheckPoint（类似于备份点）。</p>
<ul>
<li><p>Chunk Handle的数组（第一个表单）要保存在磁盘上。给它标记成NV（non-volatile, 非易失），这个标记表示对应的数据会写入到磁盘上。</p>
</li>
<li><p>Chunk服务器列表不用保存到磁盘上。因为Master节点重启之后可以与所有的Chunk服务器通信，并查询每个Chunk服务器存储了哪些Chunk，所以我认为它不用写入磁盘。所以这里标记成V（volatile），</p>
</li>
<li>版本号要不要写入磁盘取决于GFS是如何工作的，我认为它需要写入磁盘。我们之后在讨论系统是如何工作的时候再详细讨论这个问题。这里先标记成NV。</li>
<li>主Chunk的ID，几乎可以确定不用写入磁盘，因为Master节点重启之后会忘记谁是主Chunk，它只需要等待60秒租约到期，那么它知道对于这个Chunk来说没有主Chunk，这个时候，Master节点可以安全指定一个新的主Chunk。所以这里标记成V。</li>
<li>类似的，租约过期时间也不用写入磁盘，所以这里标记成V。</li>
</ul>
<p>任何时候，如果文件扩展到达了一个新的64MB，需要新增一个Chunk或者由于指定了新的主Chunk而导致版本号更新了，Master节点需要向磁盘中的Log追加一条记录说，我刚刚向这个文件添加了一个新的Chunk或者我刚刚修改了Chunk的版本号。所以每次有这样的更新，都需要写磁盘。GFS论文并没有讨论这么多细节，但是因为写磁盘的速度是有限的，写磁盘会导致Master节点的更新速度也是有限的，所以要尽可能少的写入数据到磁盘。</p>
<p>这里在磁盘中维护log而不是数据库的原因是，数据库本质上来说是某种B树（b-tree）或者hash table，相比之下，追加log会非常的高效，因为你可以将最近的多个log记录一次性的写入磁盘。因为这些数据都是向同一个地址追加，这样只需要等待磁盘的磁碟旋转一次。而对于B树来说，每一份数据都需要在磁盘中随机找个位置写入。所以使用Log可以使得磁盘写入更快一些。</p>
<p>当Master节点故障重启，并重建它的状态，你不会想要从log的最开始重建状态，因为log的最开始可能是几年之前，所以Master节点会在磁盘中创建一些checkpoint点，这可能要花费几秒甚至一分钟。这样Master节点重启时，会从log中的最近一个checkpoint开始恢复，再逐条执行从Checkpoint开始的log，最后恢复自己的状态。</p>
<h3 id="client-读文件"><a href="#client-读文件" class="headerlink" title="client 读文件"></a>client 读文件</h3><h1 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h1><h2 id="1-脑裂（Split-Brain）"><a href="#1-脑裂（Split-Brain）" class="headerlink" title="1. 脑裂（Split Brain）"></a>1. 脑裂（Split Brain）</h2><ol>
<li>脑裂（Split Brain）是指在分布式系统中，由于网络分区（Network Partition）或其他故障导致系统中的不同节点无法正常通信，进而使得系统被分割成两个或多个独立的部分，每个部分都认为自己是系统的主节点（Primary），并独立地进行操作和决策。这种情况下，系统会出现数据不一致性和决策冲突，导致系统行为异常。</li>
</ol>
<h3 id="1-脑裂的场景"><a href="#1-脑裂的场景" class="headerlink" title="1. 脑裂的场景"></a>1. <strong>脑裂的场景</strong></h3><p>   在分布式系统中，通常会有多副本（Replicas）来提高系统的容错能力。例如，VMware FT（Fault Tolerance）系统中，有一个主虚拟机（Primary VM）和一个备份虚拟机（Backup VM），它们通过一个 Test-and-Set 服务来决定谁是主节点。如果 Test-and-Set 服务本身是单点的，那么它可以通过仲裁来避免脑裂。但如果 Test-and-Set 服务本身也有多副本（例如 S1 和 S2），就可能出现脑裂。</p>
<h3 id="2-脑裂的发生"><a href="#2-脑裂的发生" class="headerlink" title="2. 脑裂的发生"></a>2. <strong>脑裂的发生</strong></h3><p>   假设系统中有两个服务器（S1 和 S2）和两个客户端（C1 和 C2）。客户端需要通过 Test-and-Set 服务来确定主节点。正常情况下，客户端会同时与两个服务器通信，确保数据一致性。但如果网络出现故障，客户端可能只能与其中一个服务器通信：</p>
<ul>
<li><strong>C1 可以访问 S1，但无法访问 S2</strong>。</li>
<li><p><strong>C2 可以访问 S2，但无法访问 S1</strong>。</p>
<p>在这种情况下：</p>
</li>
<li><p>C1 会认为 S1 是主节点，并开始执行操作。</p>
</li>
<li><p>C2 会认为 S2 是主节点，并开始执行操作。</p>
<p>此时，系统被分割成两个独立的部分，每个部分都认为自己是主节点，这就是脑裂。</p>
</li>
</ul>
<h3 id="3-脑裂的后果"><a href="#3-脑裂的后果" class="headerlink" title="3. 脑裂的后果"></a>3. <strong>脑裂的后果</strong></h3><p>   脑裂会导致以下严重问题：</p>
<ul>
<li><strong>数据不一致性</strong>：S1 和 S2 的数据可能会出现冲突，因为它们各自独立地处理请求。</li>
<li><strong>决策冲突</strong>：两个主节点可能会同时对同一资源进行操作，导致系统行为不可预测。</li>
<li><strong>系统不可用</strong>：为了避免数据不一致，系统可能需要停止服务，直到问题解决。</li>
</ul>
<h3 id="4-避免脑裂的方法"><a href="#4-避免脑裂的方法" class="headerlink" title="4. 避免脑裂的方法"></a>4. <strong>避免脑裂的方法</strong></h3><p>   为了避免脑裂，分布式系统通常会采用以下方法：</p>
<ul>
<li><strong>单点仲裁</strong>：使用一个单点（如 Test-and-Set 服务）来决定主节点。虽然单点本身是单点故障，但它可以避免脑裂。</li>
<li><strong>网络分区检测</strong>：通过检测网络分区，确保系统在分区发生时能够快速做出决策，避免两个部分各自为政。</li>
<li><strong>人工干预</strong>：在某些情况下，系统会停止自动操作，转而由人工干预来解决冲突。</li>
</ul>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. <strong>总结</strong></h3><p>   脑裂是分布式系统中的一种严重故障场景，它会导致系统分裂成多个独立的部分，每个部分都认为自己是主节点，从而引发数据不一致性和决策冲突。为了避免脑裂，系统通常需要依赖单点仲裁、网络分区检测或人工干预等方法。</p>
<h2 id="2-过半票决（Majority-Vote）"><a href="#2-过半票决（Majority-Vote）" class="headerlink" title="2. 过半票决（Majority Vote）"></a>2. 过半票决（Majority Vote）</h2><p>尽管存在脑裂的可能，但是随着技术的发展，人们发现哪怕网络可能出现故障，可能出现分区，实际上是可以正确的实现能够<strong>自动完成故障切换</strong>的系统。当网络出现故障，将网络分割成两半，网络的两边独自运行，且不能访问对方，这通常被称为网络分区。</p>
<p>在构建能自动恢复，同时又避免脑裂的多副本系统时，人们发现，关键点在于过半票决（Majority Vote）。这是Raft论文中出现的，用来构建Raft的一个基本概念。过半票决系统的第一步在于，服务器的数量要是奇数，而不是偶数。例如在上图中（只有两个服务器），中间出现故障，那两边就太过对称了。这里被网络故障分隔的两边，它们看起来完全是一样的，它们运行了同样的软件，所以它们也会做相同的事情，这样不太好（会导致脑裂）。</p>
<p>但是，如果服务器的数量是奇数的，那么当出现一个网络分割时，两个网络分区将不再对称。假设出现了一个网络分割，那么一个分区会有两个服务器，另一个分区只会有一个服务器，这样就不再是对称的了。这是过半票决吸引人的地方。所以，首先你要有奇数个服务器。然后为了完成任何操作，例如Raft的Leader选举，例如提交一个Log条目，<strong>在任何时候为了完成任何操作，你必须凑够过半的服务器来批准相应的操作</strong>。这里的过半是指超过服务器总数的一半。直观来看，如果有3个服务器，那么需要2个服务器批准才能完成任何的操作。</p>
<p>这里背后的逻辑是，如果网络存在分区，那么必然不可能有超过一个分区拥有过半数量的服务器。例如，假设总共有三个服务器，如果一个网络分区有一个服务器，那么它不是一个过半的分区。如果一个网络分区有两个服务器，那么另一个分区必然只有一个服务器。因此另一个分区必然不能凑齐过半的服务器，也必然不能完成任何操作。</p>
<p>这里有一点需要明确，当我们在说过半的时候，我们是在说所有服务器数量的一半，而不是当前开机服务器数量的一半。这个点困扰了我（Robert教授）很长时间。如果你有一个系统有3个服务器，其中某些已经故障了，如果你要凑齐过半的服务器，你总是需要从3个服务器中凑出2个，即便你知道1个服务器已经因为故障关机了。过半总是相对于服务器的总数来说。</p>
<p>对于过半票决，可以用一个更通用的方程式来描述。在一个过半票决的系统中，如果有3台服务器，那么需要至少2台服务器来完成任意的操作。换个角度来看，这个系统可以接受1个服务器的故障，任意2个服务器都足以完成操作。如果你需要构建一个更加可靠的系统，那么你可以为系统加入更多的服务器。所以，更通用的方程是：</p>
<blockquote>
<p><strong>如果系统有 2 * F + 1 个服务器，那么系统最多可以接受F个服务器出现故障，仍然可以正常工作。</strong></p>
</blockquote>
<p>通常这也被称为多数投票（quorum）系统，因为3个服务器中的2个，就可以完成多数投票。</p>
<p>前面已经提过，有关过半票决系统的一个特性就是，最多只有一个网络分区会有过半的服务器，所以我们不可能有两个分区可以同时完成操作。这里背后更微妙的点在于，如果你总是需要过半的服务器才能完成任何操作，同时你有一系列的操作需要完成，其中的每一个操作都需要过半的服务器来批准，例如选举Raft的Leader，那么每一个操作对应的过半服务器，必然至少包含一个服务器存在于上一个操作的过半服务器中。也就是说，任意两组过半服务器，至少有一个服务器是重叠的。实际上，相比其他特性，Raft更依赖这个特性来避免脑裂。例如，当一个Raft Leader竞选成功，那么这个Leader必然凑够了过半服务器的选票，而这组过半服务器中，必然与旧Leader的过半服务器有重叠。所以，新的Leader必然知道旧Leader使用的任期号（term number），因为新Leader的过半服务器必然与旧Leader的过半服务器有重叠，而旧Leader的过半服务器中的每一个必然都知道旧Leader的任期号。类似的，任何旧Leader提交的操作，必然存在于过半的Raft服务器中，而任何新Leader的过半服务器中，必然有至少一个服务器包含了旧Leader的所有操作。这是Raft能正确运行的一个重要因素。</p>
<blockquote>
<p>学生提问：可以为Raft添加服务器吗？</p>
<p>Rober教授：Raft的服务器是可以添加或者修改的，Raft的论文有介绍，可能在Section 6。如果是一个长期运行的系统，例如运行5年或者10年，你可能需要定期更换或者升级一些服务器，因为某些服务器可能会出现永久的故障，又或者你可能需要将服务器搬到另一个机房去。所以，肯定需要支持修改Raft服务器的集合。虽然这不是每天都发生，但是这是一个长期运行系统的重要维护工作。Raft的作者提出了方法来处理这种场景，但是比较复杂。</p>
</blockquote>
<p>所以，在过半票决这种思想的支持下，大概1990年的时候，有两个系统基本同时被提出。这两个系统指出，你可以使用这种过半票决系统，从某种程度上来解决之前明显不可能避免的脑裂问题，例如，通过使用3个服务器而不是2个，同时使用过半票决策略。两个系统中的一个叫做Paxos，Raft论文对这个系统做了很多的讨论；另一个叫做ViewStamped Replication（VSR）。尽管Paxos的知名度高得多，Raft从设计上来说，与VSR更接近。VSR是由MIT发明的。这两个系统有着数十年的历史，但是他们仅仅是在15年前，也就是他们发明的15年之后，才开始走到最前线，被大量的大规模分布式系统所使用。</p>
<h2 id="3-Raft-初探"><a href="#3-Raft-初探" class="headerlink" title="3. Raft 初探"></a>3. Raft 初探</h2><p>Raft会以库（Library）的形式存在于服务中。如果你有一个基于Raft的多副本服务，那么每个服务的副本将会由两部分组成：应用程序代码和Raft库。应用程序代码接收RPC或者其他客户端请求；不同节点的Raft库之间相互合作，来维护多副本之间的操作同步。</p>
<p>从软件的角度来看一个Raft节点，我们可以认为在该节点的上层，是应用程序代码。例如对于Lab 3来说，这部分应用程序代码就是一个Key-Value数据库。应用程序通常都有状态，Raft层会帮助应用程序将其状态拷贝到其他副本节点。对于一个Key-Value数据库而言，对应的状态就是Key-Value Table。应用程序往下，就是Raft层。所以，Key-Value数据库需要对Raft层进行函数调用，来传递自己的状态和Raft反馈的信息。</p>
<p>同时，如Raft论文中的图2所示，Raft本身也会保持状态。对我们而言，Raft的状态中，最重要的就是Raft会记录操作的日志。</p>
<p><img  src="./image-20250131224240484.png"   style="zoom: 67%;" /><span class="image-caption">image-20250131224240484</span></p>
<p>对于一个拥有三个副本的系统来说，很明显我们会有三个服务器，这三个服务器有完全一样的结构（上面是应用程序层，下面是Raft层）。理想情况下，也会有完全相同的数据分别存在于两层（应用程序层和Raft层）中。除此之外，还有一些客户端，假设我们有了客户端1（C1），客户端2（C2）等等。</p>
<p><img  src="./image-20250131224341803.png"  ><span class="image-caption">image-20250131224341803</span></p>
<p>客户端就是一些外部程序代码，它们想要使用服务，同时它们不知道，也没有必要知道，它们正在与一个多副本服务交互。从客户端的角度来看，这个服务与一个单点服务没有区别。</p>
<p>客户端会将请求发送给当前Raft集群中的Leader节点对应的应用程序。这里的请求就是应用程序级别的请求，例如一个访问Key-Value数据库的请求。这些请求可能是Put也可能是Get。Put请求带了一个Key和一个Value，将会更新Key-Value数据库中，Key对应的Value；而Get向当前服务请求某个Key对应的Value。</p>
<p>所以，看起来似乎没有Raft什么事，看起来就像是普通的客户端服务端交互。一旦一个Put请求从客户端发送到了服务端，对于一个单节点的服务来说，应用程序会直接执行这个请求，更新Key-Value表，之后返回对于这个Put请求的响应。但是对于一个基于Raft的多副本服务，就要复杂一些。</p>
<p>假设客户端将请求发送给Raft的Leader节点，在服务端程序的内部，应用程序只会将来自客户端的请求对应的操作向下发送到Raft层，并且告知Raft层，请把这个操作提交到多副本的日志（Log）中，并在完成时通知我。</p>
<p>之后，Raft节点之间相互交互，直到过半的Raft节点将这个新的操作加入到它们的日志中，也就是说这个操作被过半的Raft节点复制了。</p>
<p>当且仅当Raft的Leader节点知道了所有（课程里说的是所有，但是这里应该是过半节点）的副本都有了这个操作的拷贝之后。Raft的Leader节点中的Raft层，会向上发送一个通知到应用程序，也就是Key-Value数据库，来说明：刚刚你提交给我的操作，我已经提交给所有（注：同上一个说明）副本，并且已经成功拷贝给它们了，现在，你可以真正的执行这个操作了。</p>
<p>所以，客户端发送请求给Key-Value数据库，这个请求不会立即被执行，因为这个请求还没有被拷贝。当且仅当这个请求存在于过半的副本节点中时，Raft才会通知Leader节点，只有在这个时候，Leader才会实际的执行这个请求。对于Put请求来说，就是更新Value，对于Get请求来说，就是读取Value。最终，请求返回给客户端，这就是一个普通请求的处理过程。</p>
<blockquote>
<p>学生提问：问题听不清。。。这里应该是学生在纠正前面对于所有节点和过半节点的混淆</p>
<p>Robert教授：这里只需要拷贝到过半服务器即可。为什么不需要拷贝到所有的节点？因为我们想构建一个容错系统，所以即使某些服务器故障了，我们依然期望服务能够继续工作。所以只要过半服务器有了相应的拷贝，那么请求就可以提交。</p>
<p>学生提问：除了Leader节点，其他节点的应用程序层会有什么样的动作？</p>
<p>Robert教授：哦对，抱歉。当一个操作最终在Leader节点被提交之后，每个副本节点的Raft层会将相同的操作提交到本地的应用程序层。在本地的应用程序层，会将这个操作更新到自己的状态。所以，理想情况是，所有的副本都将看到相同的操作序列，这些操作序列以相同的顺序出现在Raft到应用程序的upcall中，之后它们以相同的顺序被本地应用程序应用到本地的状态中。假设操作是确定的（比如一个随机数生成操作就不是确定的），所有副本节点的状态，最终将会是完全一样的。我们图中的Key-Value数据库，就是Raft论文中说的状态（也就是Key-Value数据库的多个副本最终会保持一致）。</p>
</blockquote>
<h2 id="4-Log-同步时序"><a href="#4-Log-同步时序" class="headerlink" title="4. Log 同步时序"></a>4. Log 同步时序</h2><p>接下来我将画一个时序图来描述Raft内部的消息是如何工作的。假设我们有一个客户端，服务器1是当前Raft集群的Leader。同时，我们还有服务器2，服务器3。这张图的纵坐标是时间，越往下时间越长。假设客户端将请求发送给服务器1，这里的客户端请求就是一个简单的请求，例如一个Put请求。</p>
<p><img  src="./image-20250131225756591.png"  ><span class="image-caption">image-20250131225756591</span></p>
<p>之后，服务器1的Raft层会发送一个添加日志（AppendEntries）的RPC到其他两个副本（S2，S3）。现在服务器1会一直等待其他副本节点的响应，一直等到过半节点的响应返回。这里的过半节点包括Leader自己。所以在一个只有3个副本节点的系统中，Leader只需要等待一个其他副本节点。</p>
<p><img  src="./image-20250131225809410.png"  ><span class="image-caption">image-20250131225809410</span></p>
<p>一旦过半的节点返回了响应，这里的过半节点包括了Leader自己，所以在一个只有3个副本的系统中，Leader只需要等待一个其他副本节点返回对于AppendEntries的正确响应。</p>
<p><img  src="./image-20250131225825412.png"  ><span class="image-caption">image-20250131225825412</span></p>
<p>当Leader收到了过半服务器的正确响应，Leader会执行（来自客户端的）请求，得到结果，并将结果返回给客户端。</p>
<p><img  src="./image-20250131225835695.png"  ><span class="image-caption">image-20250131225835695</span></p>
<p>与此同时，服务器3可能也会将它的响应返回给Leader，尽管这个响应是有用的，但是这里不需要等待这个响应。这一点对于理解Raft论文中的图2是有用的。</p>
<p><img  src="./image-20250131225855632.png"  ><span class="image-caption">image-20250131225855632</span></p>
<p>好了，大家明白了吗？这是系统在没有故障情况下，处理普通操作的流程。</p>
<blockquote>
<p>学生提问：S2和S3的状态怎么保持与S1同步？</p>
<p>Robert教授：我的天，我忘了一些重要的步骤。现在Leader知道过半服务器已经添加了Log，可以执行客户端请求，并返回给客户端。但是服务器2还不知道这一点，服务器2只知道：我从Leader那收到了这个请求，但是我不知道这个请求是不是已经被Leader提交（committed）了，这取决于我的响应是否被Leader收到。服务器2只知道，它的响应提交给了网络，或许Leader没有收到这个响应，也就不会决定commit这个请求。所以这里还有一个阶段。一旦Leader发现请求被commit之后，它需要将这个消息通知给其他的副本。所以这里有一个额外的消息。</p>
</blockquote>
<p><img  src="./image-20250131225909195.png"  ><span class="image-caption">image-20250131225909195</span></p>
<p>这条消息的具体内容依赖于整个系统的状态。至少在Raft中，没有明确的committed消息。相应的，committed消息被夹带在下一个AppendEntries消息中，由Leader下一次的AppendEntries对应的RPC发出。任何情况下，当有了committed消息时，这条消息会填在AppendEntries的RPC中。下一次Leader需要发送心跳，或者是收到了一个新的客户端请求，要将这个请求同步给其他副本时，Leader会将新的更大的commit号随着AppendEntries消息发出，当其他副本收到了这个消息，就知道之前的commit号已经被Leader提交，其他副本接下来也会执行相应的请求，更新本地的状态。</p>
<p><img  src="./image-20250131225921613.png"  ><span class="image-caption">image-20250131225921613</span></p>
<blockquote>
<p>学生提问：这里的内部交互有点多吧？</p>
<p>Robert教授：是的，这是一个内部需要一些交互的协议，它不是特别的快。实际上，客户端发出请求，请求到达某个服务器，这个服务器至少需要与一个其他副本交互，在返回给客户端之前，需要等待多条消息。所以，一个客户端响应的背后有多条消息的交互。</p>
<p>学生提问：也就是说commit信息是随着普通的AppendEntries消息发出的？那其他副本的状态更新就不是很及时了。</p>
<p>Robert教授：是的，作为实现者，这取决于你在什么时候将新的commit号发出。如果客户端请求很稀疏，那么Leader或许要发送一个心跳或者发送一条特殊的AppendEntries消息。如果客户端请求很频繁，那就无所谓了。因为如果每秒有1000个请求，那么下一条AppendEntries很快就会发出，你可以在下一条消息中带上新的commit号，而不用生成一条额外的消息。额外的消息代价还是有点高的，反正你要发送别的消息，可以把新的commit号带在别的消息里。</p>
<p>实际上，我不认为其他副本（非Leader）执行客户端请求的时间很重要，因为没有人在等这个步骤。至少在不出错的时候，其他副本执行请求是个不太重要的步骤。例如说，客户端就没有等待其他副本执行请求，客户端只会等待Leader执行请求。所以，其他副本在什么时候执行请求，不会影响客户端感受的请求时延。</p>
</blockquote>
<h2 id="5-日志"><a href="#5-日志" class="headerlink" title="5. 日志"></a>5. 日志</h2><p>Raft系统之所以对Log关注这么多的一个原因是，Log是Leader用来对操作排序的一种手段。这对于复制状态机（详见4.2）而言至关重要，对于这些复制状态机来说，所有副本不仅要执行相同的操作，还需要用相同的顺序执行这些操作。而Log与其他很多事物，共同构成了Leader对接收到的客户端操作分配顺序的机制。比如说，我有10个客户端同时向Leader发出请求，Leader必须对这些请求确定一个顺序，并确保所有其他的副本都遵从这个顺序。实际上，Log是一些按照数字编号的槽位（类似一个数组），槽位的数字表示了Leader选择的顺序。</p>
<p>Log的另一个用途是，在一个（非Leader，也就是Follower）副本收到了操作，但是还没有执行操作时。该副本需要将这个操作存放在某处，直到收到了Leader发送的新的commit号才执行。所以，对于Raft的Follower来说，Log是用来存放临时操作的地方。Follower收到了这些临时的操作，但是还不确定这些操作是否被commit了。我们将会看到，这些操作可能会被丢弃。</p>
<p>Log的另一个用途是用在Leader节点，我（Robert教授）很喜欢这个特性。Leader需要在它的Log中记录操作，因为这些操作可能需要重传给Follower。如果一些Follower由于网络原因或者其他原因短时间离线了或者丢了一些消息，Leader需要能够向Follower重传丢失的Log消息。所以，Leader也需要一个地方来存放客户端请求的拷贝。即使对那些已经commit的请求，为了能够向丢失了相应操作的副本重传，也需要存储在Leader的Log中。</p>
<p>所有节点都需要保存Log还有一个原因，就是它可以帮助重启的服务器恢复状态。你可能的确需要一个故障了的服务器在修复后，能重新加入到Raft集群，要不然你就永远少了一个服务器。比如对于一个3节点的集群来说，如果一个节点故障重启之后不能自动加入，那么当前系统只剩2个节点，那将不能再承受任何故障，所以我们需要能够重新并入故障重启了的服务器。对于一个重启的服务器来说，会使用存储在磁盘中的Log。每个Raft节点都需要将Log写入到它的磁盘中，这样它故障重启之后，Log还能保留。而这个Log会被Raft节点用来从头执行其中的操作进而重建故障前的状态，并继续以这个状态运行。所以，Log也会被用来持久化存储操作，服务器可以依赖这些操作来恢复状态。</p>
<blockquote>
<p>学生提问：假设Leader每秒可以执行1000条操作，Follower只能每秒执行100条操作，并且这个状态一直持续下去，会怎样？</p>
<p>Robert（教授）：这里有一点需要注意，Follower在实际执行操作前会确认操作。所以，它们会确认，并将操作堆积在Log中。而Log又是无限的，所以Follower或许可以每秒确认1000个操作。如果Follower一直这么做，它会生成无限大的Log，因为Follower的执行最终将无限落后于Log的堆积。 所以，当Follower堆积了10亿（不是具体的数字，指很多很多）Log未执行，最终这里会耗尽内存。之后Follower调用内存分配器为Log申请新的内存时，内存申请会失败。Raft并没有流控机制来处理这种情况。</p>
<p>所以我认为，在一个实际的系统中，你需要一个额外的消息，这个额外的消息可以夹带在其他消息中，也不必是实时的，但是你或许需要一些通信来（让Follower）告诉Leader，Follower目前执行到了哪一步。这样Leader就能知道自己在操作执行上领先太多。所以是的，我认为在一个生产环境中，如果你想使用系统的极限性能，你还是需要一条额外的消息来调节Leader的速度。</p>
<p>学生提问：如果其中一个服务器故障了，它的磁盘中会存有Log，因为这是Raft论文中图2要求的，所以服务器可以从磁盘中的Log恢复状态，但是这个服务器不知道它当前在Log中的执行位置。同时，当它第一次启动时，它也不知道那些Log被commit了。</p>
<p>Robert教授：所以，对于第一个问题的答案是，一个服务器故障重启之后，它会立即读取Log，但是接下来它不会根据Log做任何操作，因为它不知道当前的Raft系统对Log提交到了哪一步，或许有1000条未提交的Log。</p>
<p>学生补充问题：如果Leader出现了故障会怎样？</p>
<p>Robert教授：如果Leader也关机也没有区别。让我们来假设Leader和Follower同时故障了，那么根据Raft论文图2，它们只有non-volatile状态（也就是磁盘中存储的状态）。这里的状态包括了Log和最近一次任期号（Term Number）。如果大家都出现了故障然后大家都重启了，它们中没有一个在刚启动的时候就知道它们在故障前执行到了哪一步。所以这个时候，会先进行Leader选举，其中一个被选为Leader。如果你回顾一下Raft论文中的图2有关AppendEntries的描述，这个Leader会在发送第一次心跳时弄清楚，整个系统中目前执行到了哪一步。Leader会确认一个过半服务器认可的最近的Log执行点，这就是整个系统的执行位置。另一种方式来看这个问题，一旦你通过AppendEntries选择了一个Leader，这个Leader会迫使其他所有副本的Log与自己保持一致。这时，再配合Raft论文中介绍的一些其他内容，由于Leader知道它迫使其他所有的副本都拥有与自己一样的Log，那么它知道，这些Log必然已经commit，因为它们被过半的副本持有。这时，按照Raft论文的图2中对AppendEntries的描述，Leader会增加commit号。之后，所有节点可以从头开始执行整个Log，并从头构造自己的状态。但是这里的计算量或许会非常大。所以这是Raft论文的图2所描述的过程，很明显，这种从头开始执行的机制不是很好，但是这是Raft协议的工作流程。下一课我们会看一种更有效的，利用checkpoint的方式。</p>
</blockquote>
<h2 id="6-应用层接口"><a href="#6-应用层接口" class="headerlink" title="6. 应用层接口"></a>6. 应用层接口</h2><p>这一部分简单介绍一下应用层和Raft层之间的接口。你或许已经通过实验了解了一些，但是我们这里大概来看一下。假设我们的应用程序是一个key-value数据库，下面一层是Raft层。</p>
<p><img  src="./image-20250203170814935.png"  ><span class="image-caption">image-20250203170814935</span></p>
<p>在Raft集群中，每一个副本上，这两层之间主要有两个接口。</p>
<p>第一个接口是key-value层用来转发客户端请求的接口。如果客户端发送一个请求给key-value层，key-value层会将这个请求转发给Raft层，并说：请将这个请求存放在Log中的某处。</p>
<p><img  src="./image-20250203170845208.png"  ><span class="image-caption">image-20250203170845208</span></p>
<p>这个接口实际上是个函数调用，称之为Start函数。这个函数只接收一个参数，就是客户端请求。key-value层说：我接到了这个请求，请把它存在Log中，并在committed之后告诉我。</p>
<p><img  src="./image-20250203170906267.png"  ><span class="image-caption">image-20250203170906267</span></p>
<p>另一个接口是，随着时间的推移，Raft层会通知key-value层：哈，你刚刚在Start函数中传给我的请求已经commit了。Raft层通知的，不一定是最近一次Start函数传入的请求。例如在任何请求commit之前，可能会再有超过100个请求通过Start函数传给Raft层。</p>
<p><img  src="./image-20250203170931436.png"  ><span class="image-caption">image-20250203170931436</span></p>
<p>这个向上的接口以go channel中的一条消息的形式存在。Raft层会发出这个消息，key-value层要读取这个消息。所以这里有个叫做applyCh的channel，通过它你可以发送ApplyMsg消息。</p>
<p><img  src="./image-20250203170948828.png"  ><span class="image-caption">image-20250203170948828</span></p>
<p>当然，key-value层需要知道从applyCh中读取的消息，对应之前调用的哪个Start函数，所以Start函数的返回需要有足够的信息给key-value层，这样才能完成对应。Start函数的返回值包括，这个请求将会存放在Log中的位置（index）。这个请求不一定能commit成功，但是如果commit成功的话，会存放在这个Log位置。同时，它还会返回当前的任期号（term number）和一些其它我们现在还不太关心的内容。</p>
<p><img  src="./image-20250203171040933.png"  ><span class="image-caption">image-20250203171040933</span></p>
<p>在ApplyMsg中，将会包含请求（command）和对应的Log位置（index）。</p>
<p><img  src="./image-20250203171052069.png"  ><span class="image-caption">image-20250203171052069</span></p>
<p>所有的副本都会收到这个ApplyMsg消息，它们都知道自己应该执行这个请求，弄清楚这个请求的具体含义，并将它应用在本地的状态中。所有的副本节点还会拿到Log的位置信息（index），但是这个位置信息只在Leader有用，因为Leader需要知道ApplyMsg中的请求究竟对应哪个客户端请求（进而响应客户端请求）。</p>
<blockquote>
<p>学生提问：为什么不在Start函数返回的时候就响应客户端请求呢？</p>
<p>Robert教授：我们假设客户端发送了任意的请求，我们假设这里是一个Put或者Get请求，是什么其实不重要，我们还是假设这里是个Get请求。客户端发送了一个Get请求，并且等待响应。当Leader知道这个请求被（Raft）commit之后，会返回响应给客户端。所以这里会是一个Get响应。所以，（在Leader返回响应之前）客户端看不到任何内容。</p>
<p>这意味着，在实际的软件中，客户端调用key-value的RPC，key-value层收到RPC之后，会调用Start函数，Start函数会立即返回，但是这时，key-value层不会返回消息给客户端，因为它还没有执行客户端请求，它也不知道这个请求是否会被（Raft）commit。一个不能commit的场景是，当key-value层调用了Start函数，Start函数返回之后，它就故障了，所以它必然没有发送Apply Entry消息或者其他任何消息，所以也不能执行commit。</p>
<p>所以实际上，Start函数返回了，随着时间的推移，对应于这个客户端请求的ApplyMsg从applyCh channel中出现在了key-value层。只有在那个时候，key-value层才会执行这个请求，并返回响应给客户端。</p>
</blockquote>
<p>有一件事情你们需要熟悉，那就是，首先，对于Log来说有一件有意思的事情：不同副本的Log或许不完全一样。有很多场合都会不一样，至少不同副本节点的Log的末尾，会短暂的不同。例如，一个Leader开始发出一轮AppendEntries消息，但是在完全发完之前就故障了。这意味着某些副本收到了这个AppendEntries，并将这条新Log存在本地。而那些没有收到AppendEntries消息的副本，自然也不会将这条新Log存入本地。所以，这里很容易可以看出，不同副本中，Log有时会不一样。</p>
<p>不过对于Raft来说，Raft会最终强制不同副本的Log保持一致。或许会有短暂的不一致，但是长期来看，所有副本的Log会被Leader修改，直到Leader确认它们都是一致的。</p>
<p>接下来会有有关Raft的两个大的主题，一个是Lab2的内容：Leader Election是如何工作的；另一个是，Leader如何处理不同的副本日志的差异，尤其在出现故障之后。</p>
<h2 id="7-Leader选举（Leader-Election）"><a href="#7-Leader选举（Leader-Election）" class="headerlink" title="7. Leader选举（Leader Election）"></a>7. Leader选举（Leader Election）</h2><p>这一部分我们来看一下Leader选举。这里有个问题，为什么Raft系统会有个Leader，为什么我们需要一个Leader？</p>
<p>答案是，你可以不用Leader就构建一个类似的系统。实际上有可能不引入任何指定的Leader，通过一组服务器来共同认可Log的顺序，进而构建一个一致系统。实际上，Raft论文中引用的Paxos系统就没有Leader，所以这是有可能的。</p>
<p>有很多原因导致了Raft系统有一个Leader，其中一个最主要的是：通常情况下，如果服务器不出现故障，有一个Leader的存在，会使得整个系统更加高效。因为有了一个大家都知道的指定的Leader，对于一个请求，你可以只通过一轮消息就获得过半服务器的认可。对于一个无Leader的系统，通常需要一轮消息来确认一个临时的Leader，之后第二轮消息才能确认请求。所以，使用一个Leader可以提升系统性能至2倍。同时，有一个Leader可以更好的理解Raft系统是如何工作的。</p>
<p>Raft生命周期中可能会有不同的Leader，它使用任期号（term number）来区分不同的Leader。Followers（非Leader副本节点）不需要知道Leader的ID，它们只需要知道当前的任期号。每一个任期最多有一个Leader，这是一个很关键的特性。对于每个任期来说，或许没有Leader，或许有一个Leader，但是不可能有两个Leader出现在同一个任期中。每个任期必然最多只有一个Leader。</p>
<p>那Leader是如何创建出来的呢？每个Raft节点都有一个选举定时器（Election Timer），如果在这个定时器时间耗尽之前，当前节点没有收到任何当前Leader的消息，这个节点会认为Leader已经下线，并开始一次选举。所以我们这里有了这个选举定时器，当它的时间耗尽时，当前节点会开始一次选举。</p>
<p>开始一次选举的意思是，当前服务器会增加任期号（term number），因为它想成为一个新的Leader。而你知道的，一个任期内不能有超过一个Leader，所以为了成为一个新的Leader，这里需要开启一个新的任期。 之后，当前服务器会发出请求投票（RequestVote）RPC，这个消息会发给所有的Raft节点。其实只需要发送到N-1个节点，因为Raft规定了，Leader的候选人总是会在选举时投票给自己。</p>
<p>这里需要注意的一点是，并不是说如果Leader没有故障，就不会有选举。但是如果Leader的确出现了故障，那么一定会有新的选举。这个选举的前提是其他服务器还在运行，因为选举需要其他服务器的选举定时器超时了才会触发。另一方面，如果Leader没有故障，我们仍然有可能会有一次新的选举。比如，如果网络很慢，丢了几个心跳，或者其他原因，这时，尽管Leader还在健康运行，我们可能会有某个选举定时器超时了，进而开启一次新的选举。在考虑正确性的时候，我们需要记住这点。所以这意味着，如果有一场新的选举，有可能之前的Leader仍然在运行，并认为自己还是Leader。例如，当出现网络分区时，旧Leader始终在一个小的分区中运行，而较大的分区会进行新的选举，最终成功选出一个新的Leader。这一切，旧的Leader完全不知道。所以我们也需要关心，在不知道有新的选举时，旧的Leader会有什么样的行为？</p>
<p>（注：下面这一段实际在Lec 06的65-67分钟出现，与这一篇前后的内容在时间上不连续，但是因为内容相关就放到这里来了）</p>
<p>假设网线故障了，旧的Leader在一个网络分区中，这个网络分区中有一些客户端和少数（未过半）的服务器。在网络的另一个分区中，有着过半的服务器，这些服务器选出了一个新的Leader。旧的Leader会怎样，或者说为什么旧的Leader不会执行错误的操作？这里看起来有两个潜在的问题。第一个问题是，如果一个Leader在一个网络分区中，并且这个网络分区没有过半的服务器。那么下次客户端发送请求时，这个在少数分区的Leader，它会发出AppendEntries消息。但是因为它在少数分区，即使包括它自己，它也凑不齐过半服务器，所以它永远不会commit这个客户端请求，它永远不会执行这个请求，它也永远不会响应客户端，并告诉客户端它已经执行了这个请求。所以，如果一个旧的Leader在一个不同的网络分区中，客户端或许会发送一个请求给这个旧的Leader，但是客户端永远也不能从这个Leader获得响应。所以没有客户端会认为这个旧的Leader执行了任何操作。另一个更奇怪的问题是，有可能Leader在向一部分Followers发完AppendEntries消息之后就故障了，所以这个Leader还没决定commit这个请求。这是一个非常有趣的问题，我将会再花45分钟（下一节课）来讲。</p>
<blockquote>
<p>学生提问：有没有可能出现极端的情况，导致单向的网络出现故障，进而使得Raft系统不能工作？</p>
<p>Robert教授：我认为是有可能的。例如，如果当前Leader的网络单边出现故障，Leader可以发出心跳，但是又不能收到任何客户端请求。它发出的心跳被送达了，因为它的出方向网络是正常的，那么它的心跳会抑制其他服务器开始一次新的选举。但是它的入方向网络是故障的，这会阻止它接收或者执行任何客户端请求。这个场景是Raft并没有考虑的众多极端的网络故障场景之一。</p>
<p>我认为这个问题是可修复的。我们可以通过一个双向的心跳来解决这里的问题。在这个双向的心跳中，Leader发出心跳，但是这时Followers需要以某种形式响应这个心跳。如果Leader一段时间没有收到自己发出心跳的响应，Leader会决定卸任，这样我认为可以解决这个特定的问题和一些其他的问题。</p>
<p>你是对的，网络中可能发生非常奇怪的事情，而Raft协议没有考虑到这些场景。</p>
</blockquote>
<p>所以，我们这里有Leader选举，我们需要确保每个任期最多只有一个Leader。Raft是如何做到这一点的呢？</p>
<p>为了能够当选，Raft要求一个候选人从过半服务器中获得认可投票。每个Raft节点，只会在一个任期内投出一个认可选票。这意味着，在任意一个任期内，每一个节点只会对一个候选人投一次票。这样，就不可能有两个候选人同时获得过半的选票，因为每个节点只会投票一次。所以这里是过半原则导致了最多只能有一个胜出的候选人，这样我们在每个任期会有最多一个选举出的候选人。</p>
<p>同时，也是非常重要的一点，过半原则意味着，即使一些节点已经故障了，你仍然可以赢得选举。如果少数服务器故障了或者出现了网络问题，我们仍然可以选举出Leader。如果超过一半的节点故障了，不可用了，或者在另一个网络分区，那么系统会不断地额尝试选举Leader，并永远也不能选出一个Leader，因为没有过半的服务器在运行。</p>
<p>如果一次选举成功了，整个集群的节点是如何知道的呢？当一个服务器赢得了一次选举，这个服务器会收到过半的认可投票，这个服务器会直接知道自己是新的Leader，因为它收到了过半的投票。但是其他的服务器并不能直接知道谁赢得了选举，其他服务器甚至都不知道是否有人赢得了选举。这时，（赢得了选举的）候选人，会通过心跳通知其他服务器。Raft论文的图2规定了，如果你赢得了选举，你需要立刻发送一条AppendEntries消息给其他所有的服务器。这条代表心跳的AppendEntries并不会直接说：我赢得了选举，我就是任期23的Leader。这里的表达会更隐晦一些。Raft规定，除非是当前任期的Leader，没人可以发出AppendEntries消息。所以假设我是一个服务器，我发现对于任期19有一次选举，过了一会我收到了一条AppendEntries消息，这个消息的任期号就是19。那么这条消息告诉我，我不知道的某个节点赢得了任期19的选举。所以，其他服务器通过接收特定任期号的AppendEntries来知道，选举成功了。</p>
<h2 id="8-选举定时器（Election-Timer）"><a href="#8-选举定时器（Election-Timer）" class="headerlink" title="8. 选举定时器（Election Timer）"></a>8. 选举定时器（Election Timer）</h2><p>任何一条AppendEntries消息都会重置所有Raft节点的选举定时器。这样，只要Leader还在线，并且它还在以合理的速率（不能太慢）发出心跳或者其他的AppendEntries消息，Followers收到了AppendEntries消息，会重置自己的选举定时器，这样Leader就可以阻止任何其他节点成为一个候选人。所以只要所有环节都在正常工作，不断重复的心跳会阻止任何新的选举发生。当然，如果网络故障或者发生了丢包，不可避免的还是会有新的选举。但是如果一切都正常，我们不太可能会有一次新的选举。</p>
<p>如果一次选举选出了0个Leader，这次选举就失败了。有一些显而易见的场景会导致选举失败，例如太多的服务器关机或者不可用了，或者网络连接出现故障。这些场景会导致你不能凑齐过半的服务器，进而也不能赢得选举，这时什么事也不会发生。</p>
<p>一个导致选举失败的更有趣的场景是，所有环节都在正常工作，没有故障，没有丢包，但是候选人们几乎是同时参加竞选，它们分割了选票（Split Vote）。假设我们有一个3节点的多副本系统，3个节点的选举定时器几乎同超时，进而期触发选举。首先，每个节点都会为自己投票。之后，每个节点都会收到其他节点的RequestVote消息，因为该节点已经投票给自己了，所以它会返回反对投票。这意味着，3个节点中的每个节点都只能收到一张投票（来自于自己）。没有一个节点获得了过半投票，所以也就没有人能被选上。接下来它们的选举定时器会重新计时，因为选举定时器只会在收到了AppendEntries消息时重置，但是由于没有Leader，所有也就没有AppendEntries消息。所有的选举定时器重新开始计时，如果我们不够幸运的话，所有的定时器又会在同一时间到期，所有节点又会投票给自己，又没有人获得了过半投票，这个状态可能会一直持续下去。</p>
<p>Raft不能完全避免分割选票（Split Vote），但是可以使得这个场景出现的概率大大降低。Raft通过为选举定时器随机的选择超时时间来达到这一点。我们可以这样来看这种随机的方法。假设这里有个时间线，我会在上面画上事件。在某个时间，所有的节点收到了最后一条AppendEntries消息。之后，Leader就故障了。我们这里假设Leader在发出最后一次心跳之后就故障关机了。所有的Followers在同一时间重置了它们的选举定时器，因为它们大概率在同一时间收到了这条AppendEntries消息。</p>
<p><img  src="./image-20250203172126615.png"  ><span class="image-caption">image-20250203172126615</span></p>
<p>它们都重置了自己的选举定时器，这样在将来的某个时间会触发选举。但是这时，它们为选举定时器选择了不同的超时时间。</p>
<p>假设故障的旧的Leader是服务器1，那么服务器2（S2），服务器3（S3）会在这个点为它们的选举定时器设置随机的超时时间。</p>
<p><img  src="./image-20250203172149555.png"  ><span class="image-caption">image-20250203172149555</span></p>
<p>这个图里的关键点在于，因为不同的服务器都选取了随机的超时时间，总会有一个选举定时器先超时，而另一个后超时。假设S2和S3之间的差距足够大，先超时的那个节点（也就是S2）能够在另一个节点（也就是S3）超时之前，发起一轮选举，并获得过半的选票，那么那个节点（也就是S2）就可以成为新的Leader。大家都明白了随机化是如何去除节点之间的同步特性吗？</p>
<p>这里对于选举定时器的超时时间的设置，需要注意一些细节。一个明显的要求是，选举定时器的超时时间需要至少大于Leader的心跳间隔。这里非常明显，假设Leader每100毫秒发出一个心跳，你最好确认所有节点的选举定时器的超时时间不要小于100毫秒，否则该节点会在收到正常的心跳之前触发选举。所以，选举定时器的超时时间下限是一个心跳的间隔。实际上由于网络可能丢包，这里你或许希望将下限设置为多个心跳间隔。所以如果心跳间隔是100毫秒，你或许想要将选举定时器的最短超时时间设置为300毫秒，也就是3次心跳的间隔。所以，如果心跳间隔是这么多（两个AE之间），那么你会想要将选举定时器的超时时间下限设置成心跳间隔的几倍，在这里。</p>
<p><img  src="./image-20250203172249003.png"  ><span class="image-caption">image-20250203172249003</span></p>
<p>那超时时间的上限呢？因为随机的话都是在一个范围内随机，那我们应该在哪设置超时时间的上限呢？在一个实际系统中，有几点需要注意。</p>
<p><img  src="./image-20250203172303521.png"  ><span class="image-caption">image-20250203172303521</span></p>
<p>首先，这里的最大超时时间影响了系统能多快从故障中恢复。因为从旧的Leader故障开始，到新的选举开始这段时间，整个系统是瘫痪了。尽管还有一些其他服务器在运行，但是因为没有Leader，客户端请求会被丢弃。所以，这里的上限越大，系统的恢复时间也就越长。这里究竟有多重要，取决于我们需要达到多高的性能，以及故障出现的频率。如果一年才出一次故障，那就无所谓了。如果故障很频繁，那么我们或许就该关心恢复时间有多长。这是一个需要考虑的点。</p>
<p>另一个需要考虑的点是，不同节点的选举定时器的超时时间差（S2和S3之间）必须要足够长，使得第一个开始选举的节点能够完成一轮选举。这里至少需要大于发送一条RPC所需要的往返（Round-Trip）时间。</p>
<p><img  src="./image-20250203172448581.png"  ><span class="image-caption">image-20250203172448581</span></p>
<p>或许需要10毫秒来发送一条RPC，并从其他所有服务器获得响应。如果这样的话，我们需要设置超时时间的上限到足够大，从而使得两个随机数之间的时间差极有可能大于10毫秒。</p>
<p>在Lab2中，如果你的代码不能在几秒内从一个Leader故障的场景中恢复的话，测试代码会报错。所以这种场景下，你们需要调小选举定时器超时时间的上限。这样的话，你才可能在几秒内完成一次Leader选举。这并不是一个很严格的限制。</p>
<p>这里还有一个小点需要注意，每一次一个节点重置自己的选举定时器时，都需要重新选择一个随机的超时时间。也就是说，不要在服务器启动的时候选择一个随机的超时时间，然后反复使用同一个值。因为如果你不够幸运的话，两个服务器会以极小的概率选择相同的随机超时时间，那么你会永远处于分割选票的场景中。所以你需要每次都为选举定时器选择一个不同的随机超时时间。</p>
<h2 id="9-可能的异常情况"><a href="#9-可能的异常情况" class="headerlink" title="9. 可能的异常情况"></a>9. 可能的异常情况</h2><p>一个旧Leader在各种奇怪的场景下故障之后，为了恢复系统的一致性，一个新任的Leader如何能整理在不同副本上可能已经不一致的Log？</p>
<p>这个话题只在Leader故障之后才有意义，如果Leader正常运行，Raft不太会出现问题。如果Leader正在运行，并且在其运行时，系统中有过半服务器。Leader只需要告诉Followers，Log该是什么样子。Raft要求Followers必须同意并接收Leader的Log，这在Raft论文的图2中有说明。只要Followers还能处理，它们就会全盘接收Leader在AppendEntries中发送给它们的内容，并加到本地的Log中。之后再收到来自Leader的commit消息，在本地执行请求。这里很难出错。</p>
<p>在Raft中，当Leader故障了才有可能出错。例如，旧的Leader在发送消息的过程中故障了，或者新Leader在刚刚当选之后，还没来得及做任何操作就故障了。所以这里有一件事情我们非常感兴趣，那就是在一系列故障之后，Log会是怎样？</p>
<p>这里有个例子，假设我们有3个服务器（S1，S2，S3），我将写出每个服务器的Log，每一列对齐之后就是Log的一个槽位。我这里写的值是Log条目对应的任期号，而不是Log记录的客户端请求。所以第一列是槽位1，第二列是槽位2。所有节点在任期3的时候记录了一个请求在槽位1，S2和S3在任期3的时候记录了一个请求在槽位2。在槽位2，S1没有任何记录。 </p>
<h1 id="Lab-2-Key-Value-Server"><a href="#Lab-2-Key-Value-Server" class="headerlink" title="Lab 2: Key/Value Server"></a>Lab 2: Key/Value Server</h1><h2 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h2><p>在本实验中，你将构建一个单机键值服务器，该服务器确保每个操作即使在网络故障的情况下也能仅执行一次，并且操作是可线性化的。后续实验将复制此类服务器以处理服务器崩溃的情况。</p>
<p>客户端可以向键值服务器发送三种不同的远程过程调用（RPC）：Put(key, value)、Append(key, arg) 和 Get(key)。服务器维护一个内存中的键值对映射。键和值均为字符串。Put(key, value) 用于在映射中安装或替换特定键的值，Append(key, arg) 将参数 arg 追加到键的值并返回旧值，Get(key) 获取键的当前值。对于不存在的键，Get 应返回空字符串。对于不存在的键执行 Append 操作时，应将其视为现有值为零长度字符串的情况。每个客户端通过 Clerk（包含 Put/Append/Get 方法）与服务器通信。Clerk 管理与服务器的 RPC 交互。</p>
<p>你的服务器必须确保应用程序对 Clerk 的 Get/Put/Append 方法的调用是可线性化的。如果客户端请求不是并发的，每个客户端的 Get/Put/Append 调用应观察到前面一系列调用所隐含的状态修改。对于并发调用，返回值和最终状态必须与操作按某种顺序依次执行时相同。调用在时间上有重叠时即为并发，例如，如果客户端 X 调用 Clerk.Put()，客户端 Y 调用 Clerk.Append()，然后客户端 X 的调用返回。一个调用必须观察到在其开始之前已完成的所有调用的效果。</p>
<p>线性化对于应用程序来说非常方便，因为这是你从一个依次处理请求的单个服务器中看到的行为。例如，如果一个客户端从服务器获得更新请求的成功响应，随后其他客户端发起的读取操作将肯定能看到该更新的效果。对于单个服务器，提供线性化相对容易。</p>
<h2 id="线性化"><a href="#线性化" class="headerlink" title="线性化"></a>线性化</h2><p>Q: 什么是线性化（linearizability）？</p>
<p>A: 线性化是定义服务在面对并发客户端请求时行为正确性的一种方式。大致来说，它规定服务应看起来像是按请求到达的顺序依次执行请求。</p>
<p>线性化是基于“历史记录”定义的：实际客户端请求和服务器响应的轨迹，标注了客户端发送和接收每条消息的时间。线性化告诉你单个历史记录是否合法；我们可以说，如果服务可以生成的每个历史记录都是线性化的，那么该服务就是线性化的。</p>
<p>对于每个客户端请求，请求消息和对应的响应消息是历史记录中的独立元素，每条消息出现在客户端发送或接收的时间点。因此，历史记录明确展示了请求的并发性和网络延迟。</p>
<p>如果可以为每个操作分配一个“线性化点”（一个时间点），使得每个操作的点位于客户端发送请求和接收响应的时间之间，并且历史记录的响应值与按点的顺序依次执行请求时得到的值相同，那么这个历史记录就是线性化的。如果没有任何线性化点的分配能满足这两个要求，那么该历史记录就不是线性化的。</p>
<p>线性化的一个重要后果是，服务在执行并发（时间上重叠）操作的顺序上有一定的自由度。特别是，如果来自客户端C1和C2的请求是并发的，服务器可能会先执行C2的请求，即使C1发送请求消息的时间早于C2。另一方面，如果C1在C2发送请求之前收到了响应，线性化要求服务表现得像是先执行了C1的请求（即C2的操作必须观察到C1操作的效果，如果有的话）。</p>
<p>Q: 线性化检查器是如何工作的？</p>
<p>A: 一个简单的线性化检查器会尝试每一种可能的顺序（或线性化点的选择），以查看是否有一种是根据线性化定义的规则有效的。由于在大型历史记录上这样做会太慢，聪明的检查器会避免查看明显不可能的顺序（例如，提议的线性化点在操作开始时间之前），在可能的情况下将历史记录分解为可以单独检查的子历史记录，并使用启发式方法首先尝试更可能的顺序。</p>
<p>这些论文描述了这些技术；我认为Knossos是基于第一篇论文，而Porcupine增加了第二篇论文中的想法：</p>
<p><a href="http://www.cs.ox.ac.uk/people/gavin.lowe/LinearizabiltyTesting/paper.pdf">http://www.cs.ox.ac.uk/people/gavin.lowe/LinearizabiltyTesting/paper.pdf</a></p>
<p><a href="https://arxiv.org/pdf/1504.00204.pdf">https://arxiv.org/pdf/1504.00204.pdf</a></p>
<p>Q: 服务是否使用线性化检查器来实现线性化？</p>
<p>A: 不；检查器仅在测试中使用。</p>
<p>Q: 那么服务是如何实现线性化的？</p>
<p>A: 如果服务实现为单个服务器，没有复制、缓存或内部并行性，那么服务几乎只需要按请求到达的顺序依次执行客户端请求。主要的复杂性来自于客户端因为认为网络丢失了消息而重新发送请求：对于有副作用的请求，服务必须小心不要执行任何给定的客户端请求超过一次。如果服务涉及复制或缓存，则需要更复杂的设计。</p>
<p>Q: 你知道有哪些现实世界中的系统使用Porcupine或类似的测试框架进行测试的例子吗？</p>
<p>A: 这种测试很常见——例如，可以看看 <a href="https://jepsen.io/analyses；Jepsen是一个测试了许多存储系统正确性（以及适当情况下的线性化）的组织。">https://jepsen.io/analyses；Jepsen是一个测试了许多存储系统正确性（以及适当情况下的线性化）的组织。</a></p>
<p>特别是Porcupine的一个例子：</p>
<p><a href="https://www.vldb.org/pvldb/vol15/p2201-zare.pdf">https://www.vldb.org/pvldb/vol15/p2201-zare.pdf</a></p>
<p>Q: 还有哪些其他的一致性模型？</p>
<p>A: 查找以下模型：</p>
<ul>
<li>最终一致性</li>
<li>因果一致性</li>
<li>叉一致性</li>
<li>可串行化</li>
<li>顺序一致性</li>
<li>时间线一致性</li>
</ul>
<p>还有数据库、CPU内存/缓存系统和文件系统中的其他模型。</p>
<p>一般来说，不同的模型在对应用程序开发者的直观性和性能方面有所不同。例如，最终一致性允许许多异常结果（例如，即使写入已完成，后续读取可能看不到它），但在分布式/复制环境中，它可以比线性化实现更高的性能。</p>
<p>Q: 为什么线性化被称为强一致性模型？</p>
<p>A: 它之所以被称为强一致性模型，是因为它禁止了许多可能会让应用程序开发者感到惊讶的情况。</p>
<p>例如，如果我调用put(x, 22)，并且我的put完成，之后没有其他人写x，随后你调用get(x)，你保证会看到22，而不是其他值。也就是说，读取会看到最新的数据。</p>
<p>另一个例子是，如果没有人写x，我调用get(x)，你调用get(x)，我们不会看到不同的值。</p>
<p>这些属性在我们将要研究的其他一致性模型（如最终一致性和因果一致性）中并不成立。这些模型通常被称为“弱”一致性模型。</p>
<p>Q: 人们在实践中如何确保他们的分布式系统是正确的？</p>
<p>A: 我猜彻底的测试是最常见的计划。</p>
<p>正式方法的使用也很普遍；可以看看这里的一些例子：</p>
<p><a href="https://arxiv.org/pdf/2210.13661.pdf">https://arxiv.org/pdf/2210.13661.pdf</a></p>
<p><a href="https://assets.amazon.science/67/f9/92733d574c11ba1a11bd08bfb8ae/how-amazon-web-services-uses-formal-methods.pdf">https://assets.amazon.science/67/f9/92733d574c11ba1a11bd08bfb8ae/how-amazon-web-services-uses-formal-methods.pdf</a></p>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3477132.3483540">https://dl.acm.org/doi/abs/10.1145/3477132.3483540</a></p>
<p><a href="https://www.ccs.neu.edu/~stavros/papers/2022-cpp-published.pdf">https://www.ccs.neu.edu/~stavros/papers/2022-cpp-published.pdf</a></p>
<p><a href="https://www.cs.purdue.edu/homes/pfonseca/papers/eurosys2017-dsbugs.pdf">https://www.cs.purdue.edu/homes/pfonseca/papers/eurosys2017-dsbugs.pdf</a></p>
<p>Q: 为什么线性化被用作一致性模型，而不是其他模型，如最终一致性？</p>
<p>A: 人们确实经常构建提供比线性化更弱一致性的存储系统，如最终一致性和因果一致性。</p>
<p>线性化对应用程序编写者有一些很好的特性：</p>
<ul>
<li>读取总是观察到最新的数据。</li>
<li>如果没有并发写入，所有读者看到相同的数据。</li>
<li>在大多数线性化系统上，你可以添加像test-and-set这样的小型事务（因为大多数线性化设计最终会依次执行每个数据项的操作）。</li>
</ul>
<p>像最终一致性和因果一致性这样的更弱方案可以允许更高的性能，因为它们不要求立即更新所有数据副本。这种更高的性能通常是决定因素。然而，弱一致性为应用程序编写者引入了一些复杂性：</p>
<ul>
<li>读取可以观察到过时的数据。</li>
<li>读取可以观察到写入的顺序错误。</li>
<li>如果你写入，然后读取，你可能看不到你的写入，而是看到过时的数据。</li>
<li>对同一项目的并发更新不是依次执行的，因此很难实现像test-and-set这样的小型事务。</li>
</ul>
<p>Q: 如何决定线性化的小橙线的位置——操作的线性化点？在图上看起来像是随机画在请求主体内的某个地方？</p>
<p>A: 这个想法是，为了证明执行是线性化的，你需要（作为人类）找到放置小橙线（线性化点）的位置。也就是说，为了证明历史记录是线性化的，你需要找到符合这些要求的操作顺序：</p>
<ul>
<li>所有函数调用都有一个线性化点，位于其调用和响应之间。</li>
<li>所有函数似乎在它们的线性化点瞬间发生，按照顺序定义的行为。</li>
</ul>
<p>因此，一些线性化点的放置是无效的，因为它们位于请求时间范围之外；其他放置是无效的，因为它们违反了顺序定义（对于键值存储，违反意味着读取没有观察到最新写入的值，其中“最新”指的是线性化点）。</p>
<p>在复杂情况下，你可能需要尝试许多线性化点顺序的组合，以找到一个能够证明历史记录是线性化的组合。如果你尝试了所有组合，但没有一个有效，那么该历史记录就不是线性化的。</p>
<p>Q: 是否存在这种情况：如果两个命令同时执行，我们能够强制执行特定行为，使得一个命令总是首先执行（即它总是有更早的线性化点）？</p>
<p>A: 在线性化的存储服务中（例如GFS或你的Lab 3），如果来自多个客户端的请求几乎同时到达，服务可以选择执行它们的顺序。尽管在实践中，大多数服务会按照请求数据包到达网络的顺序执行并发请求。</p>
<p>线性化点的概念是检查历史记录是否线性化的一种策略的一部分。实际实现通常不涉及线性化点的明确概念。相反，它们通常只是按某种串行（依次）顺序执行传入请求。你可以将每个操作的线性化点视为发生在服务执行请求期间的某个时间点。</p>
<p>Q: 我们还可以执行哪些更强的一致性检查？线性化在直觉上感觉不太有用，因为即使同时执行两个命令，你仍然可能读取到不同的数据。</p>
<p>A: 的确，线性化类似于在程序中使用线程而不使用锁——对同一数据的任何并发访问都是竞争条件。以这种方式编程是可能的，但需要小心。</p>
<p>下一个最强的一致性概念涉及事务，如许多数据库中所使用的，这实际上锁定了任何使用的数据。对于读取和写入多个数据项的程序，事务比线性化更容易编程。“可串行化”是一个提供事务的一致性模型的名称。</p>
<p>然而，事务系统比线性化系统更复杂、更慢、更难实现容错。</p>
<p>Q: 为什么验证现实系统涉及“巨大努力”？</p>
<p>A: 验证意味着证明程序是正确的，即它保证符合某些规范。事实证明，证明复杂程序的重要定理是困难的——比普通编程困难得多。</p>
<p>你可以通过尝试这门课程的实验来感受这一点：</p>
<p><a href="https://6826.csail.mit.edu/2020/">https://6826.csail.mit.edu/2020/</a></p>
<p>Q: 从指定的阅读材料来看，大多数分布式系统没有经过正式证明是正确的。那么一个团队如何决定一个框架或系统已经经过足够充分的测试，可以作为实际产品发布？</p>
<p>A: 在公司耗尽资金并破产之前，开始发布产品并获得收入是一个好主意。人们在这一点之前尽可能多地进行测试，并且通常会尝试说服一些早期客户使用该产品（并帮助发现漏洞），并明确表示产品可能无法正确工作。也许当产品功能足以满足许多客户并且没有已知的重大漏洞时，你就可以准备发布了。</p>
<p>除此之外，明智的客户也会测试他们依赖的软件。没有严肃的组织期望任何软件是无漏洞的。</p>
<p>Q: 为什么不使用客户端发送命令的时间作为线性化点？即让系统按客户端发送请求的顺序执行操作？</p>
<p>A: 很难构建一个保证这种行为的系统——开始时间是客户端代码发出请求的时间，但由于网络延迟，服务可能要到很久之后才会收到请求。也就是说，请求可能以与开始时间顺序大不相同的顺序到达服务。服务原则上可以延迟执行每个到达的请求，以防稍后到达一个具有更早发出时间的请求，但很难正确实现这一点，因为网络不保证限制延迟。而且这可能会增加每个请求的延迟，可能增加很多。话说回来，我们稍后会看到的Spanner使用了相关技术。</p>
<p>像线性化这样的正确性规范需要在足够宽松以高效实现和足够严格以提供对应用程序程序有用的保证之间找到平衡。“看起来按调用顺序执行操作”太严格，难以高效实现，而线性化的“看起来在调用和响应之间执行”虽然对应用程序开发者来说不那么直观，但可以实现。</p>
<p>Q: 如果有并发的get()操作，而同时也有并发的put()操作，get()操作可能会看到不同的值，这是否是个问题？</p>
<p>A: 在存储系统的上下文中，这通常不是问题。例如，如果我们谈论的值是我的个人资料照片，而两个人在更新照片的同时请求查看它，那么他们看到不同的照片（旧的或新的）是完全合理的。</p>
<p>一些存储系统提供了更复杂的方案，特别是事务，这使得这种情况更容易处理。“可串行化”是一个提供事务的一致性模型的名称。然而，事务系统比线性化系统更复杂、更慢、更难实现容错。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824</a></li>
</ol>
]]></content>
      <tags>
        <tag>cloud</tag>
      </tags>
  </entry>
</search>
