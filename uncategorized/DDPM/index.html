

<!DOCTYPE html>
<html lang="zh" color-mode=light>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Diffusion 学习 - EnableAsync&#39;s Blog</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate" />
  <meta name="keywords" content="golang,java">
  <meta name="description" content="DDPMddpm
这里从 $x_t$ 到 $x_{t-...">
  <meta name="author" content="EnableAsync">
  <link rel="icon" href="/images/icons/favicon-16x16.png" type="image/png" sizes="16x16">
  <link rel="icon" href="/images/icons/favicon-32x32.png" type="image/png" sizes="32x32">
  <link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180">
  <meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333">
  
    <meta rel="msapplication-TileImage" content="/images/icons/favicon-144x144.png">
    <meta rel="msapplication-TileColor" content="#000000">
  

  
<link rel="stylesheet" href="/css/style.css">


  
    
<link rel="stylesheet" href="/lib/iconfont/iconfont.css">

  

  
    
<link rel="stylesheet" href="/lib/fancybox/fancybox.css">

  

  
    
    
<link rel="stylesheet" href="/lib/highlight/a11y-dark.css">

  

  <script>
    var CONFIG = window.CONFIG || {};
    var ZHAOO = window.ZHAOO || {};
    CONFIG = {
      isHome: false,
      fancybox: true,
      pjax: false,
      lazyload: {
        enable: true,
        only_post: 'false',
        loading: '[object Object]'
      },
      donate: {
        enable: false,
        alipay: 'https://pic.izhaoo.com/alipay.jpg',
        wechat: 'https://pic.izhaoo.com/wechat.jpg'
      },
      galleries: {
        enable: true
      },
      fab: {
        enable: true,
        always_show: false
      },
      carrier: {
        enable: false
      },
      daovoice: {
        enable: false
      },
      preview: {
        background: {
          default: '',
          api: ''
        },
        motto: {
          default: '生于忧患，死于安乐',
          typing: true,
          api: '',
          data_contents: ''
        },
      },
      qrcode: {
        enable: true,
        type: 'url',
        image: 'https://pic.izhaoo.com/weapp-code.jpg',
      },
      toc: {
        enable: true
      },
      scrollbar: {
        type: 'default'
      },
      notification: {
        enable: false,
        delay: 4500,
        list: '',
        page_white_list: '',
        page_black_list: ''
      },
      search: {
        enable: true,
        path: 'search.xml'
      }
    }
  </script>

  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body class="lock-screen">
  <div class="loading"></div>
  
    


  <nav class="navbar">
    <div class="left">
      
        <i class="iconfont iconhome j-navbar-back-home"></i>
      
      
        <i class="iconfont iconqrcode j-navbar-qrcode"></i>
      
      
        <i class="iconfont iconmoono" id="color-toggle" color-toggle="light"></i>
      
      
        <i class="iconfont iconsearch j-navbar-search"></i>
      
    </div>
    <div class="center">Diffusion 学习</div>
    <div class="right">
      <i class="iconfont iconmenu j-navbar-menu"></i>
    </div>
    
      <div id="qrcode-navbar"></div>
    
  </nav>

  
  

<nav class="menu">
  <div class="menu-container">
    <div class="menu-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <ul class="menu-content"><li class="menu-item">
        <a href="/ " class="underline "> 首页</a>
      </li><li class="menu-item">
        <a href="/categories/ " class="underline "> 分类</a>
      </li></ul>
    
      <div class="menu-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
    
  </div>
</nav>
  <main id="main">
  <div class="article-wrap">
    <div class="row container">
      <div class="col-xl-3"></div>
      <div class="col-xl-6"><article class="article">
  <div class="wrap">
    <section class="head">
  <img   class="lazyload" data-original="/images/theme/post.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false">
  <div class="head-mask">
    <h1 class="head-title">Diffusion 学习</h1>
    <div class="head-info">
      <span class="post-info-item"><i class="iconfont iconcalendar"></i>April 03, 2025</span>
      
      <span class="post-info-item"><i class="iconfont iconfont-size"></i>9227</span>
    </div>
  </div>
</section>
    <section class="main">
      <section class="content">
        <h1 id="DDPM"><a href="#DDPM" class="headerlink" title="DDPM"></a>DDPM</h1><p><img    class="lazyload" data-original="image-20250403144618848.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">ddpm</span></p>
<p>这里从 $x_t$ 到 $x_{t-1}$ 的时候，预测的是 $x_{t-1}$ 的概率分布，也就是说要得到的是 $p(x_{t-1}|x_t)$，所以去噪过程是具有一定的随机性的，从 $p(x_{t-1}|x_t)$ 分布中就可以抽样出 $x_{t-1}$ 了。</p>
<h2 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h2><script type="math/tex; mode=display">
P(x_{t - 1}|x_t) = \frac{P(x_{t - 1}, x_t)}{P(x_t)} = \frac{P(x_t|x_{t - 1})P(x_{t - 1})}{P(x_t)} \quad \text{(1)}</script><p>这里的 $P(x_t|x_{t - 1})$ 是易知的，因为 $x_t = \sqrt{\alpha_t}x_{t - 1} + \sqrt{\beta_t}\epsilon_t$，其中 $\epsilon_t \sim N(0, 1)$，$\sqrt{\beta_t} \sim N(0, \beta_t)$，$x_t \sim N(\sqrt{\alpha_t}x_{t - 1}, \beta_t)$。</p>
<p>$P(x_t|x_{t - 1}) \sim N(\sqrt{\alpha_t}x_{t - 1}, \beta_t)$ 不断推导有 $P(x_t|x_0) \sim N(\sqrt{\bar{\alpha}_t}x_0, 1 - \bar{\alpha}_t)$。</p>
<ul>
<li>原先的去噪过程中 $P(x_{t - 1})$ 和 $P(x_t)$ 无法求得，为去噪过程增加条件：<script type="math/tex; mode=display">
P(x_{t - 1}|x_t, x_0) = \frac{P(x_t|x_{t - 1}, x_0)P(x_{t - 1}|x_0)}{P(x_t|x_0)} = \frac{P(x_t|x_{t - 1})P(x_{t - 1}|x_0)}{P(x_t|x_0)}</script></li>
</ul>
<p>（高斯特性）又 $P(x_t|x_0)$ 已知，则 $P(x_{t - 1}|x_0)$ 已知，得 $P(x_{t - 1}|x_t, x_0) \sim N(\tilde{\mu}_t(x_0, x_t), \tilde{\beta}_t)$。</p>
<p>$x_{t - 1} = \tilde{\mu}_t(x_0, x_t) + \sqrt{\tilde{\beta}_t}\epsilon$，$\epsilon \sim N(0, 1)$，其中 $\tilde{\mu}_t(x_t, x_0)$ 为 $\frac{\sqrt{\alpha_{t - 1}}\beta_t}{1 - \bar{\alpha}_t}x_0 + \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t - 1})}{1 - \bar{\alpha}_t}x_t$  ，$\tilde{\beta}_t = \frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t$ 。这里的 $x_0$ 未知。</p>
<ul>
<li><p>于是又有 $x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon$ ，则 $x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon)$ ，$x_0$ 可由 $x_t$ 得到了，它们之间差一个 $\epsilon$ 。</p>
</li>
<li><p>UNet 预测的就是 $x_0$ 和 $x_t$ 之间的这个噪声。那么能得到 $x_0$ ，是不是原因呢？否定的，因为 $x_0$ 的推导是借助了马尔可夫性质，所以还是要一步步推导。</p>
<p>把 $x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon)$ 代入 $\tilde{\mu}_t(x_t, x_0)$ 式中，有 $\frac{1}{\sqrt{\alpha_t}}(x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}}\epsilon)$ 。</p>
</li>
<li><p>总体脉络：从 $P(x_{t - 1}|x_t) \to P(x_{t - 1}|x_t, x_0) \to \tilde{\mu}_t(x_0, x_t) \to x_0 \to \epsilon$</p>
</li>
</ul>
<p><img    class="lazyload" data-original="53dfabcb9844f43a33026fe042dff8c.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">笔记</span></p>
<h2 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h2><ol>
<li>$ T = 1000 $</li>
<li>$ x_t=\sqrt{\alpha_t}x_{t - 1}+\sqrt{\beta_t}\epsilon $，$ \alpha_t<1 $，$ \beta_t>0 $，$ \alpha_t+\beta_t = 1 $<ul>
<li>$ x_t\sim N(\sqrt{\alpha_t}x_{t - 1},\beta_t) $</li>
<li>$ \alpha_t+\beta_t = 1 $ 的设置是为了最后易于得到 $ x_n=\sqrt{\overline{\alpha}_n}x_0+\sqrt{1 - \overline{\alpha}_n}\epsilon $ 的形式</li>
</ul>
</li>
<li><strong>能否直接跳步？</strong><ul>
<li>$ P(x_{t - 1}|x_t,x_0)=\frac{P(x_t|x_{t - 1})P(x_{t - 1}|x_0)}{P(x_t|x_0)} $ 是由贝叶斯定理得到的</li>
<li>结论：不能跳步</li>
</ul>
</li>
<li><strong>为什么不直接预测 $ x_{t - 1} $，而是预测 $ P(x_{t - 1}|x_t) $</strong><ul>
<li>这样有更多的多样性</li>
</ul>
</li>
<li><strong>论文中的变分下界分析</strong><ul>
<li>是为了证明 $ E(-\log P(x_0)) $ 等价于求 $ P(x_{t - 1}|x_t) $ 和 $ P(x_{t - 1}|x_t,x_0) $ 的 KL 散度。</li>
</ul>
</li>
</ol>
<p><img    class="lazyload" data-original="34ff3b1a482f1445724b9f1683bbd71.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">参数选择</span></p>
<h1 id="DDIM"><a href="#DDIM" class="headerlink" title="DDIM"></a>DDIM</h1><h2 id="去马尔可夫化"><a href="#去马尔可夫化" class="headerlink" title="去马尔可夫化"></a>去马尔可夫化</h2><script type="math/tex; mode=display">
P(x_{t-1} | x_t) = \frac{P(x_t | x_{t-1})P(x_{t-1})}{P(x_t)}</script><p>在 DDPM 不好求，加入 $x_0$</p>
<script type="math/tex; mode=display">
P(x_{t-1} | x_t, x_0) = \frac{P(x_t | x_{t-1}, x_0)P(x_{t-1} | x_0)}{P(x_t | x_0)} \overset{\text{DDPM}}{\Longrightarrow} \frac{P(x_t | x_{t-1})P(x_{t-1} | x_0)}{P(x_t|x_0)}</script><script type="math/tex; mode=display">
\overset{\text{DDIM}}{\Longrightarrow} P(x_s | x_k, x_0) = \frac{\text{①}P(x_k | x_s, x_0) \text{②}P(x_s | x_0)}{\text{③}P(x_k | x_0)} \quad (1)</script><ul>
<li>① ② ③ 这三部分共同决定了 $P(x_s | x_k, x_0)$ 的解。</li>
<li>3 个部分未知的越多，那么说明 $P(x_s | x_k, x_0)$ 的约束越少，解越多。</li>
</ul>
<p>但 DDPM 训练时，要满足 $P(x_t | x_0) = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon$。若不重新训练，那么这个假设仍然要保留，于是 ② ③ 是知道的。</p>
<p>在 DDPM 中，① 并没有被用到，则 (1) 式的解可以设为：</p>
<script type="math/tex; mode=display">
P(x_s | x_k, x_0) \sim \mathcal{N}(kx_0 + mx_k, \sigma^2 I)</script><p>于是</p>
<script type="math/tex; mode=display">
\begin{align*}
x_s &= (kx_0 + mx_k) + \sigma \epsilon \\
&= kx_0 + m(\sqrt{\bar\alpha_k}x_0 + \sqrt{1 - \bar\alpha_k}\epsilon') + \sigma \epsilon \\
&= (k + m\sqrt{\bar\alpha_k})x_0 + (m\sqrt{1 - \bar\alpha_k}\epsilon' + \sigma \epsilon) \\
&= (k + m\sqrt{\bar\alpha_k})x_0 + \sqrt{m^2(1 - \bar\alpha_k) + \sigma^2}\epsilon \quad \mathcal{N}(0, m^2(1 - \bar\alpha_k))\\
&= \sqrt{\bar\alpha_s}x_0 + \sqrt{1 - \bar\alpha_s}\epsilon
\end{align*}</script><p><strong>待定系数法求出 $m$ 和 $k$</strong></p>
<script type="math/tex; mode=display">
m = \frac{\sqrt{1 - \bar\alpha_s + \sigma^2}}{\sqrt{1 - \bar\alpha_k}}, \quad k = \sqrt{\bar\alpha_s} - \frac{\sqrt{1 - \bar\alpha_s - \sigma^2}}{\sqrt{1 - \bar\alpha_k}}\sqrt{\bar\alpha_k}</script><p>于是有</p>
<script type="math/tex; mode=display">
\mu = mx_k + kx_0 = \sqrt{\bar\alpha_s}x_0 + \frac{\sqrt{1 - \bar\alpha_s - \sigma^2}}{\sqrt{1 - \bar\alpha_k}}(x_k - \sqrt{\bar\alpha_k}x_0)</script><p>以及 $\sigma = \sigma$</p>
<p>相比于 DDPM 的 $s = k - 1$，DDIM 的 $s \leq k - 1$，于是可以跳步了。 </p>
<p><img    class="lazyload" data-original="9ec363832d7635f22955f09c2c27248.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">去马尔可夫化</span></p>
<h2 id="参数选择-1"><a href="#参数选择-1" class="headerlink" title="参数选择"></a>参数选择</h2><ul>
<li>$\sigma = 0$ 时为决定性采样方式，无随机性。</li>
<li>$\sigma = \sqrt{\frac{1 - \overline{\alpha}_t}{1 - \overline{\alpha}_t} \beta_t}$ 时对应 DDPM 。</li>
</ul>
<script type="math/tex; mode=display">
P(x_s | x_k, x_0) \sim \mathcal{N}(\sqrt{\alpha_s}x_0 + \sqrt{1 - \alpha_s - \sigma^2} \frac{x_k - \sqrt{\alpha_k}x_0}{\sqrt{1 - \alpha_k}}, \sigma^2 I)</script><p>当 $\sigma$ 取 $\sqrt{\frac{1 - \overline{\alpha}_t}{1 - \overline{\alpha}_t} \beta_t}$ 时，原式为 $\mathcal{N}(\frac{1}{\sqrt{\alpha_t}}(x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon), \beta_t)$ 。</p>
<h3 id="DDIM-实验设置"><a href="#DDIM-实验设置" class="headerlink" title="DDIM 实验设置"></a><strong>DDIM 实验设置</strong></h3><p><img    class="lazyload" data-original="image-20250403231724755.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="    style="zoom:80%;" /><span class="image-caption">DDIM 实验结果</span></p>
<p>$\sigma = \eta \sqrt{\frac{1 - \overline{\alpha}_t}{1 - \overline{\alpha}_t} \beta_t}$</p>
<ul>
<li>$\eta = 1$ 时即为可跳步的 DDPM 。</li>
<li>$\eta = 0$ 时，为确定性 DDIM 。</li>
<li>$\eta$ 越小，效果越好（FID 越低）。</li>
</ul>
<p><strong>总结</strong>：</p>
<ul>
<li>DDPM：高斯去噪过程，推理慢。</li>
<li>DDIM：去噪，推理快，待定系数法求 $m$，$k$ 。以及 $\sigma = 0$ 时，对于每一个 $x_t$ 有唯一确定的 $x$ 。 </li>
</ul>
<p><img    class="lazyload" data-original="34ff3b1a482f1445724b9f1683bbd71.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">参数选择</span></p>
<h1 id="Classifier-Guidance-Classifier-Free-Guidance"><a href="#Classifier-Guidance-Classifier-Free-Guidance" class="headerlink" title="Classifier Guidance / Classifier - Free Guidance"></a>Classifier Guidance / Classifier - Free Guidance</h1><h2 id="内容说明"><a href="#内容说明" class="headerlink" title="内容说明"></a>内容说明</h2><ol>
<li><strong>①</strong>：在分类器引导（CG）之前，FID不如 GAN（生成对抗网络）。  </li>
<li><strong>②</strong>：扩散模型（diffusion model）原本控制性不佳，条件生成可提升 FID。CG 本质是一种采样方法，可利用训练好的 DDPM（Denoising Diffusion Probabilistic Model）。  </li>
</ol>
<h3 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h3><ul>
<li>$\hat{q}(x_{t-1} | x_t, y) = \frac{ \hat{q}(x_{t-1} | x_t) \hat{q}(y | x_{t-1}, x_t) }{ \hat{q}(y | x_t) }$<br>注：$\hat{q}(y | x_t)$ 为常数，与 $x_{t-1}$ 无关。 </li>
<li>定义：<br>$\hat{q}(x_t | x_{t-1}, y) := q(x_t | x_{t-1})$，$\hat{q}(x_0) := q(x_0)$，无需重新训练，与 DDPM 相同。 </li>
<li>$\nabla \hat{q}(x_{t-1} | x_0, y) = \prod_{t’=1}^{t} \hat{q}(x_{t’} | x_{t’-1}, y)$（链式展开）。 </li>
</ul>
<h3 id="详细推导步骤"><a href="#详细推导步骤" class="headerlink" title="详细推导步骤"></a>详细推导步骤</h3><ol>
<li><strong>①</strong>：<br>$\hat{q}(x_{t-1} | x_t) = \frac{ \hat{q}(x_t | x_{t-1}) \hat{q}(x_{t-1}) }{ \hat{q}(x_t) }$（贝叶斯公式应用）。</li>
<li><strong>②</strong>： <ul>
<li>推导 $\hat{q}(x_t | x_{t-1})$：<br>$\hat{q}(x_t | x_{t-1}) = \int_y \hat{q}(x_t, y | x_{t-1}) dy$<br>$= \int_y \hat{q}(x_t | y, x_{t-1}) \hat{q}(y | x_{t-1}) dy$<br>$= \int_y q(x_t | x_{t-1}) \hat{q}(y | x_{t-1}) dy$（因 $\hat{q}(x_t | y, x_{t-1}) = q(x_t | x_{t-1})$）<br>$= q(x_t | x_{t-1}) \int_y \hat{q}(y | x_{t-1}) dy$<br>$= q(x_t | x_{t-1})$（因 $\int_y \hat{q}(y | x_{t-1}) dy = 1$）。</li>
<li>推导 $\hat{q}(x_t)$：<br>$\hat{q}(x_t) = \int_{x_{0:t-1}} \hat{q}(x_{0:t}) d x_{0:t-1}$<br>$= \int_{x_{0:t-1}} \hat{q}(x_0) \hat{q}(x_{1:t} | x_0) d x_{0:t-1}$。<br>进一步展开 $\hat{q}(x_{1:t} | x_0)$：<br>$\hat{q}(x_{1:t} | x_0) = \int_y \hat{q}(x_{1:t}, y | x_0) dy$<br>$= \int_y \hat{q}(x_{1:t} | y, x_0) \hat{q}(y | x_0) dy$<br>$= \int_y \hat{q}(y | x_0) \prod_{t’=1}^t \hat{q}(x_{t’} | x_{t’-1}, y) dy$<br>$= \int_y \hat{q}(y | x_0) \prod_{t’=1}^t q(x_{t’} | x_{t’-1}) dy$（因 $\hat{q}(x_{t’} | x_{t’-1}, y) = q(x_{t’} | x_{t’-1})$）<br>$= \int_y \hat{q}(y | x_0) q(x_{1:t} | x_0) dy$。</li>
</ul>
</li>
</ol>
<p>$\hat{q}(x_t)$ 的推导</p>
<script type="math/tex; mode=display">
\hat{q}(x_t) = \int_{x_{0:t-1}} q(x_0) q(x_{1:t} | x_0) dx_{0:t-1} = \int_{x_{0:t-1}} q(x_{0:t}) dx_{0:t-1} = q(x_t)</script><p><strong>说明</strong>：通过积分运算，证明了 $\hat{q}(x_t)$ 与 $q(x_t)$ 相等，体现了分布在积分变换下的不变性。</p>
<p>$q(y | x_t, x_{t-1})$ 的化简</p>
<script type="math/tex; mode=display">
q(y | x_t, x_{t-1}) = \frac{ \hat{q}(x_0 | y, x_{t-1}) \hat{q}(y | x_{t-1}) }{ \hat{q}(x_0 | x_{t-1}) } = \frac{ \hat{q}(x_0 | y, x_{t-1}) }{ \hat{q}(x_0 | x_{t-1}) } \hat{q}(y | x_{t-1})</script><p>进一步化简：</p>
<script type="math/tex; mode=display">
= q(x_t | x_{t-1}) \frac{ \hat{q}(y | x_{t-1}) }{ \hat{q}(x_0 | x_{t-1}) }</script><p><strong>说明</strong>：利用条件概率公式进行变形，结合已知分布关系化简，展示条件概率与其他分布的关联。</p>
<p>$\hat{q}(x_{t-1} | x_t, y)$ 的表达式</p>
<script type="math/tex; mode=display">
\hat{q}(x_{t-1} | x_t, y) = \frac{ q(x_{t-1} | x_t) \hat{q}(y | x_{t-1}) }{... }</script><p><strong>标注说明</strong>：红色标注强调与 <strong>DDPM 模型</strong> 的联系，表明该公式在 DDPM 框架下的应用特性。</p>
<h3 id="采样方式与近似推导"><a href="#采样方式与近似推导" class="headerlink" title="采样方式与近似推导"></a>采样方式与近似推导</h3><ul>
<li><strong>采样式</strong>：$x_t = \mu + \epsilon$，其中 $\epsilon$ 很小。</li>
<li><strong>对数概率展开</strong>：<script type="math/tex; mode=display">
\log P_\phi(y | x_t) \approx \text{泰勒展开近似}</script>进一步对 $\log P_\phi(x_{t-1} | x_t, y)$ 推导：<script type="math/tex; mode=display">
\log P_\phi(x_{t-1} | x_t, y) = -\frac{1}{2}(x_t - \mu)^T \Sigma^{-1}(x_t - \mu) + (x_t - \mu) \nabla + C</script>通过变形：<script type="math/tex; mode=display">
= -\frac{1}{2}(x_t - \mu - \Sigma \nabla)^T \Sigma^{-1}(x_t - \mu - \Sigma \nabla) + C'</script>近似为正态分布：<script type="math/tex; mode=display">
\sim N(\mu + \Sigma \nabla, \Sigma^2) \implies x_t = \mu + \Sigma \nabla + \Sigma \epsilon</script><strong>说明</strong>：描述了采样的形式，通过对数概率的展开和变形，推导得出近似正态分布的结果，展示了从概率表达式到采样公式的推导过程。</li>
</ul>
<p>通过上述推导，展现了分类器引导（CG）相关的采样方法与公式逻辑，基于 DDPM 框架且无需重新训练，体现了其在扩散模型中的应用特性。 </p>
<p><img    class="lazyload" data-original="5d117d10d332d1d5f747467b99e798f.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">5d117d10d332d1d5f747467b99e798f</span></p>
<p><img    class="lazyload" data-original="c63015d4464ad72db9343356fc0a66c.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">c63015d4464ad72db9343356fc0a66c</span></p>
<h1 id="SDE（随机微分方程）下的-Diffusion-Model"><a href="#SDE（随机微分方程）下的-Diffusion-Model" class="headerlink" title="SDE（随机微分方程）下的 Diffusion Model"></a>SDE（随机微分方程）下的 Diffusion Model</h1><h2 id="随机过程基础"><a href="#随机过程基础" class="headerlink" title="随机过程基础"></a>随机过程基础</h2><ul>
<li>布朗运动增量：$W(t+\Delta t) - W(t) \sim N(0, \Delta t)$，当 $\Delta t \to 0$ 时，可表示为微分形式 $dW = \sqrt{dt} \epsilon$，其中 $\epsilon \sim N(0,1)$，即 $dW \sim N(0, dt)$。</li>
<li>Itô 过程（扩散过程）：$dX = f(x,t)dt + g(t)dW$，描述了系统状态 $X$ 随时间 $t$ 的变化，包含确定性项 $f(x,t)dt$ 和随机性项 $g(t)dW$。</li>
</ul>
<h2 id="模型与-SDE-关联的优势"><a href="#模型与-SDE-关联的优势" class="headerlink" title="模型与 SDE 关联的优势"></a>模型与 SDE 关联的优势</h2><ol>
<li><strong>数学方法紧密结合</strong>：SDE 提供了丰富的数学工具，便于分析和求解。</li>
<li><strong>刻画分布转换</strong>：能更好地描述数据分布（data distribution）与先验分布（prior distribution）之间的相互转换，因为扩散（加噪）的逆向过程同样是扩散过程。</li>
</ol>
<h2 id="逆向过程公式"><a href="#逆向过程公式" class="headerlink" title="逆向过程公式"></a>逆向过程公式</h2><ul>
<li>一般形式：$dX = [f(x,t) - g^2(t) \nabla_x \log p_t(x)]dt + g_t d\tilde{W}$。</li>
<li>在 DDPM 中：<ul>
<li>正向扩散：$dX = -\frac{1}{2} \beta(t) X(t)dt + \sqrt{\beta(t)} dW$。</li>
<li>逆向过程：$dX = [-\frac{1}{2} \beta(t) X(t) - \beta(t) S_\theta(t)]dt + \sqrt{\beta(t)} dW$，其中 $S_\theta(t) = \nabla_{x_t} \log P(x_t | x_0) = -\frac{x_t - \mu_t}{\sigma^2}$（通过对 $P(x_t | x_0)$ 求梯度得到）。</li>
<li>由 $x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon$ 代入化简可得 $S_\theta(t) = -\frac{\epsilon}{\sqrt{1 - \alpha_t}}$。</li>
</ul>
</li>
</ul>
<h2 id="数值解法（欧拉方法）"><a href="#数值解法（欧拉方法）" class="headerlink" title="数值解法（欧拉方法）"></a>数值解法（欧拉方法）</h2><ul>
<li><strong>SDE 欧拉近似</strong>：$X(t+\Delta t) = X(t) + f(x,t)\Delta t + g(t)\Delta W$。</li>
<li><strong>ODE 欧拉法</strong>：$\frac{dx}{dt} = a(X(t))$，则 $X(t+\Delta t) = X(t) + a(X(t))\Delta t$。</li>
<li>逆向扩散采样（reverse diffusion sampler）的数值估计：<ul>
<li>$x_{i+1} = x_i + f(x,t) + g(t)\epsilon$（简化形式，$\Delta t$ 融入 $f$ 和 $g$）。</li>
<li>进一步推导 $x_i$ 的表达式：$x_i = x_{i+1} + \frac{1}{2} \beta_{i+1} x_{i+1} + \beta_{i+1} S_\theta + \sqrt{\beta_{i+1}} \epsilon$，通过近似（如泰勒公式 $(1+x)^\alpha \approx 1+\alpha x$）化简，最终得出 DDPM 是欧拉方法的特例，如 $(2 - \sqrt{1 - \beta(t)})x_{t’} + \beta’(t) S_\theta + \sqrt{\beta’(t)} \epsilon$。</li>
</ul>
</li>
</ul>
<p>以上内容系统阐述了 SDE 框架下扩散模型的数学基础、逆向过程及数值解法，体现了 SDE 在扩散模型分析中的重要作用。 </p>
<p><img    class="lazyload" data-original="b012c3a57ba9325b7e6acd7fd6703d0.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">b012c3a57ba9325b7e6acd7fd6703d0</span></p>

      </section>
      <section class="extra">
        
          <ul class="copyright">
  
    <li><strong>本文作者：</strong>EnableAsync</li>
    <li><strong>本文链接：</strong><a href="https://enableasync.github.io/uncategorized/DDPM/index.html" title="https:&#x2F;&#x2F;enableasync.github.io&#x2F;uncategorized&#x2F;DDPM&#x2F;index.html">https:&#x2F;&#x2F;enableasync.github.io&#x2F;uncategorized&#x2F;DDPM&#x2F;index.html</a></li>
    <li><strong>版权声明：</strong>本博客所有文章均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" title="BY-NC-SA" target="_blank" rel="noopener">BY-NC-SA</a> 许可协议，转载请注明出处！</li>
  
</ul>
        
        
        
  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-structure-algorithm/" rel="tag">data structure, algorithm</a></li></ul> 

        
  <nav class="nav">
    <a href="/uncategorized/mmRadar-Diffusion/"><i class="iconfont iconleft"></i>扩散模型在毫米波雷达中的使用综述</a>
    <a href="/ai/mcp/">MCP 协议学习<i class="iconfont iconright"></i></a>
  </nav>

      </section>
      
    </section>
  </div>
</article></div>
      <div class="col-xl-3">
        
          
  <aside class="toc-wrap">
    <h3 class="toc-title">文章目录：</h3>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DDPM"><span class="toc-text">DDPM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95"><span class="toc-text">基本方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9"><span class="toc-text">参数选择</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DDIM"><span class="toc-text">DDIM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%BB%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%8C%96"><span class="toc-text">去马尔可夫化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9-1"><span class="toc-text">参数选择</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DDIM-%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-text">DDIM 实验设置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Classifier-Guidance-Classifier-Free-Guidance"><span class="toc-text">Classifier Guidance &#x2F; Classifier - Free Guidance</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AE%B9%E8%AF%B4%E6%98%8E"><span class="toc-text">内容说明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC"><span class="toc-text">公式推导</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A6%E7%BB%86%E6%8E%A8%E5%AF%BC%E6%AD%A5%E9%AA%A4"><span class="toc-text">详细推导步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%87%E6%A0%B7%E6%96%B9%E5%BC%8F%E4%B8%8E%E8%BF%91%E4%BC%BC%E6%8E%A8%E5%AF%BC"><span class="toc-text">采样方式与近似推导</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SDE%EF%BC%88%E9%9A%8F%E6%9C%BA%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%EF%BC%89%E4%B8%8B%E7%9A%84-Diffusion-Model"><span class="toc-text">SDE（随机微分方程）下的 Diffusion Model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E5%9F%BA%E7%A1%80"><span class="toc-text">随机过程基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%8E-SDE-%E5%85%B3%E8%81%94%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-text">模型与 SDE 关联的优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%86%E5%90%91%E8%BF%87%E7%A8%8B%E5%85%AC%E5%BC%8F"><span class="toc-text">逆向过程公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E8%A7%A3%E6%B3%95%EF%BC%88%E6%AC%A7%E6%8B%89%E6%96%B9%E6%B3%95%EF%BC%89"><span class="toc-text">数值解法（欧拉方法）</span></a></li></ol></li></ol>
  </aside>

        
      </div>
    </div>
  </div>
</main>
  

<footer class="footer">
  <div class="footer-social"><a 
        href="https://github.com/EnableAsync "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#9f7be1'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  icongithub-fill "></i>
      </a></div>
  
    <div class="footer-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
  
</footer>
  
      <div class="fab fab-plus">
    <i class="iconfont iconplus"></i>
  </div>
  
  
  <div class="fab fab-up">
    <i class="iconfont iconcaret-up"></i>
  </div>
  
  
  
    
<script src="/js/color-mode.js"></script>

  
  
    <div class="search">
  <div class="search-container">
    <div class="search-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <div class="search-input-wrapper">
      <i class="search-input-icon iconfont iconsearch"></i>
      <input class="search-input" type="search" id="search-input" placeholder="Search..." autofocus autocomplete="off"
        autocorrect="off" autocapitalize="off">
    </div>
    <div class="search-output" id="search-output"></div>
  </div>
</div>
  
</body>

<script src="/lib/jquery/jquery.js"></script>



  
<script src="/lib/lazyload/lazyload.js"></script>




  
<script src="/lib/fancybox/fancybox.js"></script>






  
<script src="/lib/qrcode/qrcode.js"></script>




<script src="/js/utils.js"></script>
<script src="/js/script.js"></script>



















</html>