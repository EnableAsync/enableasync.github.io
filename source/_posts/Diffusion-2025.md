---
title: 2025 年的 Diffusion 在研究什么
date: 2025-04-09 12:10:00
tags: diffusion
---


好的，我将调研2024-2025年间关于扩散模型（Diffusion Models）的最新学术研究方向，重点关注具有公开GitHub代码的研究成果。
请稍等，我现在就开始调研。你可以**刷新页面**来查看进展。

# 2024–2025年扩散模型最新研究综述

近年来，**扩散模型**（Diffusion Models）在生成建模领域取得了令人瞩目的成绩，特别是在图像合成等任务上达到了新的水准。2024年至2025年间，围绕扩散模型的学术研究进一步深入，集中在**新方法、新架构和理论进展**等方面。本文将对这一时期的代表性研究方向进行综述，涵盖模型效率提升、条件控制改进、生成质量优化、理论分析突破以及大模型架构升级等内容。我们将介绍每项研究的技术细节和贡献点，并指出其是否开源提供了代码。最后，附上一张汇总表格列出相关研究的名称、作者、来源、发布日期、内容简述和代码链接。

## 模型效率与采样加速

**扩散模型的高计算量**长期以来限制了其实用性，因此不少研究致力于**提升采样效率、减少采样步数**。2024年起，这一方向涌现出多种新方案：

- **潜在一致性模型的高效训练**：Dao等人提出改进的潜在一致性模型训练方法。一致性模型（Consistency Model）是一类可单步生成样本的模型，但直接在大规模**潜在空间**（latent space）训练时表现不佳。该研究通过**Cauchy损失**替换Pseudo-Huber损失以抑制潜在空间中的**离群值**，并在早期扩散步加入额外的扩散损失，利用**最优传输耦合**降低噪声，引入**自适应缩放调度**和**非缩放LayerNorm**等技术，显著提升了一致性模型在潜在空间的训练稳定性。他们成功训练出**一步或两步即可采样高质量图像**的潜在一致性模型，使其生成质量接近常规多步扩散模型。实现代码已开源（项目**sLCT**）。这一工作缩小了一致性模型与扩散模型在潜在空间性能差距，对于**加速文本到图像等大型扩散模型采样**具有重要意义。

- **上采样扩散概率模型（UDPM）**：Abu-Hussein等人提出“Upsampling Diffusion Probabilistic Model”。不同于标准扩散模型在每一步仅降噪，该方法在**正向过程**中同时对数据进行**降采样和加噪**，即逐步降低分辨率并添加噪声；在**逆过程**则逐步**去噪并上采样**恢复清晰图像。这种设计大幅减少了所需的网络评估次数。在实验中，UDPM**仅用3次网络评估**即可生成图像，计算成本总计甚至**低于传统DDPM一次迭代**。它在CIFAR-10等数据集上取得了**FID=6.86**的优异成绩，超越了现有单步生成的高效扩散模型。此外，UDPM提供了**可解释且可插值的潜在空间**，弥补了扩散模型潜在空间难以解释的缺点。作者已在GitHub开源了代码，实现了在FFHQ等数据集上的高保真图像合成。

- **高阶采样算法与加速理论**：针对扩散模型**采样步骤多、速度慢**的问题，Li等人提出了**无需重新训练**即可加速采样的高阶算法。他们设计了改进的确定性采样器和随机采样器：新的确定性采样器（对应DDIM）收敛速率提升为$O(1/T^2)$，优于原DDIM的$O(1/T)$；改进的随机采样器（对应DDPM）收敛速率达$O(1/T)$，优于原DDPM的$O(1/\sqrt{T})$。这种方法借鉴了**高阶ODE求解器**（如DPM-Solver）的思想，并从理论上证明了采样效率的大幅提升。值得注意的是，该算法**不需要额外训练**，对扩散模型的打分估计误差具有鲁棒性。这一研究为**扩散模型快速采样**提供了坚实的理论支持。

上述方法显著改善了扩散模型的采样效率，使高质量图像的生成可在极少步内完成。这对于扩散模型在实时应用中的部署具有深远意义。

## 条件控制与多模态指导

为了**增强扩散模型生成的可控性**，研究者提出了多种**条件控制和引导机制**，使模型能灵活地接受不同模态的条件或关注数据分布的稀有部分。

- **通用指导（Universal Guidance）**：Bansal等人在ICLR 2024提出了一种**通用条件引导算法**。传统扩散模型通常针对特定条件（如文本）训练，无法直接应用新条件。该算法允许在**不重新训练扩散模型**的情况下，用任意模态的引导函数来控制生成过程。具体而言，在采样时通过与扩散过程并行的优化迭代，将外部条件（如分割图、人脸识别结果、目标检测框、图像风格或分类器输出等）转化为对噪声预测的附加引导，从而**使预训练扩散模型接受新的条件约束**。实验表明，该方法可成功利用多种指导信号生成相应图像。由于不需重新训练，通用指导具有很强的**泛用性**。作者提供了官方实现，验证了在不同条件下高质量图像生成的效果。

- **少数样本指导（Minority Guidance）**：Um等人在ICLR 2024提出了一个关注**低密度区域样本**的生成框架。扩散模型倾向于生成数据流形上高密度区域（多数类）的样本，对于**低概率的少数类样本**往往难以覆盖。该工作首先定义了一个衡量样本“独特性”的指标，以识别**数据分布中的少数样本**。然后提出了“少数指导”的采样技术，在扩散采样过程中引入一个**引导项偏向低密度区域**，鼓励模型探索具有目标罕见度的样本。通过这种引导，扩散模型生成**高质量少数样本**的能力大大提高。在医学影像等真实场景中，该方法依然显著提升了模型生成稀有案例的覆盖率和质量。作者已将代码开源，有助于后续研究者在**公平性和多样性**方向拓展扩散模型应用。

- **跨模态上下文扩散模型（ContextDiff）**：Yang等人在ICLR 2024提出**ContextDiff**框架，旨在**增强文本指导下图像/视频生成的语义对齐**。以往**文本-图像扩散模型**大多只在逆过程融入文本条件，对正向扩散过程的文本相关性考虑不足。这种不一致可能限制文本语义向生成结果的精确传达。为此，ContextDiff在**正向和逆向过程**中都注入跨模态的**文本-视觉上下文信息**，使文本条件在扩散的每个时间步都对噪声演化产生影响。通过对DDPM和DDIM过程的扩展，ContextDiff确保了**扩散轨迹与文本条件的一致性**。在文本到图像生成和文本引导视频编辑任务中，该方法取得了新的**状态-of-艺术**表现，大幅提升了生成图像与文本条件的语义一致性。作者提供了代码和模型，证明了在复杂跨模态任务中的有效性。

通过上述改进，扩散模型在**条件可控生成**方面变得更加灵活强大。不仅能适应多种模态的条件约束，还能关注数据中的少数模式和增强跨模态语义对应，从而拓宽了扩散模型在**可控生成和多样性**领域的应用前景。

## 图像质量提升与训练优化

除了速度和控制，**提升生成内容的质量**也是研究热点。2024年出现的若干工作聚焦于**改进训练目标**或**生成过程细节**，以获取更高保真的合成图像：

- **级联扩散模型结合感知损失**：Jie An等人提出**级联扩散模型（Cas-DM）**，探索将**度量函数（感知损失）引入扩散模型训练**。以LPIPS感知损失为代表的度量在一致性模型中证明有效，但在扩散模型中直接加入会因**训练目标不匹配**而失败。Cas-DM通过**两阶段网络级联**解决了这一问题：第一阶段网络与标准DDPM类似，预测噪声$\epsilon$；第二阶段网络以初步重构的图像$x_0$为输入，输出精细的$x_0$预测，并预测一个动态加权系数用于融合两阶段输出。训练时，对第二阶段预测的$x_0$施加LPIPS损失并**停止梯度回传给第一阶段**，从而既优化图像感知质量又不干扰噪声预测分支。实验证明，Cas-DM成功将LPIPS等感知指标用于扩散模型训练，**在多个基准数据集上取得了最先进的图像质量**（FID、sFID和IS指标显著提升），生成图像的细节和逼真度明显改善。这一方法表明，通过合适的架构设计，**感知级别的度量函数**可以有效提升扩散模型的生成效果。目前论文未公开完整代码，但相关方法为扩散模型融入**感知损失**提供了范式。

- **频域特征引导的生成优化（DMFFT）**：2025年有研究将**传统傅里叶频域分析**引入扩散模型的生成过程。Wang等人在Scientific Reports发表文章，提出无需额外训练即可提升生成质量的**DMFFT方法**。他们分析了扩散模型U-Net中**上采样阶段**的特征，发现通过调整特征的**频率分量（高频/低频）幅度和相位**可以影响输出图像的质量。具体地，DMFFT在扩散模型上采样的**交叉注意块（CrossAttnUpBlock）**入口处嵌入一个傅里叶变换模块，根据经验调整不同频段的缩放系数，对特征进行频域调制。大量实验表明，该方法能够**显著改善扩散模型生成图像/视频的语义对齐、结构布局、色彩纹理以及时序一致性**，同时提升艺术表现力和多样性，而**无需对扩散模型进行任何额外训练或参数改动**。这意味着只需在推理阶段对特征做频域处理，即可增强输出质量。DMFFT开辟了一个从信号处理角度优化扩散生成的新思路。

这些工作从训练目标和生成过程两个角度出发，提高了扩散模型生成结果的主观和客观质量。例如，Cas-DM通过引入感知损失使生成图像更加清晰自然，DMFFT则通过频域调控增强了图像的细节和一致性。这些改进对**实际应用中获得高保真、无失真的生成结果**非常关键。

## 理论进展与分析

随着扩散模型的应用日趋广泛，**理论研究**也在努力解释和提高这些模型的性能。2024年至2025年出现了一系列工作，从**收敛性理论**到**解析扩散过程**等方面取得进展，加深了对扩散模型原理的理解：

- **扩散模型收敛率的提升分析**：Li和Jiao等人在2024年针对扩散概率模型（DPM）的收敛性给出了更优的理论保证。此前的研究（如2023年Gupta等）已将扩散采样视作随机过程，并分析了迭代复杂度。Li等人通过引入**随机中点方法**，证明在无对数凹假设下，若采样误差容许$\epsilon$，则扩散模型要达到精度$\epsilon$所需的迭代次数可缩减为$O(d^{1/3}\epsilon^{-2/3})$（其中$d$为数据维度）。这一结果优于先前最佳的$O(d^{5/12}\epsilon^{-1})$复杂度，将依赖维度的阶降低了，并缩小了理论与实践间的差距。该工作无需假设目标分布对数凹，且允许近似的得分估计，更贴近真实扩散模型的条件。此理论进展为理解扩散模型的效率提供了新视角，并证明了**更快采样收敛率**在理论上是可实现的。

- **确定性采样器的统一收敛分析**：传统的扩散模型理论多依赖随机过程工具（如Girsanov定理）分析随机采样器，对**确定性采样**（如DDIM）缺乏统一理论。Runjia Li等人在2024年提出了一个**统一分析框架**，专门研究**确定性扩散采样器**的收敛性质。他们构建了一般性的分析方法，可适用于各种前向过程和确定性逆过程，弥补了以往只针对特定采样器分析的不足。利用该框架，作者举例分析了**方差保持型前向扩散（VP-SDE）**结合**指数积分采样方案**的情形，证明了$\tilde{O}(d^2/\epsilon)$的迭代复杂度；同时对常用的**DDIM采样器**给出了多项式复杂度的严格证明。这一统一理论为不同类型的扩散采样器提供了**可比的收敛保证**，有助于系统理解各种改进采样算法的性能边界。

上述理论工作为扩散模型提供了更坚实的数学基础。不论是提高收敛速率的算法设计，还是统一解析不同采样过程的框架，都为未来**设计更快更稳健的扩散模型**指明了方向。此外，还有研究将扩散模型视作**策略优化或控制问题**加以分析（如将生成目标融入强化学习奖励框架等），这些也拓宽了扩散模型理论研究的思路。

## 大模型与架构创新

在实践层面，2024年前后也出现了**更大规模、更强性能**的扩散模型。**Stable Diffusion XL（SDXL）**是这一时期的代表模型之一：

- **Stable Diffusion XL (SDXL)**：由Stability AI的Podell等人在2023年提出的SDXL模型是**潜在扩散模型（Latent Diffusion）**在高分辨率图像合成上的一次重大升级。与之前的Stable Diffusion版本相比，SDXL的U-Net主干参数量增加了3倍，主要得益于引入**更多的注意力模块**以及**更大的跨模态注意力上下文**。具体来说，SDXL使用了**双文本编码器**（在原有CLIP文本编码器基础上增加第二个文本编码器）来提供更丰富的文本条件语义；设计了多种新的**条件融合机制**，并采用**多长宽比训练**使模型能胜任不同尺寸的图像生成。此外，SDXL还训练了一个**后置精炼模型（refiner）**：先由基础模型生成1024×1024图像，再由精炼模型通过**图像到图像扩散**细化，提高最终输出的视觉保真度。实验结果显示，SDXL相较之前版本的稳定扩散在图像质量上有**显著提升**，在开放评测中达到可与某些封闭源SOTA生成模型媲美的水平。Stability AI已开放了SDXL的代码和模型权重，促进研究者在其基础上进行进一步开发。例如，基于SDXL的模型调优、知识蒸馏等后续研究也陆续出现，使大模型的性能得以在更广泛应用中发挥。

SDXL的成功表明，通过**扩大模型规模、改进架构和训练策略**，扩散模型在保持多样性的同时能够生成更高分辨率、更精细的图像。这也为今后**更大、更多模态**的扩散模型（如视频扩散、3D扩散）的研发提供了经验借鉴。

## 研究汇总表

如下表格汇总了2024–2025年扩散模型领域的重要研究成果，包括研究名称、主要作者、来源（会议/期刊或预印本）、发布日期、主要贡献简述以及代码链接：

| **研究名称** | **作者** | **来源** | **发布日期** | **研究内容简述** | **代码链接** |
| --- | --- | --- | --- | --- | --- |
| Stable Diffusion XL (SDXL) | Dustin Podell 等（Stability AI） | arXiv预印本（据ICLR 2024） | 2023年7月4日 (v1) | 提出大规模**潜在扩散模型**用于高分辨率文本图像生成。U-Net参数扩大3倍，引入**双文本编码器**和新条件机制，支持多尺度、多长宽比训练；另加精炼扩散模型提升细节。生成质量较以往Stable Diffusion大幅提高，开放提供模型权重。 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) (含SDXL代码和模型) |
| 改进的一致性模型潜在空间训练 (sLCT) | Quan Dao, Khanh Doan 等 | arXiv预印本 | 2025年2月3日 | 提出潜在空间下一致性模型的训练改进：使用**Cauchy损失**处理离群值，增加小步扩散损失和**最优传输**变分技术，配合**自适应缩放调度**和非缩放归一化。使一致性模型在VAE潜在空间中可**一到两步生成高质量图像**，性能接近原扩散模型。 | [quandao10/sLCT](https://github.com/quandao10/sLCT/) |
| Upsampling Diffusion Probabilistic Model (UDPM) | Shady Abu-Hussein, Raja Giryes | NeurIPS 2024 (Poster) | 2024年12月 | 提出**降采样+加噪/上采样+去噪**的扩散新流程。在正向过程将数据降维，加快逆过程。**仅需3次网络推理**即可生成图像，FID达6.86，优于以往单步生成方法。提供了可解释潜在空间和更高生成效率。 | [shadyabh/UDPM](https://github.com/shadyabh/UDPM/) |
| Universal Guidance for Diffusion Models | Arpit Bansal 等 | ICLR 2024 (Poster) | 2024年1月16日 | 提出**通用指导算法**，可在**无额外训练**情况下，用任意模态的引导信号控制扩散生成。支持分割、检测、风格等多种条件，同一扩散模型即可多条件通用。方法通过采样阶段优化实现，生成结果质量优秀。 | [arpitbansal297/Universal-Guided-Diffusion](https://github.com/arpitbansal297/Universal-Guided-Diffusion) |
| “不偏不倚”：少数样本指导 | Soobin Um 等 | ICLR 2024 (Poster) | 2024年1月16日 | 提出**少数样本生成框架**，通过定义样本独特性度量和**少数指导**采样技术，引导扩散模型关注数据分布中**低概率区域**。显著提升模型生成**罕见样本**的能力和多样性。在医疗图像等场景下亦有效。 | [soobin-um/minority-guidance](https://github.com/soobin-um/minority-guidance) |
| ContextDiff 跨模态上下文扩散 | Ling Yang 等 | ICLR 2024 (Poster) | 2024年1月16日 | 提出在**正向+逆向扩散过程中融合文本-图像上下文**的模型。通过在所有时间步传播文本条件信息，增强生成结果与文本语义的一致性。用于文本图像生成和文本指导视频编辑均达**SOTA性能**，语义对齐显著改善。 | [YangLing0818/ContextDiff](https://github.com/YangLing0818/ContextDiff) |
| Cascaded Diffusion Model (Cas-DM) | Jie An 等（微软） | IJCAI 2024 (Oral) | 2024年1月4日 | 提出**级联两阶段扩散网络**，第一阶段预测噪声，第二阶段预测图像，从而可对第二阶段应用LPIPS等**感知损失**。巧妙避免损失干扰噪声预测，实现感知优化。实现在CIFAR-10、ImageNet等上**FID、IS刷新SOTA**，生成图像伪影更少、细节更佳。 | （论文方法证明有效，代码暂未公布） |
| DMFFT 频域特征调制方法 | Tianrong Wang 等 | Scientific Reports | 2025年3月25日 | 提出利用**快速傅里叶变换**调整扩散模型特征频率分量以提升生成质量的方法。在不上线性结构中，对**高低频、幅值和相位**进行缩放，**无需模型训练**即可改善输出的语义一致性、结构和纹理。适用于文本图像和文本视频生成，增强艺术性和多样性。 | （方法基于开源Stable Diffusion实现，附于论文） |
| 加速Score-Based扩散收敛 (Provably Accelerating) | Gen Li 等 | arXiv预印本 | 2024年3月6日 | 从理论上**加速扩散采样**：设计了**高阶确定性/随机采样器**，将DDIM采样收敛阶从$O(1/T)$提升至$O(1/T^2)$，DDPM采样从$O(1/\sqrt{T})$提升至$O(1/T)$。算法无需额外训练，证明了扩散模型采样的可达更高效率。 | （算法伪代码在论文中给出，无单独代码） |
| 扩散模型收敛率改进分析 | Gen Li, Yuchen Jiao | arXiv预印本 | 2024年10月18日 | 提出改进的扩散模型收敛复杂度：证明迭代复杂度为$O(d^{1/3}\epsilon^{-2/3})$，优于此前最佳的$O(d^{5/12}\epsilon^{-1})$（$d$为数据维度)。基于随机中点方法的理论分析进一步缩小了理论与实践差距。 | （理论研究，无代码） |
| 确定性扩散采样统一分析 | Runjia Li 等 | arXiv预印本 | 2024年10月18日 | 针对**DDIM等确定性采样**缺乏统一理论的问题，提出通用分析框架。对VP扩散+指数积分方案给出$\tilde{O}(d^2/\epsilon)$复杂度，对DDIM采样证明多项式收敛。为各种扩散采样策略提供了统一的收敛性保证。 | （理论研究，无代码） |

上述汇总表中的研究成果体现了2024–2025年扩散模型领域的主要进展。从工程上的模型改进到理论层面的深入分析，这些工作共同推动了扩散模型在**效率、可控性、质量和理解**等方面的提升。展望未来，随着社区持续探索，我们有望见到扩散模型在更多元的任务和更大尺度数据上取得突破，并逐步解决当前存在的速度瓶颈和控制局限，使其在生成AI领域发挥更大的作用。

